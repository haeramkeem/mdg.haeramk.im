---
tags:
  - os
  - os-memory
  - paper-review
date: 2025-01-25
title: "(논문) Tiered Memory Management: Access Latency is the Key!, SOSP 2024 (4. Colloid with existing memory tiering systems)"
---
> [!info] 본 글은 논문 [Tiered Memory Management: Access Latency is the Key! (SOSP 2024)](https://dl.acm.org/doi/10.1145/3694715.3695968) 를 읽고 정리한 글입니다.

> [!info] 별도의 명시가 없는 한, 본 글의 모든 그림은 위 논문에서 가져왔습니다.

> [!info]- 목차
> - [[1. Introduction (Colloid, SOSP 24)|1. Introduction]]
> - [[2. Motivation (Colloid, SOSP 24)|2. Motivation]]
> - [[3. Colloid (Colloid, SOSP 24)|3. Colloid]]
> - [[4. Colloid with Existing Memory Tiering Systems (Colloid, SOSP 24)|4. Colloid with Existing Memory Tiering Systems (현재 글)]]
> - [[5. Evaluation (Colloid, SOSP 24)|5. Evaluation]]
> - [[6-7. Related Work and Conclusion (Colloid, SOSP 24)|6-7. Related Work and Conclusion]]

## 4.0. Overview

> [!tip] NXSECTION
> - `4.0` 은 overview 로, 논문에는 이런 section 은 없다.

- [[3. Colloid (Colloid, SOSP 24)|Section 3]] 의 내용을 정리해 보자면, *Colloid* 는:
	- *Latency measurement*: Latency 측정
	- *Page placement algorithm*: 측정한 latency 에 따라 default 및 alternate tier 에 몇개의 hot page 를 배치할지 결정
- 의 역할을 한다고 할 수 있다. 그러면 tiered memory 를 위해서는 다음의 두개가 더 필요하다는 것을 생각할 수 있다:
	- *Access tracking*: 어떤 page 가 hot 인가?
	- *Page migration strategy*: 어떻게 page 를 옮길것인가?
- 위의 두개의 역할은 *Colloid* 에서는 담당하지 않고, 기존의 tiered memory system 들에서 담당한다.
- 즉, [[4. Colloid with Existing Memory Tiering Systems (Colloid, SOSP 24)|Section 4]] 에서는 기존의 SOTA tiered memory system 인 [[(논문) HeMem - Scalable Tiered Memory Management for Big Data Applications and Real NVM|HeMem]], [[(논문) MEMTIS - Efficient Memory Tiering with Dynamic Page Classification and Page Size Determination|MEMTIS]], [[(논문) TPP - Transparent Page Placement for CXL-Enabled Tiered-Memory|TPP]] 들에 *Colloid* 를 통합시키는 implementation detail 에 대해 설명한다.
- 구체적으로는, 위의 세 system 에 다음의 것들을 추가적으로 구현하는 과정에 대해 설명한다:
	- 각 system 에 대한 latency measurement 구현
	- 각 system 에 대한 page placement algorithm 구현
	- 어떤 page 를 migration 할 것인가
		- 즉, 각 page 들의 access probability ($p$) 를 구하여 어떤 page 를 migration 할 것인지 결정
- 그리고 다음의 것들은 기존의 것들을 그대로 사용한다.
	- 각 system 들의 access tracking 방식
		- 이 부분에서 *Colloid* 의 access probability 와 좀 헷갈릴 수 있는데,
		- Page 의 access tracking 하는 것은 기존의 방식을 사용하고, *Colloid* 에서는 이 access tracking 을 통해 알아낸 정보들로 access probability 를 계산하여 latency balancing 을 하는 것이다.
	- 각 system 들의 page migration strategy 방식 (어떻게 옮길것인가? 언제 옮길것이냐? 등)

## 4.1. HeMem with Colloid

- HeMem 의 작동 과정을 간단히 살펴보면
	1. Busy-polling thread 를 이용해 일정 기간마다 [[Processor Event Based Sampling, PEBS (Intel Arch)|Processor Event Based Sampling, PEBS]] 를 측정하여 page 별 access frequency 를 측정한다.
	2. 각 tier 에 있는 page 들에 대한 hot list 와 cool list 를 유지하고, PEBS 로 측정한 frequency 가 일정 threshold 를 넘으면 hot list 에 추가되는 방식이다.
	3. 그리고 이 측정한 frequency 에 대한 또 다른 threshold (`COOLING_THRESHOLD`) 가 있는데, 어떤 page 가 이 threshold 에 도달하게 되면 모든 page 의 frequency 가 절반이 되는 식으로 cooling 이 이루어진다.
	4. Page migration 은 10ms 의 fixed quantum 마다 asynchronous 하게 진행된다.
- 여기서 *Colloid* 를 위한 추가 구현 사항은 다음과 같다.
	- Latency 를 측정하는 것은 (4) 번에서의 page migration thread 에서 담당한다.
		- 즉, (4) 번 thread 에서 10ms 마다 page migration 을 할 때 [[Caching Home Agent, CHA (Intel Arch)|CHA]] 를 읽어들여 queue occupancy 와 request rate 를 측정하는 것.
	- *Colloid* 의 page placement algorithm 또한 (4) 번 thread 에 구현된다.
		- 즉, [[3. Colloid (Colloid, SOSP 24)|Section 3]] 에서 말한 대로 $\Delta p$ 를 계산하고,
		- (1) 번에서 PEBS 로 측정한 per-page frequency 를 이용해 per-page access probability 를 계산한다.
			- 구체적으로는 HeMem 에서 PEBS 로 per-page frequency 를 측정하였으니,
			- Per-page frequency 를 모든 frequency 의 총합으로 나누어 per-page access probability 를 계산하는 것이다.
		- 그리고 이렇게 구한 per-page access probability 를 이용해 $\Delta p$ 를 맞추기 위한 page 들을 선정한다.
			- 이때 더 효율적으로 page selection 을 하기 위해 HeMem 와 좀 다른 list 들을 관리한다.
			- HeMem 에서는 0 ~ `COOLING_THRESHOLD` 까지의 frequency 범위를 두개로 나눠 높은 쪽에 들어가는 page 들은 hot list 로 관리하고 낮은 쪽에 들어가는 page 들은 cool list 로 관리했다면,
			- *Colloid* 에서는 이 frequency 범위를 5등분한 *bin* 이라는 범위 단위를 이용해 5개의 list 로 관리한다.
			- 그래서 높은 범위에 대한 bin 부터 뒤지며 page 들의 $p$ 합이 $\Delta p$ 보다 작거나 갖게 되도록 하는 식으로 page 들을 고르게 된다.
			- 즉, 이것은 page migration overhead 를 최소화 하기 위해 자연스레 $p$ 를 정렬하는 효과를 가진다: $p$ 가 높은애들부터 확인하여 $p$ 의 총합이 $\Delta p$ 보다는 작거나 같으면서도 최소한의 page 들을 migration 하게 된다.