---
tags:
  - database
  - db-encoding
date: 2024-09-04
title: (논문) The FastLanes Compression Layout - Decoding 100 Billion Integers per Second with Scalar Code (2. FastLanes)
---
> [!info] 본 글은 논문 [The FastLanes Compression Layout: Decoding > 100 Billion Integers per Second with Scalar Code (VLDB '23)](https://dl.acm.org/doi/10.14778/3598581.3598587) 를 읽고 정리한 글입니다.

> [!info] 별도의 명시가 없는 한, 본 글의 모든 그림은 위 논문에서 가져왔습니다.

> [!info]- 목차
> - [[1. Introduction (FastLanes, VLDB 23)|1. Introduction]]
> - [[2. FastLanes (FastLanes, VLDB 23)|2. FastLanes (현재 글)]]
> - [[3. Evaluation (FastLanes, VLDB 23)|3. Evaluation]]
> - [[4. Related Work (FastLanes, VLDB 23)|4. Related Work]]
> - [[5. Conclusion and Future Work (FastLanes, VLDB 23)|5. Conclusion and Future Work]]

## 2. FastLanes

### 2.1. Many SIMD widths

- [[Single Instruction Multiple Data, SIMD (Arch)|SIMD]] 는 처음에는 64bit register 로 시작했지만 지금은 8배나 늘어 512bit 을 지원한다.
	- 가령 x86 의 AVX512 등.
- 기존의 [[Single Instruction Multiple Data, SIMD (Arch)|SIMD]] instruction 들은 특정 사이즈의 register 에만 집중해 왔다.
- 가령 SIMD-BP128 과 같은 4-way interleaving 방식은 128bit register 에 [[Bit Packing, BP (Encoding)|BP]] 된 값 4개를 할당해 처리한다 (int 는 32bit 이므로 $32 \times 4$)
	- 이 방법을 이용해 bit 가 연속적으로 packed 되어 있으면 필요했을법한 cross-lane instructions 들 (`PERMUTE`, `BITSHUFFLE`) 을 우회해 왔다 [^permute-bitshuffle].
- 하지만 이것은 128bit register 에만 효과가 있고, 다른 사이즈의 register 에 대해서는 충분한 parallelism 이 되지 않는다고 한다.
	- 물론 그에 따라 8-way, 16-way 등의 방법도 소개되었지만 각자의 width 에 제한된다는 점은 동일하다.
- 따라서 FastLanes 에서는 미래의 언젠가는 출시될 1024bit register 를 가정하여 설계했다고 한다.
	- 이것이 `FLMM1024` register 인것
- 이것은 다음과 같은 사실에서 기인한다:
	- 더 넓은 lane width 를 기반으로 디자인된 data layout 은 lane-cross instruction 을 사용하지 않는 한 더 좁은 lane width 에 적용시키는 것은 껌이라고 한다.
		- 그냥 넓은 lane width 에서 사용한 instruction 과 동일한 기능을 하는 좁은 lane width 버전의 instruction 을 사용하면 되기 때문.
	- 하지만 반대의 경우는 참이 아니다; 더 좁은 lane width 기반의 data layout 은 놀고 있는 lane 이 생기는 등의 병렬화 감소 혹은 `PERMUTE` (`BITSHUFFLE`) instruction 의 필요성 등의 부작용이 생기게 된다 [^expensive-compensate].
	- 그렇기 때문에 FastLanes 에서는 더 큰 크기의 register 를 기준으로 설계했고, 이것을 실제 register 사이즈에 맞게 scale-down 하는 것은 아무런 문제가 없을 것이라는 주장임

![[Pasted image 20240903162420.png]]

- 위 그림이 interleaved [[Bit Packing, BP (Encoding)|BP]] 를 나타낸 그림이다.
	- 일단 각 value 들은 3bit 로 [[Bit Packing, BP (Encoding)|BP]] 되어있는 상태다. (파란색, 분홍색, 노란색이 각각 1bit 임)
	- 그리고 하나의 `FLMM1024` word ([[Single Instruction Multiple Data, SIMD (Arch)|SIMD]] 로 처리되는 단위) 는 1024bit 이고,
	- 이것으로 1024 개의 value 를 표현하기 위해서는 당연히 3개의 word 가 필요하다.
		- 1value = 3bit, 1024value = 3072bit = 3word
		- 위 그림에서는 빨간색 테두리 상자 하나가 1개의 word 이다. 따라서 세개의 word 가 그려져 있는 것을 볼 수 있음
	- Lane width 는 8bit 고, 따라서 총 128개의 lane 으로 하나의 word 가 구성된다.
	- 여기서 검은 상자 안의 숫자는 해당 value 에 대한 sequence number (logical position of the column) 이다.
		- 즉, 0이면 column 내에서 가장 첫번째 값이라는 것.
	- 이때 각 값들은 lane 들에 round-robin 식으로 분배된다.
		- seq no 를 0부터 쭉 따라가보면 알 수 있을 것이다; `value[0]` 은 `lane[0]` 에 배치되고, `value[1]` 은 `lane[1]` 에 배치되는 등
	- 근데 lane width 는 8bit 고 [[Bit Packing, BP (Encoding)|BP]] 는 3bit 이기 때문에 딱 들어맞지 않고 bit 가 좀 잘리게 된다.
		- `value[256]` 을 보자.
		- 이놈은 첫번째 word 의 `lane[0]` 에 비트 3개가 다 들어가지 못하고 하나 (파란색) 가 잘려서 두번째 word (그 다음줄) 로 떨어져 나간 것을 볼 수 있다.
		- `value[640]` 도 유사한 상황임; 이놈은 `word[1]`, `lane[0]` 에 비트 1개만 들어갈 수 있어 하나 (노란색) 만 여기에 들어가고 나머지 (파란색, 분홍색) 은 `word[2]`, `lane[0]` 로 튕긴 것을 볼 수 있다.

### 2.2. Heterogeneous ISAs

- 새로운 [[Single Instruction Multiple Data, SIMD (Arch)|SIMD]] 가 도입되면, instruction 의 관점에서 다음의 두가지 비대칭이 생긴다고 한다:
	- 일단 새로 도입된 instruction 이 기존에는 없는 기능이거나
	- 기존에 있던 instruction 이 새로운 [[Single Instruction Multiple Data, SIMD (Arch)|SIMD]] 에서는 지원하지 않는 경우
- 이 두 가지 중 어느것이든 여기에 의존하고 있는 data layout 은 문제가 생기게 된다.
- 또한 ISA 호환성 문제는 점점 더 심각해지고 있다.
	- 가령 ARM 아키텍쳐를 차용한 server 인 AWS Graviton 과 PC 인 Apple Silicon 은 ARM 의 NEON 혹은 SVE instruction set 의 서로 다른 subset 을 도입하게 된다.
- 따라서 FastLanes 에서는 이런 호환성 문제를 없애기 위해, ISA 종류와 [[Single Instruction Multiple Data, SIMD (Arch)|SIMD]] 크기 모두에 무관한 virtual instruction set 을 새로 정의하여 사용한다.
	- 즉, 모든 ISA, 그리고 모든 [[Single Instruction Multiple Data, SIMD (Arch)|SIMD]] 크기에서 공통적으로 제공하는 간단한 기능만을 사용하여 FastLanes 를 구현했다는 것.
	- 이들을 기존의 ISA 를 이용해 구현하는 것은 아주 간단하다.
		- 그냥 동일한 기능을 하는 intrinsic 을 여러번 호출하면 되기 때문.
		- 가령 1024bit 크기의 레지스터에 8bit 의 128개 lane 으로 `AND` 연산을 하는 놈을 x86 SSE 로 구현하고자 한다면
- ...는 다음 그림과 같다.

![[Pasted image 20240903165751.png]]

- 

[^permute-bitshuffle]: Lemire 의 SIMD-* 인코딩의 원리를 알아야 이 문장이 이해될듯
[^expensive-compensate]: 솔직히 잘 이해가 안된다. 뭐 좀 예시라도 들어주며 설명해주면 좋겠는데