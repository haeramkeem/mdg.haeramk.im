---
tags:
  - originals
  - snu-shpc24f
date: 2024-10-09
---
> [!info] 서울대학교 컴퓨터공학과 이재진 교수님의 "확장형 고성능 컴퓨팅" 강의를 필기한 내용입니다.
> - [[(SNU CSE) Scalable High-Performance Computing|목차]]

## Locality

- 일단 Locality 는 간단히 말하면 "조만간 사용될 것임" 을 뜻하는 것으로 생각하면 되고
- [[Locality (Replacement)|Temporal locality]] 는 시간의 측면에서의 locality 를 말한다.
	- 어떤 데이터를 참조했을 때의 "시점" 을 기준으로 가까운 시간 내에 다시 접근될 것이라는 것.
	- 즉, 최근에 사용되었던 애는 조만간 다시 사용될 것이라는 예측이다.
- [[Locality (Replacement)|Spatial locality]] 는 공간의 측면에서 locality 를 말한다.
	- 어떤 데이터를 참조했을 때 이놈의 "위치" 를 기준으로 가까운 위치의 데이터를 접근할 것이라는 것.
	- 즉, 사용되었던 애의 주변에 있는 애들도 조만간 사용될 것이라는 예측이다.

![[Pasted image 20241021100533.png]]

- 따라서 위의 serial addition 에도 위의 locality 가 모두 들어간다.
	- `A` 는 인접한 entry 가 계속 접근되니까 spatial locality 이고
	- `sum` 은 같은 곳에 계속 접근하니까 temporal locality

![[Pasted image 20241021100740.png]]

- 이건 data 에만 한정된 내용이 아니다; code 에서도 이런 locality 가 적용이 된다. 가령 위의 예시에서도
	- Loop 을 도는 동안 `L3` 가 반복해서 접근되므로 이곳은 temporal locality 가 있는 것이고
	- Instruction 실행 후에는 다음 instruction 을 사용하니까 이런 점에서는 spatial locality 가 있는 것.

## Memory hierarchy

![[Pasted image 20241021101314.png]]

- 뭐 이렇게 hierarchy 가 있는거는 알테고
- Memory 도 storage 에 비하면 cache 의 역할을 하지만 replacement 같은 것이 SW 로 구현되어있다는 점에서 SW cache 라고 부르고
	- CPU cache 는 replacement 도 HW 적으로 되어 있기 때문에 HW cache 라고 부른다.
- 참고) DRAM 에 비해 SRAM 은 더 빠르지만 transistor 도 더 많이 들어가 비싸다고 한다.

## Cache

- Cache 가 필요한 이유는 instruction 을 실행하는데 이놈이 memory 에 있기 때문.
	- Memory 에 갔다오는 시간이 대략 300cycle 정도 걸리기 때문에
	- Instruction 실행하는데는 1cycle 인데 이놈 가져오는게 300cycle 이면 배보다 배꼽이 더 크다.
- Memory 에서 cache 로 올리는 비용이 있기 때문에 당연히 locality 를 고려해서 cache 를 사용해야 한다.
	- 즉, 한번 cache 로 올리는 비용이 비싸기 때문에 한번 올리고 여러번 써먹기 위해 어떤 놈이 "조만간 사용될" 지를 고려해야 하는 것.
	- Temporal locality 의 관점에서는, 한번 access 되었으면 cache 에 올라왔기 때문에 이것을 올리는 것보다는 "언제 뺄지" 가 중요하다. 이것은 뒤에 replacement 로 결정된다.
	- Spatial locality 의 관점에서는, access 된놈만 올리는게 아니라 주변 애들을 다 같이 올린다. 이 단위를 *Cache line* 이라고 한다.
	- 따라서 cache 로 올리는 비용을 생각하면, 한번만 access 되는 놈이라면 cache 에 올리는게 더 손해일수도 있다.
- 어쨋든 cache access 관련하여 두 개의 주된 result 는
	- *Hit*: 원하는 놈 $b$ 가 $k$ 번째 level 안의 cache line 에 있는 경우
	- *Miss*: 없는 경우. 이때는 $k+1$ 번째 level 에서 $k$ 번째로 $b$ 가 포함된 cache line 을 올려야 한다.

### Cache line

![[Pasted image 20241021105012.png]]

- 일단 *Word* 라는 것은 "한 자료형 단위" 라고 생각하면 된다.
	- 즉, 자료형이 `int` 면 *Word* 의 크기는 4byte 인 것.
- 위에서 말한 대로, spatial locality 를 위해 *Cache line* 의 단위로 데이터를 갖고 온다.
	- 이것은 여러 개의 word 로 구성된다.
- 그리고 cache line 과 동일한 크기의 memory 공간으로, memory 에서 cache 로 한꺼번에 갖고 오게 되는 memory 의 영역은 *Cache block* 이라고 부른다.
	- 여기서 좀 용어가 섞일 수 있는데,
	- 보통 *Memory block* (*block*) 이라고 하면 *word* 라고 생각하고,
	- *Cache block* 이라고 할 때만 *Cache line* 에 대응되는 놈이라고 생각하자.

### Structure

![[Pasted image 20241021105657.png]]

- Memory address 로 cache 에 접근하기 위해서 위처럼 구성되어 있다.
- 일단 전체 구조는 $S$ 개의 set 으로 구성되어 있다.
	- 이것을 구분하는 것은 address 의 set index field 를 참고해서 어느 set 에 있는지 알아낸다.
- 그리고 그 안에는 $L$ 개의 cache line 이 있다.
	- 이것을 구분하는 것은 address 의 tag field 를 참고한다.
	- 얘는 index 로 접근하는게 아니라 cache line 에 적힌 tag 를 비교해서 찾아낸다.
- Cache line 안에서는 $B$ 개의 byte 가 있다.

> [!fail] #draft Timeout... 나중에 정리하겠슴다