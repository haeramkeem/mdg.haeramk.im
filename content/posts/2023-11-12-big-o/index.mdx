---
title: Big-O, Time Complexity
date: 2021-11-12
tags:
  - Algorithm
---

## 점근적 실행 시간, 시간복잡도

**1** **점근적 실행 시간 : 입력값의 갯수가 무한대를 항할 떄 함수의 실행시간 추이**

**2** 시간복잡도 : 어떤 알고리즘을 수행할 때 걸리는 시간을 설명하는 계산 복잡도

- 어렵게 생각할 거 없다.**점근적 실행 시간이랑 비슷한 개념이다**

## 빅 오 : 시간 복잡도를 표현하는 방식

**1** **O(수식)로 나타내며 저 수식은 입력값의 갯수에 따라 걸리는 시간(연산횟수)을 수식으로 표현한 것**이다

- 수식은 실제로 걸리는 시간에 대한 정확한 수식이 아닌 **”적당히 정확한” 수식을 사용**한다
- 예를들어 n개의 입력값에 대해 4n^2+2n+7의 시간이 걸린다면 여기서 최고차항 미만의 항들과 최고차항의 계수를 버리면 n^2가 될 것이다. 이 수식을 이용해 이 알고리즘의 시간 복잡도는 O(n^2)이다 라고 말 하는 것 이다

2 다음은 대표적인 빅 오의 몇가지 예시이다

- O(상수) : 아무리 입력값이 많아도 일정한 시간이 걸린다. 아주 이상적인 알고리즘이지만 다만 상수가 ㅈㄴ 크다면 별 의미 없다
- O(로그n) : 입력값에 따라서 시간이 변하지만 기울가 완만해지기 때문에 입력값의 갯수가 아무리 커도 시간이 드라마틱하게 변하지 않는다
- O(n) : 입력값에 비례해서 시간이 소모됨 선형시간 알고리즘이라고도 불리며 정렬되지 않은 리스트에서 최대최소를 찾는 알고리즘이 해당됨
- O(n로그n) : 팀소트같은 대부분의 효율 좋은 알고리즘이 여기에 해당됨
- O(n^2) : 버블정렬같은 비효율적인 알고리즘이 해당됨
- O(2^n) : 피보나치수를 재귀로 구하는 알고리즘이 여기 해당된다
- O(n!) : 가장 느린 알고리즘이다

3 주의할 점은 빅오에서의 상한과 최악을 혼동하지 말라는 것이다

- 최선평균최악의 경우의 수는 주어진 입력값이 얼마나 계산하기 간편하게 주어지느냐에 따른 것이다. 각각의 경우의 수는 해당하는 경우의 입력값이 들어왔을 때 정확한 하나의 값으로 나오게 된다
- 하지만 상한평균하한의 경우는 좀 다르다. 얘네들은 정확한 값이 아니라 대충 뭉뚱그리는 식이라고 생각하면 된다. 즉, **상한의 경우 최악의 경우 몇번의 연산을 한다라는 말이 아니고 어떠한 경우에도 이 정도의 연산횟수는 넘지 않을것이다 라는 뜻**이다
- 예를 들면 5개의 입력값이 들어왔을 때 최악의 경우 100번의 연산을 하고, 최선의 경우 50번의 연산을 하고 평균적으로는 75의 연산을 하는 알고리즘이 있다고 하자. 그럼 최선평균최악의 경우 각각의 연산횟수가 정확히 나오는 셈이다. 하지만 상한과 하한의 경우 이것을 정확히 계산해서 도출하는 형식이 아닌 아무리 오래걸려도 120회까지는 안걸릴것이다(=상한), 아무리 빨라도 50회의 연산을 할 것이다(=하한) 이런식으로 추정하는 것이다.
- 즉, O(n^2)의 경우 n개의 입력값이 들어오면 최악의 경우 n^2번의 연산을 할 것이다 이소리가 아니고 **최선**평균**최선의 경우의 수를 다 고려해 봐도 n^2만큼의 연산을 하지 않을 것이다**이런 뜻이 된다
- 참고로 상한을 잡는것이 빅 오이고, 하한이 빅 오메가, 평균을 빅 세타라고 한다.

4 보통 상한으로 빅 오를 잡긴 하지만, 분할 상환 분석을 통해서도 빅 오를 잡기도 한다

- 최악과 최선의 갭차이가 너무 많이 나면 상한으로 빅 오를 잡았을때 너무 비관적이고 정확하지도 않다. 이래서 나온 방법이 분할 상환 분석이다
- 이 갭차이가 많이 나는 예시는 동적 할당에서의 더블링을 볼 수 있다. 크기가 n인 배열에 한번 값을 push할때는 그냥 한번의 연산이면 된다. 그냥 넣으면 되기 때문이다. 하지만 그렇게 값을 계속 넣어주다가 배열이 가득 차면 언젠가는 가득 찰 것이다. 이때 크기를 두배로 늘리자고 한다면, 크기가 두배인 배열을 하나 만들고, 여기에 원래 배열에 있던 값을 하나하나 다 복사해넣고, 원래의 배열을 지워야 할 것이다. 그렇다면 평소에는 한번만 하면 됐던 연산이 갑자기 n번+알파의 연산을 해야 된다. 이때 상한으로 잡고 얘의 시간복잡도는 O(n)이라고 측정한다면 너무 억울할 것이다
- 이때 분할 상환 분석으로 측정하면, push한번당 한번의 연산이 아니라 3번정도의 연산을 한다고 가정해 놓고, push에 사용된 한번의 연산은 빼고 2번의 연산은 뭐 어디 저장해놨다고 생각하면 더블링이 발생해도 이 저장해놓은 연산을 사용한다고 생각하면 시간복잡도는 O(3)이 된다(예시일뿐 진짜 시간복잡도가 O(3)이라는건 아니다)
- 이렇게 **최악의 경우 소모되는 연산횟수를 일반적인 경우의 연산횟수에 골고루 나눠줘서 최악의 경우 너무 극단적으로 연산횟수가 치솟는것을 상쇄시키자는 분석법이 분할 상환 분석이다**
- 원래 회계에서의 용어로, 연산횟수를 돈으로 바꿔서 생각하면 한결 더 이해하기 쉬울 것이다

5 또 병렬화를 통해서도 알고리즘의 속도를 높일 수 있다

- cpu는 빠르지만 한번에 하나의 일만 하는 코어들을 갖고 있고, gpu는 느리지만 한번에 여러개의 일을 할 수 있는 코어들을 갖고 있다.
- 이것을 이용해 한번에 여러 일을 하는 식으로 알고리즘을 실행시키면 실행속도가 더 빨라지기도 하더라
