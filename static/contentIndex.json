{"archives/microelectronics.spring.2021.cse.cnu.ac.kr/(충남대)-전자회로-강의록":{"title":"(충남대) 전자회로 강의록","links":["archives/microelectronics.spring.2021.cse.cnu.ac.kr/01.-강의-개요","archives/microelectronics.spring.2021.cse.cnu.ac.kr/02.-전하,-전압,-전류","archives/microelectronics.spring.2021.cse.cnu.ac.kr/03.-파워,-저항의-직렬병렬연결","archives/microelectronics.spring.2021.cse.cnu.ac.kr/04.-전압원,-전류원","archives/microelectronics.spring.2021.cse.cnu.ac.kr/05.-캐패시터","archives/microelectronics.spring.2021.cse.cnu.ac.kr/06.-인덕터","archives/microelectronics.spring.2021.cse.cnu.ac.kr/07.-교류-신호","archives/microelectronics.spring.2021.cse.cnu.ac.kr/08.-리액턴스","archives/microelectronics.spring.2021.cse.cnu.ac.kr/09.-반도체,-P-N-도핑","archives/microelectronics.spring.2021.cse.cnu.ac.kr/10.-다이오드","archives/microelectronics.spring.2021.cse.cnu.ac.kr/11.-트랜지스터","archives/microelectronics.spring.2021.cse.cnu.ac.kr/12.-등가회로","archives/microelectronics.spring.2021.cse.cnu.ac.kr/13.-트랜지스터-Biasing","archives/microelectronics.spring.2021.cse.cnu.ac.kr/14.-CS-증폭기","archives/microelectronics.spring.2021.cse.cnu.ac.kr/15.-CMOS"],"tags":[],"content":"\n\n                  \n                  이곳에 있는 문서들은 보관이 목적이고, 관리되지 않습니다. 따라서 잘못된 정보가 포함되어 있거나 순서가 뒤죽박죽일 수 있습니다. \n                  \n                \n\n개요 §\n강의 정보 §\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n강의 구분소속교수시기학부 수업충남대학교 공과대학 컴퓨터공학과남병규 교수님2021년 봄학기\n목차 §\n\n01. 강의 개요\n02. 전하, 전압, 전류\n03. 파워, 저항의 직렬병렬연결\n04. 전압원, 전류원\n05. 캐패시터\n06. 인덕터\n07. 교류 신호\n08. 리액턴스\n09. 반도체, P N 도핑\n10. 다이오드\n11. 트랜지스터\n12. 등가회로\n13. 트랜지스터 Biasing\n14. CS 증폭기\n15. CMOS\n"},"archives/microelectronics.spring.2021.cse.cnu.ac.kr/01.-강의-개요":{"title":"01. 강의 개요","links":[],"tags":[],"content":"\n\n                  \n                  충남대학교 컴퓨터공학과 남병규 교수님의 &quot;전자회로&quot; 강의를 필기한 내용입니다. \n                  \n                \n\n\n\n                  \n                  이 문서는 보관이 목적이고, 관리되지 않습니다. 따라서 잘못된 정보가 포함되어 있거나 순서가 뒤죽박죽일 수 있습니다. \n                  \n                \n\n컴퓨터 하드웨어의 계층도 §\n\n( 추상 ) ← ( 컴구 - 논리회로 - 전자회로 ) → ( 실재 )\n\n전기회로/전자회로 §\n\n전기회로/회로이론(Electronic circuit) : 수동소자(무전원 - 다이오드, 저항 등)만 이용\n전자회로(Electric circuit) : 능동소자(유전원 - 트랜지스터) 이용\n\n트랜지스터에 따른 컴퓨터 변천사 §\n\n1세대 컴퓨터 : 진공관\n2세대 컴퓨터 : 트랜지스터\n\n접촉식 트랜지스터 : 실리콘판에 직접 접촉하는형태로 만드는 것\n그렇지 않은 것 - 원가가 싸고 하나의 실리콘에 집적하기가 더 쉽다(MOSFET 트랜지스터)\n\n\n3세대 컴퓨터 : IC\n\n여러개의 트렌지스터를 하나의 실리콘 기판에 박은것 : integrated circuit(IC)\n\n\n4세대 컴퓨터 : 마이크로 CPU - 현재\n\nVLSI(Very Large Scale Integration) : ic에 수천개의 트랜지스터를 집적함 - 마이크로 프로세서의 탄생 - 하나의 칩에 전체 cpu를 올리는게 가능해졌다(intel)\n무어의 법칙 : 18개월마다 집적되는 트랜지스터의 수가 2배가 된다는 것(예상)\nSoC(System On Chip) : 이제는 cpu뿐 아니라 gpu, 램 등 까지 전부 하나의 칩에 올리는게 가능해 졌다. 신호가 전달되는 물리적 거리가 좁아지므로 크기가 줄고 전력도 줄고 속도도 빨라진다\n\n\n"},"archives/microelectronics.spring.2021.cse.cnu.ac.kr/02.-전하,-전압,-전류":{"title":"02. 전하, 전압, 전류","links":[],"tags":[],"content":"\n\n                  \n                  충남대학교 컴퓨터공학과 남병규 교수님의 &quot;전자회로&quot; 강의를 필기한 내용입니다. \n                  \n                \n\n\n\n                  \n                  이 문서는 보관이 목적이고, 관리되지 않습니다. 따라서 잘못된 정보가 포함되어 있거나 순서가 뒤죽박죽일 수 있습니다. \n                  \n                \n\n전하 §\n\nValance electron : 최외각전자\nIonization : 최외각전자가 에너지를 받아 원자로부터 벗어나는 것\nFree electron : 원자에서 벗어난 전자\nElectric charge : 전기력을 발생시키는 원천(+, -값을 가짐)\nCharge conservation law : 전하량 보존 법칙\nElectric field : 중력장 생각해보면 이해하기 쉽다 - 전하들에 의해 발생하는 힘이 작용하는 영역\n\n전압 §\n\n전위(Electric potential) : 단위전하 하나가 전기장의 특정한 기준점 으로부터 떨어져있음으로써 생기는 전기적 위치에너지\n전압(전위차, Voltage) : 전기장 내의 두 지점간의 전위 차이(전위/전위차는 보통 혼용해서 사용함)\n\n전압(V) = 특정 전하의 위치에너지(W) / 그 전하의 전하량(Q)\n전압(V) = 전기장의 세기(E) * 두 지점 사이의 거리차이(d)\n\n\nGND(Ground) : voltage를 구할때 기준이 되는 지점 - 기준점을 따로 잡을수도 있지만 명시되어있지 않으면 ground가 기준이 된다\n\n전류 §\n\n전류(Electric current) : 전자들이 흘러가는 속도 - 전류가 원활하게 흘러가야 회로가 제대로 작동하기 때문에 전압보다 전류가 더 중요하다\n\n전류(I) = 흘러간 전하(Q) / 시간(t) - 단위시간동안 흘러간 전하\n\n\n\n전류와 전압 §\n\n전압은 약간 물통이 높이 라고 생각하면 되고\n전류는 그 물통에서 흘러나오는 물의 속도이라고 생각하자\n전압을 단위전하당 에너지로 생각해도 된다\n전압이 있어야 전류도 있다 - 즉, 전류가 흐르기 위해서는 전압이 필요함\n하지만 전압이 있다고 전류가 무조건 흐르는건 아니다 - 물통이 막혀있으면 그 안의 물은 위치에너지는 갖지만 물이 흐르지는 않는 것과 같은 이치\n"},"archives/microelectronics.spring.2021.cse.cnu.ac.kr/03.-파워,-저항의-직렬병렬연결":{"title":"03. 파워, 저항의 직렬병렬연결","links":[],"tags":[],"content":"\n\n                  \n                  충남대학교 컴퓨터공학과 남병규 교수님의 &quot;전자회로&quot; 강의를 필기한 내용입니다. \n                  \n                \n\n\n\n                  \n                  이 문서는 보관이 목적이고, 관리되지 않습니다. 따라서 잘못된 정보가 포함되어 있거나 순서가 뒤죽박죽일 수 있습니다. \n                  \n                \n\nAC, DC §\n\nAC(Alternating Current) = 교류\nDC(Direct Current) = 직류\n직류는 전류세기가 상수이기 때문에 신호를 보낼때는 교류를 사용하고 신호를 보낼 때 사용하는 전기의 전원은 안정성을 위해 직류로 받는다(신호표현 교류, 전원은 직류)\n\nResistance §\n\nR(Resistance) = 저항\n도선의 길이(l) 에 비례하고\n단면적(a) 에 반비례함\n거기에 물질상수(p) 를 곱해주면 저항값이 나온다\n즉, R = p * l / a 이다\n\nCircuits §\n\nResistive circuit : 저항이 존재하는 정상적인 회로\nOpen circuit : 개방회로 - 중간에 끊어져있어 무한대의 저항을 가지게 되는 회로 - 단선회로\nShort circuit : 단락회로 - 저항이 없어서 무한대의 전류가 흐름(이론적인 상태) - 현실적으로는 도선만 연결되어있는 상태(저항이 없는건 아니지만 아주 작은 값임) 아주 큰 전류가 흐르기 때문에 화재의 위험이 있다 - 쇼트난거\n\n옴의법칙 §\n\n전압(V) = 전류(I)x저항(R)\n언제나 적용되는 법칙이 아닌 전압과 전류가 선형적인 관계일때 적용되는 법칙이다\n예를들면 반도체의 경우 전압과 전류가 선형적인 관계가 아니게 되어 옴의법칙이 적용되지 않는다\n\n\n에너지와 파워 §\n\n에너지(W) : 일을 할 수 있는 능력 그 자체(단위 : J = 줄)\n파워(P) : 단위시간당 에너지(단위 : W = 와트)\n에너지 보존 법칙에 따라 사용한 에너지는 소리나 열 등으로 변환된다\n\n\n\n단위전하당 에너지가 전압이라고 볼 수 있고(기준이 gnd로 동일하므로) 단위시간당 흘러간 전하는 전류이므로 파워 = 전압*전류라고 볼 수도 있다\nP = VI 와 V = IR 잘 섞어서 사용하면 파워에 관해 계산할 수 있다\n\n파워 서플라이 §\n\n파워 공급 - 파워를 공급하기에 전압과 전류를 전부 공급한다고 생각해도 된다\n파워를 공급하기때문에 와트 단위로 공급한다\n\n배터리 §\n\n한쪽에는 이온화 경향이 큰 금속을 두어서 전자가 많이 발생되도록 하고\n한쪽에는 이온화 경향이 작은 금속을 두어서 자유전자가 적게 하면\n밀도차이에 의해 전자가 이동해 전류가 발생하게 된다\n\n키르히호프의 전압법칙 (Kirchhoff Voltage Law - KVL) §\n\n직렬연결 - 소자에 걸리는 전압의 총합은 전원전압과 같다\nVs = V1 + V2 + … + Vn-1 + Vn\n\n키르히호프의 전류법칙 (Kirchhoff Current Law - KCL) §\n\n접합점 : 병렬연결에서 통로가 나뉘고 합쳐지는 지점\n병렬연결 - 소자들에 흐르는 전류의 합은 전원전류와 같다 - 접합점으로 들어온 전류는 접합점으로 나가는 전류의 합과 같다\nIs = I1 + I2 + … + In-1 + In\n\n직렬연결(Serial Circuit) §\n\n전류가 흐를 수 있는 경로가 일렬로 연결된 상태\n저항들이 직렬연결된 경우에 각 저항들의 합은 전체 저항과 같다\n하나의 경로상에 흐르는 전류는 항상 동일하다\n전압은 KVL에 의해 분배된다 - 이렇게 전압이 분배되어 걸리는 것을 전압강하라고 한다\n전압 분배는 v=ir 에서 i이 일정하기 때문에 저항의 비율에따라 전압이 분배되어 들어간다. 즉, (부분저항 / 전체저항) * 전체전압 = 부분전압 이 된다\n전압원을 직렬로 연결한 경우 각 전압원의 전압의 합은 전체 전압과 같다\n전압원의 부호를 반대로 연결하면 마이너스 전압이 된다\n전류원의 경우 직렬연결을 하는 것은 정의하지 않는다 - 하나의 경로에서 전류가 달라지게 되므로\n\n계산법 §\n\n저항 : 부분저항을 더하면 전체저항이 나옴\n전류 : 동일 - 전체전압과 전체저항을 구한 후 옴의법칙 적용하면 됨\n전압 : 부분전압을 더하면 전체전압이 나옴, 부분전압은 전체전압을 저항비로 갈라먹으면 됨\n전압원 : 전압원의 전압 합이 총전압\n전류원 : 정의되지 않음\n\n병렬연결(Parallel Circuit) §\n\n경로가 두개 이상으로 갈라지는 형태\nI = v / r 이므로 전류는 저항의 역수에 비례한다.\n\n저항의 역수를 Conductance(C, 전도도) (전류를 얼마나 잘 흘려주는지의 척도)라고 하며전도도 비율에 따라 전류가 분배된다\n부분전도도 / 전체전도도 * 전체전류 = 부분전류\n\n\n저항을 병렬로 연결하면 경로가 여러개 되는 것이므로 단면적이 커지는 효과가 되어 저항값이 작아진다\n합성저항값은 저항이 작은쪽에 가깝게 설정된다 - 저항이 작은쪽이 전류가 흐르기 쉬우므로\nKCL을 이용해 유도해보면 합성저항의 역수 = 부분저항의 역수의 합이 된다\n\n즉, 전체전도도 = 부분전도도의 합\n\n\n|| 를 병렬저항에서의 합성저항 연산자로 표현한다\n\nR1 || R2 는 병렬로 연결된 R1과 R2를 합성한다는 의미이고 이것의 결과가 합성한 저항의 총 저항값이다\n\n\n전압원을 병렬하는것도 마찬가지로 정의하지 않는다\n전류원을 병렬연결한 경우 총 전류는 전류원들의 전류 합과 같다\n\n계산법 §\n\n저항 : 역수 두번취한다고 생각 - 역수취해서 더하고 그거 역수\n전류 : 부분전류를 더하면 전체전류가 나옴, 부분전류는 전체전류 저항의 역수로 갈라먹음\n전압 : 동일 - 전체전류와 전체저항 구해서 옴의법칙써라\n전류원 : 전류원 전류 합이 총전류\n전압원 : 정의되지 않음\n\n예제 §\n\n\n"},"archives/microelectronics.spring.2021.cse.cnu.ac.kr/04.-전압원,-전류원":{"title":"04. 전압원, 전류원","links":[],"tags":[],"content":"\n\n                  \n                  충남대학교 컴퓨터공학과 남병규 교수님의 &quot;전자회로&quot; 강의를 필기한 내용입니다. \n                  \n                \n\n\n\n                  \n                  이 문서는 보관이 목적이고, 관리되지 않습니다. 따라서 잘못된 정보가 포함되어 있거나 순서가 뒤죽박죽일 수 있습니다. \n                  \n                \n\n전압원, 전류원 §\n\n전압원 전류원 둘다 전력을 공급한다 - 전압원이라고 전압만 공급하는건 아니다 이말이다\n전압원은 전압을 일정하게 공급하는 장치이고\n전류원은 전류를 일정하게 공급하는 장치다\n\n이상적인 전압원 §\n\n부하에 걸리는 전류가 변화해도 일정한 전압을 걸어줌\n즉, 전류를 많이 잡아먹는놈이 들어와도 전압이 일정하게 유지됨\n그리고 내부저항도 없음\n물탱크 생각하면 이해하기 쉬움\n\n실제 전압원 §\n\n실제 전압원은 이상적인 전압원보다 적은 전압을 제공한다 - 전압원의 내부 물리적, 화학적 구성에 의해 저항(내부저항)이 생기기 때문\n그리고 이상적인 전압원과는 다르게 전류를 갑자기 많이먹으면 전압이 변한다\n전압이 떨어지는것을 표현하기 위해 작은 저항이 직렬 로 연결되어 있는것으로 회로도를 그린다\n\n이상적인 전류원 §\n\n마찬가지로 부하에 걸리는 전압이 달라져도 항상 일정한 전류를 공급한다\n내부저항도 없다\n트랜지스터가 전류원의 역할을 해준다\n\n실제 전류원 §\n\n실제 전류원도 마찬가지로 내부저항이 존재해서 전류가 좀 떨어짐\n전류가 떨어지는 것을 표현하기 위해 큰 저항이 병렬 로 연결되어 있는것으로 표현한다\n저항값이 커야되는 이유는 이 저항값이 커야 나머지 하나의 병렬 가지에 걸리는 전류의 값이 적게 강하되기 때문\n\nThevnin Theorem §\n\n테브난 등가회로\n전압원을 단순화하는 회로이다 - 같은 역할을 하지만 더 단순하게 표현할 수 있게 해준다\nVth(테브난 등가 전압원) : 전압을 제공하는 복잡한 회로를 그냥 하나의 전압원으로 하나로 퉁친 것\nRth(테브난 등가 저항) : 전압원에 존재하는 여러개의 저항을 하나의 저항으로 퉁치는 것\n마치 추상화마냥 복잡한거는 다 빼고 그래서 총 전압은 얼마고 저항을 얼마인지 결과만 보는 것이다\n얘는 전압원 하나와 직렬연결된 저항 하나로 단순화된다\n\nThevnin 등가 전압 구하기 §\n\n외부회로를 떼어낸다\n떼어냄으로써 전류가 흐르지 않는 부분의 저항도 다 없다고 생각하고 쇼트시킨다\n외부로 출력되는 지점이랑 연결된 저항의 양단의 전압을 구하면 그게 Thevnin 등가 전압이다\n\nThevnin 등가 저항 구하기 §\n\n마찬가지로 외부회로를 떼어낸다\n이번에는 전류가 흐르지 않는 부분의 저항을 쇼트시키는게 아니고 전압원을 쇼트시킨다\n외부로 출력되는 양단을 임의의 전압원의 양단이라고 생각하고 저항을 구하면 그게 Thevnin 등가 저항이다\n\n예제 §\n\n\n\nNorton Theorem §\n\n마찬가지로 전류원과 내부저항을 Norton 전류원과 Norton 저항으로 퉁치는 것\nIn : 노턴 등가 전류\nRn : 노턴 등가 저항\n얘는 전류원 하나와 병렬연결된 저항 하나로 단순화된다\n\nNorton 등가 전류 구하기 §\n\n외부 부하를 쇼트시키고\n외부부하쪽으로 흐르는 전류 구해주면 된다\n\nNorton 등가 저항 구하기 §\n\n얜 그냥 테브난이랑 똑같던데?\n걍 전원 쇼트시키고 외부부하기준으로 저항 구해주면 된다\n\n테브난 회로를 이용해 노턴회로구하기 §\n\n보면 결국에는 저항의 위치하고 전원종류만 바뀔 뿐 같은 회로이다\n따라서 테브난에서 외부 쇼트시키고 전류구하면 그게 노턴전류고 여기서 저항위치만 바꿔주면 노턴이 된다\n반대로 노턴에서 올때는 저항 양단전압이랑 외부송출전압이랑 같으니까 여기 전압 구해주고 저항위치 바꿔주면 됨\n\n테브난/노턴은 전압원, 전류원 구분하지 않는다\n전압원이라고해서 테브난으로만 바꿀 수 있는게 아니고 전류원이라고 해서 노텉으로만 바꿀 수 있는건 아니다\n\n\n"},"archives/microelectronics.spring.2021.cse.cnu.ac.kr/05.-캐패시터":{"title":"05. 캐패시터","links":[],"tags":[],"content":"\n\n                  \n                  충남대학교 컴퓨터공학과 남병규 교수님의 &quot;전자회로&quot; 강의를 필기한 내용입니다. \n                  \n                \n\n\n\n                  \n                  이 문서는 보관이 목적이고, 관리되지 않습니다. 따라서 잘못된 정보가 포함되어 있거나 순서가 뒤죽박죽일 수 있습니다. \n                  \n                \n\n에너지 저장 소자 §\n\n얘네들은 에너지를 임시로 저장하는거지 배터리처럼 계속 저장하는건 아니다\n\nCapacitor §\n\n축전기\n전압 형태로 에너지를 저장\n전기장을 이용\n\nInductor §\n\n유도기\n전류형태로 에너지를 저장\n자기장을 이용\n\nCapacitor §\n원리 §\n\n금속평판 두개 사이에 절연체를 하나 놓고 전류를 가해주면\n양 극단에 음전하와 양전하가 채워지면 둘 사이에 전기장이 걸리며 전기적 위치에너지가 생기므로 전압이 저장되게 되는 원리이다\n\nCapacitance §\n\nCapacitance(축전 용량) - 얼마나 전하를 채울 수 있는지(물리량 표시 - C, 단위 - F)\n1F은 1V의 전하에 1Q의 전하가 저장될 수 있음을 의미한다\n물이 많이 들어갈수록 물통의 크기가 커지고 물의 양이 같을 경우 물의 높이가 낮을수록 물통의 크기가 큰 것이므로 ( 물의 양 = 전하의 양 = Q ), ( 물의 높이 = 전압 = V ) 따라서 C = Q / V 이다 - Q = CV 로 기억하고있어라\nQ = CV 에서 전하를 전압으로 적분하면 축전기에 들어간 에너지의 양이 나온댄다\n\n구조적 특징에 따른 용량 §\n\n도체판의 면적에 비례하고\n판간 거리에 반비례한다 - 판간 거리가 작아지면 위치에너지가 작아지므로 전압이 낮아져 전원과의 전위차가 생겨 전류가 흐르게 돼 전하가 더 많이 충전된다(전하가 더 많이 충전되어 결국 원래 전압으로 돌아와 전위차가 없어지게 된다)\n가운데 들어간 절연체가 뭔지에 따라서도 달라진다 - 절연체의 원자가 잘 분극되는 소재라면 전기장이 더 수월하게 형성될거고 그렇지 않다면 전기장 형성이 제대로 이루어지지 않을 것이다\n\n캐패시터 직렬, 병렬 연결 §\n직렬 연결 (Serial capacitor) §\n\n캐패시터가 직렬연결되면 판간 거리가 증가하는 효과 이므로 총 캐패시턴스는 작아짐(충전되는 전하의 양은 더 적어짐)\n직렬일 경우 전류는 일정하므로 Q의 값은 어디서나 동일함(전류 = 단위시간당 흐른 전하이므로)\n하지만 전압은 분배됨\nV = Q / C 인데 Q는 일정하므로 1 / C가 분배된다고 생각할 수 있을 것이다 - C의 역수 비율로 분배된다\n즉, 병렬로 연결된 저항들의 합성저항을 구하는 것과 같은 계산법으로 구할 수 있다\n\n병렬 연결 (Parrarel capacitor) §\n\n캐패시터가 병렬연결되면 금속판 면적이 늘어나는 것과 유사하므로 더 많은 전하가 충전되게 된다\n병렬연결에서는 전류가 분배되므로 Q가 분배된다고 생각할 수 있다\n근데 Q = C * V 이므로 CV가 분배된다고 생각 할 수도 있을 것이다\n근데 병렬에서는 V가 일정하므로 C가 분배되는 것이다(부분부분의 C의 합은 전체 C의 합과 같음)\n\n정리 §\n\n저항에서와 마찬가지로 직렬이면 전류가 일정하고 전압이 분배되며 병렬이면 전류가 분배되고 전압이 일정하다\n다만 분배될때는 저항과는 반대로 분배된다고 생각하면 된다\n\n저항은 직렬일때 저항비로 분배되고 병렬일때는 저항의 역수비로 분배되지만 캐패시터는 직렬일때 캐패시턴스의 역수비로 전압이 분배되고 병렬일때 캐패시턴스 비율로 전류가 분배된다\n\n\n\n정상, 과도 상태 §\n\nTransient state(과도상태) : 회로가 안정적으로 작동하기 전에 잠깐동안 혼란스러운 것 - 전류가 혼란스럽게 변화하므로 AC(교류)처럼 흐른다\nSteady state(정상상태) : 과도상태를 지나 회로가 안정화된 상태 - 전류가 일정하므로 DC(직류)처럼 흐흔다\n이 상태들은 미분방정식으로 수학적으로 표시할 수 있고 변수분리법 정도는 알고있어야 한다 = 같은 변수는 같은 항에 몰아넣는거\n\n캐패시터의 충전, 완충, 방전 §\n\n캐패시터가 충전/방전되는 과정에서는 전류가 흐르지만 충전이 완료되면 전류가 흐르지 않는다\n즉, 충전이 되고 있는 과도상태에서는 전류가 흐르지만 충전이 완료된 정상상태가 되면 전류가 흐르지 않는다\nAC를 흘리고 DC를 차단하는 효과\n전압이 천천히 변하면 충전되어 전류가 끊어질 수도 있으므로 전압이 빠르게 변해야 전류도 그만큼 잘 흐르게 된다 - 따라서 아래와 같은 수식이 성립한다\n\n\n\n과도상태에서는 단락의 경우처럼 전류가 흐른다\n\n전류의 흐름을 방해하는 것은 저항밖에 없다\n\n\n정상상태에서는 개방의 경우처럼 전류가 흐르지 않는다\n캐패시터가 방전될때는 전류가 반대로 흐르며 처음에는 최대전류를 흘려주다가 점점 세기가 약해진다\n캐패시터에 걸리는 전압은 불연속적으로 변할 수 없지만 전류는 불연속적으로 변할 수 있다\n\n전압은 충전하는데 시간이 걸리기 때문에 시간이 걸리지만 전류는 그 충전된 전압에 의해 흐르는 것이므로 반대로 흐르거나 끊어지거나 하는 등의 불연속적인 흐름이 일어날 수 있다\n\n\n\n\n\n따라서 위와 같은 형식의 충전 방전 곡선이 나타나며 저 v(t) 수식하고 I(t) 수식은 외워놓자\n\n캐패시터의 쓰임 §\n\n일단 캐패시터가 들어있으면 전압은 불연속적으로 변하지 않는다\n\n캐패시터가 들어있는 이상 전압이 충전되기 때문에 전압이 끊겨도 이 캐패시터가 방전되며 전압을 공급해줘 전압이 서서히 줄어들고 마찬가지로 갑자기 전압이 높아져도 캐패시터가 충전되며 서서히 높아지게 된다\n\n\n하지만 전류는 불연속적으로 변할 수 있다\n\n캐패시터가 방전되는 동안에는 전류가 반대로 흐르기도 하고 전선이 단락되면 전류가 흐르지 않으므로 전류의 갑작스러운 변화는 가능하다\n\n\n따라서 이러한 성질을 이용해 전압이 변화하는 상황에서도 비교적 일정하게 전압을 공급해주는 회로를 구성하는 것이 가능하다\n\nRC 시정수 §\n\n타우(t), RC : 캐패시터의 충전, 방전 속도를 결정하는 상수\n실제 회로에서는 약간의 저항, 캐패시터가 항상 존재하게 된다\n\n전선이 가지고 있는 저항, 전선과 인접한 전선 간의 유격에 따른 캐패시터 등\n\n\n이런 자연발생적인 저항과 캐패시터 때문에 회로의 동작 속도가 어느정도 제한된다\n\n저항은 전류를 제한하기 때문에 동작속도를 제한시키고\n캐패시터는 의도치 않은 전하 충전이 생기기 때문에 전압을 제한해 동작속도를 제한한다\n\n\n시정수(타우, t) = 의도하지 않은 저항(R) * 의도하지 않은 캐패시터(C)\n"},"archives/microelectronics.spring.2021.cse.cnu.ac.kr/06.-인덕터":{"title":"06. 인덕터","links":[],"tags":[],"content":"\n\n                  \n                  충남대학교 컴퓨터공학과 남병규 교수님의 &quot;전자회로&quot; 강의를 필기한 내용입니다. \n                  \n                \n\n\n\n                  \n                  이 문서는 보관이 목적이고, 관리되지 않습니다. 따라서 잘못된 정보가 포함되어 있거나 순서가 뒤죽박죽일 수 있습니다. \n                  \n                \n\nInductor §\n\n한국어로 유도기라고 한다\n전류를 자기장 형태로 저장하는 것\n전자석처럼 코일형태를 띄고 있다\n코일형태로 만들어서 자속(자기장)을 저장하는 것\n기억 안나면 인덕션 생각해라 - 인덕션도 코일의 저항을 이용해 열을 발생시키므로 인덕터도 코일처럼 생겼으며 이 코일에 의한 자속으로 전류를 붙잡아두는 것\n\n인덕터의 원리 - 렌츠의 법칙 §\n\n자속이 전류를 흘러주게 하는 관성과 같은 역할을 해서 전류를 저장할 수 있게 한다\n전류를 저장한다는 것은 전류를 유지킨다는 것을 의미한다\n전압이 없어져도 자속이 어느정도 남아있으니까 자속이 없어질때까지는 전류가 흐른다는 뜻\n자속이 전류의 관성과 같은 놈이므로 전류의 변화가 생기면 그에 대한 저항력을 발생시킨다(전류의 변화에 저항하는 힘을 유도한다고 해서 유도기)\n저항이 줄어들어 전류가 커지면 다음과 같은 일이 일어난다\n\n저항이 줄어들면 전류가 높아져야 되는데 이 순간 변화에 대항하기 위해 인덕터의 양단에 전류방향과 반대방향으로 전압이 걸린다\n이러면 저항과 인덕터 간의 전위차가 줄어들어서 전류가 높아지지 않는다\n하지만 결국에는 에너지를 점점 잃으면서 다시 반발력을 잃고 점점 전류가 증가하게 된다\n\n\n그리고 반대의 경우로 저항이 높아져 전류가 작아지면 다음과 같은 일이 일어난다\n\n저항을 높여버리면 전류가 줄어야 하는데 인덕터 입장에서는 관성을 유지하기 위해 전류의 방향과 같은 방향으로 전압이 걸린다\n따라서 저항과 인덕타 간의 전위차가 커져 전류가 낮아지지 않는다\n하지만 마찬가지로 점점 힘을 잃으며 전류가 점차 낮아지게 된다\n\n\n이렇듯 인덕터를 달면 전류의 변화가 드라마틱하게 일어나지 않고 점진적으로 일어나게 된다\n\n캐패시터랑 반대쥬? 인덕터는 전압의 불연속적인 변화는 가능하지만 전류의 불연속적인 변화는 불가능하다\n\n\n이러한 전류흐름의 관성을 유지하려고 하는 것을 렌츠의 볍칙이라고 한다\n\nInductance 수학적으로 계산하기 §\n\n인덕턴스(유도용량, L) - 전류의 변화에 저항하는 방향으로 전류를 발생시키는 능력 = 자속 저장 능력\n\n\n\n인덕턴스 = 자속의 양 * 전류\n\n전류에 반비례하는 이유는 적은 전류에서는 자속이 추가되는게 더 쉽지만 전류가 큰 경우에는 이미 많은 자속이 들어있기 때문에 자속을 더 추가하는것이 더 힘들기 때문이다\n\n\n단위는 H(Henry)이다\n\n1H = 1초에 1A의 전류가 변할때 1V의 전압이 유도된다는것\n\n\n\n\n\n유도전압(Vind) = 유도용량(L) * 전류변화속도(di/dt)\n\n\n\n에너지(W)를 전류(I)를 이용해 저장한다\n\n기하구조에 따른 용량 §\n\n\n코일의 길이에 반비례\n\n코일을 촘촘하게 감으면 자기장들이 중첩돼서 더 세어져 더 많은 전류를 저장할 수 있게 된다\n따라서 코일에 사용된 도선의 길이가 같을 때 코일의 길이가 길어지면 그만큼 듬성듬성하게 감긴하는 뜻이므로 용량은 줄어들게 됨 - 용수철 길게 늘린거 생각하면 된다\n\n\n코일단면적에 비례\n\n코일 단면적이 늘어나면 더 많은 자속을 저장할 수 있으므로\n\n\n권선수의 제곱에 비례 - 권선수는 코일을 감은 횟수를 의미함\n\n코일을 많이 감으면 자속의 갯수 자체도 늘어나고 밀도도 늘어나므로 제곱에 비례하는 거랜다\n\n\n투자율에 비례\n\n투자율이라는 것은 코일 가운데에 들어있는 물질이 얼마나 잘 자화되는지의 수치이다\n즉, 그냥 가운데 있는 물질이 뭐냐에 따라 달라지는 값 - 원자 주변도 전자가 돌기 때문에 이것도 하나의 원자 자석이 될 수 있는데 이것들이 얼마나 주변 자기장에 따라 잘 정렬되는지\n정리하면 코일의 가운데에 들어가는 물질이 투자율이 좋아 잘 정렬되면 그만큼 자속이 방해받지 않는 것 이므로 용량도 늘어나게 된다\n\n\n\n인덕터의 직렬, 병렬 연결 §\n\n얘도 걸리는 전압 전류 계산하는 것은 KCL, KVL이용해서 구하면 된다\n다만 직렬연결, 병렬연결시에 인덕턴스가 어떻게 변화하는지는 다음과 같다\n\n직렬연결된 인덕터의 인덕턴스 §\n\n\n같은 밀도로 코일을 더 감는것과 마찬가지 이므로 자속을 더 저장할 수 있어 인덕턴스가 늘어난다\n\n병렬연결된 인덕터의 인덕턴스 §\n\n\n얘는 의미론적으로 이해하기는 좀 어렵다\n그냥 병렬 합성 저항처럼 인덕턴스를 계산해주면 된다\n\n정리 §\n\n인덕터의 합성 인덕턴스 계산은 저항의 합성 저항 구하는 것처럼 생각해주면 된다\n\n즉, 직렬연결하면 인덕턴스도 늘어나고\n병렬연결하면 인덕턴스도 줄어든다\n\n\n\n정상, 과도상태 §\n\n렌츠의 법칙에 따라 변화한다\n충전될때는 전류의 방향에 반하는 방향으로 전압이 걸려 전류가 서서히 증가한다\n\n단계적으로 알아보면\n\n\n먼저 전압을 걸면 일단 인덕터에는 그에 반하는 힘이 바로 유도되어 반대방향으로 같은 전압이 유도된다\n하지만 점차 힘을 잃으며 전압이 점차 낮아지다가\n정상상태에 들어가면 유도전압이 0으로 떨어지게 된다\n\n\n방전시에는 원래의 전류 방향으로 전압을 걸어 전류를 계속 흘려줘 전류가 서서히 감소한다\n\n이것도 단계적으로 알아보면\n\n\n일단 전압을 해제하면 인덕터에는 그에 반하는 힘이 바로 유도되어 같은방향으로 같은 전압이 유도된다\n하지만 점차 힘을 잃으며 전압이 낮아지다가\n유도전압이 0으로 떨어지면 그제서야 전류가 흐르지 않게 되는 것\n\n\n따라서 인덕터는 dc를 흘리고 ac를 차단한다 - 인덕터는 변화를 싫어하므로 ac를 차단하게 된다\n\n인덕터의 개방법 §\n\n인덕터가 있을 때 회로를 급작스럽게 단선시켜버리면 인덕터에 반대의 전압이 걸리기 때문에 단선된 부분에 공기를 통해 전류가 흐르게 되어 스파크가 일어난다\n이러한 위험한 상황을 피하기 위해서는 인덕터가 발생시키는 전압에 의한 전류를 흐를 수 있도록 백도어를 하나 만들어 주는게 중요하다\n\n하나의 도선을 인덕터와 병렬적으로 연결한 다음 회로를 단선시키면 연결한 도선으로 전류가 흐르며 점차 방전되게 된다\n\n\n\n충전, 방전시에의 수식적 해석 §\n\n\n이 공식 외워놔라\nKVL에 의해 저항에 걸리는 전압과 인덕터에 유도된 전압을 더하면 원래의 전압이 됨\n\n저 Ri(t) 는 R * I(t) 로 옴의 법칙에 의해 저항에 걸린 전압과 같다\n그 뒤에 L어쩌고는 위에서 나온 인덕턴스 * 전류변화 속도 이므로 Vind즉, 유도전압을 의미하는 것을 알 수 있다\n\n\n충전될 때에는 저 Vs에 전원의 전압을 넣어줘서 풀면 되는거고 방전될때는 Vs에 0을 넣어줘서 풀면 되는거다 - 방전될때는 전압이 걸리지 않으므로\n풀어보면 충전시에는 I(t) 가\n\n\n\n방전시에는\n\n\nRL 시정수 §\n\n\nRL 시정수는 전류가 얼마나 잘 변화하는지를 나타내는 상수이다\n계산은 타우(t) = 자연발생 저항(R) / 자연발생 인덕턴스(L) 로 한다\nRC 시정수와 마찬가지로 타우(t) 로 표기한다\n이 시정수가 작으면 변화가 잘 일어나지 않고\n크면 변화가 빠르게 일어난다\n\n실제에서의 자연적인 요소 §\n\n사실 인덕터는 회로에서 많이 마주치기가 힘들다 - 캐패시터와 마찬가지로 코일을 감지 않더라도 도선에서 인덕터가 자연적으로 발생하게 된다\n하지만 아주 빠르게 변화하는 칩이거나 아주 사이즈가 큰 보드가 아니라면 이 인덕턴스는 잘 보이지 않는다\n보통 전자회로를 만들때 자연적으로 발생하는 방해요소는 저항(R) 과 캐패시터(C) 두가지를 주로 고려하게 된다\n"},"archives/microelectronics.spring.2021.cse.cnu.ac.kr/07.-교류-신호":{"title":"07. 교류 신호","links":[],"tags":[],"content":"\n\n                  \n                  충남대학교 컴퓨터공학과 남병규 교수님의 &quot;전자회로&quot; 강의를 필기한 내용입니다. \n                  \n                \n\n\n\n                  \n                  이 문서는 보관이 목적이고, 관리되지 않습니다. 따라서 잘못된 정보가 포함되어 있거나 순서가 뒤죽박죽일 수 있습니다. \n                  \n                \n\n전원과 신호 §\n\n전원은 항상 일정한 에너지가 공급되어야 하기 때문에 DC를 필요로 한다\n하지만 신호의 경우 변화가 중요하기 때문에 AC를 필요로 한다\nAC는 정현파의 형태로 나타나며 전류가 변할때는교류전류이고 전압이 변할때는 교류전압이다\n\n정현파, 푸리에 변환 §\n\n정현파(sinusoidal) - 사인 / 코사인 그래프 형태를 의미함\n이 세상의 모든 신호는 푸리에 변환을 이용해 정현파들의 합성으로 분리해낼 수 있다\n따라서 세상의 모든 신호는 주파수/진폭만 다른 여러개의 정현파의 합으로 나타내 진다\n이 성질을 이용하면 데통에서 배운거처럼 신호를 분석할 때 주파수 / 진폭 그래프를 이용할 수 있는 것\n이런 주파수 / 진폭그래프를 이용하면 콘볼루션이라는 복잡한 연산을 곱셈으로 변환이 가능하고 미분방정식을 대수방정식으로 변환이 가능하다 - 뭔지 몰라도 됨 - 그냥 신호를 푸리에 변환한 후 주파수 / 진폭 그래프를 사용하면 쉽게 분석할 수 있더라\n\n정현파의 각주파수, 위상각 §\n용어정리 §\n\n\n각주파수(w) : 회전속도 = 위상이 얼마나 빨리 변하는가\n\n각주파수(w) = 2 * 파이 * 주파수\n\n\n진폭(최대값, Vp) : 알제? 0을 기준으로 가장높이, 혹은 낮은지점까지의 거리\n최소-최대값(Vpp) : 진폭의 두배것제\n위상각(세타) : 위상을 각도로 표현하는 것\nLag : 기준점에 비해 ~도 뒤짐\nLead : 기준점에 비해 ~도 앞섬\n\n정현파의 일반적인 표현 §\n\n위의 용어들을 이용해 정현파를 표현해보면 다음과 같다\n\n\n\nwt : 각주파수는 회전하는 속도이므로 거기에 시간을 곱해주면 시간변화를 각도변화로 바꿔주게 된다\n\n무리에서의 속도를 생각해보면 됨 - 속도에 시간을 곱하면 시간변화를 거리변화로 나타낼 수 있는거랑 마찬가지더라\n\n\nθ : 위상각 - 그림보니까 위상각이 뭔지 감 오제? 정현파가 어느정도 평행이동했냐 이말이여\n여기에 sin붙이고 진폭 A를 붙여주면 딱 나오제\n\n오일러 공식 §\n\n\n복소수를 도입함으로써 지수함수 &lt;-&gt; 삼각함수 간에 변환을 하게 도와주는 공식\n일반적으로 삼각함수의 연산은 복합한데 비해 지수함수의 연산은 간단하기 때문에 삼각함수로 표현되는 정현파를 계산할때 많은 도움을 준다\nRe[x] 는 실수파트를 나타내고 Im[x] 이 허수파트를 나타낸다\n신호는 사인/코사인 함수로 이루어져 있는데 이것을 연산하는 것은 쉽지 않다\n하지만 이것을 지수함수로 계산하면 아주 간편하기 때문에 오일러 공식을 이용해 삼각함수를 복소수를 곁들인 지수함수로 표현하여 계산하고자 하는 것 이다\n\n복소신호 §\n\nAC신호는 정현파이고 이것은 삼각함수로 표현된다\n근데 오일러 공식은 삼각함수와 지수함수와의 관계성을 나타내기 때문에\n정현파인 AC신호를 오일러 공식을 이용해 복소수와 지수함수로 표현한 것이 복소신호이다\n복소수의 연산이 더 간편하기 때문에 전류, 전압, 저항 등의 거의 모든 것들을 복소수로 바꿔서 계산하게 된다\n\n페이져(phasor) §\n\n페이져(Phasor) 는 진폭과 위상을 복소 각좌표계에 표현하는 복소신호의 표현방식이다\n주파수는 고려되지 않는다 - phasor는 주파수는 같고 진폭와 위상이 다른 여러 신호를 비교, 합성할때 사용하는 기법이다\n\n페이져로의 변환, 분석 §\n\n일단 진폭이 A이고 위상이 θ인 신호를 페이져로 표현하면 다음과 같다\n\n\n\n이제 이걸 복소 극좌표에 표현할때는 진폭은 벡터의 길이, 위상은 x축과 벡터의 각도로 표현한다\n\n\n\n그러면 이런식으로 표현이 된다\n이제 그럼 얘를 복소 극좌표에서 복소 직각좌표로 변환할때는 삼각함수를 이용해주면 된다\n\n그럼 (Acosθ, Asinθ) 가 되겠쥬?\n\n\n근데 복소좌표에서는 (x, y) 는 x+jy 와 같다 - 따라서 저놈은 요래 표현할 수 있다\n\nAcosθ+jAsinθ\n\n\n근데 또 저놈은 오일러 공식에 의해 이렇게 표현되게 된다\n\nAexp(jθ)\n\n\n따라서 다음과 같은 관계가 생기는 거다\n\n\n페이져의 연산 §\n\n덧셈, 뺼셈 - 페이져를 직각좌표로 바꿔 (x1+jy1) +- (x2+jy2) 를 이용한다\n곱셈, 나눗셈 - 페이저를 지수함수형태로 변환해 연산한다\n\n곱셈 - (A1 * A2)exp(j(θ1+θ2)) - 즉, (A1 * A2) &lt; (θ1 + θ2)\n나눗셈 - (A1 / A2)exp(j(θ1 - θ2)) - 즉, (A1 / A2) &lt; (θ1 - θ2)\n\n\n\n페이져 변환 §\n\n페이져를 삼각함수형태나 지수함수형태로 바꾸는거 연습 많이 해노라\n삼각함수로의 변환 - 복소 극좌표를 복소 직각좌표로 변환 - 빗변이 A이고 각도가 θ인 직각삼각형 그려서 계산하면 편하다\n지수함수로의 변환 - ‘&lt;‘ 부분을 e^j로 바꾸거나 아니면 진폭이 앞에 곱해져있고 위상이 위의 지수부로 올라가있다는것 을 꼭 기억하라\n직각좌표를 페이저로 변환 - 피타고라스 이용해서 빗변인 진폭 구하고 아크탄젠트(arctan)이용해서 각도인 위상 구하라\n"},"archives/microelectronics.spring.2021.cse.cnu.ac.kr/08.-리액턴스":{"title":"08. 리액턴스","links":[],"tags":[],"content":"\n\n                  \n                  충남대학교 컴퓨터공학과 남병규 교수님의 &quot;전자회로&quot; 강의를 필기한 내용입니다. \n                  \n                \n\n\n\n                  \n                  이 문서는 보관이 목적이고, 관리되지 않습니다. 따라서 잘못된 정보가 포함되어 있거나 순서가 뒤죽박죽일 수 있습니다. \n                  \n                \n\nAC회로에서의 캐패시터 §\n\n\n저항과 캐패시터에 나타나는 전압, 전류도 모두 정현파로 나타난다\n캐패시터는 전류가 가해져야 전하가 충전돼서 전위가 생길 수 있기 때문에 전류가 전압보다 위상이 90도 앞선다\n\n전류가 점점 줄어들어 0이 되는 구간을 보면 캐패시터가 점점 충전되긴 하지만 전류가 줄어들기 때문에 충전속도도 점점 느려진다\n그러다가 전류가 0을 넘어 반대로 흐르게 되면 이것은 캐패시터의 방전시 전류의 방향과 같기 때문에 충전량도 점점 줄어들게 된다\n그러다가 전류가 반대방향으로 최대로 흐르는 지점에서는 충전했던 전하가 고갈이 나기 때문에 0이 되었다가\n전류가 반대방향으로 계속 흐르기 때문에 캐패시터도 아까와는 반대의 극성으로 충전되게 되는 것\n이러한 연유로 캐패시터에 흐르는 전류와 캐패시터의 전압은 90도의 위상차가 생기게 되는 것 이다\n전류가 있어야 전압이 있기 때문에 전압이 전류보다 위상이 90도 늦다라고 기억해라\n\n\n근데 옴의 법칙은 전류와 전압의 위상차가 없는 선형적인 관계일 때 성립하는 등식인데 지금은 위상차가 생기므로 캐패시터가 존재하면 옴의 법칙은 적용되지 않는다\n즉, 그냥 dc회로에 저항만 있는 경우에는 v=ir이 성립해 항상 비례관계이지만 이 경우에는 비례관계가 아닌 위상차가 생긴다는 것\n따라서 I ~ jV 의 관계가 성립한다 → j는 허수인데 이게 90도 회전한다는 의미를 가지기도 한다\n\nj를 두번 곱하면 -1인데 이것을 복소 극좌표계에서 각도의 입장에서 보면 180도 회전이기 때문에 그냥 j는 90도 회전의 의미를 갖게 되는 것\n\n\n\n리액턴스 §\n\n리액턴스(X) : 캐패시터와 인덕터에서 나타나는 AC전류에 의한 반응저항을 의미하며 복소수로 표현되기 때문에 복소저항이라고도 부른다\n캐패시터에서는 용량성 리액턴스라고 부르고, 인덕터에서는 유도성 리액턴스라고 한다.\n저항과 유사한 역할을 하긴 하지만 저항과는 다음과 같은 차이점이 있다\n\n전류를 소비하지 않고\n주파수에 따라 저항값이 달라지고\n전압과 전류 사이에 위상차(j)를 발생시킴\n\n\n\n용량성 리액턴스 §\n\n캐패시터에서 발생하는 리액턴스를 용량성 리액턴스(복소저항), 기호로는 Xc로 표기한다\n\n유도과정 §\n\n\n정현파로 주어지는 전압을 오일러 공식을 이용해 복소수를 이용해 표현한 것을(오일러 공식에는 허수부가 존재하는데 왜 저렇게 표현되는지는 모르겠으나 걍 받아들여라)\nt로 미분해 dv / dt 를 구하고\n그것을 이용해 i를 구한 후 - 전류는 캐패시턴스가 클수록, 전압이 빠르게 변할수록 잘 흐른다고 캐패시터 부분에서 말했었쥬?\n옴의 법칙을 이용해 저항을 구해보면\n\n\n1 / jwc 가 되는데 복소수로 표현된 저항이므로 복소저항, 즉 리액턴스이다\n따라서 용량성 리액턴스(Xc) = 1 / jwc 로 표현된다\n\n얘를 의미론적으로 이해해보면 w가 주파수이므로 전압의 주파수가 높다는 것은 결국에는 캐패시터에서 전류를 더 잘 흐르게 하므로 리액턴스인 Xc는 작아지게 되는 것\n\n\n문제에서 리액턴스의 크기가 주어지면 1 / wc 만 주어진 것 이므로 -j 를 붙여서 위상에 대한 정보까지 추가해서 계산 해야 한다\n\nAC회로에서의 인덕터 §\n\n\n전류의 변화가 클수록 많은 전압이 유도되므로 전류 정현파의 접선의 기울기가 제일 큰 0에서 전압이 제일 많이 유도된다 → 전압이 전류보다 위상이 90도 앞선다 - 꼭 기억할 것!!\n\n캐패시터와 비교해서 캐패시터는 뭐가 앞서고 인덕터는 뭐가 앞서는지 꼭 기억할 것\n\n\nV ~ jI 인 셈이다\n\n유도성 리액턴스 §\n\n인덕터에서 유도되는 리액턴스를 유도성 리액턴스(복소저항), 기호로는 Xl라고 부른다\n\n유도과정 §\n\n\n이번에는 정현파로 주어지는 전류를 오일러 공식을 이용해 복소수로 표현한 것을\n양변을 t로 미분해 di / dt 를 구한다\n그리고 인덕터에서는 전류가 빠르게 변할때 높은 전압이 유도됨을 이용하여 전압에 대한 공식을 유도하고\n마찬가지로 옴의법칙을 이용해 저항을 구해보면\n\n\n유도성 리액턴스(Xl) = jwL 이 나오게 된다\n\n얘를 의미론적으로 이해해보면 전류의 주파수인 w가 크다는 것은 그만큼 전류가 빠르게 변하는 것이고 그럼 유도전압이 많이 유도되어 전류가 흐르기 힘들어진다. 따라서 Xl이 커지는 것\n\n\n이때에도 유도성 리액턴스의 크기가~옴으로 주어지면 위상정보인 j를 붙여야 Xl값이 나오게 된다\n\n임피던스 §\n\n복소저항과 일반저항을 포괄하는 상위개념이 임피던스 이다 - 단위는 그대로 옴을 사용함\n임피던스(Z) = 순수저항(R) + 리액턴스(X) * j 즉, 순수저항이 실수부이고 리액턴스가 허수부인 것 이다\n따라서 저항과 캐패시터, 인덕터가 섞여있는 회로에서의 임피던스는 얘네를 +, || 를 통해 합성한 후 실수부와 허수부를 나누면 구할 수 있다\n교류회로에서 V = IZ 가 성립한다\n임피던스 저항의 상위개념이기 때문에 저항처럼 직렬시에는 더해주고 병렬시에는 저항처럼 || 연산을 하면 된다\n\n반대개념들 §\n\n컨덕턴스(G) : 저항의 역수(옛날에 배웠던 전도도)\n서셉턴스(B) : 리액턴스의 역수\n어드미턴스(Y) : 임피던스의 역수\nY = G + Bj 로 표현된다\n어드미턴스에서 Y = G + Bj 를 역수취하면 1 / G + 1 / B 와는 다르다고 생각할 수 있는데 G = R / (R^2 + X^2), B = -X / (R^2 + X^2) 가 성립하기 때문에 같댄다 - 별로 중요한건 아님\n\n교류 회로의 해석 §\n\n이제부터 모든 값들이 페이저로 제시된다\n즉, 전압도 페이저의 형태로(페이저 V), 전류도 페이저로(페이저 I), RLC임피던스도 페이저로(페이저 Z)로 제시된다\n하지만 옴의법칙에서 저항만 임피던스로 바꾼 V = IZ 가 성립하고\nKCL, KVL, 직렬 / 병렬에서의 전류 / 전압 분배 등등이 여전히 성립하기 때문에 얘네들을 이용해 회로를 해석해주면 된다\n\n예제 §\n\n\n\n\n\n\n단위환산 §\n\n나노(-9) → 마이크로(-6) → 밀리(-3) → 0 → 키로(3) → 메가(6) → 기가(9) → 테라(12)\n\n저역 통과 필터 §\n\n출력포트랑 캐패시터를 병렬로 연결한 후 낮은 주파수의 신호가 들어오면 캐패시터는 DC를 차단하기 때문에 여기로는 전류가 안흐르고 출력포트쪽으로 전류가 흘러 낮은 주파수의 신호를 잡아낼 수 있게 된다\n하지만 높은 주파수의 신호가 들어오면 전류가 캐패시터쪽으로 많이 흐르기 때문에 출력으로는 별로 안나와 높은 주파수의 신호를 차단할 수 있게 된다\n"},"archives/microelectronics.spring.2021.cse.cnu.ac.kr/09.-반도체,-P-N-도핑":{"title":"09. 반도체, P N 도핑","links":[],"tags":[],"content":"\n\n                  \n                  충남대학교 컴퓨터공학과 남병규 교수님의 &quot;전자회로&quot; 강의를 필기한 내용입니다. \n                  \n                \n\n\n\n                  \n                  이 문서는 보관이 목적이고, 관리되지 않습니다. 따라서 잘못된 정보가 포함되어 있거나 순서가 뒤죽박죽일 수 있습니다. \n                  \n                \n\n규소 결정 만드는 기법 §\n\n그 소금결정만드는거마냥 작은 규소조각 넣은담에 냅두면 커다란 규소 결정이 완성된다\n\n반도체에서의 양자역학 §\n\n전자도 입자성과 파동성을 둘 다 가지기 때문에 부도체의 경우에도 일부 뚫고 지나간다\n즉, 캐패시터의 경우 완충되면 전류가 안통하는게 상식적인 일이지만 아주 소량의 전류는 흐르게 된다\n이러한 성질을 투과파(Tunneling) 이라고 한다\n세상의 모든 물질은 입자성과 파동성을 둘 다 가진다\n이때 파동성이라는거는 확률이 파동형태로 존재한다는 얘기이다\n전자들이 존재하는 궤도가 존재한다는 것( = 양자화 되어 있다는 것)은 그 궤도에서 돌아야 정상파를 이룰 수 있기 때문 - 몰라도됨 솔직히\n\n전자와 원자 구분 §\n\nvalance electoron : 최외곽전자\nconduction electron : 자유전자, 전도전자\nion : 전자가 떨어져 나간 상태의 원자\n\n전자와 정공 §\n\n전자가 자유전자가 되면 그 전자가 빠져나간 곳이 빈 구멍이 되는데 이 구멍을 정공이라고 한다\n전자가 이동하는 과정은 반대방향으로 정공이 이동하는 것과 필요충분조건이 되기 때문에 정공의 움직임도 전류 흐름의 한 징표라고 생각할 수 있다\n\n전자의 움직임와 정공의 움직임은 반대인데 전류는 전자의 움직임과 반대로 흐르므로 정공의 움직임 방향이 전류의 방향이라고 할 수 있는 것\n\n\n반도체에서 전자와 정공은 가만히 있는게 아니라 생성과 소멸(재결합)을 끊임없이 반복한다\n\n전자가 free상태가 되었다가 또 다른 정공을 만나면 걸로 들어가고 하는 것이 계속해서 반복됨\n자유전자가 생기면 정공도 같이 생기고 이 자유전자가 움직이다가 다른 정공을 만나 재결합하면 또 같이 사라지기 때문에 전체적으로 전기적 중성을 유지하는 것\n이렇게 생길때는 하나씩 생기고 재결합하여 소멸할때도 하나씩 사라지는 것을 EHP(Elec-Hole-Pair) 라고 하더라\n\n\n전자의 움직임은 그냥 자유롭게 돌아다니는 반면 정공의 움직임은 인접한 전자가 그 정공을 채워줌으로써 간접적으로 이동하게 되는 것 이므로 전자가 정공보다 더 빠르고 자유롭게 움직인다\n\n대략 속도가 2배정도 차이난다더라\n\n\n\nEnergy Band §\n\n\n이미 알고있겠지만 원자들이 여러개가 공유결합해서 묶이면 전자 껍질들이 중첩되어 전자가 존재할 수 있는 공간이 하나의 선이 아니라 저렇게 띄를 이루게 됨\n그중에서도 최외각 전자가 존재하는 구역을 Valance band 라고 하고\n자유전자가 존재하는 구역을 Conduction band 라고 한다\n이 Valance band와 Conduction band가 겹쳐져 있으면 최외각 전자가 언제든 Valance band에 들어가 이동할 수 있으므로 이러한 경우를 도체(Conductor) 라고 하는거고\n두 band사이 간격이 멀어 최외각 전자가 Conduction band로 가기 힘들다면 부도체(Insulator) 가 되는 거다\n근데 두 band사이 간격이 애매해 좀만 에너지를 가해줘도 최외각 전자가 Conduction band로 가게 된다\n\nDrift, Diffuse §\n\n전압을 걸어주면 그 전위차에 따라 전류가 흐르는 것을 Drift 전류 라고 한다\n근데 전압 없이도 전자/정공의 밀도차이에 따라 전류가 흐를 수도 있는데 이것을 Diffuse 전류 라고 한다\n\nN-도핑 §\n\n실리콘판에 중간중간 최외각 전자가 하나 더 많은 5족 원소를 끼워넣으면 공유결합에 관여하지 않는 전자가 생기므로 자유전자가 되기 쉬운 전자들이 많아진다\n이렇게 5족 원소를 끼워넣어 순수실리콘보다 자유전자가 많게 만든 반도체를 N-도핑 이라고 한다\n\n이런 5족 원소들을 자유전자를 제공해준다는 의미에서 Donors 라고도 한다\n\n\n순수 실리콘보다 전자가 많다는 의미에서 Negative - Dopping인 것\n\n다만 그렇다고 얘가 음극을 띄는건 아니다 - 전자를 추가한게 아니고 5족원소를 추가한 것이기 때문에 양성자의 전하도 더 많아져 전기적으로는 중성을 띰\n\n\n그렇다고 정공이 아예 없는건 아니다 - 전자가 그만큼 더 많으시다는 거지\n\nP-도핑 §\n\n반대로 3족 원소를 끼워넣으면 공유결합에 관여하는 전자가 적어지기 때문에 그 부분이 정공으로 남게 된다\n3족원소를 끼워넣어 정공이 많게 만든 반도체를 P-도핑 이라고 한다\n\n3족 원소는 정공을 제공해서 전자를 받아들인다는 의미에서 Acceptors 라고도 한다\n\n\n순수 실리콘보다 정공이 많다는 의미에서 Positive-doping\n\n얘도 마찬가지로 정공이 많다는 거지 전기적으로 양극을 띈다는얘기는 아니다 - 전기적으로는 여전히 중성\n\n\n그렇다고 전자가 아예 없는건 아니다 - 정공이 그만큼 더 많으시다는 거지\n\nFermi level §\n\nFermi level의 정의는 전자 존재 확률이 0.5인 곳을 나타내는 선이다\n이것을 의미론적으로 이해해보면\n\n자유전자가 많이 있는 경우에는 전자가 높은 에너지 레벨까지 존재할 수 있으므로 이 Fermi level도 올라간다 - 즉, 자유전자가 많으면 Fermi level은 올라간다\n하지만 반대로 자유전자가 적은 경우에는 전자가 낮은 에너지 레벨에만 채워지므로 Fermi levle도 낮아진다 - 즉, 자유전자가 적으면 Fermi level도 낮아진다\n\n\n따라서 Fermi level은 자유전자가 얼마나 많이 있느냐를 나타냄 - 전자가 몇층까지 채워져 있느냐\n\nN도핑은 자유전자가 많으므로 Fermi level이 높고\nP도핑은 자유전자보다 정공이 더 많으므로 Fermi level이 낮다\n\n\n"},"archives/microelectronics.spring.2021.cse.cnu.ac.kr/10.-다이오드":{"title":"10. 다이오드","links":[],"tags":[],"content":"\n\n                  \n                  충남대학교 컴퓨터공학과 남병규 교수님의 &quot;전자회로&quot; 강의를 필기한 내용입니다. \n                  \n                \n\n\n\n                  \n                  이 문서는 보관이 목적이고, 관리되지 않습니다. 따라서 잘못된 정보가 포함되어 있거나 순서가 뒤죽박죽일 수 있습니다. \n                  \n                \n\nMajority, Minority Carrier §\n\n주된 전류 매개체가 뭐냐에 따라 나눠진다\n\n\n\nP도핑에서는 정공이 메이저가 되고 전자가 마이너가 되는거고\nN도핑에서는 전자가 메이저가 되고 정공이 마이너가 되는 것이다\n\nPN Junction §\n\nPN Junction, 또는 다이오드(Diode) 은 P-도핑의 실리콘과 N-도핑의 실리콘을 접합시켜놓은 것\n전류는 ( N &lt;- P ) 방향으로 흐르고 P도핑인 쪽을 Anode, N도핑인 쪽을 Cathode 라고 한다\n\n이렇게 P와 N을 접합시켜놓으면 무슨일이 일어나느냐 §\n\n처음에는 Diffuse 현상이 일어난다\n\nP는 정공이 많고 N은 적으므로 정공이 N쪽으로 움직이고\n반대로 N쪽은 전자가 많고 P쪽은 적으므로 P쪽으로 밀도차에 의해 흘러가게 된다\n\n\n하지만 이렇게 정공과 전자가 흘러가면\n\nP도핑의 접합부 근처는 정공이 다 N도핑쪽으로 도망가 음이온들이 많아지게 되고\nN도핑의 접합부 근처에는 전자들이 P도핑쪽으로 도망가 양이온들이 많아지게 된다\n\n\n이렇게 이온화가 되면 더이상 전기적 중성이 아니기 때문에 양극을 갖는 N도핑쪽 접합부 → 음극을 갖는 P도핑쪽 접합부 방향으로 자기장이 흘러 더 이상 전자와 정공이 흘러들어오지 못하도록 힘을 가한다\n\n즉, 이 자기장은 이온들 밀도차이에 의한 전압차에 의해 발생하게 된다 - 이것을 붙박이 전압(Buit-in potential) 이라고 하는 것\n잉크물같은 경우에는 한놈이 도망가고 나면 그 옆에있던 놈이 그자리로 와서 채워지고 또 그자리를 옆에놈이 채워지고 하는 식으로 밀도가 동일해질때까지 확산이 일어나지만\n얘의 경우에는 도망가고 채워지고 하는 작업이 어느정도 수준에 다다르면 붙박이 전압이 걸리기 때문에 도망간 자리를 채우지 못하는 현상이 일어남\n실리콘의 경우에는 이 built-in potential이 0.7V정도 걸린다고 한다\n\n\n이렇게 접합부 양쪽으로 이온이 가득해 진 층을 공핍층이라고 한다 - 이곳에는 전자나 정공이 있는게 아니라 이온들만 가득하기 때문에 캐리어가 부족하다는 의미\n\n공핍층의 형성을 Energy band의 관점에서 바라보기 §\n\n\n접합전에는 N타입에는 전자가 많기 때문에 Fermi level인 Ef가 높게 형성되어 있다. 반대로 P타입에는 전자가 적기 때문에 Ef가 낮게 형성되어 있는 것 이다.\n근데 이제 접합을 시키면 접합부 주변의 N타입의 전자들이 P로 흘러가며 N타입의 접합부 주변의 전자가 적어져 Ef가 점점 낮아진다\n그리고 P타입의 접합부는 전자들이 점점 많아지기 때문에 Ef가 점점 높아지게 된다\n그러다가 Ef가 같아지는 시점이 되면 더 이상 붙박이 전압때문에 전자, 정공이 이동하지 못하고 공핍층(SCR)이 생기며 유지되게 되는 것\n\n\n여기서 주목할 점은 Ef가 움직이면서 Ec와 Ev가 어떻게 변화하냐는 것이다\n\nEf의 변화에 따라 Ec와 Ev도 동일하게 움직이게 되는데\nEc와 Ev는 P와N이 접합된 이상 끊어지지 않기 때문에 Ef가 변화하면서 접합부 주변이 휘어지면서 언덕이 만들어지게 된다\n접합한 당시에는 두번째 그림처럼 Ec와 Ev가 평평하게 나타나지만\n점점 전자와 정공이 이동하며 P타입의 Ef가 올라감과 함께 Ec, Ev도 올라가고\n반대로 N타입의 Ec, Ev는 떨어진다\n그렇게 되면서 첨에는 평평하다가 Ef가 변화함에 따라 점점점 휘어지며\n전자, 정공의 이동이 끝나면 저렇게 크게 휘어지게 되며 휘어진 공간에는 캐리어가 존재하지 않기 때문에 저 구간이 공핍층이 되는 것\n즉, 접합 초기에는 휘어진 구간이 작아 공핍층이 작게 형성되는 반면 Ef가 움직임에 따라 점점 많이 휘며 휘어진 구간도 넓어져 공핍층이 넓게 형성되는 것\n\n\n저 그림을 좀 생각해보면 전자들은 저 언덕을 넘어가지 못한다\n\n전자가 에너지를 받아야 더 높은 에너지 준위로 올라가는데 지금은 어떠한 외부 에너지도 가해지지 않고 있으므로\n\n\n정공의 움직임은 전자들의 움직임에 의해 일어나는 상대적인 움직임인 것을 고려해 보면 Ev의 언덕부분의 전자들이 더 올라와 정공을 메꿔줘야 정공이 아래로 움직일 수 있는데 언덕부분의 전자들이 올라오지 못하므로 정공도 아래로 내려갈 수 없는 것이라고 이해하면 된다\n\n순방향으로 전압을 걸었을 때 §\n\nN타입에 음극, P타입에 양극의 전압을 거는 것을 순방향 전압(Forward bias) 을 건다고 한다\n전압을 걸기 전까지는 전자들이 저 붙박이 전압때문에 밀려나 공핍층을 넘어가지 못했다면, 붙박이 전압보다 높은 전압을 걸어주게 되면 저 공핍층을 넘어갈 힘을 가지게 되어 전자들이 다시 넘어가기 시작한다\n마찬가지로 정공들도 붙박이 전압보다 큰 전압이 가해지면 공핍층을 넘어서 넘어가게 된다\n그럼 P타입에는 N타입에서 넘어온 전자들이 점점 많아져 Ef가 점점 높아지고\nN타입에는 P타입에서 넘어온 정공들이 점점 많아져 Ef가 점점 낮아진다\n\n이것은 붙박이 전압보다 더 센 전압을 걸어주게 되면 걸어준 전압에서 붙박이 전압을 뺀 만큼의 전압이 순향향으로 걸리므로 전자, 정공이 다시 이동하기 시작하고 전자와 정공이 이동함에 따라 Ef가 점차 변화하며 공핍층이 없어져 걸어준 전압만큼의 전압이 전자, 정공에게 그대로 걸리는 것으로 생각할 수도 있다\n\n\n\n\n\n따라서 위 그림처럼 Ef가 변화하고 그에 따라 두 타입의 Ec, Ev간 언덕이 없어져 전자들이 흐르게 되는 것\n\n얘는 이렇게도 생각할 수 있다 - N타입쪽은 전자가 들어와 양이온쪽에 채워지고 P타입은 정공이 들어와 음이온에 채워지므로 공핍층이 사라져 전류가 흐르게 되는 것\n\n\n\n다이오드에서의 소수 캐리어 §\n\n\n위 그래프는 다이오드에서 소수 캐리어의 밀도를 나타낸다\n\n즉, 빨간색은 N타입에서의 소수 캐리어 이므로 정공의 밀도를 나타내고\n파란색은 P타입에서의 소수 캐리어이므로 전자의 밀도를 나타낸다\n\n\n보면 넘어간 다음에는 e^(qV/KT) 의 수식을 따라 감소하게 되는것을 알 수 있다\n\n왜냐면 소수 캐리어는 말 그대로 소수이기 때문에 각각의 타입에서 환영받지 못하기 때문에 감소하게 되는 것이다\n그리고 여기서 q, K, T는 상수에 가깝다. 즉, 공핍층으로부터 멀어질 수록 전압에 지수적으로 밀도가 감소하게 되는 것\n\n\n\n다이오드내부에서 전류를 운반하는 캐리어 §\n\n\n다이오드도 하나의 경로기 때문에 여기에 걸리는 총 전류는 일정하다(초록색)\n그리고 전자와 정공 모두 전류를 흘리는데 일조하기 때문에 이 전자와 정공의 밀도 또한 얘네들에 의해 흘려지는 전류와 연관이 있다\n\n즉, 실선에 해당하는 소수 캐리어에 의한 전류는 위에서 본 소수 캐리어의 밀도와 동일한 양상을 취한다 - 공핍층에서 멀어질수록 전압에 지수적으로 감소하게 되는 것\n\n\n근데 총 전류는 일정하므로 (총 전류 - 소수 캐리어에 의한 전류)를 통해 점선에 해당하는 부분인 주류 캐리어에 의한 전류 를 구할 수 있는 것\n\n즉, N타입 에서 정공에 의해 흐르는 전류(실선)가 거리에 따라 점점 감소하는데 총 전류는 일정하므로 정공 대신 전자에 의한 전류는 점점 증가해야되고 이건 P타입에서도 반대로 마찬가지가 된다\n\n\n노란색 부분인 공핍층은 캐리어의 밀도가 변하지 않기 때문에 해당 캐리어의 밀도변화에 의한 전류의 변화가 없다 - 따라서 수평하게 나오게 되는 것\n따라서 저런 그래프가 나오게 되는 것\n\n역방향으로 전압을 걸었을 때 §\n\n반대로 P타입에 음극, N타입에 양극을 거는 것을 역방향 전압(Reverse bias) 이라고 한다\n역방향 전압이 걸리면 전류가 통하지 않는다. 그 이유는\n\nP타입에 음극이 걸리므로 정공들이 접점으로부터 멀어져 접점부에 음전하가 더 많이 생기는 효과가 생기고\nN타입에는 양극이 걸리므로 전자들 또한 접점으로부터 멀어져 접점부에 양전하가 더 많아지는 효과가 생기는 것\n따라서 공핍층이 더 두꺼워지는 효과가 생겨 공핍층 이온에 따른 전기장이 더 세어져(즉, 붙박이 전압이 더 세어져)전류가 흐르기 어려워 지는 것이다\n\n\n다르게 생각해보면 역방향의 전압을 건다는 것은 공핍층에 생긴 붙박이 전압과 같은 방향으로 전압을 거는 것 이기 때문에 더욱이 전류가 흐르기 어려워진다라고도 할 수 있다\n\n\n\n에너지 밴드의 관점에서 이해해보면 N타입에 양극을 걸어주면 전자들이 양극으로 빠져나가기 때문에 전자의 숫자가 적어져 Efn가 더 내려가고\nP타입에 음극을 걸어주면 P타입에 전자가 많아지므로 Efp는 더 올라가게 된다\n따라서 접합부의 Ec, Ev간 격차가 더 심해져 저렇게 더 높은 언덕이 생기게 되는 것\n\n소수 캐리어의 농도 §\n\n\n보면 왼쪽이 N타입(양극), 오른쪽이 P타입(음극)이고 저 Xp는 정공의 농도가 없어지는 지점, Xn은 전자의 농도가 없어지는 시점이다\nN타입의 양극으로부터 주입된 정공은 어느정도까지는 무난하게 접근하다가 강한 붙박이 전압(급한 기울기의 언덕)에 의해 P타입으로 빠른속도로 끌려가게 된다(왼쪽 그림의 N → P방향으로 이동하는 정공의 모습) - 따라서 오른쪽 그림처럼 N타입의 양극으로 주입된 정공이 한동안은 일정한 밀도를 유지하다가 P타입으로 빨려들어가는 정공이 생기는 시점부터 밀도가 줄어들고 0이되는 지점에서 공핍층이 시작되는 것\nP타입에서도 마찬가지의 현상이 벌어져 공핍층에 가까워질 수록 전자의 농도가 줄어들다가 0이 되면 공핍층이 시작되게 되는 것\n다만 이렇게 전자와 정공이 반대편으로 끌려갔다고 해서 전류가 흐르지는 않는다 - 끌려간 전자와 정공은 반대편에서 이온에 포섭되게 되어 반대편의 전극으로 가지는 않는 것\n\n역방항 전압을 걸어줄때 흐르는 미세전류 §\n\n역방향 전압을 걸어줬을때 전류가 흘러야 하지 않음에도 불구하고공핍층 부근에서 생성된 전자, 정공 쌍은 약간의 전류를 흐르게 하기도 한다\n공핍층 주변에 전자, 정공이 생겼다고 해보자 - 얘는 실온에서의 열에너지때문에 생기기도 한다\n공핍층 주변이 아니라면 생겨봤자 다시 다른 전자, 정공이 만나서 쌍소멸된다 - 쌍생성과 쌍소멸의 비중이 같기 때문에 총 전하는 일정하게 유지되는 것\n하지만 공핍층에서 이런 쌍생성이 일어나면 좀 다르다 - P타입에서 발생된 전자는 공핍층의 전기장에 의해 N타입으로 drift되고 N타입에서 발생한 정공은 마찬가지로 전기장에 의해 P타입으로 drift되게 된다 - 전기장에 의한 전류이므로 drift전류이다\n\n근데 지금 N타입에 양극을 걸어주고 P타입에 음극을 걸어준 역방향 전압 상황이므로 이 역전압의 방향과 맞는 미세한 전류가 흐르게 되는 것\n\n\n순방향일때는 언덕이 없어져 전류가 흐르는 것으로 Diffuse전류이고 역방향 미세전류는 언덕을 내려가며생기는 전류이므로 Drift전류란다\n\n정리 §\n\n다이오드에서의 Capacitor적인 성질 §\n\n공핍층의 경우 캐리어가 없기 때문에 부도체나 마찬가지다\n근데 부도체를 가운데에 끼고 양옆에 전하가 걸린 것이 캐패시터와 유사하기 때문에 다이오드는 자연적으로 캐패시터의 성질도 가지게 된다\n이러한 성질은 junction capacitor 라고 한다\n\nBreakdown §\n\n역방향 전압을 씨게 걸어주면 어느지점부터는 역방향 전류가 폭발적으로 흐르게 되는데 이러한 현상을 breakdown 이라고 한다\nAvalanche breakdown(눈사태 현상) : 강한 역전압을 걸어주게 되면 언덕의 기울기가 매우 가팔라져 공핍층에서 전자들이 이동하는 속도가 빨라지게 된다\n\n근데 얘가 그냥 가는게 아니고 원자들에게 부딪쳐 원자들이 파손돼 원자들에 포섭되어있던 전자도 같이 쏟아져 나오게 된다\n이렇게 이동하는 전자들이 많아져 전류도 세지게 되는 것\n즉, 정리해보면 역방향 전압에서 발생하는 미세전류가 전압이 쎄지면 크게 흐르는데 이 과정에서 원자에 포섭되어있던 전자와 충돌하며 그놈까지 같이 튀어나와 강한 전류가 흐르는 것\n결국에는 다이오드의 수명이 줄어들게 된다\n\n\nTunneling(Zener) breakdown : 전자의 파동성때문에 부도체를 일부 통과하는 tunneling현상에 의해 생기는 역전류.\n\n근데 이제 공핍층도 부도체라고 생각할 수 있으므로 이 공핍층을 tunneling현상으로 빠져나와 흐르는 역전류라고 할 수 있다.\n부도체의 두께, 그리고 부도체와 도체 간의 에너지 장벽의 차이에 따라 지수적으로 통과하는 양이 감소하게 된다\n그런데 도핑을 고농도로 하면 공핍층의 두께가 작아지게 된다(그냥 이해하지말고 받아들여라 - 고농도이므로 이온들도 고농도로 포진하게 돼 결국에는 같은 수의 이온이 생겨도 폭이 좁아지게 된댄다)\n이 공핍층도 하나의 부도체로 생각할 수 있는데 이 공핍층의 두께가 작아지므로 터널링에 의한 전자의 이동이 더 수월해 전압을 조금만 높여도 역전류가 많이 생길 수 있게 된다\n얘는 원자를 파손시키는게 아니므로 다이오드의 수명은 줄어들지 않는다.\n\n\n\n\n\n위 그림으로 이해하면 된다 - tunneling현상에 의해 저 에너지 준위 간의 공간을 뛰어넘음으로 인해 생기는 역전류를 의미하며\n고농도로 도핑할수록 공핍층의 밀도도 늘어나 공핍층의 부피는 줄어들어 저런 tunneling현상이 더 잘 일어나게 되는 것\n\n전류 흐름 정리 §\n\n\n일단 순방향일때는 붙박이 전압을 넘기 전까지는 천천히 전류가 증가하다가 붙박이를 넘으면 폭발적으로 흐름\n그리고 역방향이 되면 역방향 미세전류가 흐르다가 일정 전압을 넘어서면 breakdown이 걸려 폭잘적으로 흐른다\n\nAC-DC 정류 회로 §\n\n\n처음에 전압이 올라가면 캐패시터는 비워져있으므로(따라서 캐패시터는 현재 전압이 0이므로) 순방향 전압이 다이오드에 걸려 캐패시터에 물이 채워짐과 동시에 전압이 출력된다\n그러다가 전압이 낮아져 캐패시터의 전압보다 낮아지게 되면 다이오드에서는 역방향이 걸려 차단하게 된다\n그럼 차단된 동안에는 캐패시터가 점점 자신의 전압을 소비하면서 대신 전압을 걸어주게 되어 여전히 전압의 방향이 바뀌지 않고 같은 방향으로 전압이 출력된다\n그러다가 다시 전압이 올라가 캐패시터의 전압보다 높아지면 다시 다이오드에 순방향이 걸리므로 다시 캐패시터가 소비한 만큼 채우며 전압이 출력된다\n\n\n이 동작을 반복하며 전압의 방향이 바뀌지 않고 계속 이어지게 되는 것이다 - 다만 캐패시터가 충전-살짝 방전을 반복하므로 전압이 일정하게 유지되지는 않는다\n\nLED §\n\n순방향에서 전자가 정공에 들어가며 에너지를 방출하는데 이 에너지의 주파수가 가시광선에 해당하면 빛이 나므로 빛을 방출하는 다이오드다 해서 LED가 되는 거다\n"},"archives/microelectronics.spring.2021.cse.cnu.ac.kr/11.-트랜지스터":{"title":"11. 트랜지스터","links":[],"tags":[],"content":"\n\n                  \n                  충남대학교 컴퓨터공학과 남병규 교수님의 &quot;전자회로&quot; 강의를 필기한 내용입니다. \n                  \n                \n\n\n\n                  \n                  이 문서는 보관이 목적이고, 관리되지 않습니다. 따라서 잘못된 정보가 포함되어 있거나 순서가 뒤죽박죽일 수 있습니다. \n                  \n                \n\n트랜지스터의 역할 §\n\nAmplify : 신호를 증폭시켜줌\nSwitch : 신호를 끄고 킬 수 있음\n트랜지스터만 증폭기능이 있기 때문에 active element(능동소자) 라고 한다\n\n트랜지스터의 종류 §\n\nBipolar Junction Transistor(BJT) - 실리콘과 게이트를 직접 연결 - 옛날유물\nMOSFET - 실리콘과 게이트를 절연체를 두고 연결 - 싸고 집적하기 좋아 현재 사용하는 트랜지스터\n\nMOSFET §\n\n\nP타입에 절연체(insulator) 를 통해 전극이 붙어있는 형태를 갖는 것이 제일 큰 특징이다\n\n이런 절연막을 통한 전극구조를 MOS라고 부른다\n위 그림에서 게이트와 P타입 사이에 있는 저놈이 절연체임\n\n\n이런 절연막을 통해 얻어낼 수 있는 것은 이 절연막으로 인해 캐패시터적인 특성을 얻게 된다 - 전극|절연체|P타입 이렇게 연결되므로\n\n이러한 구조를 MOSCAP이라고 부르고 여기의 P양쪽에 N을 붙이면 이게 MOSFET 이 된다\n\n\n소스랑 드레인은 구조적으로 구분되어 있는게 아니고 전압을 어디에 걸어주느냐에 따라 결정된다\nBody에는 Gate 와 반대의 전압을 걸어줘야 PN접합부에 역방향이 걸려 Body로 전류가 빠져나가지 않고 드레인으로 가게 된다\n\nN, PMOS §\n\nNMOS : 양쪽에 N 타입을 도핑한 것\n\n순방향일때 전자가 끌려와서 전류가 흐르는 구조 - 양쪽에 N타입이 있으므로 길이 열리려면 전자가 끌려와야됨\n가운데에 양극을 걸어줘야 전류가 흐른다\n소스에서 전자가 공급되어야 하므로 소스가 드레인보다 전압이 낮다(실제로는 전자는 음극에서 양극으로 흐르므로 소스에 전자가 공급되려면 소스에 음극을 걸어줘야 전자가 공급된다) - 따라서 드레인 → 소스로 전류가 흐르게 된다\nNMOS는 양쪽에 N타입을 도핑했고, 양쪽의 N타입을 연결해야되기 때문에 전자를 가지고 길을 열고, 전자를 끌여들여야 되기 때문에 게이트에 양극을 걸어줘야되고, 소스에서 전자를 공급받아야되기때문에 소스에 낮은전압을 걸어 드레인 → 소스로 전류가 흐른다로 기억할 것\n\n\nPMOS : 양쪽에 P타입을 도핑한 것\n\n순향향일떄 정공이 끌려와서 전류가 흐르는 구조 - 양쪽에 P타입이 있으므로 길이 열리려면 정공이 끌려와야 됨\n가운데에 음극을 걸어줘야 전류가 흐른다\n소스에서 정공이 공급되어야 하므로 소스가 드레인보다 전압이 높다(정공은 양극에서 음극으로 흐르기 때문에 소스에 양극이 걸려야 한다) - 따라서 소스 → 드레인으로 전류가 흐르게 된다\nPMOS는 양쪽에 P를 도핑했고, 양쪽의 P를 연결해주기 위해 정공을 끌어와야 되고, 정공을 끌어오기 위해 게이트에 음극을 연결해야 되고, 소스로 정공을 공급해줘야되기때문에 소스에 높은전압을 걸어 소스 → 드레인으로 전류가 흐른다라고 기억할 것\n\n\n\nCMOS §\n\nNMOS와 PMOS모두 각각의 장단점이 있다 - 각각 효율적인 경우가 있고 아닌 경우가 있다 이거다\n그래서 NMOS와 PMOS를 둘 다 적절히 섞어서 사용해 서로의 단점을 상쇄시키게 하는데 이걸 CMOS라고 한다 - NMOS와 PMOS를 둘 다 사용하는 것을 CMOS라 하는 거\n\nNMOS 트랜지스터의 동작 §\n\nPMOS트랜지스터는 이와 반대로 동작한다고 생각하면 되겠쥬?\nAccumulation → Depletion → Inversion의 세 과정을 거쳐서 Channel(전선, 물길 등등으로 이해해라)이 생성된다 - 시험각\n\n\nAccumulation §\n\nAccumulation : 게이트에 음극을 연결하거나 아무 전극도 연결하지 않은 상태처음에는 아무 전극도 걸어주지 않았기 때문에 양쪽의 N타입 사이에는 정공이 많이 있게 된다(가운데에는 P타입 이므로)\n\nDepletion §\n\nDepletion : 게이트에 양극을건 직후의 단계그러다가 게이트에 양극을 걸어주면 정공들이 밀려나게 된다\n\nInversion §\n\nInversion : 게이트에 양극을 걸어 channel이 생긴 단계정공들이 물러나고 그 쪽에 전자가 몰리면서 P타입이지만 마치 N타입 인것마냥 작동한다 - 따라서 두 N타입 가운데에 N타입이 생긴 격이므로 전류가 흐르게 된다\n\n문턱전압 - Threshold voltage §\n\nV-oxide : MOS cap에 전압을 걸때는 가운데 절연층에 해당하는 전압보다 높은 전압을 걸어줘야 한다(1미터 물탱크에 물을 담을때에는 1미터보다 높이 올라가서 물을 부어야 되는것으로 이해하면 됨)\nV-depletion : 정공을 몰아내는데 필요한 전압\nV-inversion : 전자들을 끌어오는데 필요한 전압\n이 세 전압을 더한 것이 V-threshold 이며 이 전압보다 큰 전압을 걸어줘야 가운데 channel이 생겨 소스와 드레인이 연결되게 된다\n평균적으로 0.4볼트정도 된댄다\n그리고 NMOS의 경우 소스는 전압이 낮아야되므로 게이트의 경우에는 소스보다는 전압이 높아야 된다\n근데 이 소스와 게이트의 전압차이는 문턱전압보다 높아야 된다 - 낮으면 channel이 생기지 않으므로\n따라서 Vgs를 게이트와 소스와의 전압차라고 하고 Vth를 문턱전압이라고 할때 전류가 흐르기 위해서는\n\nVgs = Vg - Vs &gt; Vth 여야 한다는 것\n즉, Vs보다 Vth만큼 큰 전압을 Vg에 걸어줘서 channel을 열고 Vg보다도 더 큰 전압을 Vd에 걸어주면 channel도 열리고 전압차도 존재하기 때문에 드레인 → 가운데 P타입의 상부 → 소스 이렇게 전류가 흐르게 되는 것\n\n\n\nNMOS 트랜지스터에 흐르는 전류 §\n구조적 특징에 따른 전류 §\n\n\n소스와 드레인의 전압차에 의해 전류가 흐르므로 당연히 drift 전류가 흐른다\nL(length) : 소스와 드레인 사이의 거리(가로) - 전류가 흘러야되는 channel의 거리\nW(width) : 게이트의 크기(세로) - 전류가 흐르는 channel의 폭\n당연히 거리에는 반비례하고 폭에는 비례해서 전류가 흐른다 - Ids 비례 W / L - 전류는 NMOS에서는 드레인에서 소스로 흐르므로 ds로 표기한다\n산화막의 두계에도 전류가 관련된다 - 산화막의 두께를 tox라고 하는데 이게 크면 P쪽에 전자가 모이는 것이 힘들어지므로 channel도 잘 안생기게 된다 - Ids 반비례 tox\n\n얘도 결국에는 캐패시터의 역할이므로 Ids 비례 C(캐패시턴스) 라고도 말할 수 있다\n\n\nP타입 결정의 균일도에도 영향을 받는다 - 균일하게 결정이 배열되있으면 전자가 더 이동하기 쉬워 전류가 높아지고 균일하지 않으면 전자이동에 방해를 받아 전류가 낮아지게 된다 - 이때의 균일도는 Mobility - 뮤 로 표기한다 - 따라서 Ids 비례 뮤 의 식이 성립한다\n\nVgs, Vds와 전류와의 관계를 각각 살펴보면 §\n\n트랜지스터의 경우에는 다른 소자와는 다르게 전압을 걸어주는 곳이 두군데이다 - 게이트와 드레인\n게이트 전압이 전류에 미치는 영향을 보면 게이트 전압 중 문턱전압은 소실되므로 이것을 뺀 Ids 비례 (Vgs - Vth) 가 성립한다\n그리고 드레인에 흐르는 전압이 전류에 미치는 영향을 보면 얘를 계산해봤더니 Vds 가 Vgs - Vth 와 같아질때 최대 전류가 흐른다\n따라서 종합해보면 Ids 비례 (Vgs - Vth)^2 의 관계가 성립하게 된다\n왜 Vds = Vgs - Vth 가 되는지는 Pinch-Off 라는 현상때문에 그렇게 된다\n\n전자는 게이트 전압에 의한 힘과 드레인 전압에 의한 힘을 둘 다 받게 된다\n그래서 소스에 가까이 있는 전자의 경우에는 게이트쪽의 힘을 많이 받게 되고(드레인에 의한 힘은 거리가 멀어서 약하므로) 드레인에 가까이 있는 전자의 경우에는 드레인쪽의 힘을 많이 받게 된다\n그래서 소스에 가까운 전자는 느리게 움직이고 드레인에 가까운 전자는 빠르게 움직이게 된다\n따라서 소스쪽은 전자가 느리게 움직여 전자가 포화되고 드레인쪽은 전자가 빠르게 움직여 전자가 고갈되게 된다 - 이 고갈되는 것을 Saturation 이라고 한다\n근데 고갈되게 되면 channel이 점차 끊어지는 효과가 되어 전류가 흐르기 힘들어진다 - 그래서 전류가 더이상 커지지 않고 최대값으로 일정하게 유지된다\n포화 전까지 전압과 전류가 비례에 가깝게 변화하는 구간을 Linear 혹은 triode 구간이라고 한다 - 이때에는 트랜지스터가 저항처럼 움직이게 된다(저항도 V=IR 에 의해 비례하므로)\n그리고 포화 후 전류가 일정하게 유지되는 구간을 Saturation 구간이라고 한다\n이때 이 고갈이 시작되는 시점은 게이트쪽 힘과 드레인쪽 힘이 같아지는 시점에서부터 시작되게 되므로 드레인과 게이트에 같은 전압을 걸어줘 고갈이 시작되지 않게 하는 것이 최대의 전류를 흐르도록 하게 하는 것이다\n\n\n\n구조적특징과 Vgs, Vth를 고려한 전류 공식 §\n\n\n따라서 트랜지스터의 전류공식은 위와 같다 이건 외워야된댄다\n\n종합 - Vds, Vgs에 따른 전류의 변화 §\n\n\nVgs는 Vth이후부터 이차함수의 곡선으로 증가한다\nVds는 Linear구간에서는 증가하다가 Saturation구간에서는 일정해진다\n\n이런 Saturation구간에서 전류가 일정해지는 것은 이것이 전류원으로 활용될 수도 있다는 것을 의미한다\n\n\n이것을 종합한게 오른쪽의 그래프이다\n\n일단 빨간색 선은 Vds와 전류와의 관계 그래프이다\n그리고 파란색 선은 Vgs와 전류와의 관계 그래프이다\n그럼 이렇게 생각하면 된다 - Vgs가 결정되면 저 파란색 선에 의해 그때의 전류도 결정되겠쥬?\n그럼 그때의 Vgs까지 Vds가 증가할때까지는 Linear하게 동작하고 그 이후부터는 Saturation하게 동작하는 것이고\nVds가 증가함에 따라 전류는 언제까지 증가할것인가가 저 Vgs를 이용해 구한 전류까지 증가하다가 그 전류, 그 Vgs의 지점에 도달하면 일정하게 전류가 흐르는 것이다\n정리해보면 파란색 선이 Vgs를 이용해 빨간색 그래프가 Linear에서 Saturation으로 바뀌게 되는 지점을 구하게 해주는 그래프고 빨간색 선은 말그대로 Vds에 따른 전류의 그래프이다.\n그리고 빨간색 선이 여러개인 이유는 Vgs의 값에 따가 빨간색 그래프가 저렇게 왔다갔다 한다는 것을 나타낸 것이라고 할 수 있다\n\n\nCut-off 구간은 Vgs가 Vth보다 낮아 전류가 흐르지 않는 상황을 의미한다\nAmplifier(증폭) 으로 동작하게 할 때는 Saturation(포화구간)을 이용한다\nSwitch(스위치) 으로 동작하게 할 때는 Cut-off와 Linear구간을 오가며 스위칭을 하는 것이다\n\nVds와 Vgs간의 관계 §\n\n\n오른쪽 위를 보면 캐패시터가 하나 달려있는데 걍 무시해라 - Vds로 걸어주는 전압인데 전원처럼 계속 일정한 전압을 걸어주는게 아니라 배터리나 캐패시터처럼 사용할수록 고갈되는 놈임\n따라서 Vgs가 점점 열리면 물통의 밸브가 점점 열리는 것이므로 Vds의 전압은 점점 낮아지게 되는 것 이다\n근데 보면 Cut-off구간에서는 밸브가 아직 제대로 열리지 않은 것이므로 전압이 안떨어지다가\n밸브가 열리게 되면 Saturation구간에서부터 시작한다 - Vds의 전압이 올라가는 구조가 아니고 떨어지는 구조이므로 위에서 본 그래프를 오른쪽 → 왼쪽으로 읽어야됨\n이제 Saturation구간에서는 전류가 일정하게 흐르기 시작하므로 전압이 급격하게 떨어진다\n그러다가 전압이 더 떨어져 Linear구간에 접어들면 흐르는 전류가 점차 감소하기 때문에 전압도 완만하게 떨어지는 것\n근데 보면 Vgs가 0일때 Vds가 1이 되고 Vgs가 1일때 Vds가 0이 되므로 이것은 NOT게이트로도 활용이 된다 - Inversion의 역할도 하게된다 이말이야\n\nChannel-length modulation §\n\n\n포화돼서 전류가 일정하게 흐른다고 했는데 실제로는 전류가 조금씩은 증가한다\n이건 왜냐면 고갈된 부분은 전자가 아주 빠르게 이동하기 때문에 고갈되는건데 그러한 고갈범위가 늘어난다는 것은 전자가 빠르게 이동하는 구간이 넓어지므로 전류도 살짝 증가하는 효과가 난다\n이 효과는 람다 로 표현하며 이것을 수식에 포함시키면 다음과 같다\n\n\n\n시험때는 이제 이 효과를 감안해서 풀어라 / 무시해서 풀어라 이렇게 나올테니 그것에 따라 수식을 사용하면 된다 - 결국에는 이 식도 외워야된다는 소리임\n이렇게 포화상태에서 전류가 변화하는건 좋은 것이 아니다 - 전류가 일정하다는 것을 이용해서 전류원 등으로 사용을 하므로\n"},"archives/microelectronics.spring.2021.cse.cnu.ac.kr/12.-등가회로":{"title":"12. 등가회로","links":[],"tags":[],"content":"\n\n                  \n                  충남대학교 컴퓨터공학과 남병규 교수님의 &quot;전자회로&quot; 강의를 필기한 내용입니다. \n                  \n                \n\n\n\n                  \n                  이 문서는 보관이 목적이고, 관리되지 않습니다. 따라서 잘못된 정보가 포함되어 있거나 순서가 뒤죽박죽일 수 있습니다. \n                  \n                \n\n등가회로 §\n\n이전에 배운 회로를 분석하는 방법(KCL, KVL등등)은 수동소자 에 대해 분석하는 일인데 트렌지스터는 능동소자 이기 때문에 앞에서 배운것들을 적용시키지는 못한다\n그래서 저 트랜지스터의 기능을 수동소자들의 조합으로 표현하는 것을 등가회로라고 말하며 이렇게트랜지스터는 등가회로로 전환한 다음 회로이론으로 회로를 분석하게 된다\n\n소신호모델, 대신호모델 §\n\n\n대신호모델(Large Signal Model) : 신호의 진폭이 큰 경우\n\n트랜지스터를 가지고 증폭을 하려 하는데 신호가 이미 크다면 증폭할 필요가 없다\nVgs와 전류의 곡선에서 Vgs에 따라 전류가 이차함수적으로 중가하는데 원 신호가 왜곡되게 된다\n만약에 비례관계면 x축의 변화와 동일한 파형으로 y축으로 나올텐데 제곱관계이기 때문에 x축의 변화와 다른 파형으로 y축으로 나온다\n따라서 대신호모델은 별로 신경쓰지 않는다\n\n\n소신호모델(Small Signal Model) : 신호의 진폭이 작은 경우\n\n얘는 입력신호가 작기 때문에 증폭할 필요가 있음\n그리고 x축의 변화가 작으므로 이것은 제곱관계이긴 하지만 비례관계와 유사하기 때문에 왜곡이 적음\n따라서 소신호 모델을 주로 사용하게 된다\n얘는 AC Model 이라고도 한다\n따라서 얘는 Vgs에 전류가 선형적으로 비례하는 것으로 근사가 가능하다 - 선형근사라고 함\n\n\n\n소신호모델에서 전류와 전압 §\n\n\n소신호 모델에서는 Vgs와 I는 비례하게 되는데 이때의 비례상수 가 gm이다\n즉, Ids = gm * Vgs 가 되는 셈\ngm은 결국에는 기울기기 때문에 Vgs-I 곡선에서 특정 위치에서의 미분값으로 구할 수 있다\n얘를 의미론적으로 이해해보면 gm이 클때는 같은 전압을 걸어줘도 큰 전류가 흐르고 작을때는 작은 전류가 흐름\n전압은 GS에 걸었는데 전류는 DS로 흐른다 - 이렇게 전압을 걸어준 노드와 전류가 흐르는 노드가 다르다는 의미로 저 m이 붙는 것\ngm = Ids / Vgs 인데 컨덕턴스(C) = 저항의 역수 = I / V 이므로 이것도 전류가 얼마나 잘 흐르냐의 척도인 conductance의 일종이라고 할 수 있고\n저 다르다는 속성때문에 trans를 붙여 gm을 Transconductance라고도 부른다\n\n\n\nVgs로 미분해주면 첫번째 수식이 나온다\n그리고 Vgs - Vth를 Id로 표현하면 두번째 수식이 나오고\n2unCox를 Id와 Vgs - Vth로 나타낸 것이 세번째 수식이다\n\n소신호모델에서의 저항 §\n\n\n\n포화상태에서 Channel length modulation에 의해 전류가 조금씩 흐를때 이때의 기울기 역수를 ro 라고 한다 - 이것도 일종의 저항이기 때문\n얘는 결국에는 저항 = 전압 / 전류 인데 저 기울기는 전류 / 전압이므로 역수를 취한 것과 같다\n얘는 이제 뭔의미냐면 ro가 클수록 전류가 잘 안바뀌는 것이므로 완벽하게 포화되는 것이도 작을수록 포화되어도 전류가 잘 바뀌는 것으로 엉성하게 포화되는 것을 말한다\n얘는 이제 DC저항이 아니고 AC저항이기 때문에 전류의 변화가 어렵도록 만드는 저항의 역할을 한다\n그리고 얘는 Vds에 대한 Ids의 관계이므로 입출력 노드가 같아 trans라는 말이 안붙게 되는 것 - 그냥 output resistance 라고 해서 ro 라고 표현하는 것이다\n\nSupply Voltages §\n\n이제는 전압을 회로에 그릴때 배터리 기호 대신 VDD, VSS 의 용어를 사용한다\nVDD : 배터리가 인가해주는 가장 높은 전압\nVSS : 배터리가 인가해주는 가장 낮은 전압\n그리고 보통은 최소전압을 0V, GND로 표현했었는데 전압은 전위차이기때문에 VSS가 0이 아닌 값을 가질 수도 있다\n\nAC Ground §\n\n\n보면 첫번째 그림은 DC를 기준으로 변화하고 있으므로 DC + AC라고 할 수 있다\n근데 DC는 그냥 값일 뿐 아무런 정보도 전달하지 않는다 - 실제로 정보를 전달하는 것은 저 변화에 의한 AC이므로\n따라서 그냥 DC전압도 GND로 취급해 0으로 만들어 AC만 생각하는 것을 AC Ground라고 한다\nDC전압을 GND(0)로 취급해 AC만 생각해서 회로를 분석하는 것을 AC Model 이라고 하는 것 - 회로에서도 DC는 GND(0)로 생각한다\n\n트랜지스터의 전류원으로써의 기능 §\n\n\nNMOS, PMOS모두 포화상태일때 전류원으로의 기능을 하며 그때의 전압관계는 빨간색 글씨와 같다\n\nNMOS, PMOS의 등가회로 §\n\n\ngm과 ro를 반영한 NMOS, PMOS의 등가회로는 오른쪽과 같이 나타내진다\n근데 결국에는 위아래로 비교해보면 동일하다는 것을 알수 있다 - NMOS든 PMOS든 동일한 등가회로가 나옴\n"},"archives/microelectronics.spring.2021.cse.cnu.ac.kr/13.-트랜지스터-Biasing":{"title":"13. 트랜지스터 Biasing","links":[],"tags":[],"content":"\n\n                  \n                  충남대학교 컴퓨터공학과 남병규 교수님의 &quot;전자회로&quot; 강의를 필기한 내용입니다. \n                  \n                \n\n\n\n                  \n                  이 문서는 보관이 목적이고, 관리되지 않습니다. 따라서 잘못된 정보가 포함되어 있거나 순서가 뒤죽박죽일 수 있습니다. \n                  \n                \n\nBiasing §\n\n트랜지스터가 제대로 작동할 수 있도록 전압을 잡아주는 일\n전압은 이 아래 두가지의 기능을 잘 수행하도록 잡아줘야됨\n\n기능1 : turn on 일단 MOSFET트랜지스터가 켜지도록 해야됨\n기능2 : saturation 포화상태에서 동작하도록 해야됨\n\n\n여기서 전압을 잡아주는 것은 GND, 즉 DC전압을 적당히 세팅해주는 것을 의미한다\n즉, DC전압을 적당히 줘서 트랜지스터가 켜져있고 포화상태에 들어가 있는 상태를 만들고 AC신호를 흘려서 증폭의 역할을 하게 하는것\n\nVgs, Vds Biasing §\n\n\nVDD와 출력단자 사이에 저항 Rd를 넣어야 VDD의 전압이 바로 출력으로 나가지 않는다 - 이유는 묻지 마셈 - 걍 저기다가 저항을 넣으면 VDD와 출력단자가 분리되는 효과를 준댄다\ngate를 입력 drain을 출력전압으로 보통 사용한댄다 - 그래서 Vgs로 교류전압을 넣어주면 Vds로 증폭된 교류전압이 나오는 구조\n\n\n\nCut-off구간이나 기울기가 -1이 되기 전까지는 증폭이 일어나지 않는다 - Cut-off구간에서는 아예 DC전압이 출력되고 기울기가 -1보다 크지 않은 지점까지는 DC + AC가 출력되지만 증폭이 되지 않고 오히려 감축된다\n보면 saturation과 linear의 경계쯤에 있는 놈은 saturation쪽은 경사가 가파른데 linear는 경사가 완만하기 때문에 saturation쪽인 위로 증폭은 잘 되지만 linear쪽인 아래쪽은 증폭이 잘 안되게 된다 - 즉, 왜곡이 일어남\n따라서 saturation구간에 Vgs를 잡아 제대로 왜곡없이 증폭되게 해야 한다 - 이것을 biasing 이라고 하는 것\n근데 보면 AC + DC 이기 때문에 고정된 DC를 기준으로 AC가 왔다갔다 하는거라고 보면 된다\nbiasing이라는 것은 저 Vgs의 AC + DC 중 DC를 적당히 잡아 saturation의 구간에서 왔다갔다 할 수 있도록 하는 것\n\n\n\n입력신호를 바로 Vgs로 넣어주면 너무 전압이 낮기 때문에 cutoff구간에서 놀게 된다\n하지만 그렇다고 VDD를 입력신호랑 합쳐서 넣게 되면 이번에는 너무 커서 linear구간에서 놀게 된다\n그래서 R1라는 저항을 추가하고 GND를 추가해 전류가 흐르게 해주면 전압강하가 일어나게 된다\n하지만 R2저항이 없으면 바로 GND와 직결돼 0V가 되므로 R2저항을 추가해 적당히 전압강하가 일어나게 하는 것\n\n\n\nRs를 추가해 소스의 전압을 올려 Vgs의 전압을 낮춰줘 saturation구간에 포함될 수 있게 해주는 기법도 있는데 이것을 축태, Degredation 이라고 한다\n위 그림에서 증폭률(A)는 gm * RD 이기 때문에 RD를 최대한 올려주는 것이 중요하다.\n\n근데 Rd를 너무 올리게 되면 Vds가 너무 작아져 Vgs보다도 작아지면 Linear구간에 빠지기 때문에 Linear에 빠지지 않는 선에서 Rd를 정하는 것이 중요하다\n\n\nVDD와 Vth는 항상 주어진다\nVy는 Saturation관계식인 Vy &gt; Vx - Vth 로부터 구하고 Id는 트랜지스터 공식으로부터 구한다\ngm구하는 공식 외워놔야된다 - gm 비례 W / L 를 이용해 gm을 구함\n기호를 봤을 때 화살표가 흘러들어오는 방향이면 PMOS, 흘러나가는 방향이면 NMOS이다\nPMOS의 경우에는 Vs가 Vg보다 높기 때문에 Vgs는 음수가 나온다\nsaturation상태에서는 Vds가 바뀌어도 Ids는 일정하기 때문에 Id의 전류는 Rd저항과는 무관하고 Vgs와만 관련된다 - 꼭 기억할 것\n트랜지스터의 출력 임피던스는 당연히 0에 가까울 수록 좋겠제? 근데 트랜지스터의 입력 입피던스는 클수록 좋다\n\n뭔 소린지 모르겠는데 트랜지스터로 들어오는 전기에 붙어있는 저항과 입력저항의 비율로 트랜지스터에 입력되는 전기가 결정되는데 입력저항이 무한대면 들어오는 전기에 붙어있는 저항이 없어지는 효과이므로 무한대면 좋다? 걍 외워라 이건\n그래서 게이트에 절연체가 붙어있어 임피던스가 무한이므로 게이트를 입력단자로 쓰는 것이 현명\n그리고 트랜지스터에는 ro저항이 있는데 saturation을 시켜주기 위해 ro저항은 당연히 크다 - 근데 출력 임피던스는 작아야 좋으므로 ideal하지는 않다\n\n\n\n\n\n소스쪽에서 들여다본 저항은 1 / gm 이다\ngm이 클수록 전류를 잘 흘려주기 때문에 1 / gm 은 작은 값이다\n\n\n\n따라서 이렇게 된다\n\n게이트에서 본 임피던스는 임피던스때문에 무한대이다\n드레인에서 본 임피던스는 ro이기 때문에 큰값이다\n소스에서 본 임피던스는 1 / gm 이기 때문에 작은 값이다\n\n\n"},"archives/microelectronics.spring.2021.cse.cnu.ac.kr/14.-CS-증폭기":{"title":"14. CS 증폭기","links":[],"tags":[],"content":"\n\n                  \n                  충남대학교 컴퓨터공학과 남병규 교수님의 &quot;전자회로&quot; 강의를 필기한 내용입니다. \n                  \n                \n\n\n\n                  \n                  이 문서는 보관이 목적이고, 관리되지 않습니다. 따라서 잘못된 정보가 포함되어 있거나 순서가 뒤죽박죽일 수 있습니다. \n                  \n                \n\n신호 증폭하기 §\n\n진폭을 키우는 일을 말함\n작은 신호를 수신한 경우 그걸 키워주기 위해 사용\n아날로그 신호의 경우 이것을 증폭시켜 디지털 신호를 만들어낸다 - 증폭후 윗단을 잘라 각진형태의 디지털 신호를 만들어낸다\n그리고 이런 디지털 신호를 NOT게이트같은걸로 처리하게 되는 것\n푸리에 급수를 이용하면 어떤 신호도 정현파로 바뀌기 때문에 정편파의 증폭만 가능하면 임의의 신호도 증폭할 수 있는 것\n\n증폭기의 종류 §\n\n여기서 Common 이라는 것은 AC GND를 의미한다\n즉, Common Source(CS) 는 소스가 GND가 되는 증폭기를 의미한다\n그리고 Common Gate(CG) 는 게이트가 GND가 되는 증폭기를 의미하는 것\n또한 Source Follower(SF), Common Drain(CD) 는 드레인이 GND이 되는 증폭기를 의미하는 것이다\n\n얘는 출력이 소스로 넣어준 것과 거의 동일하게 나오기 때문에 source follwer라고 부르는 것\n\n\n\nCommon Source §\n\n얘는 입력과 위상이 180도 바뀌어서 증폭되는 형태로 나온다\n\n\n\n트랜지스터의 경우 전압을 입력받아 전류를 출력하므로 전류를 전압으로 바꿔주기 위해 저 Rout을 다는 것 - 옴의 법칙에 따라 전류가 저항이랑 만나 전압이 되는 것\n저렇게 트랜지스터에 저항을 다는 것을 증폭기를 구성핟나고 하더라\nVout근처에 저 회색 캐패시터는 전선이 존재하기 때문에 기생적으로 생기는 캐패시터이다\nVin이 올라가 문이 열리면 물이 빠져나가므로 캐패시터가 비워져 Vout은 아래루 감소하는 것\n반대로 Vin이 내려가 문이 닫히면 다시 물이 채워지므로 캐패시터도 채워져 Vout도 위로 올라가는 것이다.\n\n\n\ngm이 클수록 물이 더 많이 빠져나가니까 출력전압이 더 아래로 떨어지고 Rout이 클수록 물이 빠져나갈때 물을 더 보충해주지 않으니까 출력전압이 아래로 떨어진다 - 이렇게 출력이 아래로 떨어질 수록 더 많이 증폭되는 셈임\n이렇게 입력과 출력이 반대이므로 증폭과 동시에 NOT게이트로의 동작을 하게 되는 것이다\n"},"archives/microelectronics.spring.2021.cse.cnu.ac.kr/15.-CMOS":{"title":"15. CMOS","links":[],"tags":[],"content":"\n\n                  \n                  충남대학교 컴퓨터공학과 남병규 교수님의 &quot;전자회로&quot; 강의를 필기한 내용입니다. \n                  \n                \n\n\n\n                  \n                  이 문서는 보관이 목적이고, 관리되지 않습니다. 따라서 잘못된 정보가 포함되어 있거나 순서가 뒤죽박죽일 수 있습니다. \n                  \n                \n\nGain구하기 §\n\n아날로그 신호의 증폭에는 small signal이기 때문에 소구간을 미분값으로 근사해 증폭률인 gain을 구하지만\n디지털 신호의 경우에는 0과 1이므로 big signal이기 때문에 saturation 전체를 하나의 직선으로 근사해 gain을 구한다\n\nCMOS §\n\nCMOS의 경우에는 transition gain이 매우 가파르고\ntransition 전후로는 최고와 최저로 전압이 일정하게 유지되는 full-swing이 이루어지므로 디지털 신호를 처리하기에 용이하다\n그리고 transition gain이 매우 가파르기 때문에 small signal이 더 잘 증폭되는데\n\n\n\n그때의 증폭률이 다음과 같다 - small signal gain\n\nParasitic RC §\n\nLinear 구간에서는 얘가 약간 저항처럼 구동하기 때문에 이떄의 저항과 도선의 저항을 트랜지스터에 기생하는 저항이라 해서 Parasitic R이라고 하고\nMOScap이나 도선간 간격때문에 생기는 캐패시턴스를 Parasitic C라고 한다\n\nRise &amp; Fall Time, Propagation Delay §\n\nRise Time : 최대 전압의 10%에서부터 90%까지 올라가는데 걸리는 시간\nFall Time : 마찬가지로 90%에서 10%까지 걸리는 시간\nPropagation Delay : rise, fall시에 최대전압의 50%가 되는 시간의 차이 - 절반 충전 / 방전되기까지의 시간 차이 - RC시정수가 충전속도와 관련있기 때문에 저 PD는 0.69RC로 나타난다\n\n\n\n이런 수식으로도 정리 가능한데 살펴보면 당연하게도 입력전압이 높을수록 더 빨리 회로가 작동한다\np를 위에 달고 n을 아래에 달면 vth drop문제가 생겨 noise margin이 줄어들어 최대전압이 1이 되지 못하고 0.6정도로 떨어지고 최소전압도 0이 되지 못하고 0.4가 되는 등의 문제가 생긴다?\n\n맞는지 모르겠네\n\n\n"},"archives/practicalcoding.spring.2021.cse.cnu.ac.kr/(충남대)-실전코딩-강의록":{"title":"(충남대) 실전코딩 강의록","links":["archives/practicalcoding.spring.2021.cse.cnu.ac.kr/01.-개발-프로세스","archives/practicalcoding.spring.2021.cse.cnu.ac.kr/02.-Git-(1)","archives/practicalcoding.spring.2021.cse.cnu.ac.kr/03.-Git-(2)","archives/practicalcoding.spring.2021.cse.cnu.ac.kr/04.-Backend-개발-(1)","archives/practicalcoding.spring.2021.cse.cnu.ac.kr/05.-Backend-개발-(2)","archives/practicalcoding.spring.2021.cse.cnu.ac.kr/06.-Spring-Boot-Annotation","archives/practicalcoding.spring.2021.cse.cnu.ac.kr/07.-MSA-(1)","archives/practicalcoding.spring.2021.cse.cnu.ac.kr/08.-MSA-(2)","archives/practicalcoding.spring.2021.cse.cnu.ac.kr/09.-테스팅","archives/practicalcoding.spring.2021.cse.cnu.ac.kr/10.-Frontend-개발"],"tags":[],"content":"\n\n                  \n                  이곳에 있는 문서들은 보관이 목적이고, 관리되지 않습니다. 따라서 잘못된 정보가 포함되어 있거나 순서가 뒤죽박죽일 수 있습니다. \n                  \n                \n\n개요 §\n강의 정보 §\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n강의 구분소속교수시기학부 수업충남대학교 공과대학 컴퓨터공학과N/A2021년 봄학기\n목차 §\n\n01. 개발 프로세스\n02. Git (1)\n03. Git (2)\n04. Backend 개발 (1)\n05. Backend 개발 (2)\n06. Spring Boot Annotation\n07. MSA (1)\n08. MSA (2)\n09. 테스팅\n10. Frontend 개발\n"},"archives/practicalcoding.spring.2021.cse.cnu.ac.kr/01.-개발-프로세스":{"title":"01. 개발 프로세스","links":[],"tags":[],"content":"\n\n                  \n                  충남대학교 컴퓨터공학과의 &quot;실전코딩&quot; 강의를 필기한 내용입니다. \n                  \n                \n\n\n\n                  \n                  이 문서는 보관이 목적이고, 관리되지 않습니다. 따라서 잘못된 정보가 포함되어 있거나 순서가 뒤죽박죽일 수 있습니다. \n                  \n                \n\nPeople §\n\nDeveloper : 실 개발자 - 디자이너도 포함됨\nCustomer / End user : 고객\nSkateholder : 돈시간 등의 자원을 지원해주거나 아이디어 등의 제공을 하는 사람 - 개발자들을 지휘하고 관리하는 사람 (총 책임자CEO같은 사람들이것제)\n\nTime §\n모든 개발에는 때가 있고 때를 놓치면 쓸모없는 프로그램이 되기도 한다\n시간관리 예시 §\n\nskateholder의 요구 → 개발 → 유지 → 서비스 종료\n지속적으로 버전업데이트를 하면서 성장하는 것(MS의 오피스)\nMSA : 전체의 개발 틀을 깨지 않으며 소규모 업데이트를 지속적으로 하는 것(주로 클라우드 서비스들이 이렇게 함)\n\nWaterfall 개발 방법론 §\n\n다음단계로 넘어가면 이전단계를 고치지 못하는 방식 - 컨베이어밸트같은 과정이다\n건축쪽의 경우 이런식으로 진행된다\n소프트웨어 개발쪽에는 효율적이지 않은 경우가 많다\nskateholder의 요구 → 디자인 → 개발 → 테스트 → 배포\n각 단계가 완성될때까지 다음 단계로 넘어가지 않는다\n각 단계마다 결과물이 문서로 나오게 된다 + 팀 사이즈가 크다(크기 때문에 관리를 위해 문서가 필요한 부분도 있다) + 코드 작성 가이드가 엄격하게 존재한다\n결과물이 나오고 나면 유지보수 없이 프로젝트가 끝이 난다\n\nAgile 개발 방법론 §\n\nWaterfall 방식의 문제점을 해결하고자 나온 방법론\nSkateholder가 요구사항을 쭉 나열하고 개발하는 방식이 아닌 skateholder가 한팀으로 묶여서 skateholder가 요구사항을 하나 던지고 그걸 만들고 자체적으로 테스트를 하는 과정을 skateholder가 만족할때까지 계속 반복한다\n즉, 작은 waterfall을 무수히 반복하는것과 비슷하다\n팀 사이즈가 작다 + 코드 작성 가이드가 그렇게 엄격하지 않다(팀 규모가 작기때문에 코드에서 이해되지 않는 부분은 바로바로 당사자에게 물어볼 수 있으므로) + 유동적으로 피드백이 오고간다\n실행 가능한 결과물이 나오는데 중요하다 - waterfall의 경우 프로젝트가 마무리 되어야 결과물이 나오는 반면에 agile의 경우 완벽한 결과물을 원하는게 아닌 미흡하더라도 빠르게 결과물을 내놓고 이것을 점진적으로 보완해나가는 방식으로 진행된다\n결과물이 나오고 나서도 지속적인 업데이트를 하며 유지보수를 한다\n한국에서는 수직문화가 상당히 강하기 때문에 agile이 제대로 시행되지 않는다\n이렇듯 agile이 제대로 작동하기 위해서는 문화에도 많은 영향을 받게 된다\n\nAgile Manifesto §\n\nWaterfall의 양식이나 절차에 얽매이는게 아니라 skateholder, developer, end user 즉, 이 서비스와 관련된 사람들간의 소통에 집중하자\n절차나 문서가 중요한게 아니라 실제로 돌아가는 소프트웨어가 중요한거다 - 별기능 없어도 만드는게 중요하다\n소비자와 상호작용을 하며 계속 피드백을 받으며 지속적으로 업데이트\n이렇게 계속 업데이트를 할때 원활하게 하기 위해 변화에 유연하게 코드를 짜는게 중요하다\n\nPO §\n\nagile 팀 내에서 결정권을 가지고 리드하는 역할\n그렇다고 해서 이사람이 다른 팀원들보다 우위에 있는 것은 아니다. agile팀은 모두 균등한 권위를 가지지만 프로젝트를 행할때 어느정도 결정을 내려야 할 사람도 필요하기 때문에 존재하는 것\n\nAgile이 집중하는 것 §\n\n빠른 전개(agility)\n빠른 피드백과 인정(resilient)\n실질적으로 작동하는 소프트웨어\n연속적인 배포\n사용자 입장(user story)에서 사용하기 쉬운 소프트웨어\n\nUser story §\n\nAs a : 나는 누구이고\nI want : 내가 원하는 것은 이것이고\nSo that : 이것을 원하는 이유는 ~이다\n\nMVP §\n\nMinimum Viable Product\n모든걸 다 제공하는 것을 소프트웨어를 만드는게 아닌 다른건 아니더라고 이것때문에라도 사용자들은 이것을 쓸 것이다\n모든 기능을 다 제공하는게 아니고 핵심적인 몇가지 기능에만 집중해라\n소프트웨어의 제일 핵심적인 기능, 이것을 제일 먼저 개발하게 된다\n\nAgile method(종류) §\n\nScrum : sprint를 통해 프로젝트를 진행하는 것 - 이 수업에서 체험해 볼 놈이다\nKanban : 뭐 도요타에서 처음 시도해 대박을 쳤다는데 뭔지는 몰라\nXD : 짧은 주기로 결과물을 계속 내놓으면서 계발하는거\nTDD : agile manifesto의 네번째랑 관련이 있다??\n얘네들이 뭔차이인지는 잘 모름 - 몰라도 된다\n\n실제 Agile의 작동 과정 §\n\nSprint : Agile의 짧은 요구-계발-테스트 사이클 - 보통 1~4주 정도 걸린다\nMilestone(M) : 실제 현실에서는 매번 사이클이 돌때마다 배포되지는 않는다 - 어느 시점까지는 우리가 이것을 해야겠다라는 목표지점\n\nPlanning §\n\nProduct backlog : skateholder의 요구사항을 정리\nSprint planning meeting : 요구사항을 가지고 각 요구사항을 구현하는데 며칠정도 걸릴지/어떤것들이 필요한지 등을 검토\nSprint backlog : 실제로 sprint를 진행할 요구사항들을 정리\n이런것들을 티켓화해서 관리(결정사항을 티켓이라 부른다?)\n\nSprint §\n\nGrooming : 본격적으로 스트린트에 들어가기 전에 요구사항들을 다시 한번 리뷰하는 것\nDaily scrum(meeting) : 매일 같이 일하는 사람들과 진행상황, 문제점 등등을 의무적으로라도 소통을 하는 것\n우리가 원하는 기능이 구현되었다고 생각되는 시점에 Demo로 넘어간다\n\nDemo §\n\nSkateholder 나 end user들의 피드백을 받고 반영/최종 테스트 등을 하며 결과물을 내놓음\n\nRetro §\n\n이번 사이클을 회고하며 이번 사이클에 어떤점이 좋았고 어떤점이 문제였는지 등을 검토하는 것\n"},"archives/practicalcoding.spring.2021.cse.cnu.ac.kr/02.-Git-(1)":{"title":"02. Git (1)","links":[],"tags":[],"content":"\n\n                  \n                  충남대학교 컴퓨터공학과의 &quot;실전코딩&quot; 강의를 필기한 내용입니다. \n                  \n                \n\n\n\n                  \n                  이 문서는 보관이 목적이고, 관리되지 않습니다. 따라서 잘못된 정보가 포함되어 있거나 순서가 뒤죽박죽일 수 있습니다. \n                  \n                \n\n명령어들 §\n\nHEAD^ : 내가 한 마지막 커밋 바로 이전의 커밋\nSoft : staged area\nMixed : working directory\nHard : delete\nbranch branch_name 으로 가지칠 수 있고\n그냥 branch만 하면 현재 브랜치와 존재하는 브랜치들을 볼 수 있다\n그리고 checkout branch_name으로 브랜치를 바꿀 수 있다\nhead라는 포인터가 있고 branch를 하면 master말고 헤드가 가리킬 수 있는놈이 하나 더 생긴다 - 이때 checkout을 하면 이제 헤드가 그 브랜치로 옮겨가게 되는 것\nMerge 과정에서 충돌이 있을 경우 오류 내용에 어느 파일에서 충돌이 있었는지 보여준다. 그 다음 그 파일에 들어가면 충돌되는 두 내용이 헤드와 브랜치별로 보여지는데 그 중에 맘에드는걸 남기고 git add . 를 해준 다음 commit을 해주면 문제없이 정상적으로 작동하게 된다\n하나의 기능을 다 완료했을 때 = commit으로 적을 내용이 있을 때 = commit을 하는 것이 정석이다\n스쿼시 머지? 리베이스?\nSquash : 브랜치를 하나 만들고 거기다가 커밋을 졸라게 한 다음 다른 브랜치로 와서 git merge —squash branch_name을 하게 되면 전에 브랜치에서 했던 커밋 내역이 다 사라지면서 머지된다. 그래서 머지 이후에 새로 커밋을 하면 브랜치에서 커밋한 내용들은 다 사라지고 브랜치를 만들기 전 커밋에 지금 한 새로운 커밋 이렇게 커밋이 바로 연결되게 된다 - squash옵션을 주지 않으면 커밋한 내용까지 전부 다 머지되는데 이 옵션을 주게 되면 브랜치에서 커밋한 내용들이 없어지게 된다\nGit rebase -i HEAD~2 : 헤드부터 두개의 커밋을 하나로 합쳐서 커밋메세지를 수정할 수 있음\n마스터 브랜치는 절대로 커밋 메세지를 수정하면 안된다\n다른사람의 커밋 메세지를 절대 함부로 건들면 안된다\n이것 실행하면 커밋한 순서대로 위에서부터 옵션선택창이 뜨게 된다. *먼저 커밋한 놈을 pick하고 나중에 커밋한 놈을 squash로 주면 된다\n그리고 그 다음 창에서 커밋 메세지를 고치면\nGit log했을 때 두 커밋 메세지가 하나로 합쳐져 내가 수정한 커밋 메세지로 나오는 것을 보게 된다\n"},"archives/practicalcoding.spring.2021.cse.cnu.ac.kr/03.-Git-(2)":{"title":"03. Git (2)","links":[],"tags":[],"content":"\n\n                  \n                  충남대학교 컴퓨터공학과의 &quot;실전코딩&quot; 강의를 필기한 내용입니다. \n                  \n                \n\n\n\n                  \n                  이 문서는 보관이 목적이고, 관리되지 않습니다. 따라서 잘못된 정보가 포함되어 있거나 순서가 뒤죽박죽일 수 있습니다. \n                  \n                \n\ngit stash §\n\n작압을 하다가 갑자기 할 일이 생겨서 다른 브랜치로 넘어가야될때 지금 하고있는걸 잠깐 저장했다가 나중에 다시 불러올 수 있게 하는 기능\n하기만 지금 하고있던일이 많으면 그냥 커밋하는게 낫댄다\n\nstash : 하고있던일 저장 - 파일이 임시저장소로 옮겨져 사라진다\nlist : stash된것들 목록\npop : 다시 불러옴\ngit stash branch branch_name_ : branch_name_의 브랜치가 생성되고 stash에 있던게 브랜치로 옮겨진다\n\n\n\ngit cherry-pick §\n\n다른 브랜치의 커밋 내용을 현재 브랜치로 땡겨오는 것\n머지랑 비슷한데 머지는 다른 브랜치의 가장 최신 커밋을 떙겨오는거고 체리픽은 다른 브랜치의 특정 커밋을 땡겨오는 거인듯\n\n좋은 오픈소스 찾기 §\n\n라이선스 확인\ncode에서 최근 커밋 확인\nissue에서 어떤 이슈가 있는지 확인\npull에서 소통이 잘 되는지 확인하기\ncontributors에서 커밋이 지속적으로 되고있는지 확인하기\n\n\n한번 오픈소스를 고르면 나중에 다시 빠꾸치기가 힘들기 때문에 처음에 고를때 신중해야 한다\n\n컨트리뷰션 §\n\n오타 수정해서 PR날리거나\n번역해서 PR날리거나\nfirst-timers-only라는 issue의 label을 참고하면 좋음 - 얘네는 컨트리뷰션을 첨하는 사람들을 위해 체험판처럼 이슈를 일부로 안고치고 냄겨놓는 것이다 - 이 이슈도 뭐 대단한게 아닌 쉬운것 - 약간 뉴비들을 위한 캠페인 같은거다\n\n컨트리뷰션 과정 §\n\n오픈소스를 찾고\n그것을 내 계정으로 fork한다\n그리고 내 로컬에 clone받고\n그것을 작업한 뒤\n내 계정에 push한다\n그리고 pull request를 날려 merge해주기를 기다리면 된다\n\nsync하기 §\n\ngit fetch origin : 레포의 main을 내 origin으로 커밋을 땡겨옴 - 땡겨오기만 하지 머지되지는 않는다 - 레포의 커밋을 내 origin의 remote라는 가상의?브랜치로 땡겨옴\ngit pull origin branch_name_ : fetch하고 merge를 동시에 - fetch한 이후 이 origin / remote브랜치의 내용을 origin / main브랜치로 땡겨오게 된다\n내 로컬이 origin인듯\npull이랑 pull request랑 다른거다\n\ngit tag §\n\n버전의 중요한 특정 지점에 표시를 할때 tag를 한다\n브랜치랑 비슷하지만 브랜치는 수정이랑 삭제 등이 용이하지만 태그는 수정이랑 삭제는 안된다 - checkout은 되지만 push등은 안된다\n뭐 정기 배포 이럴때 쓴다\n\nHEAD, HEAD^ §\n\nHEAD : 가장 촤근 커밋\nHEAD^ : 가장 최근 커밋의 바로 이전 커밋\ngit-scm.com/book/ko/v2 꼭 들어가봐라\n"},"archives/practicalcoding.spring.2021.cse.cnu.ac.kr/04.-Backend-개발-(1)":{"title":"04. Backend 개발 (1)","links":[],"tags":[],"content":"\n\n                  \n                  충남대학교 컴퓨터공학과의 &quot;실전코딩&quot; 강의를 필기한 내용입니다. \n                  \n                \n\n\n\n                  \n                  이 문서는 보관이 목적이고, 관리되지 않습니다. 따라서 잘못된 정보가 포함되어 있거나 순서가 뒤죽박죽일 수 있습니다. \n                  \n                \n\n메이븐(maven) §\n\nhomebrew처럼 자바 라이브러리에 대한 패키지를 관리하는 프로그램이다\nide에서 메이븐 프로젝트를 하나 만든 다음(메이븐 프로젝트는 정해진 프레임워크가 있는데 이렇게 해주면 자동으로 맞춰준다) pom.xml에 &lt;dependencies&gt; 태그를 만든 다음 maven central repository에서 &lt;dependency&gt; 태그를 복사해가 붙여넣으면 ide가 알아서 jar을 찾아서 꽂아준다\ncentral repository가 아닌 다른 레포에서 다운받으려면 &lt;repositories&gt; 태그를 이용해 레포를 추가해준다(리눅스의 apt에서 ppa추가하는거마냥)\njava -jar 경로 일케해주면 실행가능한(main함수가 있는) jar파일을 실행할 수 있다\n터미널에 mvn install을 하면 pom.xml에 있는 내용을 가지고 내 로컬 프로젝트를 jar로 바꿔준다\n\nHTTP §\n\nHyper Text Transfer Protocol\n데통에서 배웠제? 이것도 통신을 위한 하나의 약속이다\n우리가 뭔가를 요청하면 컴터가 그것을 http에 맞게 서버로 보내고 서버에서는 html파일을 또 http에 맞게 나의 컴터로 데이터를 전송하는 것이다\n서버에서 나한테 보낼때는 응답 코드 - response status을 같이 날린다 → 즉, 처리의 결과를 같이 보낸다 → 404 not found에서 404가 그 응답 코드이며 백의자리에 따라 성공, 에러 등의 종류가 나뉜다\nHTTP request header : 여기에 요청사항의 여러 정보들이 담긴다. method에는 어떤 요청을 하는지(get : 정보를 가져옴 등등) accept에는 나의 브라우져가 어떤 미디어를 지원하는지(뭐 png파일은 읽을 수가 없다 등등)의 정보를 같이 보내게 된다\n\nDNS §\n\nDomain Name Server\n뭐 .com이나 .io같은 도메인을 관리하고 사용자가 요청하면 그에 따른 ip를 돌려주는 등의 서비스를 해주는 서버\n\nWAS §\n\n웹 서버가 있고 그 안에 웹 컨테이너가 있는데 이놈이 DB랑 교신하면서 정적의 html파일이 아닌 html파일을 동적으로 변형시켜서 보내주는 그런 형식\n뭐 jsp를 생각하면 개발자가 jsp로 개발을 하면 그것을 웹 컨테이너가 자바파일로 바꾸고 실행을 해서 보여주는 형태\n이것도 옛날의 유물이다\n\n현대의 웹서버 §\n\n이제는 프론트쪽과 백쪽이 나뉘어져 있다\n프론트쪽 부분은 AWS같은 클라우드에서 받아오고 데베에 접근해야 되는 요청의 경우에는 클라우드와는 분리되어있는 서버에서 받아서 보여주게 된다 - 프론트와 백을 처리하는 부분이 다르다 = 역할분담이 되어있는 셈\n클라우드에서는 프론트쪽을 받아오는데 대신 데베에 접근해서 채워넣어야 되는 부분들은 빠진 상태로 받아온다 → 그리고 채워넣어야 되는 부분은 서버컴에서 데베에 접근해서 채워넣게 된다\n\nJSON §\n\nJavaScript Object Notation\n말그대로 자바스크립트 객체문서이다\n\n{\n    &quot;key1_&quot; : &quot;value1_&quot;,\n    &quot;key2_&quot; : &quot;value2_&quot;,\n    &quot;key3_&quot; : &quot;value3_&quot;\n}\n\n이런식으로 {}로 묶여있는 애들이 알다시피 자바스크립트에서의 객체이다 {}가 객체다\n문자열은 반드시 “”로 묶어야 한다\n무조건 키 - 벨류쌍으로 구성돼야하며 : 로 구분짓는다\n대괄호 []로 묶어서 배열을 나타낸다\n그냥 별생각없이 이 규칙만 지키면 된다\n\nAPI 통신을 위한 방법들 §\n\nSOAP 통신 : 웹브라우져가 아닌 다른 응용프로그램쪽에서 api를 땡겨오거나 할때 쓰는 엄격하고 복잡한 프로토콜\nREST 통신 : SOAP통신이 너무 어려워서 제대로 api들을 사용하지 못하는거같아서 나온 개념 - 지금은 얘가 주로 쓰인다 - 겨의 평정수준\n그냥 단순하게 클라이언트가 자원을 요청하면 그것을 서버에서 보내주는 형식으로 api가 통신된다\n자원 : 뭐 api에 들어있는 데이터들을 말하는 듯 - 얘네를 url에 복수형으로 이름지어서 포함시켜라\n동작 : 동작의 경우에는 http의 method에 이미 들어있으니 동작은 url에 포함시키지 말아라\n\nFramework §\n\n코드와 라이브러리를 합쳐서 프레임워크라고도 한다\n자바진영의 제일 유명한 프레임위크가 spring이며 여기에서도 많이 쓰는 기능이나 라이브러리는 이미 다 추가해놓은게 spring boot이다\nspring은 웹 컨테이너등도 다 설정해줘야하지만 spring boot에는 이것도 내장되어 있다\n실행가능한 jar파일만 서버로 보내면 바로 서버로 작동하게 된다 - 바로 활용 가능하댄다\n\nSpring IoC, DI §\n\nIoC : 스프링측에서 자동으로 객체들을 관리하는 것?\nDI : new로 객체생성을 자동으로 해주는 것?\n뭐 굳이 귀찮게 new Class이지랄 안해도 @를 통한 annotation을 활용하면 필요한 객체의 생성과 삭제 등등을 스프링측에 위임한다는 개념\n"},"archives/practicalcoding.spring.2021.cse.cnu.ac.kr/05.-Backend-개발-(2)":{"title":"05. Backend 개발 (2)","links":[],"tags":[],"content":"\n\n                  \n                  충남대학교 컴퓨터공학과의 &quot;실전코딩&quot; 강의를 필기한 내용입니다. \n                  \n                \n\n\n\n                  \n                  이 문서는 보관이 목적이고, 관리되지 않습니다. 따라서 잘못된 정보가 포함되어 있거나 순서가 뒤죽박죽일 수 있습니다. \n                  \n                \n\nSpring boot starter §\n\nspring initializr라고 구글에 치면 스프링 프로젝트를 다운받을 수 있는 창이 뜬다\n여기서 뭐 자바 버전 몇을 쓸건지, 메이븐/그래들 중에 뭘 쓸건지, dependency는 뭐를 쓸건지 등등을 결정해서 다운받으면\n이런것들이 다 적용되어서 패키지가 하나 다운받아지는데 여기다가 자기가 원하는 api를 구축한다든지 그런걸 해주면 된다\n뷔페마냥 내가 원하는걸 고르면 기본세팅을 다 해서 프로젝트를 만들어주는 사이트\n\n로그지 §\n\n로그지를 외부 파일로 분리하는것은 아주 중요한 일이다 : 보통 서버가 돌아갈때는 저렇게 ide상에서 실행시키는게 아니기 때문에 로그 내역을 얻다 저장해주지 않으면 볼 수 없거나 날라가기 쉽상이다\n뭔가 문제가 생겼을떄 로그지를 보고서 뭐가 문제인지 파악을 해야 하기 때문에 로그지를 별도의 파일로 분리하는게 중요하다는 것\n\n로그지 읽기 §\n\nTRACE → DEBUG → INFO → WARN → ERROR 순으로 계층이 이루어져 있는데 - 뭐 중요도 순서겠지\n로그를 보면 INFO 18647 - - - 뭐 이런식으로 되어있을 거다\n이말은 지금 INFO 이하의 내용은 출력을 안하고 있다는 얘기인거임 - TRACE나 DEBUG의 내용이 있을텐제 로그에는 출력이 되고있지 않으므로\nWARN, ERROR가 발생하면 이제 저 INFO가 WARN이나 ERROR로 바뀌며 문구를 출력해주겟지\n\n내가 원하는 놈 추적해서 로그지에 쓰기 §\n\n내가 원하는 놈을 추적하고 싶을때는 추적을 원하는 클래스에 @Slf4j 를 붙이고\n[log.info](http://log.info/)**(“~~~”)** 를 통해 문구를 출력한다\n포매팅하고싶을때는 %d, %s같은거 대신 {} 를 쓰면 자동으로 포매팅이 된다\n\n스프링 프로젝트의 구성 §\n\n스프링도 MVC모델처럼 기능별로 패키지를 나눠서 구현한다\n컨트롤러 패키지 : 프론트와의 소통 창구\n서비스 : 실질적인 작업이 이루어지는 곳 - 로지컬한 작업은 다 여기서 한다\n레포지토리 : DB와의 소통 창구\nAPI : 외부서버와의 소통 창구 - 외부 서버의 api를 처리하기 위한 곳\n도메인 : api통신할때 주고받는 json파일이랑 대응되는 클래스들을 정의하는 곳 - json파일을 담는 그릇 클래스들을 선언하는 곳이라고 생각하면 된다\n콘피그 : 설정\n\nCRUD시스템을 위한 HTTP 메소드 §\n\nC : HTTP 프로토콜에서는 POST라는 메소드를 사용\nR : GET이라는 메소드를 사용\nU : PUT - 덮어쓰기 방식의 업데이트, PATCH - 기존꺼 수정하는 방식으로 업데이트\nD : DELETE라는 메소드를 사용\n\n인자 전달법의 종류와 url표기 §\n\nRequest body : 여기서 body == json이라고 생각하면 된다. 즉, json파일을 통째로 넘기는 방식이다. 얘는 url에 리소스만 표시한다 - /resource\nRequest param : 얘는 json파일을 전달하는게 아니라 json파일의 한 변수값만 넘기는 방식이다. url은 /resource?variable=value형식으로 적는다\nPath variable : 얘도 변수값만 넘기는데 url을 resource value이런식으로 적는다는 차이점이 있다\n여기서 주의할 점은 이 방법들과 url표기는 필요충분조건이 아니라는거다 - 해당 방법을 사용하면 해당 url표기를 따라야 되지만 url표기가 그렇다고 해서 해당 방법을 무조건 쓰는것은 또 아니라 이거다\n\nHTTP메소드들의 인자 전달법 §\nPOST §\n\n얘는 무조건 json파일이 필요하므로 request body방식으로 인자를 전달받는다\n\nGET §\n\n특정 json을 조회하기 위해 특정 변수의 값을 인자로 받아야 될 필요가 있으므로 request param방식이나 path variable방식을 쓰면 된다\nbody로도 특정 변수의 값을 받을 수는 있지만 보통 GET의 경우에는 request body를 쓰지 않는다\n\nPUT, PATCH §\n\n얘는 request body나 path variable을 쓴다.\n근데 request param방식을 왜 안쓰는지는 잘 모르겠음\n\nDELETE §\n\n얘도 조회 후 삭제를 하므로 request param이나 path variable을 사용한다\nGET과 마찬가지로 보통 request body는 사용하지 않는다\n\nDB 연동하기 §\n\n디펜던시를 통해 DB와 프로젝트를 연결해주는 클래스를 넣어줄 수 있다\nspring-boot-starter-data-jdbc 에 들어있는 JDBCTemplate 을 통해 SQL형 데이터베이스의 튜플들을 자바 클래스로 매핑시켜줄 수 있고\nspring-boot-starter-data-mongodb 에 들어있는 MongoTemplate 를 통해 non-SQL인 mongoDB의 개체를 자바 클래스로 매핑해줄 수 있다\nspring-boot-starter-web 의 RestTemplate 를 통해 외부서버와 통신할때 Rest api들을 자바 클래스로 매핑해줄 수도 있다\n\n디펜던시 추가하기 §\n&lt;dependency&gt;\n\t&lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;\n\t&lt;artifactId&gt;spring-boot-starter-data-mongodb&lt;/artifactId&gt;\n&lt;/dependency&gt;\nMongoTemplate 사용하기 §\n\n먼저 repository패키지를 만들어서 사용할 클래스를 하나 만들어준다\n그리고 거기에다가는 필드에 MongoTemplate를 넣어주고 @Autowired한다\n그리고 이놈을 사용할 서비스 클래스에 방금 만든 레포클래스를 필드에 넣어주고 @Autowired한다\n그리고 레포클래스에 db에 접근할 메소드들을 만들어주면 끝\n\nCRUD 구축하기 §\n\n\nPOST : insert계열메소드 쓰면 된다\n\n\nGET : find계열메소드 쓰면 된다\n\n\nPATCH, PUT : update계열메소드 쓰면 된다\n\nupdate계열 메소드를 쓸때는 Update객체가 필요하다\n\nUpdate update = new Update();\nupdate.set(&quot;key&quot;, &quot;value&quot;);\n\n\nDELETE : REMOVE계열메소드 쓰면 된다\n\n\n질의문 작성하기 §\n\n\nCriteria클래스 : 기준. 어떤 키:벨류값을 가지고 있는 도큐먼트를 검색할건지\nCriteria criteria = new Criteria(&quot;key&quot;);\ncriteria.is(&quot;value&quot;);\n/*이런식으로 and(key)메소드를 활용해 여러 키:벨류를 활용할 수도 있음*/\ncriteria.is(&quot;value&quot;).and(&quot;key2&quot;).is(&quot;value2&quot;);\n\n\nQuery클래스 : Criteria객체를 질의문으로 만들어주는 놈\nQuery query = new Query(criteria);\n\n"},"archives/practicalcoding.spring.2021.cse.cnu.ac.kr/06.-Spring-Boot-Annotation":{"title":"06. Spring Boot Annotation","links":[],"tags":[],"content":"\n\n                  \n                  충남대학교 컴퓨터공학과의 &quot;실전코딩&quot; 강의를 필기한 내용입니다. \n                  \n                \n\n\n\n                  \n                  이 문서는 보관이 목적이고, 관리되지 않습니다. 따라서 잘못된 정보가 포함되어 있거나 순서가 뒤죽박죽일 수 있습니다. \n                  \n                \n\nSpringframework라이브러리 §\n\n@Slf4j : 이 클래스의 활동 내역을 내가 로그지를 통해 확인하고 싶다는 뜻\n@RestController : 해당 클래스를 컨트롤러로써 객체생성\n@Post(Get, Put, Patch, Delete)Mapping : HTTP의 메소드들을 구현한 함수라는 것을 알려줌\n\n@….Mapping(“/resources”)로 url을 지정해 줄 수 있다\n\n\n@RequestBody : 매개변수의 인자로써 json을 받고 싶다는 뜻이다 - 받은 json파일을 해당 클래스에 대응시켜 주라는 뜻\n@Service : 해당 클래스를 서비스로써 객체 생성\n@Autowired : 다른 클래스(컨트롤러, 서비스 같은애들)를 갖고와서 이 클래스에서 사용하려고 할 때\n@RequestParam : url을 “?variable=value”형태로 지정하고 싶을 때 사용\n\n@RequestParam같은 경우에는 @GetMapping()의 괄호에 암것도 안넣어줘도 된다\n여러개의 매개변수를 받을 때에는 그냥매개변수마다 annotation을 붙여주면 된다\n\n\n@PathVariable : url을 “resources/variable”형태로 지정하고 싶을 때 사용\n\n@PathVariable같은 경우에는 @GetMapping(“resources{variable}”)이렇게 url을 지정해줘야 한다\n여러개의 매개변수를 받을때는 매개변수마다 annotation을 넣어주고 url은 resources{variable1}/{variavle2} 이래해주면 된다\n!!주의!! 하나의 http메소드를 구현할때 path variable, request param은 한번씩만 써야 된다 - 하나의 http메소드를 두개의 자바 메소드로 구현할때 둘 다 path variable을 쓴다던지 하면 실행중 에러나 강종된다\n\n\n@ResponseStatus(HttpStatus.xxx) : http 상태 코드를 클라이언트에게 주고싶을때 사용한다 - 괄호 안에 상태의 종류를 넣으면 된다 - HttpStatus.NOT_FOUND를 주면 그 유명한 404를 갖다주게 된다 - 굳이 이런 400번대가 아니어도 정상적으로 요청이 처리됐다는거를 알려주기 위해 일반 클래스/함수에도 사용해도 된다\n@EnableScheduling, @Schduled(fixedDelay …L) : 배치성 작업(timeInterval같은거) - 클래스에는 @EnableScheduling을 넣어주고 함수에 @Scheduled넣어주면 된다 - 괄호에는 fixedDelay넣어주면 고정된 시간간격이 되고 밀리초 단위로 시간을 적어주면 된다\n@Async : 함수에 얘를 붙이면 자동으로 쓰레드가 하나 생성되어 거기에서 돌아간다\n\n주의할 점 : 무조건 public 함수여야 하고\nself-invocation 함수는 안된다?? - 뭔지 모르겠음\n그리고 쓰레드가 너무 많이 생성되면 heap overflow가 될 수도 있다는 점\n\n\n@Configuartion, @Bean : 스프링의 기본 설정값이 아닌 나만의 설정값을 주고 싶을때 클래스에는 @Configuration, 함수에는 @Bean을 넣어주면 된다. 그러면 스프링이 시작될때 기본 설정 말고 이 설정값으로 변경해서 구동되게 되는 것\n\nLombok라이브러리 §\n\n@Data : 게터, 세터를 전처리방식으로 만들어줌\n@No(All)ArgsConstructor : 생성자를 전처리로 만들어줌\n"},"archives/practicalcoding.spring.2021.cse.cnu.ac.kr/07.-MSA-(1)":{"title":"07. MSA (1)","links":[],"tags":[],"content":"\n\n                  \n                  충남대학교 컴퓨터공학과의 &quot;실전코딩&quot; 강의를 필기한 내용입니다. \n                  \n                \n\n\n\n                  \n                  이 문서는 보관이 목적이고, 관리되지 않습니다. 따라서 잘못된 정보가 포함되어 있거나 순서가 뒤죽박죽일 수 있습니다. \n                  \n                \n\nScale-up, Scale-out §\n\nScale-up : 서버컴의 하드웨어적인 사양을 올리는 것\nScale-out : 서버컴를 여러개 구축해서 분산처리하는 것\n물리적인 컴퓨터의 갯수로 구분짓는다고 생각하면 된다\n\nMonolithic, Microservice Architecture §\n\nMonolithic Architecture : 하나의 프로젝트로 모든 서비스를 다 처리하는 것\nMicroservice Architecture : 서비스마다 프로젝트를를 하나씩 둬서 운용하는 것 - 그래서 요청이 오면 그것을 그에 맞는 처리부로 넘겨주는 역할을 하는 것이 load-balancer이다\n물리적인 컴퓨터의 갯수와는 상관없이 서비스를 전담하는 서버를 하나의 컴퓨터라도 여러개 구성하는지 하나로 쓰는지로 구분짓는다\n\nMonolithic Architecture의 장단점 §\n\n장점\n\n개발과 배포가 쉽다\n스케일링하기가 비교적 용이하다\n따라서 거의 모든 서비스가 초기에는 이 방식으로 시작한다\n\n\n단점\n\n어떤 코드가 어디 있는지 찾기가 힘들다\n코드를 컴파일하거나 하는 등의 과정이 아주 느리다 - 코드의 크기가 아주 크기 때문\n따라서 배포에 걸리는 과정도 오래걸리게 된다\n새로운 팀원이 들어왔을때 적응하기가 힘들다 - 모든 소스 코드를 다 이해하고 있어야 되므로\n새로운 플랫폼(프로그래밍 언어, 개발환경)으로 옮겨가는 것이 굉장히 힘들다\n부분적 스케일링이 불가능하다 - 제공하는 서비스 중 하나만이 부하가 많이 걸려도 서버 전체의 스케일링이 필요하다\n팀레벨의 스케일링이 힘들다 - 특정 서비스를 전담하는 팀에서 문제가 생기면 모든 서비스가 문제가 생기게 된다\n\n\n\nMicroservice Architecture의 장단점 §\n\n장점\n\n일단 서비스별로 서버가 나뉘어져 있기 때문에 내가 어떤 서비스를 맡았으면 이부분에만 집중하면 된다\n따라서 내가 관리해야 할 코드의 길이가 현저히 줄어든다 - 이것은 팀에 새로운 팀원이 들어왔을 때에도 이 서비스를 위해 이해해야 할 코드가 적어 적응하는 시간이 적게 걸리게 된다\n그리고 부분적인 배포의 경우에도 서비스 전체를 컴파일하는게 아니기 때문에 배포의 시간이 적게걸린다 - 또한 컴파일시간이 적게 걸린다는 것은 컴파일 오류가 났을 때 대처하기가 쉽고 지금 내가 하로 있는 일이 뭐였는지 까먹지 않아 길을 안 잃을 수가 있다\n새로운 플랫폼으로 옮겨가는 것, 부분적인 스케일링을 하는 것 등등의 것들이 더 간편해진다\n구분이 명확하기 때문에 코드가 어느 서버로 가야 하는지, 이 코드가 이 서버에서는 더이상 사용하지 않아 지워하 하는 놈인지 등등을 판단하기가 쉽다\nFault isolation : 부분적인 문제가 있어도 시스템 전체가 죽지 않음\ncircuit breaker : 해당 서비스가 제대로 작동하는지를 계속 체크해서 문제가 생겼을 경우 빠르게 파악해 낼 수 있음\n팀레벨의 스케일링이 편하다 - 각 팀이 각자의 스케줄을 갖고 개발을 할 수 있으며 자기 팀과 연관이 없는 코드를 신경 안써도 된다\n자신의 서비스에 맞는 언어/데이터베이스를 사용할 수 있다\n서비스 하나가 서버이자 클라이언트이기 때문에 클라이언트 입장에서의 관점을 더 잘 이해해 다른 서버에 요청하고 받는 과정을 구현하는 것이 더 쉬워진다\n\n\n단점\n\n디버깅이 어려움 - 여러개의 서버가 얽혀있으니까 디버깅 할때 여러군데를 들러야 한다 - 따라서 어디가 정확하고 어디가 부정확한지를 구분하는 것이 중요하다 - 이걸 알아야 어디를 먼저 테스트해봐야 할 지 알 수 있으므로\n글로벌한 관점에서 테스트를 하기가 힘들다\n다른 서비스랑 서버간 통신을 하기 때문에 TCP통신을 사용하므로 Stop-N-Wait ARQ를 사용하게 된다 - 따라서 서비스간의 통신이 상대적으로 느릴 수 밖에 없다 - 대신 통신 과정을 간소화한 것을 개발해 통신속도를 줄이기도 한다\n서버마다 라이브러리를 import시키기 때문에 라이브러리를 중복해서 import시켜야 된다 - 따라서 코드 양 전체적으로 봤을때 더 많아질 수도 있다 - 내가 라이브러리를 만드는 경우 여러번 만들어야될 수도 있는 것\n유료 라이선스가 필요한 것을 사용할때 서버마다 라이선스를 지불해야 되기 때문에 비용이 더 많이 청구될 수도 있다\n시스템 전반적인 감을 잡기가 힘들다\n데이터베이스간 일관성을 유지하기 힘들다 - 데이버테이스끼리도 통신을 하게 되는 구조이므로 통신 에러가 나면 일관성이 깨지게 된다\n단순하게 함수 하나 호출하는 작업인 경우에도 이것을 api통신으로 전달해서 실행해야되기 때문에 endpoint(url)이 점점 복잡해지게 되어 나중에는 이 url이 뭐하는놈인지도 헷갈리게 되고 그렇게 될 수도 있다 - 그리고 사용하는 도메인도 많아지기 때문에 인증서 관리 등등 번거로워지게 된다 - 그래서 service discovery라는걸 사용하기도 한다 - 얘는 이제 각 서비스에 도메인을 연결하는 방식이 아닌 도메인은 하나만 연결하고 요청이 들어오면 거거를 도메인 없이 그냥 ip로 변환해 넘겨주게 되는 식으로 작동\n배포순서도 신경써야 된다 - 다른 서비스가 아직 준비가 안됐는데 먼저 배포를 하게 되면 당연히 에러가 나게 된다 - 따라서 다른 서비스의 하위 버전도 호환 가능하게 하는 코드를 갖고 있다가 그 서비스가 업그레이드 되면 내 서비스도 그걸 제거해서 다시 배포하고 그런식의 불필요한 작업들이 생길 수도 있다\n항상 구동되어야 하는 경우 다른 서비스가 안될때 나도 죽지 않고 구동되어야 할 플랜B를 항상 마련해두어야 한다\n\n\n\nBlue, Green 무중단 배포 §\n\n기존의 서비스를 blue라고 하고 옮겨갈 애를 green이라고 한다\n그리고 green의 배포가 준비되면 blue에서 green으로 요청 처리 스트림을 옮겨준다\n이후 blue서비스로 들어오는 요청이 전부 처리되면, blue의 경우 폐기되게 된다\n이런식으로 서비스의 중단 없이 배포가 가능하다\n"},"archives/practicalcoding.spring.2021.cse.cnu.ac.kr/08.-MSA-(2)":{"title":"08. MSA (2)","links":[],"tags":[],"content":"\n\n                  \n                  충남대학교 컴퓨터공학과의 &quot;실전코딩&quot; 강의를 필기한 내용입니다. \n                  \n                \n\n\n\n                  \n                  이 문서는 보관이 목적이고, 관리되지 않습니다. 따라서 잘못된 정보가 포함되어 있거나 순서가 뒤죽박죽일 수 있습니다. \n                  \n                \n\nDevOps §\n\n개발자는 개발만, 서버관리는 관리자만 이렇게 하는 전통적인 팀 구성이 아닌\n개발자가 서버관리와 배포까지도 관여하는 그런 구조를 의미한다\n\nFunctional Team §\n\n기획, 개발, 데베, 디자인, 인프라(물리서버) 등등 팀이 명확하게 구분되어 있고 그 팀은 그 팀이 맡은 역할만 하는 구조\n\n장점 §\n\n고용이 쉽다 - 한가지만 잘하는 사람을 뽑아도 되니까 + 개인의 능력을 측정하기도 쉬우니까 인사고과도 쉽다\n지금 서비스의 유지보수가 아니라 새로운 큰 서비스를 런칭한다는 등의 큰 프로젝트에는 목표가 팀마다 같기 때문에 효율적으로 운용된다 - 큰 프로젝트의 경우 효율적이다\n\n단점 §\n\nSilo Effect : 약간 팀 간 서로의 사정을 모르니까 서로간 사이가 안좋아지고 소통이 잘 안될 수가 있다 - 단합이되는게 아니고 서로 이기적 관계가 될 수 있다 - 작은 유지보수의 경우 비효율적이다\n\nProduct-based Team(Agile Organization) §\n\n팀을 기능 위주로 구성하는게 아닌 서비스 위주로 구성하는 것\nProduct Owner : 더 나은 서비스가 되기 위해서는 어떤것들이 필요한지 등등의 생각을 하는 사람\nDev Manager : 스크럼 마스터. 애자일 팀 안에서 애자일 사이클이 잘 돌아갈 수 있도록 관리해주는 역할\n이런 사람들하고 개발자, 디자이너, DBA, 인프라 전문가 들이 하나의 서비스를 위해 다 같이 모여서 일하는 구조\n하나의 서비스를 일으키기 위해 다같이 모여서 단합하는 분위기이다\n물론 개인의 주 업무는 있지만 이것만 하는게 아니고 디자이너가 html도 가능하면 이사람도 같이 돕던가 하는 식으로 다양한 업무를 겸직하게 된다\n이런 주 업무가 아닌 일을 soft skill라고 하는데 이런 스킬의 역량이 필요하다는 점에서 고용, 능력측정 등이 어려운 면이 있다\n그리고 다른 서비스 팀과는 여전히 단절되어 silo effect가 아예 없어지지는 않는다\n\nCloud Computing §\n\n컴퓨터를 필요한 만큼 쓰고, 사용한 만큼 돈내는 구조\n여기서 컴퓨터는 물리적 컴퓨터가 아니고 가상의 컴퓨터를 말한다\n\n종류 §\n\nInfrastructure - Iaas : 컴퓨터만 띡 주는거 - 환경은 내가 다 설정해야 된다\n개발환경까지 다 제공해주는거\nSaaS : 완성된 서비스를 하나 제공하는거 - 웹메일같은거\n\n장점 §\n\nAgility : 리소스를 세팅하기가 쉽고 안쓰는거 지우기도 편하다?\nElasticity : 스케일링이 쉽고 빠르다\nCost : (잘만 사용하면) - 가격을 절감할 수 있다\nDeploy globally : 서비스를 개시하는데 물리적 지역의 제약이 없다 - 미국서버를 열라면 미국에 가야되는데 클라우드를 이용하면 그럴리가 없다\n"},"archives/practicalcoding.spring.2021.cse.cnu.ac.kr/09.-테스팅":{"title":"09. 테스팅","links":[],"tags":[],"content":"\n\n                  \n                  충남대학교 컴퓨터공학과의 &quot;실전코딩&quot; 강의를 필기한 내용입니다. \n                  \n                \n\n\n\n                  \n                  이 문서는 보관이 목적이고, 관리되지 않습니다. 따라서 잘못된 정보가 포함되어 있거나 순서가 뒤죽박죽일 수 있습니다. \n                  \n                \n\nBox test §\n\nBlackbox test : 외부 인터페이스 테스트\nWhitebox test : 내부 코드 테스트\n\nVerification, Validation §\n\nVerification : 개발자가 의도한대로 동작하는가\nValidation : 기획자가 의도한대로 동작하는가\n\nUnit test §\n\nUnit test : 가장 작은 단위의 테스트\n테스트하는데 시간이 적게 걸린다는 장점이 있음\n외부에 의존하지 않는 테스트이다 - 외부 코드랑 연동해서 테스트하는 것은 unit test라고 하지 않는다\n이걸 하는 이유\n\n내 코드를 신뢰하지 못하기 때문\n내가 짠 코드여도 시간이 지나면 까먹기 때문 - 잘 기억은 안나도 잘못 코드를 수정하면 알려준다\n다른 코드와 엮였을 때 잘못된 영향을 받으면 알려준다\n\n\n이걸 안만드는 이유\n\n시간이 없어서\n내가 만든다 해도 다른사람들이 안만드면 어차피 전체적으로는 제대로 돌아간다는 것을 확신할 수 없기 때문\n내 코드에 대한 자신감 - 내가 작성하는 코드는 내가 제일 잘 안다\n테스트 코드를 잘못 만들면 이걸 고치느라 배보다 배꼽이 더 커진다\n\n\n\n테스트 코드 짜기 §\n네이밍 §\n\n파일이름 바로 뒤에 Test로 이름을 붙여서 파일을 만든다 - 테스트파일을 빠르게 찾기 위함\n메소드 이름도 마찬가지로 메소드 이름 바로 뒤에 Test를 붙여서 메소드 이름도 지어준다\n\n메소드의 경우 @Test어노테이션을 붙여줘야 된다 - 이걸 붙여줘야 테스트 코드로써 프레임워크가 작동한다\n\n\n원래는 코드를 먼저 짜고 테스트 코드를 짜는데 테스트 코드를 짜고 코드를 짜는것도 좋다 - 이 경우를 TDD라고 한다\n간결한 이름보다는 길어도 명확하게 테스트의 목적이 뭔지 명확하게 설명해주는 이름을 쓰는게 낫다\nisAdult_ageLessThan18_false 처럼 메소드명, 테스트할것, 기대되는 결과값 이런식으로 작명을 해주는 것이 중요하다\nJUnit : 자바의 테스트 프레임워크(C언어는 CUnit, 파이썬은 PyUnit등의 프레임워크가 있음)\n\n어노테이션 §\n\n@BeforeClass : 테스트 시작 전 한번 실행\n@AfterClass : 테스트 종료 후 한번 실행\n@Before : 테스트 케이스 마다 이전 실행\n@After : 테스트 케이스 마다 이후 실행\nAfterClass, BeforeClass는 테스트 시작 전 후 한번씩 실행되고 After, Before는 테스트케이스를 한번 돌릴때마다 전후로 실행됨 - 한번만 실행되는게 아니고 반복실행되는거\n@Ignore : 테스트하지 않음\n@Test(expected = … ) : 기대하는 Exception이 제대로 나오는지 확인한다(Exception이 제대로 나는지를 확인하기 위함)\n@Test(timeout = … ) : 주어진 시간(밀리초) 안에 실행이 되는지 검사\n\n메소드 §\n\n단정문 - 값이 이게 맞는지를 테스트하는 함수(assert …)\njunit.assertTrue() : 인자의 내용이 참인지를 테스트\njunit.assertFalse() : 거짓인지를 테스트\njunit.assertEquals() : 두 인자가 같은가\njunit.assertSame() : 두 인자가 === 인가\nhamcrest : 여기서도 assert문을 지원하지만 좀 더 가독성이 좋다는 장점이 있다\nassertThat(A, is(B)) : A가 B인지를 테스트\n나머지 함수들은 JUnit, hamcrest 쓸때 인터넷에 찾아보고 필요한거 찾아 써보자\n\nTDD §\n\n테스트코드를 먼저 짜고 코드를 작성하는 기법\n코드가 깔끔하고 유지보수가 편하다는 장점\n개발시간이 증가하고 테스트코드가 어려운 경우 배보다 배꼽이 더 크며 적응이 어렵다는 단점\n"},"archives/practicalcoding.spring.2021.cse.cnu.ac.kr/10.-Frontend-개발":{"title":"10. Frontend 개발","links":[],"tags":[],"content":"\n\n                  \n                  충남대학교 컴퓨터공학과의 &quot;실전코딩&quot; 강의를 필기한 내용입니다. \n                  \n                \n\n\n\n                  \n                  이 문서는 보관이 목적이고, 관리되지 않습니다. 따라서 잘못된 정보가 포함되어 있거나 순서가 뒤죽박죽일 수 있습니다. \n                  \n                \n\n자바스크립트의 비동기성 §\n\n비동기 라는 것은 실행하는 것은 순차적으로 일어나지만 실행 결과는 순차적으로 일어나지 않는 것을 의미한다\n함수의 매개변수로 cb를 사용하여 여기에 함수를 넣으면 바디를 실행하고 넣어준 함수를 실행하게 하여 순차적으로 일어날 수 있게 한다 - call back의 약자임\n\n프레임워크 §\n\nES6를 사용할 때 구버전인 ES5도 지원해주기 위해 BABEL을 이용하면 ES6를 ES5로 컴파일해준다\n그리고 CSS도 Post-CSS란 애를 사용하면 약간 프로그래밍 언어처럼 CSS를 수정할 수 있게 해주는데 이때 WebPack이라는 놈을 사용하면 저 Post-CSS를 CSS로 바꿔준다\n\n여러 디펜던시를 모아서 js, css, jpg, png파일로 딱 만들어주는 것이 WebPack이다\n\n\n"},"archives/아까이브-갈든---Archive-Garden":{"title":"아까이브 갈든 - Archive Garden","links":["archives/microelectronics.spring.2021.cse.cnu.ac.kr/(충남대)-전자회로-강의록","archives/practicalcoding.spring.2021.cse.cnu.ac.kr/(충남대)-실전코딩-강의록"],"tags":[],"content":"\n\n                  \n                  &quot;아까이브 갈든&quot; 은 정리는 안돼있지만 버리기에는 &quot;아까&quot; 운 작물들을 모아놓는 곳입니다. \n                  \n                \n\n\n\n                  \n                  이곳에 있는 문서들은 보관이 목적이고, 관리되지 않습니다. 따라서 잘못된 정보가 포함되어 있거나 순서가 뒤죽박죽일 수 있습니다. \n                  \n                \n\n\n\n                  \n                  현재 기존의 Notion 및 Bear 에 기록된 문서들의 Migration 작업이 진행중입니다. \n                  \n                \n\n입구 §\n\n(충남대) 전자회로 강의록\n(충남대) 실전코딩 강의록\n"},"botanicals/algorithm/(Botanical-Garden)-Algorithm,-Data-Structure":{"title":"(Botanical Garden) Algorithm, Data Structure","links":["botanicals/algorithm/algorithm/sort/Merge-Sort-(Algorithm)","botanicals/algorithm/data-structure/linear/Sorted-Run-(Data-Structure)","botanicals/algorithm/data-structure/map/Bloom-Filter-(Data-Structure)","botanicals/algorithm/data-structure/tree/Balanced-Tree,-B-Tree-(Data-Structure)","botanicals/algorithm/data-structure/tree/Binary-Search-Tree,-BST-(Data-Structure)"],"tags":[],"content":"개요 §\n\nAlgorithm 및 Data structure 관련 잡식들\n귀찮아도 언젠간 정리해야 된다.\n\n작물들 §\nAlgorithm §\nSort §\n\nMerge Sort\n\nData Structure §\nLinear §\n\nSorted Run\n\nMap §\n\nBloom Filter\n\nTree §\n\nBalanced Tree, B Tree\nBinary Search Tree, BST\n"},"botanicals/algorithm/algorithm/sort/Merge-Sort-(Algorithm)":{"title":"Merge Sort (Algorithm)","links":[],"tags":["용어집","algorithm","sort"],"content":"\n\n                  \n                  본 글은 #draft 상태입니다. \n                  \n                  \n                \n                \n\n 그림 추가\n 예제 코드 추가\n\n\n가 뭔데? §\n\nDivide-and-conquer 를 이용한 sort 방식이다.\n원하는 배열을 정렬되어 있는 배열들의 집합으로 나눈 다음, 이것을 합치는 방식으로 진행된다.\n이것을 좀 더 구체적으로 확인해 보자.\n\n1. Divide §\n\n배열을 절반으로 잘라 두개의 배열로 만든다.\n이 과정을 배열의 원소가 하나가 될 때까지 재귀적으로 반복한다.\n\n2. Merge §\n\n우선, 원소가 하나인 배열은 정렬되어 있다고 간주한다.\n두 정렬된 배열을 합치는 것은 two-pointer 로 수행한다.\n\n일단 두 정렬된 배열의 크기 총합과 같은 크기의 배열을 하나 준비한다.\n두 정렬된 배열의 맨 앞에 pointer 를 하나씩 두고,\n두 pointer 가 가리키는 값 중 같거나 작은 값을 준비한 배열에 넣는다.\n추가한 뒤에는 해당 pointer 를 하나 움직인다.\n모든 pointer 가 두 배열의 끝까지 가게 되면 준비한 배열에는 모든 값이 정렬되어 들어가게 된다.\n\n\n\n장단점 §\n장점 §\n\n장점은 시간복잡도가 O(log(N)) 이라는 것이다.\n\nDivide 에 소요되는 시간이 O(log(N)) 이고\nMerge 에 소요되는 시간이 O(N) 이므로\n\n\n\n단점 §\n\n단점은 추가적인 배열이 필요하기 때문에 공간복잡도가 높다는 것이다.\n"},"botanicals/algorithm/data-structure/linear/Sorted-Run-(Data-Structure)":{"title":"Sorted Run (Data Structure)","links":["botanicals/algorithm/algorithm/sort/Merge-Sort-(Algorithm)"],"tags":["용어집","data-structure"],"content":"\n\n                  \n                  참고한 것들 \n                  \n                  \n                \n                \n\nFlink 0.3 시절 공식문서\nLSM tree 자바 구현과정 블로그 글\n\n\n가 뭔데? §\n\n\n사진 출처\n\n\n한마디로 설명하면 “Key 를 기준으로 (1) 중복 없이 (2) 정렬된 (3) overlay 되지 않은 key-value data file 들의 집합” 정도가 된다.\n이것을 Top-down 으로 살펴보자:\n\n하나의 Sorted run 은 여러개의 data file 들로 구성된다.\n그리고 각각의 data file 들에는 key-value 쌍들이 저장되는데,\n이 key-value 쌍들은 key 를 기준으로 정렬되어 있고\n중복된 key 를 가지지 않는다.\n또한 해당 data file 들의 key 들은 overlap 되지 않는다.\n\n범위가 겹치지 않는다는 것인데, 예를 들어 아래와 같은 경우는 안된다는 소리이다.\n\nData File 1 은 [(A:1), (C:3), (E: 5)]\nData File 2 는 [(B:2), (D:4), (F: 6)]\n\n\n위와 같은 것이 sorted run 이 되려면, 각 파일이 다음처럼 되어 있어야 한다.\n\nData File 1 은 [(A:1), (B:2), (C: 3)]\nData File 2 는 [(D:4), (E:5), (F: 6)]\n\n\n\n\n\n\n위의 그림에서 보다시피 다른 sorted run 들 간에는 key 가 중복되거나 overlay 될 수도 있다.\n\nMerging Sorted Runs §\n\n각각의 Sorted run 을 merge 하여 하나의 sorted run 으로 만드는 것은 Merge sort 를 이용하면 된다.\n즉, 이미 두 sorted run 들은 정렬되어 있기 때문에 two-pointer 로 합치기만 하면 되기 때문.\n조금 더 자세히 설명하자면, 다음처럼 merge 된다:\n\n각각의 sorted run 의 시작점에 pointer 를 둔다.\n두 pointer 가 가리키는 두 key-value pair 중 key 가 더 작은 pair 를 buffer 에 넣어두고, 해당 pointer 를 한칸 움직인다.\n만일 두 pair 의 key 가 같다면, 더 최신의 값을 사용한다.\n두 pointer 가 sorted run 를 끝까지 다 \b훑었다면, buffer 에 있는 내용을 적당히 잘라 data file 로 만들어 merging 을 종료한다.\n\n\n즉, 시간복잡도는 O(n) 이 된다.\n\nMerge sort 에서 divide 하는 시간이 빠졌으므로 O(log(n)) 이 없어지는 것.\n\n\n"},"botanicals/algorithm/data-structure/map/Bloom-Filter-(Data-Structure)":{"title":"Bloom Filter (Data Structure)","links":[],"tags":["용어집","data-structure"],"content":"\n\n                  \n                  참고한 것들 \n                  \n                \n\n티스토리 블로그\n\n\n블룸 필터 (Bloom Filter) §\n\n블룸 필터는 원소가 집합 내에 존재하는지 확률적으로 알 수 있게 해주는 자료구조이다.\n여기서 확률적으로 라는 말이 중요한데, 이것은 False-positive 가 존재할 수도 있다는 의미이다.\n\n즉, 블룸필터를 돌렸을 때 “존재하지 않음” 으로 결과가 나오면 해당 원소는 반드시 집합 내에 존재하지 않지만,\n“존재함” 으로 결과가 나오면 집합 내에 있을수도 있고 없을 수도 있다는 얘기이다.\n\n\n따라서 블룸 필터는 이름처럼 “필터” 의 용도로 사용하게 된다.\n\n검사할 원소의 갯수가 음청나게 많은 경우에, 블룸 필터를 먼저 돌려서 확실하게 존재하지 않는 원소들만 먼저 걸러내고, 나머지에 대해 다른 방법을 이용해 검사하면 되는 것.\n\n\n\n아이디어 §\n\n이 블룸 필터를 생각한 사람은 당연히 블룸씨 일거고, 이것은 Space/time trade-offs in hash coding with allowable errors (CACM Mag) 에서 공개되었다.\n이름에서부터 알 수 있듯이,\n\n원리 §\n\n\n블룸 필터를 hash 함수의 collision 을 아주 똑똑하게 사용한다.\n원소를 집합에 추가할 때는 hash 함수를 돌려서 그 결과를 어딘가에 저장해 놓고\n원소를 집합에 존재하는지 검사하고자 할 때도 hash 함수를 돌려서 그의 결과를 저장된 것들과 비교하면 다음과 같은 결과가 나올 수 있다:\n\n우선, hash 결과가 저장된 것들 중에 없다면 해당 원소는 집합에 한번도 추가된 적이 없다고 결론내릴 수 있다.\n\n한번이라도 추가됐다면 저장된 것들 중에 분명히 있어야 되기 때문.\n\n\n하지만 hash 결과가 저장된 것들 중에 있다면\n\n진짜 그 원소가 추가된 적이 있었을 수도 있지만\n이 부분이 중요하다 - 검사하는 원소와 collision 되는 다른 원소가 추가되었을 수도 있다.\n\n\n\n\n구체적으로는 결과를 bit array 에 저장한다.\n\nHash 의 결과가 4bit 라면, 0~15 까지 16개의 값을 가질 수 있으므로 16bit 저장소를 사용하게 되는 것.\n따라서 “John Smith” 을 hash 한 결과가 2 이라면, 2번째 index 의 bit 에 1을 저장해 원소가 추가되었음을 표시한다.\n이렇게 하면 bit comparison 으로 결과를 알 수 있어 빠르기 때문.\n\n\n\n\n\n                  \n                  그림이 좀 안맞죠? \n                  \n                \n\n위키피디아 에서 가져온 그림을 수정해서 사용했는데 가운데 “hashes” 부분이 좀 헷갈릴 수 있을것 같아 첨언하자면,\n저 “hashes” 는 bit array 가 아니라 hash 의 결과고, bit array 는 표현 안돼있습니다.\n\n"},"botanicals/algorithm/data-structure/tree/Balanced-Tree,-B-Tree-(Data-Structure)":{"title":"Balanced Tree, B Tree (Data Structure)","links":["botanicals/algorithm/data-structure/tree/Binary-Search-Tree,-BST-(Data-Structure)"],"tags":["용어집","data-structure","tree"],"content":"\n\n                  \n                  참조한 것들 \n                  \n                \n\n어떤 B-Tree 소개 블로그 글\n어떤 Index, B+Tree 소개 블로그 글\n\n\nBalanced Tree 의 필요성 §\n\nBST 를 생각해 보면 일반적인 경우에는 탐색의 시간복잡도가 log2(n) 이지만\n최악의 경우인 모든 노드가 치우쳐져있는 경우 (전부 일렬로 연결되어 있는 경우) 에는 탐색의 시간복잡도는 n 이 된다\n따라서 트리가 항상 균형을 이루는 상태 (모든 Leaf 노드가 같은 레벨에 존재하는 상태) 로 유지될 수 있게 한다면, 어떤 경우에도 시간복잡도는 logx(y) 일 것이다\n\nB-Tree §\n\nB-Tree 는 Balanced Tree 의 일종인데\nB-Tree 의 경우에는 자식이 2개 이상일 수 있고 노드의 Key 는 1개 이상일 수 있다\n\n여기서 Key 가 뭐냐면\nBST 의 경우에는 Key 가 1개라고 말할 수 있다 → 1개의 키를 기준으로 그것보다 크면 오른쪽으로 내려가고 작으면 왼쪽으로 내려가자네\n이제 B-Tree에서는 이러한 키가 여러개가 될 수 있다는 거임 → 뭐 예를 들어서 키가 n, m으로 2개면 n보다 작으면 왼쪽으로, n 보다 크거나 같고 m 보다 작으면 중간으로, m 보다 크면 오른쪽으로 내려가는 식\n성질이 이렇기 때문에 키는 반드시 오름차순으로 정렬되어 있어야 하고 키의 갯수보다 하나 많은 자식 노드를 가질 수 있다\n\n\n한 노드가 가질 수 있는 자식의 최대 개수가 M 라면 그걸 M차 B-Tree 라고 부른다\n\n따라서 위에서 설명한 것을 토대로 생각해보면 한 노드에 들어갈 수 있는 키의 최대 갯수는 M - 1 개 이다.\n\n\n정리해보면 M차 B-Tree 의 조건은 다음과 같다\n\n루트와 리프를 제외한 Node 중 어떤 한 Node 의 Key 개수가 k라면 (1 ≤ k ≤ M - 1) 자식의 개수의 범위는 M / 2 ~ k + 1 이다.\n\n모든 Node 의 키의 개수가 동일하지 않아도 된다 → k 는 노드마다 다를 수 있다는 것\n\n\nNode 의 Key 는 정렬된 상태로 존재해야 한다\n자식 Node 들의 Key 는 현재 Node 의 Key 를 기준으로 나뉜다\n\n이말이 결국에는 이말과 같은소리임\n이제 B-Tree에서는 이러한 키가 여러개가 될 수 있다는 거임 → 뭐 예를 들어서 키가 n, m으로 2개면 n보다 작으면 왼쪽으로, n 보다 크거나 같고 m 보다 작으면 중간으로, m 보다 크면 오른쪽으로 내려가는 식\n\n\n모든 Leaf Node 들은 같은 Level 에 존재한다.\n\n\n\nB+Tree §\nB+Tree 란 §\n\nB-Tree 의 경우 단일 검색은 빠르지만 Full scan 을 하기 위해서는 결국 트리의 모든 노드를 방문해야 하기 때문에 비효율적이랜다\n\n아니 근데 어차피 모든 트리 노드 방문하는 것도 선형 시간 복잡도 아닌가\n\n\n어쨋든 그래서 B+Tree 의 특징은 다음과 같다\n\n데이터는 리프노드에만 저장된다\n리프노드가 아닌 노드는 자식의 포인터와 자식을 찾아가기 위한 Key 만 들어간다\n\n그래서 Key 가 중복될 수도 있다던데 뭔소린지는 잘 모르겠누\n\n\n데이터 노드인 리프노드는 링크드 리스트맹키로 일렬로 연결되어 있다.\n\n\n"},"botanicals/algorithm/data-structure/tree/Binary-Search-Tree,-BST-(Data-Structure)":{"title":"Binary Search Tree, BST (Data Structure)","links":[],"tags":["용어집","data-structure","tree"],"content":"\n\n                  \n                  본 글은 #draft 상태입니다. \n                  \n                  \n                \n                \n\n 내용 보강하기\n 그림 추가하기\n\n\nBST §\n\n트리 생성 규칙은 다음과 같다.\n\nNode 는 어떤 값 (Key 라고 부르기도 한다) 을 담고 있다.\nNode 의 자식은 최대 2개이다.\nNode 의 왼쪽 자식의 값은 본인의 값보다 작고, 오른쪽 자식의 값은 본인의 값보다 커야 한다.\n\n\n이름에 “Search” 가 들어가는 이유는 특정 값을 찾기에 유용한 자료구조이기 때문이다.\n\n간단히 설명하면, 어떤 값 x 를 찾기 위해서는\n\nRoot node 부터 시작해\n\bx 가 node 의 key 보다 작으면, 왼쪽 node 로, 크면 오른쪽 node 로 내려가는 작업을\nx 를 찾을 때 까지 반복하면 된다.\n\n\n\n\n"},"botanicals/algorithm/draft/Log-Structure-Merge-Tree,-LSM-Tree-(Data-Structure)":{"title":"Log Structure Merge Tree, LSM Tree (Data Structure)","links":[],"tags":["용어집","data-structure","tree"],"content":"\n\n                  \n                  본 글은 #draft 상태입니다. \n                  \n                  \n                \n                \n\n 논문 (Patrick O’Neil - The Log-Structured Merge-Tree (LSM-Tree)) 읽고 정리\n\n"},"botanicals/algorithm/draft/Skip-List-(Data-Structure)":{"title":"Skip List (Data Structure)","links":[],"tags":["용어집","data-structure"],"content":"\n\n                  \n                  본 글은 #draft 상태입니다. \n                  \n                  \n                \n                \n\n 내용 추가\n\n"},"botanicals/algorithm/draft/Sparse-Index-(Data-Structure)":{"title":"Sparse Index (Data Structure)","links":[],"tags":["용어집","data-structure"],"content":"\n\n                  \n                  본 글은 #draft 상태입니다. \n                  \n                  \n                \n                \n\n 내용 정리\n DB 로 옮길 수도 있음\n\n"},"botanicals/cybersecurity/(Botanical-Garden)-Cybersecurity":{"title":"(Botanical Garden) Cybersecurity","links":["botanicals/cybersecurity/docs/Symmetric-Key-for-TLS---TLS-통신에-대칭키를-사용하는-이유","botanicals/cybersecurity/docs/x509v3-Basic-Constraints-extension-explained---Basic-Constraints-란-q","botanicals/cybersecurity/docs/x509v3-Key-Usage-and-Extended-Key-Usage-extension-explained---Key-Usage-와-Extended-Key-Usage-란-q","botanicals/cybersecurity/terms/Certificate-Authority,-CA-(PKIX)","botanicals/cybersecurity/terms/Certificate-Signing-Request,-CSR-(PKIX)","botanicals/cybersecurity/terms/Common-Name,-CN-(PKIX)","botanicals/cybersecurity/terms/Mutual-TLS,-mTLS-(PKIX)","botanicals/cybersecurity/terms/Serial-Number-(PKIX)","botanicals/cybersecurity/terms/Subject-Alternative-Name,-SAN-(PKIX)"],"tags":[],"content":"개요 §\n\nCybersecurity 와 관련된 문서들을 모아 놓는 곳\n이긴 하지만 주인장이 이것에 관해 아는 것이 거의 없기 때문에 보통 암호학 혹은 인증서 관련 내용이 저장되어 있을 것이다.\n\n문서집 §\n\nTLS 통신에 대칭키를 사용하는 이유\nBasic Constraints 란?\nKey Usage 와 Extended Key Usage 란?\n\n용어집 §\n\nCertificate Authority (CA)\nCertificate Signing Request, CSR\nCommon Name (CN)\nMutual TLS (mTLS)\nSerial Number\nSubject Alternative Name (SAN)\n"},"botanicals/cybersecurity/docs/Symmetric-Key-for-TLS---TLS-통신에-대칭키를-사용하는-이유":{"title":"Symmetric Key for TLS - TLS 통신에 대칭키를 사용하는 이유","links":[],"tags":["pkix"],"content":"\n\n                  \n                  Info 참고한 문서 - Quora\n                  \n                \n\nTLS 에서는 비대칭키만 사용하는 것 아녔음?? §\n\n라고 알았다면, 뭔가 잘못된 것이다.\nTLS 통신에서의 암호화는 간략하게 설명하면 다음과 같이 이루어진다\n\nClient 가 대칭키를 생성할 시드값 (pre-master secret) 을 생성\nClient 가 인증서에 포함되어 있는 (비대칭) 공개키로 이것을 암호화 하여 Server 에게로 전송함\nServer 는 (인증서를 생성할 때 사용된, 공개키와 쌍을 이루는) 비대칭 개인키로 전송받은 것을 복호화 하여 시드값을 알아냄\nClient 와 Server 모두 이 시드값을 이용해 동일한 대칭키를 계산해냄\n위의 과정을 거치면 Client 와 Server 에게 동일한 대칭키가 공유되었으므르, 이것을 이용해 본격적인 통신을 하며 데이터를 암복호화함\n\n\n근데 왜? 비대칭키로도 암복호화가 가능한데 왜 대칭키로 통신을 할까?\n\n그것을 알려드림 §\n\n데이터 통신을 사용할 때 비대칭키를 사용하면 발생할 수 있는 문제가 두가지 있다고 한다.\n\n1. 데이터의 크기 §\n\n일단 비대칭키는 많은 데이터를 암복호화 할 용도로 설계되어 있지 않다.\n\nModulus 보다 작은 크기의 데이터만 처리 가능하고, 만일 이것보다 클 경우 나눠서 처리해야 한다.\n\n\n하지만 대칭키의 경우에는 거의 무한대 크기의 데이터도 처리가 가능하다고 한다.\n\n2. 연산의 속도 §\n\n비대칭키를 이용해 데이터를 암복호화하는 것은 대침키에서의 암복호화와 비교했을 때, 비용이 큰 연산이다.\n\n대칭키의 경우에는 bitwise operation 정도의 간단하고 빠른 (심지어 HW 의 도움으로 더욱 가속이 가능한) 연산이 주가 되어 데이터를 암복호화 하지만,\n비대칭키의 경우에는 다소 복잡한 연산들이 들어가기 때문\n\n\n"},"botanicals/cybersecurity/docs/x509v3-Basic-Constraints-extension-explained---Basic-Constraints-란-q":{"title":"x509v3 Basic Constraints extension explained - Basic Constraints 란?","links":["botanicals/cybersecurity/terms/Certificate-Authority,-CA-(PKIX)","botanicals/cybersecurity/docs/x509v3-Key-Usage-and-Extended-Key-Usage-extension-explained---Key-Usage-와-Extended-Key-Usage-란-q","botanicals/cybersecurity/docs/x509v3-Basic-Constraints-extension-explained---Basic-Constraints-란-q"],"tags":["pkix"],"content":"\n\n                  \n                  참고 문서 - RFC5280\n                  \n                \n\nBasic Constraints §\n\n간단하다.\n이 인증서가 (1) CA 인지, (2) 만일 CA 라면, 자식 Intermediate certificate 를 몇개나 만들 수 있는지 명시하는 부분이다.\n\n(1) 항목은 cA 필드를 이용해 명시하고,\n(2) 항목은 pathLenConstraint 필드를 이용해 명시한다.\n\n\nRFC5280 에는 이 항목을 다음과 같은 구조체로 정의한다:\n\nBasicConstraints ::= SEQUENCE {\n\tcA                      BOOLEAN DEFAULT FALSE,\n\tpathLenConstraint       INTEGER (0..MAX) OPTIONAL\n}\n\n항목들 §\ncA §\n\n별로 어려울 건 없다; 이 인증서가 CA 인지를 나타내는 boolean 값이다.\n\ncA:TRUE 라면, 이 인증서는 CA 인증서로 사용할 수 있는거고\ncA:FALSE 라면 그 반대겠지\n\n\n만일 이 값이 설정돼있지 않거나 cA:FALSE 라면, keyCertSign 또한 설정되면 안되고, 공개키가 인증서 서명을 검증하는데 사용되어서도 안된다고 한다.\n\npathLenConstraint §\n\n이건 이 인증서가 생성할 수 있는 자식 CA (Intermediate certificate) 가 몇개인지를 제한하는 값이다.\n\n제한 의 말뜻처럼, 이 값을 명시하지 않으면 무한대의 자식 CA 를 생성할 수 있다\n\n\n다만, 여기에는 인증서 체인의 마지막 non-CA 인증서 (End-entity certificate) 은 포함되지 않는다.\n\n즉, pathLenConstraint 값이 0 이라면, 이 인증서를 이용해 자식 인증서를 생성할 때 CA 는 생성하지 못하지만 CA 가 아닌 인증서는 생성할 수 있다는 소리이다.\n주의할 점은 (비록 흔하진 않지만) 마지막 인증서가 CA 일 경우에는 포함이 된다는 것이다.\n\n\n이 값이 효력이 있기 위해서는 cA 가 TRUE 여야 하고 keyCertSign 또한 설정되어 있어야 한다.\n"},"botanicals/cybersecurity/docs/x509v3-Key-Usage-and-Extended-Key-Usage-extension-explained---Key-Usage-와-Extended-Key-Usage-란-q":{"title":"x509v3 Key Usage and Extended Key Usage extension explained - Key Usage 와 Extended Key Usage 란?","links":["botanicals/cybersecurity/docs/Symmetric-Key-for-TLS---TLS-통신에-대칭키를-사용하는-이유","botanicals/cybersecurity/docs/x509v3-Key-Usage-and-Extended-Key-Usage-extension-explained---Key-Usage-와-Extended-Key-Usage-란-q","botanicals/cybersecurity/terms/Mutual-TLS,-mTLS-(PKIX)"],"tags":["pkix"],"content":"\n\n                  \n                  Info 참고한 문서\n                  \n                \n\n개요 §\n\n인증서 생성시에 명시할 Key Usage 와 Extended Key Usage 들에 대해 정리해 보자.\n\n물론, 모두 정리하지는 않고 사용해본 애들을 추가하며 정리해나갈 예정.\n\n\n\n이런게 왜 필요하지? §\n\n인증서에 포함되어 있는 공개키의 사용 범위를 제한하는 역할을 한다.\n기본적인 Key Usage 와 이것의 확장판이라고 할 수 있는 Extended Key Usage 가 있다.\n\nKey Usage (KU) §\n\n기본적인 Key Usage.\n\n즉, 인증서의 키가 어떻게 사용될 수 있는지를 명시하는 부분이다.\n\n\nOpenSSL Configuration 파일에는 다음처럼 명시할 수 있다.\n\n[req]\nx509_extensions = v3_req\n\n[v3_req]\nkeyUsage = 항목들 나열...\n\nDigital Signature (digitalSignature) §\n\n어떤 형태로든 디지털 서명을 생성하는 일을 일컫는다.\n아주 흔한 유스케이스이기 때문에, 인터넷 환경에서 사용되는 인증서에서는 기본적으로 활성화 되게 된다.\n\nKey Encipherment (keyEncipherment) §\n\n암호키를 암호화할 수 있게 하는 것\n\n인데, 이렇게만 말하면 뭔가 말장난같으니 조금 더 추가하자면, TLS 통신에 사용되는 대칭키를 비대칭 키로 암호화 하는 등의 유스케이스를 위한 기능이다.\n\n\n\nCertificate Signing (keyCertSign) §\n\n인증서를 서명할 수 있게 하는 것.\n보통 Root / Intermediate CA 들에게 부여되어 자식 인증서를 생성해서 서명할 수 있도록 한다.\n\nData Encipherment (dataEncipherment) §\n\n암호키가 아닌 애플리케이션 데이터를 암호화할 수 있게 하는 것\n이것 또한 아주 흔한 유스케이스이기 때문에, 인터넷 환경에서 사용되는 인증서에서는 기본적으로 활성화 되게 된다.\n\nExtended Key Usage (EKU) §\n\n기본적인 Key Usage 들에 추가적인 기능들.\n인데, 키 보다는 인증서가 어떻게 사용될 수 있는지를 명시하는 부분이라고 할 수 있다.\nOpenSSL Configuration 파일에는 다음처럼 명시할 수 있다.\n\n[req]\nx509_extensions = v3_req\n\n[v3_req]\nextendedKeyUsage = 항목들 나열...\n\nTLS Web Server Authentication (serverAuth) §\n\n일반적인 TLS 통신에서, Server 가 CA 의 도움을 받아 자신의 신원을 인증할 수 있도록 하는 기능이다.\n\nTLS Web Client Authentication (clientAuth) §\n\n일반적인 TLS 에 사용되는 Server Auth 과 달리, mTLS 통신에서 Client 가 CA 의 도움을 받아 자신의 신원을 인증할 수 있도록 하는 기능이다.\n"},"botanicals/cybersecurity/draft/Border-Gateway-Protocol-Security-Extension,-BGPsec-(Security)":{"title":"Border Gateway Protocol Security Extension, BGPsec (Security)","links":[],"tags":["용어집"],"content":"\n\n                  \n                  본 글은 #draft 상태입니다. \n                  \n                  \n                \n                \n\n 내용 정리\n\n"},"botanicals/cybersecurity/draft/Public-Key-Infrastructure,-PKI-(Security)":{"title":"Public Key Infrastructure, PKI (Security)","links":[],"tags":["용어집","security"],"content":"\n\n                  \n                  본 글은 #draft 상태입니다. \n                  \n                  \n                \n                \n\n 내용 정리\n\n"},"botanicals/cybersecurity/draft/Resource-Public-Key-Infrastructure,-RPKI-(Security)":{"title":"Resource Public Key Infrastructure, RPKI (Security)","links":["botanicals/cybersecurity/draft/Public-Key-Infrastructure,-PKI-(Security)","botanicals/networks/draft/Autonomous-System,-AS-(Network)","botanicals/networks/draft/Border-Gateway-Protocol,-BGP-(Network)","botanicals/networks/bgp/terms/Regional-Internet-Registry,-RIR-(Network)"],"tags":["용어집","security"],"content":"\n\n                  \n                  참고한 것 \n                  \n                  \n                \n                \n\n어떤 회사 글\n위키피디아\nRFC6480\n\n\n\n\n                  \n                  본 글은 #draft 상태입니다. \n                  \n                  \n                \n                \n\n 내용 정리\n\n\n뭘까 §\n\n어떤 자원 (Resource) 를 기존의 PKI 를 이용해 인증하는 프레임워크인데\n여기서 자원은 IP Prefix 와 그것을 소유하고 있는 AS 의 ASN 의 매핑을 의미한다.\n\n왜 많고 많은 자원중에 하필이면 이것이냐 라고 물어본다면\n이것이 등장하게 된 계기가 BGP 에서의 보안 취약점을 해결하기 위해 등장한 것이기 때문이다.\n즉, 자꾸 어떤 이상한 놈이 자기가 갖고 있지도 않은 IP Prefix 를 가지고 있다고 떠들어대는 것을 막기 위함인 것.\n\n\n이놈은 다른 인터넷 관련 자원인 public IP 나 ASN 처럼 RIR 이 발급, 관리한다.\n\nRIR 은 요청이 들어오면 (아마 나름의 검증 절차를 거친 뒤에) 이 인증서를 발급해 준다.\n이 인증서는 1년마다 갱신하는 것이 원칙이고\nRIR 은 root CA 로서 self-signed certificate 으로 이 인증서를 발급해 준다.\n\n\n\nRoute Origination Authorization (ROA) §\n\n이때 저 IP Prefix 와 ASN 를 적고 이것을 서명한 문서를 Route Origination Authorization (ROA) 라고 한다.\n아래와 같은 방식으로 구성된다고 한댜:\n\nRouteOriginAttestation ::= SEQUENCE {\n    version [0] INTEGER DEFAULT 0,\n    asID  ASID,\n    ipAddrBlocks SEQUENCE (SIZE(1..MAX)) OF ROAIPAddressFamily\n}\n\nASID ::= INTEGER\n\nROAIPAddressFamily ::= SEQUENCE {\n    addressFamily OCTET STRING (SIZE (2..3)),\n    addresses SEQUENCE (SIZE (1..MAX)) OF ROAIPAddress\n}\n\nROAIPAddress ::= SEQUENCE {\n    address IPAddress,\n    maxLength INTEGER OPTIONAL\n}\n\nIPAddress ::= BIT STRING\n\n\n여기서 RouteOriginAttestation 을 서명한 것이 ROA 가 된다 (아마?)\n우선 여기서 그다지 중요하지 않은 내용부터 정리해 보자.\n\nversion: ROA 의 버전을 의미한다. 조건 0이다.\naddressFamily: IP 버전 (IPv4, IPv6) 을 명시하는 부분이다. IPv4 일 경우에는 0001, IPv6 일 경우에는 0002 가 들어간다.\n\n\n\nIP Prefix, ASN §\n\nRPKI 의 핵심이 IP Prefix 와 ASN 를 인증하는 것이기 때문에 당연히 들어가야 되는 항목이 맞는데\n눈여겨볼 점은 IP Prefix (addresses) 는 여러개를 지정할 수 있고 ASN (adID) 은 하나만 지정이 가능하다는 것이다.\n즉, 한 AS 는 여러 IP Prefix 를 advertise 할 수 있고 그것에 대한 ROA 인증서를 생성할 수 있다.\n하지만 어떤 기관은 여러개의 AS 를 소유할 수 있는데, 이것에 대해서는 하나의 ROA 로 안된다는 얘기이다.\n\n각각의 AS 에 대해 ROA 를 발급받아야 하는 것.\n\n\n\nMaximum Prefix Length §\n\nMaximum Prefix Length 는 말 그대로 IP Prefix 의 길이이다.\n가령, ASN-3 은 address: 193.0.0.0/21 와 maxLength: 22 를 적어서 ROA 를 생성할 수 있다.\n\n이렇게 하면 ASN-3 은 193.0.0.0/21 과 193.0.0.0/22, 193.0.4.0/22 등의 IP Prefix 들은 advertise 할 수 있지만,\n193.0.2.0/23 이나 193.0.7.0/24 등의 IP Prefix 는 advertise 할 수 없다.\n\n193.0.0.0/21 에 다 포함되지 않나? 라고 생각할 수 있는데\nBGP 작동 원리를 떠올려 보면 이것은 분명히 다르다는 것을 알 수 있다.\nBGP 는 라우팅을 할 때 longest-matching 을 사용하기 때문에, 다른 AS 에서 193.0.7.0/24 를 advertise 하지 않는다면 해당 패킷들은 ASN-3 으로 가게 되겠지만\n만일 다른 AS 가 193.0.7.0/24 를 advertise 하면 그쪽으로 가게 되는 것.\n\n\n\n\n기본값은 IP Prefix 에 적힌 Length 이다.\n\n즉, 위의 예시에서 maxlen: 22 가 없다면, ASN-3 은 193.0.0.0/22 를 advertise 하지 못한다.\n\n\n그리고 위의 ROA 구조를 보면 알 수 있듯이, 이 값은 IP Prefix 마다 설정할 수 있다.\n\nIP Prefix 를 여러개 명시할 경우, 각각에 대한 maxLength 를 설정할 수 있다.\n\n\n\nState §\n\n이 ROA 를 검증했을 때에는 세가지의 결과가 나올 수 있다.\n\nvalid: ROA 에 있는 IP Prefix 와 ASN 이 advertise message 에 있는 것과 동일함\ninvalid: ROA 에 있는 IP Prefix 와 ASN 이 advertise message 에 있는 것과 동일하지 않음\nnot-found: Advertise message 에 ROA 가 없음\n\n\n\nConfiguration Example (Cisco) §\n!  \nrouter bgp 65000  \naddress-family ipv4 unicast  \nneighbor 10.0.102.1 route-map rtmap-PEX1-3 in  \nbgp bestpath prefix-validate allow-invalid  \n!  \nroute-map rtmap-PEX1-3 permit 10  \nmatch rpki invalid  \nset local-preference 50  \n!  \nroute-map rtmap-PEX1-3 permit 20  \nmatch rpki not-found  \nset local-preference 100  \n!  \nroute-map rtmap-PEX1-3 permit 30  \nmatch rpki valid  \nset local-preference 200  \n!  \nroute-map rtmap-PEX1-3 permit 40  \n!\n\n\n위에는 Cisco router 의 설정 예시인데\nrtmap-PEX1-3 을 보면\n\ninvalid 일 때는 local preference 를 50\nnot-found 일 때는 100\nvalid 일 때는 200 으로 설정한 것을 볼 수 있다.\n\n\n즉, RPKI 의 상태에 따라 신뢰할 수 있는 정도를 반영해 local preference 를 다르게 준 셈.\n"},"botanicals/cybersecurity/draft/Subject-Key-Identifier,-SKID-(PKIX)":{"title":"Subject Key Identifier, SKID (PKIX)","links":[],"tags":["pkix","용어집"],"content":"\n\n                  \n                  본 글은 #draft 상태입니다. \n                  \n                  \n                \n                \n\n 내용 정리\n\n"},"botanicals/cybersecurity/terms/Certificate-Authority,-CA-(PKIX)":{"title":"Certificate Authority, CA (PKIX)","links":[""],"tags":["pkix","용어집"],"content":"\n\n                  \n                  참고 문서\n                  \n                \n\n용어 설명 §\n\n“인증서를 발급해주는 신뢰할 수 있는 기관”\n그럼 이딴게 왜 필요하지? 싶을 수 있는데, CA 가 필요한 이유를 메디쏜 디지딸 갈든 에 접속하고자 하는 김해람씨의 상황으로 이해해 보자.\n\n김해람씨는 ‘메디쏜 디지딸 갈든’의 아주 멋진 작물들을 구경하기 위해 접속을 한다.\n그럼 이제 서버는 김해람씨에게 “내가 진짜 ‘메디쏜 디지딸 갈든’ 서버가 맞아” 라는 것을 확신시켜 주기 위해 서버 인증서를 제시하게 된다.\n근데 김해람씨는 이 인증서를 받아들고 고민에 빠진다: 이게 진짜 ‘메디쏜 디지딸 갈든’ 서버가 맞을까? 혹시 어떤 해커가 사칭하기 위해 ‘메디 쏜디 지딸 갈든’ 으로 가짜 웹사이트를 만들어 뿌린거라면?\n이때 CA 가 등장한다. 김해람씨는 이 인증서를 발급해준 CA 를 (서버 인증서에 이미 포함되어 있는) CA 인증서를 통해 확인하고, 이 CA 가 “이 웹사이트가 진짜 ‘메디쏜 디지딸 갈든’이 맞아!” 라는 것을 보장해 준다는 것을 알게 된다.\nCA 의 보증과 함께 김해람씨는 안심하면서 이 웹사이트에 접속한다.\n\n\n실제로 ‘메디쏜 디지딸 갈든’ 의 인증서를 확인해 보면 다음처럼 되어 있는 것을 볼 수 있다:\n이게 서버 인증서이고:\n\n\n\nIssued By 항목에 있는 것이 CA 이다: Let’s Encrypt 라는 기관에서 발급해 준 것임을 알 수 있다.\n\n\n\n그럼 이런 생각이 들 수 있다: 아니 그럼 CA 는 어떻게 믿어?\n\n이건 그냥 믿어야 한다. 사실 보안의 끝은 신뢰이기 때문.\n인증서를 발급해주는 공인 CA 들이 몇개 있는데, (위에서 나온 Let’s Encrypt 도 그중 하나) 이들의 인증서는 웹 브라우저에 이미 내장되어 신뢰하도록 설정되어 있다.\n\n즉, 이 공인 CA 들에 대해서는 믿어 주자고 인터넷 생태계에서 이미 합의가 되어 있다는 것.\n\n\n\n\n이것도 직접 확인해보자\n크롬브라우저 기준, 이곳 으로 접속하면 보안 관련 설정을 볼 수 있다. 여기에서 Advanced 항목에 Manage Certificates 을 통해 어떤 인증서들이 신뢰되도록 설정돼있는지 확인할 수 있다.\n\n…근데 맥에서는 잘 안보인다. 윈도우에서는 잘 보였었는데\n\n\n근데 만일 CA 를 확인해 봤을 때 이런 공인 CA 가 아니면 어떻게 될까? 인터넷 돌아다니다 보면 가끔 보이는 이 경고창이 “이 CA 는 믿을 수 없다네” 라는 뜻이다.\n\n\n\n물론 자연스럽게 (안전하지 않음) 버튼을 누르며 들어가는 게 습관이 됐지만, 어쨋든 이런 웹사이트는 문제가 있을 수 있으니 조심해야 한다.\n"},"botanicals/cybersecurity/terms/Certificate-Signing-Request,-CSR-(PKIX)":{"title":"Certificate Signing Request, CSR (PKIX)","links":["botanicals/cybersecurity/terms/Common-Name,-CN-(PKIX)"],"tags":["pkix","용어집"],"content":"\n\n                  \n                  참고 문서 - GlobalSign\n                  \n                \n\n용어 설명 §\n\n별거 없다 - Certificate (인증서) Signing (서명) Request (요청), 즉, 이 파일에 담긴 내용을 가지고 인증서를 하나 생성해 달라는 일종의 신청서 같은 것이라 보면 된다.\n이 파일에는 크게 두 종류의 정보가 담긴다:\n\n서버 정보\n\nCommon Name (CN) 부터 해서, Organization (O), Organization Unit (OU) 등의 요청하는 서버에 대한 정보들\n\n\n인증서에 사용될 \b키 쌍에 대한 정보\n\n키 쌍 중에서 공개키와, 키 타입 (RSA 인지 ECC 인지 등), 그리고 키 길이 (RSA 의 경우 2048 인지 4096인지 등) 정보\n\n\n\n\n"},"botanicals/cybersecurity/terms/Common-Name,-CN-(PKIX)":{"title":"Common Name, CN (PKIX)","links":["botanicals/cybersecurity/terms/Subject-Alternative-Name,-SAN-(PKIX)"],"tags":["용어집","pkix"],"content":"\n\n                  \n                  참고 문서\n                  \n                \n\n용어 설명 §\n\nCN 혹은 Common Name 은 간단하게 생각하면 인증서의 도메인이다.\n\n물론 이렇게만 설명하면 잘못된 설명일 수 있다.\n서버의 이름 이라고 보통 설명하지만 그렇게 말하면 감이 잘 안오잖아 그치?\n\n\n가령 지금 자네가 보고 있는 이 블로그 의 인증서를 확인하면 CN 이 도메인과 동일하게 mdg.haeramk.im 로 되어 있는 것을 볼 수 있다.\n\n\n\n근데 여러개의 도메인을 인증하고 싶은 경우 CN 을 사용하면 하나만 인증할 수 있기 때문에 좀 불편하다.\n그래서 나온게 SAN (Subject Alternative Name) 이다\n\nCN 설정 예시 §\nOpenSSL Config 파일 예시 §\n\nOpenSSL Config 파일에서는 다음과 같이 CN 을 지정해 줄 수 있다\n\n[req]\ndistinguished_name = cert_dn\n\n[cert_dn]\nCN = 여기에 적으면 된다!\n\nopenssl 명령어 예시 §\n\nOpenSSL Config 를 사용하지 않고 openssl 명령어에서 바로 넣어줄 때는 -subj 옵션을 사용하면 된다.\n10년짜리 Self-signed 인증서를 만드는 아래의 명령어를 참고하자.\n\nopenssl req -x509 \\\n    -newkey rsa:4096 \\\n    -keyout key.pem \\\n    -out cert.pem \\\n    -sha256 -days 3650 -nodes \\\n    -subj &quot;CN=여기에 적으면 된다!&quot;"},"botanicals/cybersecurity/terms/Mutual-TLS,-mTLS-(PKIX)":{"title":"Mutual TLS, mTLS (PKIX)","links":[],"tags":["용어집","pkix"],"content":"\n\n                  \n                  Info 참고한 글\n                  \n                \n\n용어 설명 §\n\n기존의 Server cert 로만 암호화 통신을 진행하던 TLS 와 달리,\nServer cert 와 Client cert 모두 사용해서 암호화 통신을 제공하는 방법이다.\n\n장점? §\n\n이걸 사용해서 좋은점 중에 하나는, Token 혹은 Password 같은 기존의 인증수단에 추가적인 방어막을 하나 더 칠 수 있다는 것이다.\n\n예를 들어 Brute force attack 이나 Phishing attack 과 같은 방법으로 Password 가 노출되었을 때, 이 탈취한 Password 로 접근하는 것을 막을 방법이 (뭐 Password 를 변경하는 것 이외에는) 없었는데\n만약 mTLS 를 이용하게 되면 Password 이외에도 Client 의 TLS 인증서와 개인키까지 있어야 서버에 인증할 수 있기 때문에 이러한 공격에서 더 안전할 수 있다.\n\n\n\n단점? §\n\n단점이라기 보다는 왜 일반적인 통신에서는 mTLS 가 아니라 TLS 를 사용하는 이유에 대해 생각해 보자\n\nmTLS 를 사용하기 위해서는 Client 한테도 TLS 인증서가 있어야 하잖어?\n근데 내가 노트북에서 접속할 때랑 핸드폰에서 접속할 때 모두 인증이 가능하게 하려면 노트북과 핸드폰이 같은 Client 인증서 를 공유하거나\n각각 Client 인증서를 생성해야 하는데 이건 딱 봐도 관리가 여간 복잡한 게 아니기 때문이다.\n\n\n\n작동 방식 §\n기존 TLS 작동 방식 §\n\n간단히 살펴보면,\n\n클라이언트가 서버 접속\n서버가 TLS 인증서 제시\n클라이언트가 서버의 TLS 인증서를 (제 3의 기관을 통해) 신뢰할 수 있는지 검증\n암호화 통신 시작\n\n\n인 반면, mTLS 는 여기에 추가적인 step 이 붙는다.\n\nmTLS 작동 방식 §\n\n저 참고한 글 에서 처럼 추가적인 step 에 bold 처리를 해서 보면, 다음처럼 수행된다\n\n클라이언트가 서버 접속\n서버가 TLS 인증서 제시\n클라이언트가 서버의 TLS 인증서를 (제 3의 기관을 통해) 신뢰할 수 있는지 검증\n클라이언트가 TLS 인증서 제시\n서버가 클라이언트의 TLS 인증서를 (제 3의 기관을 통해) 신뢰할 수 있는지 검증\n서버가 클라이언트의 접속을 허용\n암호화 통신 시작\n\n\n"},"botanicals/cybersecurity/terms/Serial-Number-(PKIX)":{"title":"Serial Number (PKIX)","links":[],"tags":["용어집","pkix"],"content":"\n\n                  \n                  참고할만한 공식문서\n                  \n                \n\n용어 설명 §\n\nCA 가 인증서를 발급해 줄 때, 발급한 인증서에 Unique Identifier 를 부여하기 위해 사용하는 값이다.\n일반적으로는 다른 인증서랑 겹치지 않는 양의 정수를 이용해 값을 부여하나, 가령 Self-signed 인증서 등에서는 0 혹은 음의 정수를 사용하기도 한다고 한다.\n"},"botanicals/cybersecurity/terms/Subject-Alternative-Name,-SAN-(PKIX)":{"title":"Subject Alternative Name, SAN (PKIX)","links":["botanicals/cybersecurity/terms/Common-Name,-CN-(PKIX)"],"tags":["용어집","pkix"],"content":"\n\n                  \n                  참고 문서\n                  \n                \n\n용어 설명 §\n\n인증서가 여러개의 도메인을 인증할 수 있도록 해주는 기능이다.\nCommon Name 에서도 설명한 것처럼, 이것이 하나의 도메인밖에 커버하지 못한다는 문제를 해소하기 위해 나왔다.\n\nSAN 설정 예시 §\nOpenSSL Config 파일 예시 §\n\nOpenSSL Config 파일에서는 다음과 같이 SAN 을 지정해 줄 수 있다\n\n[req]\nx509_extensions = v3_req\n\n[v3_req]\nsubjectAltName = @alt_names\n\n[alt_names]\nDNS.0 = 첫번째 도메인\nDNS.1 = 두번째 도메인\nIP.0 = IP 도 가능하다!\n"},"botanicals/database/(Botanical-Garden)-Database":{"title":"(Botanical Garden) Database","links":["botanicals/database/rocksdb/Leveled-Compaction-(RocksDB)","botanicals/database/rocksdb/LSM-Tree-(RocksDB)","botanicals/database/rocksdb/Memtable-(RocksDB)","botanicals/database/rocksdb/Static-Sorted-Table,-SST-(RocksDB)"],"tags":[],"content":"개요 §\n\n주인장 김해람씨는 2024년 3월 11일 중대한 과오를 저질러 Cloud Engineer 에서 DB 분야로 전직하게 된다. 이에 따라 RocksDB 와 같은 돌을 굴리게 되는데..\n\n작물들 §\nRocksDB §\n\nLeveled Compaction\nLSM Tree\nMemtable\nStatic Sorted Table, SST\n"},"botanicals/database/draft/Write-Ahead-Log,-WAL-(Database)":{"title":"Write Ahead Log, WAL (Database)","links":[],"tags":["용어집","database"],"content":"\n\n                  \n                  본 글은 #draft 상태입니다. \n                  \n                  \n                \n                \n\n 내용 정리\n\n"},"botanicals/database/rocksdb/LSM-Tree-(RocksDB)":{"title":"LSM Tree (RocksDB)","links":["botanicals/algorithm/draft/Log-Structure-Merge-Tree,-LSM-Tree-(Data-Structure)","botanicals/os/papers/논문---The-design-and-implementation-of-a-log-structured-file-system","botanicals/algorithm/draft/Sparse-Index-(Data-Structure)","botanicals/database/rocksdb/Memtable-(RocksDB)","botanicals/algorithm/draft/Skip-List-(Data-Structure)","botanicals/database/rocksdb/Static-Sorted-Table,-SST-(RocksDB)","botanicals/algorithm/data-structure/linear/Sorted-Run-(Data-Structure)"],"tags":["용어집","database","rocksdb"],"content":"\n\n                  \n                  참고한 것들 \n                  \n                  \n                \n                \n\nRocksDB 공식 문서 - Compaction\nRocksDB 공식 문서 - Leveled Compaction\n\n\n\n\n                  \n                  그림 출처 \n                  \n                \n\n별도의 명시가 있지 않는 한, 그림들은 RocksDB 공식문서 에서 가져왔습니다.\n\n\n\n\n                  \n                  내용의 범위 \n                  \n                \n\n본 글의 내용은 LSM Tree 의 RocksDB 구현체를 기준으로 설명합니다. Patrick O’Neil 의 논문 및 LSM 의 이론적인 내용은 여기 담겨있지 않습니다.\n\n\n기본 아이디어 §\n\nLSM 의 기본 아이디어는 다음과 같다:\n\n\nLog-structured (sequential write) 를 통해 write 성능을 개선한다.\n\n일반적으로 sequential write 는 write 성능을 개선하는 것으로 알려져 있다. (참고 사례 - LFS)\n\n\nSorting + Level 을 통해 read 를 최적화 한다.\n\nSorting 되어 있으면 binary search 를 통해 key 에 대한 value 를 빨리 찾을 수 있기 때문.\n\n\nCompaction 을 통해 log-structured 에서 발생하는 데이터 중복 문제를 해소한다.\n\nLog-structured, Sequential Write §\n\n위에서 말한 것 처럼, 모든 key-value pair 는 sequential write 된다.\n\nUpdate 는 in-place update 가 아닌, 새로운 pair (기존의 key + 새로운 value) 를 sequential write 하면 된다.\nDelete 또한 in-place delete 가 아닌, 데이터가 지워졌음을 알리는 특별한 pair (기존의 key + 특별한 value) 를 sequential write 하면 된다.\n\n이때의 특별한 value 를 Tombstone (묘비) 라고 부른다.\n\n\n\n\n\nSorting and Leveled Architecture §\n\n그럼 이때 read (retrieval; key 에 대한 value 를 읽어오는 것) 은 어떻게 하면 좋을까.\n\n우선 가장 간단하게는 Linear Search 를 시도해 볼 수 있다.\n\n즉, pair 가 sequential write 되어 있기 때문에, 반대 방향으로 linear search 를 하며 key 에 대한 가장 최신의 value 를 읽어오면 되지 않을까.\n하지만 이 방법은 너무 느리다. O(N) 이기 때문.\n\n\n아니면 hash map 을 사용하는 방법도 있다.\n\nKey 에 대한 가장 최신의 value 주소를 메모리상에 hash map 으로 관리하면 이런 search 과정 없이 바로 디스크에서 value 를 읽어올 수 있을 것이다.\n하지만 이 방법은 key 가 많아질 경우 메모리 공간을 너무 많이 잡아먹는다는 단점이 있다.\n\n\n결국에는 시간과 공간 간의 trade-off 가 있는 셈이다.\n\n\n이것을 LSM 에서는 Sorting 과 Level 로 해소한다.\n\nSorting 을 하면 binary search 로 pair 를 찾을 수 있기 때문에 linear search 보다는 빠르고, hash map 을 사용하는 것보다는 메모리를 절약할 수 있기 때문.\n다만 sorting 을 한다는 것은 sequential 하지 않다는 것을 의미한다.\n이를 위해 LSM 에서는 level 이라는 단위로 sorting 을 하고, 각 level 을 sequential write 하여 sorting 과 sequential 를 조화시킨다.\n\n\n\n\n\n                  \n                  Level 과 Sequential write \n                  \n                \n\n지금은 이해를 위해 Level 단위로 Sequential write 가 된다고 설명했지만, 실제 작동 방식은 조금 더 복잡하고, 명확하게 말하자면 level 단위의 sequential write 는 틀린 얘기이다.\n더 구체적인 얘기는 아래에서 하도록 하고 지금은 최신의 key-value pair 는 상위 level 에, 오래된 pair 는 하위 pair 에 위치한다는 것만 알고 넘어가자.\n\n\n\n이 방식에서 read 는 다음처럼 수행할 수 있을 것이다.\n\n최신의 pair 는 상위 level 에 있기 때문에 상위 level 에서부터 binary search 를 수행해 pair 가 있는 지 찾고, 없다면 다음 level 로 넘어가며 read 를 하면 되지 않을까.\n아니면 다음 level 로 넘어가며 level 간 linear search 를 하는 대신에, sparse index 등을 이용하여 더욱 최적화 할 수도 있을 것이다.\n\n\n\nCompaction Process §\n\n근데 이렇게 sequential write 하다 보면 분명히 용량이 부족해지는 나날이 온다.\n이 상황에서 지울만한 데이터를 생각해 보면, 하나밖에 떠오르지 않을 것이다: 최근에 update 되어서 outdated 된 옛날의 key-value pair.\n따라서 주기적으로, 혹은 적당한 조건이 충족되었을 때 Compaction 을 수행하며 최근의 pair 만 남기고 이전의 중복된 pair 들은 싹 정리해 주는 과정을 거친다.\n\n실제 구조 §\n\n자 그럼 위의 아이디어들이 실제로는 어떻게 되어 있는지 확인해 보자.\n\nLevel-based File Structure §\n\n\n위에서 말한 Level 은 실제로 위와 같은 모습을 띄고 있다.\n\n헷갈리지 말자: Level 은 번호가 작을수록 상위 Level 이다.\n\n\n이 구조를 Top-down 으로 살펴보자.\n\n최상단: Memtable §\n\n우선 제일 위에는 ==Memtable 이라는 인메모리 write buffer== 가 있다.\n\n즉 어떤 key-value pair 가 write 되면, 일단 제일 먼저 이곳에 저장되고, 추후에 디스크로 flush 되는 것.\n\n\n이 memtable 은 RocksDB 에서는 기본적으로 skiplist 로 구현되고, append-only 로 작동한다.\n\n왜 굳이 메모리에 있는데 append-only 일까? 라는 생각이 든다면 Memtable 문서에서 더 자세한 내용을 확인하자.\n\n\n\n\bStatic Sorted Table (SST) §\n\nMemtable 에 있던 key-value 쌍들은 디스크에 flush 될 때, SST 라는 파일로 저장된다.\n==Static Sorted Table (SST) 는 key 를 기준으로 중복 없이 정렬되어 있고, 수정이 불가능한 key-value pair 들의 모음 파일==이다.\n\nLevel 0 (L0) §\n\n이렇게 ==Memtable 에 있던 내용이 SST 가 되어 처음으로 디스크에 저장되는 장소가 Level0 (L0)== 이다.\n이 level 은 다른 level 들과는 다른 특별한 공간이다.\n\n아래에서 설명할 Level Size Limit 이나 Sorted Run 은 level 에 적용되지 않는다.\n즉, Memtable 에서 L0 로 내려올 때는 그냥 SST 로 변환되어 내려오기만 하고, SST 간의 key 중복 혹은 key 범위 겹침 등은 얼마든지 가능하다.\n\n\n여기에 있던 SST 들의 개수가 level0_file_num_compaction_trigger 에 도달하면 모든 SST 가 Compaction 을 통해 다음 level 로 내려간다.\n\nLevel 1 ~ MAX (L1 ~ LMAX) §\n\n이 레벨들은 크기는 다르지만, 공통된 특징을 지닌다. 하나씩 살펴보자.\n\nLevel Size Limit §\n\n\n각 Level 은 정해진 size limit 이 있고, 하위 level 로 내려갈수록 이 limit 은 커진다.\n\n기본적으로 Exponential 하게 증가한다고 생각하면 된다.\n\n\n그리고 만약 이 size limit 을 넘게 되면, Compaction 이 진행되어 넘친 데이터를 아래로 내려보내게 된다.\n\nSorted Run §\n\n\n각 level 은 Sorted Run 이다.\n\n즉, level 을 구성하는 SST 들 간에는 중복된 key 가 존재하지 않고, key 의 범위도 겹치지 않는다.\n\n\n이렇게 함으로써 level 내에서는 binary search 로 원하는 key-value pair 를 빠르게 잡아낼 수 있다.\n\n일단 각 SST 의 시작 혹은 끝 key 들을 모아 binary search 를 하여 원하는 key 가 어느 SST 에 있는지 찾고,\n해당 SST 내에서 또 binary search 하여 요놈잡았다 를 하는 것.\n\n\n그런데 어떻게 이것이 가능할까? 상위 level 에서 SST 가 내려오면 분명히 내려온 SST 와 원래 있던 SST 간에는 중복된 key 들도 있을 것이고, 범위도 겹칠텐데, 어떻게 이런 sorted run 상태를 유지할 수 있을까?\n\n정답은 Compaction 에 있다.\n\n\n\nR/W Operation §\n\n위에서도 중간중간 설명하긴 했지만, 이 구조에서 어떻게 R/W 를 수행하는지 총정리를 해보자.\n\n\n\n                  \n                  #draft 추후에 작성할 예정입니다. \n                  \n                  \n                \n                \n\n 내용 정리\n R/W 과정 정리\n\n"},"botanicals/database/rocksdb/Leveled-Compaction-(RocksDB)":{"title":"Leveled Compaction (RocksDB)","links":["botanicals/database/rocksdb/LSM-Tree-(RocksDB)","botanicals/algorithm/data-structure/linear/Sorted-Run-(Data-Structure)","botanicals/database/rocksdb/Static-Sorted-Table,-SST-(RocksDB)","botanicals/algorithm/algorithm/sort/Merge-Sort-(Algorithm)"],"tags":["용어집","database","rocksdb"],"content":"\n\n                  \n                  참고한 것들 \n                  \n                  \n                \n                \n\nRocksDB 공식 문서\n간단하게 자바로 구현한 것 + 소스코드 - 깃헙\nZNS: Avoiding the Block Interface Tax for Flash-based SSDs (USENIX ATC ‘21) 의 4.2 섹션\n미디엄 블로그\nFlink 0.3 시절의 공식문서\n\n\n\n\n                  \n                  이미지 출처 \n                  \n                \n\n별도의 명시가 없으면, RocksDB 공식 문서 에서 갖고왔습니다.\n\n\nLeveled Compaction (Tiered + Leveled Compaction) Policy §\n\nLeveled Compaction 은 RocksDB 의 LSM Tree 에 대한 Compaction Policy 이다.\nCompaction 의 가장 큰 목적은\n\n각 level 이 각자의 size limit 을 넘지 않도록 조절해 주고\n각 level 이 sorted run 상태, 즉 SST 간에 중복된 key 혹은 범위가 겹치는 key 가 없도록 유지시켜 빠른 search 와 용량 최적화를 보장해주는 것이다.\n\n\n그럼 이제 구체적인 작동 과정을 살펴보자.\n\n과정 §\n\n\n위에서 compaction 의 목적이 size limit 을 준수하기 위한 것이라고 했으니까, size limit 이 넘었을 때의 상황을 예로 들어 compaction 이 어떻게 수행되는 것인지 알아보자.\n\n물론 compaction 이 수행되는 조건은 이것만 있는 것이 아니다.\n\n\n위와 같이 size limit 을 넘어가게 되면, 하나 이상의 SST 를 골라 다음 level 로 내려보낸다.\n내려보낼 때는 다음과 같은 두 경우가 있을 수 있다.\n\n우선 다음 level 에 아무런 SST 도 없을 때에는, 즉 현재 level 이 bottom level 이었을 경우에는, 새로 level 을 생성하고 그냥 SST 를 내려보내기만 한다.\n하지만 다음 level 에 SST 가 있을 때에는, 다음 level 의 SST 들 중 key 범위가 겹치는 SST 들과 Merge 하게 된다.\n\n\n\nMerge §\n\n위에서 설명한 compaction 의 목적 두번째: level 을 sorted run 상태로 만들기 위해 merge 작업이 수행된다.\n이름부터 merge 이듯이, 여기서는 merge sort 를 사용한다.\n\n어차피 각 SST 들이 정렬되어 있기 때문에 merge sort 로 하면 O(N) 으로 완수할 수 있기 때문.\n즉, two-pointer 로 해당 SST 들을 쭉 스캔하며 하나의 stream 으로 만들고, 그것을 여러개의 SST 로 잘라 새로 저장하는 하게 된다.\n다른 문서들 (Merge Sort, Merging Sorted Runs) 에서도 여러번 설명했기에 여기서는 더 설명 안해도 되겠지?\n\n\nMerge 의 target 이 된 SST 는 전부 삭제되고, merge 의 결과로 나온 SST 들이 해당 level 에 새로 생성된다.\n이때, 해당 level 의 size limit 을 초과하지 않는다면 그냥 생성되고 끝나지만\n\nMerge 의 결과로 또 해당 level 에 size limit 을 초과할 수도 있다. 이때에는 또 compaction 이 연쇄적으로 일어나게 된다.\n\n\n\nCompaction Policy §\n\n\n                  \n                  #draft 이 항목은 추후에 작성될 예정입니다. \n                  \n                  \n                \n                \n\n Compaction 조건\n SST 선택하기\n Level 선택하기\n\n\nCompaction 을 언제 할까? §\n\n위 예시처럼, level size limit 을 초과했을 때 compaction 이 수행되기도 하지만, 다음과 같은 상황에서도 compaction 이 수행될 수 있다.\n\nSST 는 어떻게 선택할까? §\n\n돌라돌라 골림판~\n\nLevel 은 어떻게 선택할까? §\n\n이게 뭔소린가 싶을 수 있는데,\n여러개의 level 이 size limit 을 넘어 compaction 을 할 level 을 선택해야 할 상황이 생기기도 한다.\n이때는 그럼 다음과 같은 방식으로 level 을 선택한다.\n"},"botanicals/database/rocksdb/Memtable-(RocksDB)":{"title":"Memtable (RocksDB)","links":["botanicals/database/rocksdb/LSM-Tree-(RocksDB)","botanicals/algorithm/draft/Skip-List-(Data-Structure)"],"tags":["용어집","database","rocksdb"],"content":"\n\n                  \n                  참고한 것들 \n                  \n                  \n                \n                \n\nRocksDB 공식문서\n\n\nMemory Table, Memtable §\n\nRocksDB 의 LSM 에서의 in-memory buffer 공간을 일컫는다.\n어떤 key-value pair 가 write 되면, 일단 제일 먼저 이곳에 저장되고, read 도 이 공간을 제일 먼저 찾아보게 된다.\n여기의 내용은 추후에 memtable 이 꽉 차는 등의 조건이 맞으면 디스크로 flush 된다.\n\nMutable, Immutable memtable §\n\n\b디스크로의 flush 과정을 좀 더 세분하게 살펴보자: 메모리 공간에는 Mutable memtable 과 Immutable memtable 이 있다.\n일단 인메모리 write buffer 로 사용되는 공간은 mutable memtable 이고, 여기에 데이터들이 write 된다.\n그리고 해당 공간이 다 차게 되면 일단 인메모리에서 immutable memtable 로 전환되고, 추후에 flush 되는 것.\n\nDefault Policy §\nSkip List §\n\n일단 Memtable 의 구현은 Skip list 로 되어 있어서 read 작업은 O(log(N)) 으로 수행된다.\n\nMemtable 에 다른 자료구조를 사용할 수도 있다. 하지만 default 로는 skiplist 를 사용하도록 되어 있고, 지원하는 기능도 이게 더 많다.\n가령, 바로 아래에서 설명할 concurrent 기능도 skiplist 에서만 사용 가능하다.\n\n\n\nAppend-only, allow_concurrent_memtable_write Option §\n\n그리고 여기서의 update 는 in-place 가 아닌 append only (out-place) 로 이루어 진다.\n\n왜 디스크도 아니고 메모리 공간에 있는 memtable 을 굳이 append only 로 작동하게 만들었을까 의문을 가질 수도 있는데\n이것은 concurrent write 를 가능하기 하기 위함이다.\n\bIn-place update 의 경우에는 여러 thread 가 접근했을 경우에 lock 을 걸며 write 해야 하기 때문에 concurrent 가 불가능하지만\nAppend only 를 하면 굳이 이러지 않아도 되기 때문.\n물론 위 내용은 default 설정을 말하는 것이다\n\nDefault 로는 concurrent write (allow_concurrent_memtable_write: true) + append only (inplace_update_support: false) 지만, concurrent 를 비활성화 하고 in-place 를 활성화 할 수도 있다.\n\n\n\n\n\nInternal Key §\n\n그럼 skiplist 에서 어떻게 append only 를 할 수 있을 까. 이것은 internal key 를 이용해서 수행한다.\n\n외부적으로 보여지는 key 에 추가적으로, 내부적으로는 append only 를 위해 internal key 를 사용하게 되는데\n여기에는 key 에 부가적으로 sequence no. 가 들어가 해당 키에 대한 일종의 version 까지 붙여서 skip list 에 넣게 된다.\n\n\n즉, 겉으로 보기에는 key -&gt; value 형태지만, 실제로 skiplist 에 저장되는 노드는 [key, seq] -&gt; value 인 것.\n"},"botanicals/database/rocksdb/Static-Sorted-Table,-SST-(RocksDB)":{"title":"Static Sorted Table, SST (RocksDB)","links":["botanicals/algorithm/draft/Log-Structure-Merge-Tree,-LSM-Tree-(Data-Structure)","botanicals/os/terms/Internal-Fragment-(OS)"],"tags":["용어집","database","rocksdb"],"content":"\n\n                  \n                  참고한 것들 \n                  \n                  \n                \n                \n\nRocksDB 공식문서 - Static Sorted Table\n\n\nSSTable §\n\nRocksDB 에서 Static Sorted Table (SST, SSTable) 은 실제 key-value 데이터를 담는 파일 하나를 지칭한다.\n중요한 특징은:\n\nStatic: 내용을 변경하는 것이 불가능하다.\nSorted: Key 를 기준으로 중복 없이 정렬되어 있다.\n\n\n\n\n\n                  \n                  Static Sorted, Sorted String \n                  \n                \n\nLSM 구현본마다 SST 를 Static Sorted Table 혹은 Sorted String Table 등으로 다르게 부르기도 한다.\n하지만 약자 “SST” 는 거의 통일되어 있는 듯.\n\n\nType §\n\nRocksDB 에서는 두 종류의 SST 구현체가 존재한다.\n\nBlock-based table §\n\n스토리지에 저장될 용도로 설계된 default SST type 이다.\n따라서 당연히 스토리지의 특성을 최대한 반영하고 있다:\n\nSST 의 크기는 internal fragment 를 최대한 줄이기 위해 기본적인 block size 인 4KB 의 배수로 구성된다.\n따라서 memory 에 올릴 때에도 block 단위로 올리고, block 단위로 캐싱도 한다.\n\n\n이 SST 는 효율적으로 데이터를 저장하기 위해 압축이나 encoding 을 사용하기도 한다. (옵션인듯)\n\nPlain table §\n\n이 SST type 은 인메모리로 사용하기 위한 구조이다.\n즉, data persistency 보다는 performance 에 중점이 맞춰져 있고, 따라서 다음과 같은 기능을 제공한다.\n\nMemory map (mmap) 을 사용하여 빠른 성능을 제공한다.\n이에 추가적으로, binary search 도 모자라 hash index 도 제공해 데이터를 더 빠르게 읽어올 수 있도록 한다.\n\n\n"},"botanicals/elasticsearch/(Botanical-Garden)-ElasticSearch":{"title":"(Botanical Garden) ElasticSearch","links":["botanicals/elasticsearch/docs/TL;DR-ElasticSearch---엘라스틱서치-간단하게-시작하기","botanicals/elasticsearch/docs/ElasticSearch-Architecture---엘라스틱서치-아키텍처","botanicals/elasticsearch/docs/Read-&-Write-Operation-in-ElasticSearch---엘라스틱서치-RW-과정-정리","botanicals/elasticsearch/terms/_doc-(ElasticSearch)","botanicals/elasticsearch/terms/_id-(ElasticSearch)","botanicals/elasticsearch/terms/Apache-Lucene","botanicals/elasticsearch/terms/Cluster-(ElasticSearch)","botanicals/elasticsearch/terms/Commit-API-(Lucene)","botanicals/elasticsearch/terms/Coordinating-Node-(ElasticSearch)","botanicals/elasticsearch/terms/Data-Node-(ElaticSearch)","botanicals/elasticsearch/terms/Document-(ElasticSearch)","botanicals/elasticsearch/terms/Flush-(ElasticSearch)","botanicals/elasticsearch/terms/Flush-API-(Lucene)","botanicals/elasticsearch/terms/Index-(ElasticSearch)","botanicals/elasticsearch/terms/Index-(Lucene)","botanicals/elasticsearch/terms/Indexing-(ElasticSearch)","botanicals/elasticsearch/terms/Master-Node-(ElasticSearch)","botanicals/elasticsearch/terms/Merge-(Lucene)","botanicals/elasticsearch/terms/Node-(ElasticSearch)","botanicals/elasticsearch/terms/Primary-Shard-(ElasticSearch)","botanicals/elasticsearch/terms/Read-API-(Lucene)","botanicals/elasticsearch/terms/Refresh-(ElasticSearch)","botanicals/elasticsearch/terms/Replication-Shard-(ElasticSearch)","botanicals/elasticsearch/terms/Segment-(Lucene)","botanicals/elasticsearch/terms/Shard-(ElasticSearch)","botanicals/elasticsearch/terms/Type-(ElasticSearch)"],"tags":[],"content":"개요 §\n\n엘라스틱서치 정보 저장고\n주로 참조한 문서는,\n\n(웹) 김종민의 ElasticSearch 가이드북\n(책) 엘라스틱서치 바이블\n\n\n\n문서들 §\n\n엘라스틱서치 간단하게 시작하기\n엘라스틱서치 아키텍처\n엘라스틱서치 RW 과정 정리\n\n용어들 §\n\n_doc\n_id\nLucene\nCluster\nCommit API (Lucene)\nCoordinating Node\nData Node\nDocument\nFlush\nFlush API (Lucene)\nIndex\nIndex (Lucene)\nIndexing\nMaster Node\nMerge (Lucene)\nNode\nPrimary Shard\nRead API (Lucene)\nRefresh\nReplication Shard\nSegment (Lucene)\nShard\nType\n"},"botanicals/elasticsearch/docs/ElasticSearch-Architecture---엘라스틱서치-아키텍처":{"title":"ElasticSearch Architecture - 엘라스틱서치 아키텍처","links":["botanicals/elasticsearch/terms/Cluster-(ElasticSearch)","botanicals/elasticsearch/terms/Node-(ElasticSearch)","botanicals/elasticsearch/terms/Document-(ElasticSearch)","botanicals/elasticsearch/terms/Index-(ElasticSearch)","botanicals/elasticsearch/terms/Shard-(ElasticSearch)"],"tags":[],"content":"오버뷰 §\n\n\n이미지 출처: “엘라스틱서치 바이블”, 여동현 저\n\n\n물리적으로 봤을 때, Cluster 하나는 여러개의 Node 로 구성된다\n논리적으로 봤을 때에는, Document 들이 모여 Index 가 되고, 이것이 Cluster 내에서의 검색 단위가 된다\nIndex 는 각 Node 에 Shard 란 이름으로 분산 저장된다\n"},"botanicals/elasticsearch/docs/Read-&-Write-Operation-in-ElasticSearch---엘라스틱서치-RW-과정-정리":{"title":"Read & Write Operation in ElasticSearch - 엘라스틱서치 RW 과정 정리","links":["botanicals/elasticsearch/terms/Read-API-(Lucene)","botanicals/elasticsearch/terms/Document-(ElasticSearch)","botanicals/elasticsearch/terms/Refresh-(ElasticSearch)","botanicals/elasticsearch/terms/Flush-API-(Lucene)","botanicals/elasticsearch/terms/Flush-(ElasticSearch)","botanicals/elasticsearch/terms/Commit-API-(Lucene)"],"tags":[],"content":"읽기 §\n\nLucene Read 를 통해 파일로 저장된 문서 를 메모리로 올림\n만일 문서 가 변경되었을 때에는, 주기적인 Refresh 작업 (혹은 명시적인 API 호출) 이후에야 변경사항이 반영됨\n\n(디스크에) 쓰기 §\n\n\n이미지 출처: “엘라스틱서치 바이블”, 여동현 저\n\n\n수정사항이 있으면 일단은 메모리 버퍼에 저장\nES Refresh 를 통해 Lucene Flush 작업을 수행해서 수정사항이 논리적으로 파일에 저장될 수 있도록 함\nES Flush 를 통해 Lucene Commit 작업을 수행해서 수정사항이 물리적으로 파일에 저장될 수 있도록 함\n"},"botanicals/elasticsearch/docs/TL;DR-ElasticSearch---엘라스틱서치-간단하게-시작하기":{"title":"TL;DR ElasticSearch - 엘라스틱서치 간단하게 시작하기","links":[],"tags":[],"content":"Docker container 띄우기 §\n\ngithub://deviantony/docker-elk 레포지토리를 이용하면 편하다\n\ngit clone git@github.com:deviantony/docker-elk.git\ncd docker-elk\ndocker compose setup\ndocker compose up -d\n키바나 접속 §\n\nlocalhost:5601 로 접속하면 되고,\ngithub://deviantony/docker-elk 에서 설정을 하나도 건드리지 않았다면\n\nID: elastic\nPW: changeme\n\n\n이다\n\n실습용 데이터 다운로드 §\n\n키바나에서 햄버거 아이콘 → Management → Integrations\n\n\n\n검색창에 Sample Data 검색\n\n\n\n하단의 Other sample data sets 에서 세 데이터 모두 추가\n\n키바나 웹 IDE 활용 §\n\n햄버거 아이콘 → Management → Dev Tools\n\n"},"botanicals/elasticsearch/terms/Apache-Lucene":{"title":"Apache Lucene","links":[],"tags":[],"content":"용어 설명 §\n\nApache 재단이 관리하는 오픈소스 검색 라이브러리\n"},"botanicals/elasticsearch/terms/Cluster-(ElasticSearch)":{"title":"Cluster (ElasticSearch)","links":["botanicals/elasticsearch/terms/Node-(ElasticSearch)"],"tags":[],"content":"용어 설명 §\n\nNode 들의 모음\n"},"botanicals/elasticsearch/terms/Commit-API-(Lucene)":{"title":"Commit API (Lucene)","links":["botanicals/elasticsearch/terms/Flush-API-(Lucene)","botanicals/elasticsearch/terms/Apache-Lucene","botanicals/elasticsearch/terms/Commit-API-(Lucene)","botanicals/elasticsearch/terms/ElasticSearch","botanicals/elasticsearch/terms/Flush-(ElasticSearch)"],"tags":[],"content":"용어 설명 §\n\nLucene Flush 는 시스템의 페이지 캐시에 데이터를 넘겨주는 것까지만 한다\n\n즉, 실제로 디스크로 내려보내는게 아닌 메모리버퍼의 내용을 메모리에 있는 페이지 캐시에 저장해서 커널의 Paging memory management 에 의해 디스크로 내려갈 수 있게 한다\n\n\n따라서 Lucene 은 주기적으로 fsync syscall 을 날려 커널의 Paging memory management 가 페이지 캐시에 있는 내용을 디스크로 내려보내도록 하는데, 이것을 Lucene Commit 이라고 한다\n하지만 그래도 ES 의 입장에서 볼때 Lucene Flush 를 하는 것은 파일로 저장된 것이나 마찬가지의 효과이다\n\n즉, Lucene Flush 에 추가적으로 Lucene Commit 까지 되어야 수정사항이 검색결과에 반영되는게 아니다 이거야\n페이지 캐시라는 것이 IO 성능을 높이기 위해 디스크의 내용을 메모리에 캐싱해 놓은 것이기 때문에, open syscall 을 호출한 client 의 입장에서 볼때 open 이후 process memory 공간에 들어온 데이터가 디스크에서 가져온 것인지 캐싱된 내용을 가져온 것인지 구분하지 못한다\n\n\n따라서 Lucene Commit 은 새로고침의 목적이 아닌 영속성의 목적이다\n\n즉, 수정사항을 검색결과에 반영하기 위해서는 Lucene Flush 로 충분하고\n재부팅 등의 상황으로 인해 메모리의 내용이 날아갔을 때에도 데이터 손실이 없도록 하는 Persistent 의 목적이다\n\n\n이 과정은 엘라스틱서치의 Flush 과정 에서 수행된다\n"},"botanicals/elasticsearch/terms/Coordinating-Node-(ElasticSearch)":{"title":"Coordinating Node (ElasticSearch)","links":["botanicals/elasticsearch/terms/Node-(ElasticSearch)","botanicals/elasticsearch/terms/Data-Node-(ElaticSearch)"],"tags":[],"content":"용어 설명 §\n\n얘는 약간 Proxy 의 기능을 하는 Node Role 중 하나다\n\nClient 와 Data Node 사이에 위치하면서 Client 의 Request 를 Data Node 에 전달하고, 반대의 Response 도 전달해주는 역할\n\n\n"},"botanicals/elasticsearch/terms/Data-Node-(ElaticSearch)":{"title":"Data Node (ElaticSearch)","links":["botanicals/elasticsearch/terms/Shard-(ElasticSearch)","botanicals/elasticsearch/terms/Node-(ElasticSearch)"],"tags":[],"content":"용어 설명 §\n\nShard 를 저장하고 IO 를 수행하는 Node Role\n\n말그대로 데이터 노드이다\n\n\n"},"botanicals/elasticsearch/terms/Document-(ElasticSearch)":{"title":"Document (ElasticSearch)","links":["botanicals/elasticsearch/terms/ElasticSearch"],"tags":[],"content":"용어 설명 §\n\n뭐 당연한 말이지만 ES 에서 각 JSON 형식의 문서를 일컫는 용어이다\n"},"botanicals/elasticsearch/terms/ElasticSearch":{"title":"ElasticSearch","links":[],"tags":[],"content":"용어 설명 §"},"botanicals/elasticsearch/terms/Flush-(ElasticSearch)":{"title":"Flush (ElasticSearch)","links":["botanicals/elasticsearch/terms/Flush-API-(Lucene)","botanicals/elasticsearch/terms/ElasticSearch","botanicals/elasticsearch/terms/Commit-API-(Lucene)","botanicals/elasticsearch/terms/Flush-(ElasticSearch)","botanicals/elasticsearch/terms/Refresh-(ElasticSearch)"],"tags":[],"content":"용어 설명 §\n\nLucene 의 Flush 와 이름이 같아서 헷갈리긴 한데\nES 에서 Lucene Commit 을 호출해 데이터의 영속성을 보장 (디스크에 진짜 저장) 하는 과정을 말한다\nES Flush 는 ES Refresh 보다도 더 비용이 많이 드는 연산이기에, 이것도 수정사항이 있을 때 마다가 아닌, 적당한 주기마다 수행한다\n\n이것도 물론 ES 의 Flush API 를 사용하면 강제로 ES Flush 를 수행할 수 있다\n\n\n"},"botanicals/elasticsearch/terms/Flush-API-(Lucene)":{"title":"Flush API (Lucene)","links":["botanicals/elasticsearch/terms/Document-(ElasticSearch)","botanicals/elasticsearch/terms/Apache-Lucene","botanicals/elasticsearch/terms/Indexing-(ElasticSearch)","botanicals/elasticsearch/terms/Flush-API-(Lucene)","botanicals/elasticsearch/terms/Commit-API-(Lucene)"],"tags":[],"content":"용어 설명 §\n\n메모리 버퍼에 임시로 저장된 Document 를 디스크로 내려보내는 Lucene 의 API\nWrite 요청이 있을때마다 디스크 IO 를 하면 비효율적이기 때문에 문서가 색인 되면 메모리 버퍼에 들고 있게 됨\n그러다가 적당한 시기마다 디스크로 내려보내게 되고, 이때의 디스크로 내려보내는 작업을 Flush 라고 한다\n\n다만, 진짜로 디스크에 쓰는게 아니라 커널에 디스크에 써달라고 전달만 한다\n진짜로 디스크에 쓰는 것은 Commit API (Lucene) 에서 수행된다\n\n\n"},"botanicals/elasticsearch/terms/Index-(ElasticSearch)":{"title":"Index (ElasticSearch)","links":["botanicals/elasticsearch/terms/Document-(ElasticSearch)","botanicals/elasticsearch/terms/Shard-(ElasticSearch)","botanicals/elasticsearch/terms/Index-(ElasticSearch)","botanicals/elasticsearch/terms/Index-(Lucene)","botanicals/elasticsearch/terms/Apache-Lucene","botanicals/elasticsearch/terms/ElasticSearch"],"tags":[],"content":"용어 설명 §\n\nDocument 의 모음\n인데, Shard 로 분산되어 저장된다\n\n분산 저장, 검색 §\n         -&gt; SHARD -&gt; LUCENE INDEX\nES INDEX -&gt; SHARD -&gt; LUCENE INDEX\n         -&gt; SHARD -&gt; LUCENE INDEX\n\n\n아래의 세 정보를 조합하면,\n\nES Index 는 여러개의 Shard 로 구성\nShard 는 Lucene Index 와 1:1 대응\nLucene 은 하나의 Lucene Index 내에서 검색\n\n\nES 는 여러 Shard 에 걸쳐서 검색이 가능하다는 것을 알 수 있다\n\n즉, Lucene 은 하나의 Lucene Index 에서만 검색이 가능하지만,\n(아마 Lucene Thread 를 여러개 돌리거나 해서) ES Index 안에 있는 여러 ES Shard 들에 대해 동시에 검색이 가능하다\n그래서 새 문서가 생성되면 여러 ES Shard 에 분산 저장, 색인하고 읽어들일때도 여러 ES Shard 에서 문서를 읽어들여 합친다\n\n\nES 는 Lucene 을 분산 처리가 가능하도록 확장한 솔루션 이라고 생각할 수 있는 것\n"},"botanicals/elasticsearch/terms/Index-(Lucene)":{"title":"Index (Lucene)","links":["botanicals/elasticsearch/terms/Index-(Lucene)","botanicals/elasticsearch/terms/Segment-(Lucene)","botanicals/elasticsearch/terms/Apache-Lucene"],"tags":[],"content":"용어 설명 §\n\nLucene Index 는 이제 Lucene Segment 들의 집합인데\nLucene 은 이 Lucene Index 내에서만 검색이 가능하다\n\n즉, 여러 인덱스에 걸쳐서 검색을 하는 건 불가능하다\n\n\n"},"botanicals/elasticsearch/terms/Indexing-(ElasticSearch)":{"title":"Indexing (ElasticSearch)","links":["botanicals/elasticsearch/terms/ElasticSearch"],"tags":[],"content":"용어 설명 §\n\n색인\n문서를 Parsing 해서 색인을 생성해 놓아 빠르게 검색될 수 있게 하는 것\n인데, ES 에서는 문서가 생성되면 자동으로 파싱해서 인덱싱하므로 생성 대신 색인이라는 용어를 쓰기도 하는 것 같다\n"},"botanicals/elasticsearch/terms/Master-Node-(ElasticSearch)":{"title":"Master Node (ElasticSearch)","links":["botanicals/elasticsearch/terms/Cluster-(ElasticSearch)","botanicals/elasticsearch/terms/Node-(ElasticSearch)","botanicals/elasticsearch/terms/Master-Node-(ElasticSearch)"],"tags":[],"content":"용어 설명 §\n\nCluster 전체를 관리하는 기능을 수행하는 Node Role 중 하나다\nMaster Node 후보가 있고, 이 중에서 한놈이 선택되어 맡게 됨\n아마 Master 라는 네이밍은 조만간 폐기되지 않을까\n"},"botanicals/elasticsearch/terms/Merge-(Lucene)":{"title":"Merge (Lucene)","links":["botanicals/elasticsearch/terms/Segment-(Lucene)","botanicals/elasticsearch/terms/Merge-(Lucene)","botanicals/elasticsearch/terms/Apache-Lucene"],"tags":[],"content":"용어 설명 §\n\nLucene Segment 의 불변성 때문에 그 갯수가 계속 늘어나게 되는데, 무한정 늘어날 수는 없기 때문에 적당한 시점에 수행하는 병합 과정을 Lucene Merge 라고 한다\n\n이 과정에서 삭제 플래그가 걸린 세그먼트 가 실제로 삭제된다\n비용을 많이 먹는 작업이지만 이후에는 검색 성능이 나아진다 (한번의 IO 로 해결할 수 있으니까?)\n뭐 Lucene 이 알아서 적당히 병합을 하는가 보지만, ForceMerge API 를 통해 명시적으로 병합을 수행할 수 있다\n\n다만, 이때에는 더이상의 추가적인 세그먼트가 생성되지 않을 것 같은 시점에 세그먼트를 병합하는 것이 좋다고 한다\n\n크기가 큰 세그먼트가 있을 때 작은 세그먼트가 추가되면 자동 세그먼트 병합 대상 선정에서 영원히 누락될 수도 있기 때문이라고 한다\n약간 자동 세그먼트 병합시에는 크기가 비슷한 것들끼리 묶어 모두 균등한 크기가 되도록 하는 모양인데 크기차이가 너무 나버리면 병합되지 않기 때문인듯\n\n\n\n\n\n\n"},"botanicals/elasticsearch/terms/Node-(ElasticSearch)":{"title":"Node (ElasticSearch)","links":["botanicals/elasticsearch/terms/Cluster-(ElasticSearch)","botanicals/elasticsearch/terms/Node-(ElasticSearch)","botanicals/elasticsearch/terms/Master-Node-(ElasticSearch)","botanicals/elasticsearch/terms/Coordinating-Node-(ElasticSearch)","botanicals/elasticsearch/terms/Data-Node-(ElaticSearch)"],"tags":[],"content":"용어 설명 §\n\n흔히 분산 시스템에서 일컫는 것과 같이, Cluster 를 구성하는 각 서버를 의미한다\n\nNode 가 가질 수 있는 Role §\n\nNode 는 다음의 세 Role 중 하나 이상의 Role 을 수행한다\n\nMaster Node\nCoordinating Node\nData Node\n\n\n"},"botanicals/elasticsearch/terms/Primary-Shard-(ElasticSearch)":{"title":"Primary Shard (ElasticSearch)","links":["botanicals/elasticsearch/terms/Shard-(ElasticSearch)","botanicals/elasticsearch/terms/Replication-Shard-(ElasticSearch)","botanicals/elasticsearch/terms/Primary-Shard-(ElasticSearch)","botanicals/elasticsearch/terms/Node-(ElasticSearch)"],"tags":[],"content":"용어 설명 §\n\n원본 Shard\n즉, 이 Shard 를 복제해서 Replication Shard 를 생성하는 식으로 고가용성을 구현한다\n그래서 아마 Primary Shard 와 이것을 복제한 Replication Shard 는 같은 Node 에 배치되지 않았던 것 같다\n"},"botanicals/elasticsearch/terms/Read-API-(Lucene)":{"title":"Read API (Lucene)","links":["botanicals/elasticsearch/terms/Document-(ElasticSearch)","botanicals/elasticsearch/terms/Apache-Lucene","botanicals/elasticsearch/terms/Read-API-(Lucene)","botanicals/elasticsearch/terms/Flush-API-(Lucene)","botanicals/elasticsearch/terms/Refresh-(ElasticSearch)"],"tags":[],"content":"용어 설명 §\n\n디스크에 파일 형태로 저장된 문서 를 읽어들이는 API 인데\n이 용어 자체보다는 작동 과정을 아는게 더 중허겠지\n\n작동 과정 §\n\n일단 Lucene 은 문서 들을 파일 형태로 저장하는데\n읽기 작업 을 하기 위해서는 open syscall 이 호출되어 메모리공간으로 올라간다\n따라서 이 시점에 읽어와진 내용만이 검색에 반영된다\n\n즉, 읽어와진 다음에 변경된 내용은 검색에 반영이 안된다\n\n예상컨데 Read API 로 올라온 메모리 공간과 Flush API 에서 사용하는 메모리 버퍼는 다른 공간인 것 같다\n그렇기에 변경이 이루어 졌을 때 Read API 에 저장된 내용은 변경되지 않아 검색에 반영이 안되는 것 아닌가\n\n\n\n\n변경된 내용을 검색 결과에 반영하기 위해서는 Flush API 를 호출하고 파일을 다시 열어야 한다\n\n이 과정은 엘라스틱서치의 Refresh API 에 의해 구현된다\n\n\n"},"botanicals/elasticsearch/terms/Refresh-(ElasticSearch)":{"title":"Refresh (ElasticSearch)","links":["botanicals/elasticsearch/terms/Document-(ElasticSearch)","botanicals/elasticsearch/terms/Flush-API-(Lucene)","botanicals/elasticsearch/terms/Refresh-(ElasticSearch)","botanicals/elasticsearch/terms/ElasticSearch","botanicals/elasticsearch/terms/Apache-Lucene"],"tags":[],"content":"용어 설명 §\n\n문서 가 변경되었을 때, 이것을 디스크에 반영 하고 파일을 다시 open 하여 검색 결과에 반영되도록 하는 과정\nRefresh 과정은 비용이 많이 드는 연산으로, 변경될 때마다 하지 않고 적절한 시기마다 주기적으로 수행한다\n\n물론 ES 의 Refresh API 를 사용하면 강제로 실행할 수도 있다\n\n\n\nCode Ref §\n\nLucene 의 DirectoryReader 클래스로 파일을 열고 색인에 접근하기 위한 객체인 IndexReader 를 얻는다\n수정사항을 검색에 반영하기 위해서는 DirectoryReader.openIfChanged 를 통해 파일을 새로 열어주고, IndexReader 를 새로 받은 후 기존의 IndexReader 는 닫아서 반영이 되게 함\n\nDirectoryReader.openIfChanged 를 통해 아마 Lucene Flush 작업이 이루어지는 것 같음\n\n\nElasticsearch 의 refreshIfNeeded 메소드\nElasticSearch 의 createReaderManager 메소드\n"},"botanicals/elasticsearch/terms/Replication-Shard-(ElasticSearch)":{"title":"Replication Shard (ElasticSearch)","links":["botanicals/elasticsearch/terms/Primary-Shard-(ElasticSearch)","botanicals/elasticsearch/terms/Shard-(ElasticSearch)"],"tags":[],"content":"용어 설명 §\n\nPrimary Shard 를 복제해서 만든 Shard\n"},"botanicals/elasticsearch/terms/Segment-(Lucene)":{"title":"Segment (Lucene)","links":["botanicals/elasticsearch/terms/Segment-(Lucene)","botanicals/elasticsearch/terms/Document-(ElasticSearch)","botanicals/elasticsearch/terms/Apache-Lucene","botanicals/elasticsearch/terms/Merge-(Lucene)"],"tags":[],"content":"용어 설명 §\n\nLucene Segment 는 문서 파일 들의 집합이다\nLucene 은 모든 Lucene Segment 을 대상으로 하여 검색한다\n\n불변 (Immutable) 성 §\n\nLucene Segment 는 불변 (Immutable) 한 성질을 가지고 있다\n\n즉, 새 문서가 생성되면 Lucene Segment 가 추가되고,\n삭제되면 삭제 플래그만 걸어놓으며,\n변경되면 삭제 플래그를 걸어놓은 상태로 새로 Lucene Segment 를 생성한다\n\n\n이때, Lucene Segment 가 무한히 늘어나는 것을 막기 위해 자동으로 Merge 작업이 수행된다\n"},"botanicals/elasticsearch/terms/Shard-(ElasticSearch)":{"title":"Shard (ElasticSearch)","links":["botanicals/elasticsearch/terms/Index-(ElasticSearch)","botanicals/elasticsearch/terms/Node-(ElasticSearch)","botanicals/elasticsearch/terms/Index-(Lucene)","botanicals/elasticsearch/terms/Primary-Shard-(ElasticSearch)","botanicals/elasticsearch/terms/Replication-Shard-(ElasticSearch)"],"tags":[],"content":"용어 설명 §\n\nIndex 를 여러 Node 에 분산시켜 저장하게 되는데, 이때 한 Node 에 저장되는 단위\nLucene Index 를 래핑한 것이다 (1:1 매핑이 되는듯)\n\nShard 의 종류 §\n\nPrimary Shard 와 Replication Shard 로 종류가 나뉜다\n"},"botanicals/elasticsearch/terms/Type-(ElasticSearch)":{"title":"Type (ElasticSearch)","links":["botanicals/elasticsearch/terms/Index-(ElasticSearch)","botanicals/elasticsearch/terms/Document-(ElasticSearch)","botanicals/elasticsearch/terms/_doc-(ElasticSearch)","botanicals/elasticsearch/terms/Type-(ElasticSearch)"],"tags":[],"content":"\n\n                  \n                  DEPRECATED 된 개념임 \n                  \n                \n\n용어 설명 §\n\nIndex 내에서 Document 들을 논리적으로 묶는 단위\n\n이 개념은 폐기되었다 §\n\n지금은 Document 들을 논리적으로 묶고싶다면 그냥 새로운 Index 를 생성해야 한다\nBackward-compability 를 위해 _doc 이라는 Type 하나만 사용한다\n\n즉, API 에 Type 을 명시하는 부분에 _doc 외에는 다른 것이 올 수 없다\n\n\n"},"botanicals/elasticsearch/terms/_doc-(ElasticSearch)":{"title":"_doc (ElasticSearch)","links":["botanicals/elasticsearch/terms/Type-(ElasticSearch)"],"tags":[],"content":"용어 정리 §\n\nType (ElasticSearch) 이 Deprecated 됨에 따라, API Backward-compatibility 를 위해 남겨놓은 유일한 Type (ElasticSearch)\n"},"botanicals/elasticsearch/terms/_id-(ElasticSearch)":{"title":"_id (ElasticSearch)","links":["botanicals/elasticsearch/terms/Document-(ElasticSearch)","botanicals/elasticsearch/terms/Index-(ElasticSearch)","botanicals/elasticsearch/terms/_id-(ElasticSearch)","botanicals/elasticsearch/terms/Cluster-(ElasticSearch)"],"tags":[],"content":"용어 설명 §\n\nDocument (ElasticSearch) 의 ID\n( Index + _id (ElasticSearch) ) 조합은 Cluster (ElasticSearch) 내에서 유일하다\n"},"botanicals/kubernetes/(Botanical-Garden)-Kubernetes":{"title":"(Botanical Garden) Kubernetes","links":["botanicals/kubernetes/docs/Kubeconfig-파일로-Kube-apiserver-에-직접-cURL-찔러보기","botanicals/kubernetes/docs/Kubernetes-Control-Plane-TLS-explained---컨트롤-플레인-인증서-톺아보기","botanicals/kubernetes/docs/제-4회-테크-데이---Kubernetes-Korea-Group-커뮤니티-기술-세미나-참석-기록","botanicals/kubernetes/docs/Security-model-in-etcd---etcd-에서-사용되는-인증서들","botanicals/kubernetes/troubleshoots/Ingress-NGINX---\"upstream-sent-too-large-http2-frame-4740180\"-에러-해결기","botanicals/kubernetes/troubleshoots/RabbitMQ-on-Kubernetes---Troubleshooting-error-\"Command-df-timed-out\""],"tags":[],"content":"\n\n                  \n                  저도 압니다. 커리어에 비해 여기에 작물이 별로 없다는 것. 지금 열심히 마이그레이션 하는 중이니깐은 좀만 기달려 주시요. \n                  \n                \n\n개요 §\n\n쿠버네티스 정보 저장고\n2022년 3월부터 쿠버네티스를 재배해온 농사꾼으로써,\n\n쿠버네티스 / 컨테이너 (도커) 관련 개념들\n사내 온프레미스 GPU 클러스터를 운영하며 겪었던 것들\n폐쇄망 환경에서의 온프레미스 GPU 클러스터를 운영하며 겪었던 것들\n쿠버네티스 /  Cloud native 생태계의 다양한 OSS 들\n이외 다양한 것들\n\n\n이 저장되어 있습니다.\n\n\b작물들 §\n\nKubeconfig 파일로 Kube apiserver 에 직접 cURL 찔러보기\n컨트롤 플레인 인증서 톺아보기\n제 4회 테크 데이 - Kubernetes Korea Group 커뮤니티 기술 세미나 참석 기록\netcd 에서 사용되는 인증서들\n\n병든놈 고치기 §\n\nIngress NGINX - “upstream sent too large http2 frame 4740180” 에러 해결기\nRabbitMQ on Kubernetes - “Command timed out: ‘df -kP …‘” 에러 해결기\n"},"botanicals/kubernetes/docs/Kubeconfig-파일로-Kube-apiserver-에-직접-cURL-찔러보기":{"title":"Kubeconfig 파일로 Kube apiserver 에 직접 cURL 찔러보기","links":[],"tags":[],"content":"개요 §\n\n물논 kubectl 을 사용하면 간편하게 Kube apiserver 에 API 를 찔러서 기능들을 활용할 수 있지만,\n인증서 관련 디버깅을 해야되거나, 아니면 작동 원리 등이 궁금할 때 kubectl 을 사용하지 않고 직접 cURL 로 Kube apiserver 에 접근하는 것은 알아두면 좋다.\n\n심지어 cURL 의 --verbose 옵션을 이용해 추가적인 정보를 얻을 수도 있다..!\n\n\nKube apiserver 에 cURL 을 찌르기 위해서는 다음의 세 파일이 필요하다:\n\nCA 인증서: Kube apiserver 는 보통 self-signed CA 인증서를 사용하기 때문에, cURL 에게 해당 CA 를 신뢰해야 한다는 것을 알려줘야 한다\nClient 인증서: Client 인증서가 필요한 이유는 두가지 이다:\n\nmTLS (mutual TLS) 를 제공하기 위해. 즉, Client &lt;-&gt; Kube apiserver 양방향 통신 간 암호화를 지원하기 위해\nClient 인증을 위해: Kube apiserver 에 Client 의 정보를 전달할 때, 이 인증서의 CN (Common Name) 과 O (Organization) 항목을 사용한다.\n\n\nClient 개인키: Client 인증서에 대한 개인키 파일\n\n\n그래서 YAML Query (yq) 를 이용해 Kubeconfig 파일에서 필요한 정보들을 뽑아내 Kube apiserver 에 cURL 를 찔러보자\n\n말이 너무 많다! (TL;DR) §\n\n아래 실습은 Kubeconfig 로 /etc/kubernetes/admin.conf 를 이용하기에, Control plane node 에서 진행해야 한다.\n\n\nyq 로 admin.conf 에서 CA 인증서 뽑아내기\n\nyq &#039;.clusters.[0].cluster.certificate-authority-data&#039; /etc/kubernetes/admin.conf | base64 -d\n결과 예시:\n-----BEGIN CERTIFICATE-----\n### 뭔가 심오한 알파벳들 ###\n-----END CERTIFICATE-----\n\n\nyq 로 kube-apiserver 진입점 url 뽑아내기\n\nyq &#039;.clusters.[0].cluster.server&#039; /etc/kubernetes/admin.conf\n결과 예시:\nhttps://localhost:6443\n\n\nyq 로 client 인증서 뽑아내기\n\nyq &#039;.users.[0].user.client-certificate-data&#039; /etc/kubernetes/admin.conf | base64 -d\n결과 예시:\n-----BEGIN CERTIFICATE-----\n### 뭔가 심오한 알파벳들 ###\n-----END CERTIFICATE-----\n\n\nyq 로 client 인증서 개인키 뽑아내기\n\nyq &#039;.users.[0].user.client-key-data&#039; /etc/kubernetes/admin.conf | base64 -d\n결과 예시:\n-----BEGIN RSA PRIVATE KEY-----\n### 뭔가 심오한 알파벳들 ###\n-----END RSA PRIVATE KEY-----\n\n\n위에서 뽑아낸 정보를 이용해 cURL 로 Kube-apiserver 에 직접 API 를 찔러보자\n\ncurl \\\n    --cacert &lt;(yq &#039;.clusters.[0].cluster.certificate-authority-data&#039; /etc/kubernetes/admin.conf | base64 -d) \\\n    --cert &lt;(yq &#039;.users.[0].user.client-certificate-data&#039; /etc/kubernetes/admin.conf | base64 -d) \\\n    --key &lt;(yq &#039;.users.[0].user.client-key-data&#039; /etc/kubernetes/admin.conf | base64 -d) \\\n    $(yq &#039;.clusters.[0].cluster.server&#039; /etc/kubernetes/admin.conf)\n\n그럼 아래와 같이 결과가 정상적으로 나오는 것을 볼 수 있다\n\n{\n  &quot;paths&quot;: [\n    &quot;/.well-known/openid-configuration&quot;,\n    &quot;/api&quot;,\n    &quot;/api/v1&quot;,\n    &quot;/apis&quot;,\n    &quot;/apis/&quot;,\n    &quot;/apis/acme.cert-manager.io&quot;,\n    &quot;/apis/acme.cert-manager.io/v1&quot;,\n    // 후략 ...\n}"},"botanicals/kubernetes/docs/Kubernetes-Control-Plane-TLS-explained---컨트롤-플레인-인증서-톺아보기":{"title":"Kubernetes Control Plane TLS explained - 컨트롤 플레인 인증서 톺아보기","links":["botanicals/cybersecurity/terms/Mutual-TLS,-mTLS-(PKIX)","botanicals/kubernetes/draft/API-Aggregation-Layer-on-Kubernetes---쿠버네티스-앞에-Proxy-서버-붙이기","botanicals/kubernetes/docs/Kubernetes-Control-Plane-TLS-explained---컨트롤-플레인-인증서-톺아보기","botanicals/kubernetes/docs/Security-model-in-etcd---etcd-에서-사용되는-인증서들"],"tags":[],"content":"\n\n                  \n                  Info 이 공식 문서를 주로 참고했지요\n                  \n                \n\n어떤게 있을까? §\n\n일단 인증서 파일들은 /etc/kubernetes/pki 디렉토리에 있다.\n\b아래의 명령어로 Kubeadm 이 생성하는 인증서와 만료기간, CA 정보 등을 확인할 수 있다.\n\nsudo kubeadm certs check-expiration\n\n그럼 아래처럼 나온다.\n\n[check-expiration] Reading configuration from the cluster...\n[check-expiration] FYI: You can look at this config file with &#039;kubectl -n kube-system get cm kubeadm-config -o yaml&#039;\n\nCERTIFICATE                EXPIRES                  RESIDUAL TIME   CERTIFICATE AUTHORITY   EXTERNALLY MANAGED\nadmin.conf                 Aug 30, 2024 11:38 UTC   364d            ca                      no      \napiserver                  Aug 30, 2024 11:38 UTC   364d            ca                      no      \napiserver-etcd-client      Aug 30, 2024 11:38 UTC   364d            etcd-ca                 no      \napiserver-kubelet-client   Aug 30, 2024 11:38 UTC   364d            ca                      no      \ncontroller-manager.conf    Aug 30, 2024 11:38 UTC   364d            ca                      no      \netcd-healthcheck-client    Aug 30, 2024 11:38 UTC   364d            etcd-ca                 no      \netcd-peer                  Aug 30, 2024 11:38 UTC   364d            etcd-ca                 no      \netcd-server                Aug 30, 2024 11:38 UTC   364d            etcd-ca                 no      \nfront-proxy-client         Aug 30, 2024 11:38 UTC   364d            front-proxy-ca          no      \nscheduler.conf             Aug 30, 2024 11:38 UTC   364d            ca                      no      \n\nCERTIFICATE AUTHORITY   EXPIRES                  RESIDUAL TIME   EXTERNALLY MANAGED\nca                      Aug 28, 2033 11:38 UTC   9y              no      \netcd-ca                 Aug 28, 2033 11:38 UTC   9y              no      \nfront-proxy-ca          Aug 28, 2033 11:38 UTC   9y              no\n\n\n자 그럼 이제 이 인증서들을 차근차근 살펴보자구\n\nKubernetes Control Plane 에서 사용하는 인증서들 §\n\n\nControl Plane 의 모든 구성요소들은 기본적으로 mTLS(mutual TLS) 로 통신하기 때문에, Server cert 뿐만 아니라 Client cert 도 생성되게 된다.\n따라서 인증서들이 경장히 많이 생성되게 되는데, 이들 모두를 신뢰하기 위해 Self-signed root CA cert 를 생성하고 이것을 신뢰하도록 Host level 에 설정하는 식으로 구현된다.\n\nAPT 로 Kubernetes 관련 패키지를 설치하다 보면 dependency 로 ca-certificates 라는 패키지가 포함되어 있는 것을 확인할 수 있는데, 이 툴을 이용해 Host level trust 를 제공한다.\n\n\n어쨋든 그럼 사용되는 인증서들을 대략 다음과 같이 세가지로 분류해 볼 수 있다.\n\nCA 인증서\n(CA-Signed) Server 인증서\n\n이 인증서들은 x509 key usage 에 Server Auth 가 포함되어 있다\n\n\n(CA-Signed) Client 인증서\n\n이 인증서들은 x509 key usage 에 Client Auth 가 포함되어 있다\n\n\n\n\n\nCA 인증서 §\n\nca\n\n클러스터 내에서 범용적으로 사용되는 CA\n파일 위치: /etc/kubernetes/pki/ca.{crt,key}\n\n\netcd-ca\n\netcd 와 관련된 구성요소들이 통신할 때 사용하는 CA\n파일 위치: /etc/kubernetes/pki/etcd/ca.{crt,key}\n\n\nfront-proxy-ca\n\nKube-apiserver 앞단에 NGINX 같은 proxy 를 둘 수 있는데, 이때 사용하는 CA\n\n이러한 proxy 를 이용해 사용자 인증 과정을 proxy 에 위임하거나, proxy 에서 생성하는 로그를 통해 접속을 모니터링 하는 등의 방식으로 클러스터를 구성할 수 있다… 자세한 건 이 문서 를 보자\n\n\n파일 위치: /etc/kubernetes/pki/front-proxy-ca.{crt,key}\n\n\n\n(CA-Signed) Server 인증서 §\n\napiserver\n\nKube-apiserver 가 접근하는 클라이언트들에게 제시하는 Server 인증서.\n파일 위치: /etc/kubernetes/pki/apiserver.{crt,key}\n\n\netcd-server (Client, Server 겸용)\n\netcd 가 접근하는 클라이언트들에게 제시하는 Server 인증서.\n\n뒤 에서 한번 더 말하겠지만, 이 인증서는 Client 인증서로 사용할 수도 있다.\n\n\n파일 위치: /etc/kubernetes/pki/etcd/server.{crt,key}\n\n\netcd-peer (Client, Server 겸용)\n\netcd 가 접근하는 etcd member 들에게 제시하는 Server 인증서.\n\n이 인증서도 Client 인증서로 사용할 수도 있다. (뒤 에서 한번 더 등장한다.)\nMember 가 다른 member 에 접근했을 때 server 인증서로 etcd-server 를 제시할 지 아니면 etcd-peer 를 제시할 지 궁금해서 이 디버깅 기록 에서 확인해 봤는데, etcd-peer 인증서가 날라왔다.\n\n\n파일위치: /etc/kubernetes/pki/etcd/peer.{crt,key}\n\n\n\n(CA-Signed) Client 인증서 §\n\nadmin.conf\n\n클러스터 관리자가 Kube-apisever 에 접근하기 위해 제시하는 Kubeconfig 형태의 인증서.\n파일 위치: /etc/kubernetes/admin.conf\n\n\napiserver-etcd-client\n\nKube-apiserver 가 etcd 에 접근하기 위해 제시하는 인증서.\n파일 위치: /etc/kubernetes/pki/apiserver-etcd-client.{crt,key}\n\n\napiserver-kubelet-client\n\n\bKube-apiserver 가 kubelet 에 접근하기 위해 제시하는 인증서.\n파일 위치: /etc/kubernetes/pki/apiserver-kubelet-client.{crt,key}\n\n\ncontroller-manager.conf\n\nKube-controller-manager 가 Kube-apiserver 에 접근하기 위해 제시하는 Kubeconfig 형태의 인증서.\n파일 위치: /etc/kubernetes/controller-manager.conf\n\n\netcd-healthcheck-client\n\n클라이언트가 Etcd 에 접근하기 위해 제시하는 인증서.\n\n찾아보니 Control Plane 구성 요소들 중에 이 인증서를 사용하는 것은 없는 것 같다.\n확실하진 않지만, 이거 를 보면 etcdctl 등의 툴로 etcd 클러스터에 접근하기 위한 용도인 듯 하다.\n\n\n파일 위치: /etc/kubernetes/pki/etcd/healthcheck-client.{crt,key}\n\n\netcd-server (Client, Server 공용)\n\n\b솔직히 나도 이게 왜 Client 인증서인지 모르겠다.\n\n일단 x509 key usage 에 server auth 말고 client auth 도 포함이 되어 있어서 Client 인증으로도 사용할 수 있다는 것은 알겠는데,\n어떻게 사용되는지는 아직 확인 안됨.\n\n\n파일 위치: /etc/kubernetes/pki/etcd/server.{crt,key}\n\n\netcd-peer (Client, Server 공용)\n\netcd member 가 다른 etcd member 에 접근하기 위해 제시하는 인증서.\nClient, Server 공용이다. 즉, x509 key usage 에 server auth 와 client auth 가 모두 포함되어 있다.\n파일위치: /etc/kubernetes/pki/etcd/peer.{crt,key}\n\n\nfront-proxy-client\n\nKube-apiserver 앞단에 위치한 proxy 가 Kube-apiserver 에 접근하기 위해 제시하는 인증서.\n파일 위치: /etc/kubernetes/pki/front-proxy-client.{crt,key}\n\n\nscheduler.conf\n\nKube-scheduler 가 Kube-apiserver 에 접근하기 위해 제시하는 Kubeconfig 형태의 인증서.\n파일 위치: /etc/kubernetes/scheduler.conf\n\n\n\n기타 - 위 그림에서 (괄호) 로 표시된 항목 §\n\n(kubelet.conf)\n\nKubelet 이 Kube-apiserver 에 접근하기 위해 제시하는 Kubeconfig 형태의 인증서\n인데, kubeadm certs 명령어에 표시되지 않는 이유는 이 인증서가 자동으로 rotation 되기 때문이다.\n\n즉, 주기적으로 재생성되며 기간이 만료되지 않게 자동으로 관리되기 때문\n\n\n\n\n\n(kube-system/cm/kube-proxy)\n\nKube-proxy 가 kube-apiserver 에 접근하기 위해 제시하는 Kubeconfig 형태의 인증서\n인데, 얘는 파일로 관리되지 않고 클러스터 내에 ConfigMap 으로 저장된다.\n그리고 Client 인증서가 아니라 Service Account 의 Token 방식으로 Kube-apiserver 에 인증한다.\n다음 명령어로 내용을 확인할 수 있다.\n\n\n\nkubectl -n kube-system get cm kube-proxy -ojsonpath=&#039;{.data.kubeconfig\\.conf}&#039;\n\n(whatever)\n\n얘는 사용자가 Proxy 서버에 인증한다는 것을 의미하기 위해 그려놓았고, 딱히 뭐 정해진 뭔가는 없다.\nProxy 서버를 설정(구현) 하기 나름\n\n\n"},"botanicals/kubernetes/docs/Security-model-in-etcd---etcd-에서-사용되는-인증서들":{"title":"Security model in etcd - etcd 에서 사용되는 인증서들","links":["botanicals/kubernetes/docs/Kubernetes-Control-Plane-TLS-explained---컨트롤-플레인-인증서-톺아보기","botanicals/cybersecurity/terms/Mutual-TLS,-mTLS-(PKIX)","botanicals/shellscript/openssl/openssl---Server-인증서-다운로드-하기","botanicals/kubernetes/docs/Security-model-in-etcd---etcd-에서-사용되는-인증서들"],"tags":[],"content":"\n\n                  \n                  참고한 공식 문서\n                  \n                \n\n개요 §\n\n이 글 을 적다가 etcd 에서 사용되는 인증서들 용도가 헷갈려서 직접 확인해본 내용들.\netcd 클러스터를 직접 구축해봤으면 더 좋았겠지만, 일단 Kubeadm 으로 생성한 쿠버네티스 클러스터 controlplane 의 etcd 클러스터를 이용했다.\n\netcd 의 인증서들 §\n\n\n일반적인 서버 프로그램의 인증서 관련 설정 처럼, etcd 에서도 그냥 cert-file 혹은 key-file 이라 한다면 이것은 Client-to-server communication 에서 사용되는 인증서를 일컫는다.\n\n이들은 2379 포트로 통신할 때 사용되고, 외부 클라이언트가 접근할 용도이다.\n\n\n그런데 말입니다 etcd 에는 peer 가 붙은 인증서 관련 설정들이 있는데, 이것은 etcd 가 분산 DB 이기 때문에 각 서버끼리 통신하는 데 사용되는 인증서 설정이다.\n\n즉, server-to-server 혹은 server-to-cluster 통신에 사용되는 인증서인 것.\n이들은 2380 포트로 통신할 때 사용된다.\n\n\n그럼 이제 쿠버네티스 클러스터의 controlplane node 중 하나에 ssh 로 접속해서 어떤 식으로 설정되어 있는지, 진짜로 그렇게 작동하는지 등을 확인해 보자.\n\nClient-to-server communication §\n관련 설정들 §\n\n먼저, etcd pod 의 관련 설정부터 보면 다음과 같다.\n\n# 파일위치: /etc/kubernetes/manifests/etcd.yaml\n- etcd\n- --advertise-client-urls=https://${HOST_IP}:2379\n- --cert-file=/etc/kubernetes/pki/etcd/server.crt\n- --client-cert-auth=true\n# 중략...\n- --key-file=/etc/kubernetes/pki/etcd/server.key\n- --listen-client-urls=https://127.0.0.1:2379,https://${HOST_IP}:2379\n# 중략...\n- --trusted-ca-file=/etc/kubernetes/pki/etcd/ca.crt\n\nClient 가 접근할 진입점에 관한 설정들\n\n--advertise-client-urls : 이 etcd member 가 담당할 클라이언트의 url. 해당 값은 클러스터의 다른 etcd member 에 전파하여 자신이 어떤 Client 를 담당하는지 공유한다.\n--listen-client-urls : 클라이언트의 접속을 허용할 IP 와 Port.\n\n\n인증서와 관련된 설정들\n\n--cert-file : 클라이언트가 접속했을 때, 제시할 Server 인증서.\n--client-cert-auth : 이 값이 true 라면, 통신시에 mTLS 를 강제한다. 즉, 클라이언트도 인증서를 제시해야 한다.\n--key-file : 클라이언트가 접속했을 때, 제시할 Server 인증서에 대한 개인키.\n--trusted-ca-file : 신뢰할 CA 인증서.\n\n\n\nClient 인증서를 직접 만들어 요청해보기 §\n\nConfiguration 파일 작성 (test-client.conf)\n\n[req]\ndistinguished_name = cert_dn\nx509_extensions = v3_req\nprompt = no\n\n[cert_dn]\nCN = test-client\n\n[v3_req]\nkeyUsage = critical, digitalSignature, keyEncipherment\nextendedKeyUsage = clientAuth\nbasicConstraints = critical, CA:FALSE\nsubjectKeyIdentifier = hash\n\n\n사용할 개인키 (test-client.key) 및 CSR (Certificate Signing Request - test-client.csr) 생성\n\nopenssl req -new -nodes \\\n\t-newkey rsa:2048 \\\n\t-keyout test-client.key \\\n\t-out test-client.csr \\\n\t-config test-client.conf\n\n인증서 생성 (test-client.crt)\n\nsudo openssl x509 -req -days 1 -sha256 \\\n\t-in test-client.csr \\\n\t-extensions v3_req \\\n\t-extfile test-client.conf \\\n\t-CA /etc/kubernetes/pki/etcd/ca.crt \\\n\t-CAkey /etc/kubernetes/pki/etcd/ca.key \\\n\t-CAcreateserial \\\n\t-out test-client.crt\n\n그리고 이 인증서를 바탕으로, 2379 포트로 요청을 보내면 정상적으로 응답이 오는 것을 볼 수 있다.\n\ncurl \\\n\t--cacert /etc/kubernetes/pki/etcd/ca.crt \\\n\t--cert test-client.crt \\\n\t--key test-client.key \\\n\thttps://${HOST_IP}:2379/version\n{&quot;etcdserver&quot;:&quot;3.5.6&quot;,&quot;etcdcluster&quot;:&quot;3.5.0&quot;}\n\nServer 는 어떤 인증서를 제시할까? §\n\nopenssl s_client 모듈로 Server 가 어떤 인증서를 제시하는지 확인해 보자.\n\nopenssl s_client -showcerts -connect ${HOST_IP}:2379 &lt;/dev/null 2&gt;/dev/null \\\n\t| openssl x509 -text -noout\nCertificate:\n    Data:\n        Version: 3 (0x2)\n        Serial Number: ### 어쩌고 ###\n        Signature Algorithm: sha256WithRSAEncryption\n        Issuer: CN = etcd-ca\n        Validity\n            Not Before: Jan  0 00:00:00 0000 GMT\n            Not After : Jan  0 00:00:00 0000 GMT\n        Subject: CN = ${HOSTNAME}\n        Subject Public Key Info:\n            Public Key Algorithm: rsaEncryption\n                RSA Public-Key: (2048 bit)\n                Modulus:\n                    ### 어쩌고 ###\n                Exponent: 65537 (0x10001)\n        X509v3 extensions:\n            X509v3 Key Usage: critical\n                Digital Signature, Key Encipherment\n            X509v3 Extended Key Usage: \n                TLS Web Server Authentication, TLS Web Client Authentication\n            X509v3 Basic Constraints: critical\n                CA:FALSE\n            X509v3 Authority Key Identifier:\n                keyid:### 어쩌고 ###\n            X509v3 Subject Alternative Name: \n                DNS:${HOSTNAME}, DNS:localhost, IP Address:${HOST_IP}, IP Address:127.0.0.1, IP Address:0:0:0:0:0:0:0:1\n    Signature Algorithm: sha256WithRSAEncryption\n         ### 어쩌고 ###\n\n\n확인해 보면, Issuer 는 etcd-ca 이고, x509 key usage 에 Server auth 가 포함되어 있는 인증서인 것을 알 수 있다.\n근데 설정에 따르면, Server 인증서로 /etc/kubernetes/pki/etcd/server.crt 를 제시하도록 되어 있었다. 아래의 명령어로 실제로 그런지 확인해 보자.\n\ndiff \\\n\t&lt;(openssl s_client -showcerts -connect ${HOST_IP}:2379 &lt;/dev/null 2&gt;/dev/null | openssl x509 -outform PEM) \\\n\t/etc/kubernetes/pki/etcd/server.crt\n\n실행해보면 아무것도 출력되지 않는 것을 확인할 수 있다. 즉, 둘 간의 차이가 없다는 것을 알 수 있다.\n\nPeer (server-to-server / cluster) communication §\n관련 설정들 §\n\n이제 Peer 통신에서 사용하는 인증서를 확인해보자. etcd pod 에서 관련 설정들은 다음과 같다.\n\n# 파일위치: /etc/kubernetes/manifests/etcd.yaml\n- etcd\n# 중략\n- --initial-advertise-peer-urls=https://${HOST_IP}:2380\n- --initial-cluster=${HOSTNAME}=https://${HOST_IP}:2380\n# 중략\n- --listen-peer-urls=https://${HOST_IP}:2380\n# 중략\n- --peer-cert-file=/etc/kubernetes/pki/etcd/peer.crt\n- --peer-client-cert-auth=true\n- --peer-key-file=/etc/kubernetes/pki/etcd/peer.key\n- --peer-trusted-ca-file=/etc/kubernetes/pki/etcd/ca.crt\n# 후략\n\netcd member 들의 접근 진입점에 대한 설정들\n\n--initial-advertise-peer-urls : 다른 etcd member 들의 url.\n--initial-cluster : 다른 etcd 클러스터에 합류하는 경우, 해당 클러스터의 url (기본값은 자기자신이다).\n--listen-peer-urls : 다른 etcd member 의 접근을 허용할 IP 와 Port.\n\n\n인증서 관련 설정들\n\n--peer-cert-file : etcd member 가 접근했을 때, 제시할 Server 인증서.\n--peer-client-cert-auth : etcd member 에 대해 mTLS 를 강제할 것인지에 대한 여부. 즉, 이 값이 true 라면, etcd member 가 접근할 때에 Client 인증서를 제시해야 한다.\n--peer-key-file : etcd member 가 접근했을 때, 제시할 Server 인증서에 대한 개인키.\n--peer-trusted-ca-file : 신뢰할 CA 인증서\n\n\n\nClient 인증서를 직접 만들어 요청해보기 §\n\n…는 해보려 했으나 잘 안된다. 인증서 관련 문제는 아닌 것 같은데, cURL 로 보내면 EMPTY_RESPONSE 가 오고, grpcurl 로 보내면 timeout 이 발생한다.\n\netcd 로그에는 tls: first record does not look like a TLS handshake 에러가 출력된다.\n찾아보니 https 으로 요청을 보내지 않아서 그렇다고 하는데… grpcurl 에는 인증서만 설정하면 https 로 보내는 것 같은데 좀 이상함.\n일단 여기까지 하고 나중에 좀 더 확인해봐야 겠다.\n\n\n\nsudo grpcurl -cacert /etc/kubernetes/pki/etcd/ca.crt -cert /etc/kubernetes/pki/etcd/peer.crt -key /etc/kubernetes/pki/etcd/peer.key ${HOSTNAME}:2380 list\n{&quot;level&quot;:&quot;warn&quot;,&quot;ts&quot;:&quot;2023-12-21T02:56:29.148Z&quot;,&quot;caller&quot;:&quot;embed/config_logging.go:169&quot;,&quot;msg&quot;:&quot;rejected connection&quot;,&quot;remote-addr&quot;:&quot;$IP:$PORT&quot;,&quot;server-name&quot;:&quot;&quot;,&quot;error&quot;:&quot;tls: first record does not look like a TLS handshake&quot;}\n{&quot;level&quot;:&quot;warn&quot;,&quot;ts&quot;:&quot;2023-12-21T02:56:30.150Z&quot;,&quot;caller&quot;:&quot;embed/config_logging.go:169&quot;,&quot;msg&quot;:&quot;rejected connection&quot;,&quot;remote-addr&quot;:&quot;$IP:$PORT&quot;,&quot;server-name&quot;:&quot;&quot;,&quot;error&quot;:&quot;tls: first record does not look like a TLS handshake&quot;}\n{&quot;level&quot;:&quot;warn&quot;,&quot;ts&quot;:&quot;2023-12-21T02:56:31.480Z&quot;,&quot;caller&quot;:&quot;embed/config_logging.go:169&quot;,&quot;msg&quot;:&quot;rejected connection&quot;,&quot;remote-addr&quot;:&quot;$IP:$PORT&quot;,&quot;server-name&quot;:&quot;&quot;,&quot;error&quot;:&quot;tls: first record does not look like a TLS handshake&quot;}\n{&quot;level&quot;:&quot;warn&quot;,&quot;ts&quot;:&quot;2023-12-21T02:56:33.865Z&quot;,&quot;caller&quot;:&quot;embed/config_logging.go:169&quot;,&quot;msg&quot;:&quot;rejected connection&quot;,&quot;remote-addr&quot;:&quot;$IP:$PORT&quot;,&quot;server-name&quot;:&quot;&quot;,&quot;error&quot;:&quot;tls: first record does not look like a TLS handshake&quot;}\n{&quot;level&quot;:&quot;warn&quot;,&quot;ts&quot;:&quot;2023-12-21T02:56:37.999Z&quot;,&quot;caller&quot;:&quot;embed/config_logging.go:169&quot;,&quot;msg&quot;:&quot;rejected connection&quot;,&quot;remote-addr&quot;:&quot;$IP:$PORT&quot;,&quot;server-name&quot;:&quot;&quot;,&quot;error&quot;:&quot;tls: first record does not look like a TLS handshake&quot;}\n\nServer 는 어떤 인증서를 제시할까? §\n\nClient-to-server TLS 실습 에서와 마찬가지로, openssl s_client 모듈로 Server 가 어떤 인증서를 제시하는지 확인해 보자.\n\nopenssl s_client -showcerts -connect ${HOST_IP}:2380 &lt;/dev/null 2&gt;/dev/null \\\n\t| openssl x509 -text -noout\nCertificate:\n    Data:\n        Version: 3 (0x2)\n        Serial Number: ### 어쩌고 ###\n        Signature Algorithm: sha256WithRSAEncryption\n        Issuer: CN = etcd-ca\n        Validity\n            Not Before: Jan  0 00:00:00 0000 GMT\n            Not After : Jan  0 00:00:00 0000 GMT\n        Subject: CN = ${HOSTNAME}\n        Subject Public Key Info:\n            Public Key Algorithm: rsaEncryption\n                RSA Public-Key: (2048 bit)\n                Modulus:\n                    ### 어쩌고 ###\n                Exponent: 65537 (0x10001)\n        X509v3 extensions:\n            X509v3 Key Usage: critical\n                Digital Signature, Key Encipherment\n            X509v3 Extended Key Usage: \n                TLS Web Server Authentication, TLS Web Client Authentication\n            X509v3 Basic Constraints: critical\n                CA:FALSE\n            X509v3 Authority Key Identifier:\n                keyid:### 어쩌고 ###\n            X509v3 Subject Alternative Name: \n                DNS:${HOSTNAME}, DNS:localhost, IP Address:${HOST_IP}, IP Address:127.0.0.1, IP Address:0:0:0:0:0:0:0:1\n    Signature Algorithm: sha256WithRSAEncryption\n         ### 어쩌고 ###\n\n\n그럼 Client-to-server TLS 실습 에서와 유사하게, Issuer 는 etcd-ca 이고, x509 key usage 에 Server auth 가 포함되어 있는 인증서인 것을 알 수 있다.\n그럼 이 인증서는 과연 --peer-cert-file 로 설정돼 있는 /etc/kubernetes/pki/etcd/peer.crt 와 동일할까? 아래의 명령어로 확인해 보자.\n\ndiff \\\n\t&lt;(openssl s_client -showcerts -connect ${HOST_IP}:2380 &lt;/dev/null 2&gt;/dev/null | openssl x509 -outform PEM) \\\n\t/etc/kubernetes/pki/etcd/peer.crt\n\n실행해보면 마찬가지로 아무것도 출력되지 않는다. 설정한 대로 잘 작동하고 있다는 뜻이다.\n"},"botanicals/kubernetes/docs/제-4회-테크-데이---Kubernetes-Korea-Group-커뮤니티-기술-세미나-참석-기록":{"title":"제 4회 테크 데이 - Kubernetes Korea Group 커뮤니티 기술 세미나 참석 기록","links":[],"tags":[],"content":"\n\n                  \n                  세미나에 참석하며 적은 내용들이라 다소 글이 어수선합니다. \n                  \n                \n\n\n\n                  \n                  Info DevOcean 행사 소개\n                  \n                \n\n개요… §\n\n\n2023년 4월 6일에 을지로 SKT 타워 4층 SUPEX 홀에서 열린 “제4회 테크 데이 - Kubernetes Korea Group 커뮤니티 기술 세미나” 에 참석한 뒤 내용을 정리해 보았다.\n\nSession 1) Everything in Kubernetes - 모든 것을 쿠버네티스 위에 올릴 수 있다 §\n\n참고) CNCF 가 후원하는 Kubernets Community Days Korea 가 7월에 한다고 한다.\n\n일시: 2023-07-03 ~ 04\n코엑스 그랜드볼룸\n\n\n\nIaC §\n\nCloud resource: 이것도 terraform 을 안쓰고 operator 로 가능하더라.\nOSS: Crossplane - The cloud-native control plane framework\nreconcile 을 통해 self healing 도 된다 (지우면 재생성)\n\nMulti tenency K8s §\n\nCluster API: cluster in cluster 가 가능하다.\nOSS: vcluster - Virtual Kubernetes Clusters\n\nLinux Capability 와 Privilege 가 가장 관건이 될듯.\nCase study: Adobe - Kubecon 2022 Detroit: How Adobe Planned For Scale With Argo CD, Cluster API, And VCluster - Joseph Sandoval &amp; Dan Garfield\n\n\nTinkerbell: Nutanix, OpenStack 이랑 비슷한 것 같은데.. 잘 모르겠다. (Tinkerbell.org)\n\nVirtual Machine §\n\nK8s 위에 VM 띄우기\nOSS: KubeVirt\n\nCase study: NVIDIA: KubeVirt Deep Dive: Virtualized GPU Workloads on KubeVirt - David Vossel &amp; Vishesh Tanksale\n\n\nVM 은 아니지만 이런것도 있음: ContainerSSH: Launch containers on demand\n\nServerless §\n\nOSS: Knative\n\nCase study: KubeCon Europe 2022: Overview and State of Knative - Mauricio Salatino, VMware &amp; Carlos Santana, IBM\n\n\n\nCICD §\n\nCI OSS: Tekton\nCD OSS: Argo CD\n\nWorkflow §\n\nArgo workflow, Kubeflow: airflow 비슷\n\nDBaaS §\n\nDB 를 쿠버네티스 위에 올려서 사용하는 사례가 점점 더 많아지고 있다.\n\n하지만 장애발생시 K8s 가 원인인지 아닌지 확인할 수 있게 쿠버네티스 전문가가 필요하다.\n\n\nMySQL operator OSS: Vitess\n\nCase Study: Slack, Youtube, GitHub\n\n\n\nKyverno vs OPA §\n\nKyverno 보다는 OPA (Gatekeeper) 가 요즘 더 뜬다고 한다.\n\nISP 가 제공하는 5G 통신망을 OSS 로 구축하는놈이 있다? §\n\nOpen5GS\nUERANSIM\n5G on Kubernetes\nPrivate 5G, 5GaaS\n\nSess 2 - 개발부터 배포까지 전반의 과정 §\n\n이미지는 RO 레이어지만, 컨테니어가 실행되면 그때 RW 되는 레이어가 하나 추가된다더라\npause 컨테이너: 컨테이너 하나가 무조건 떠야지 linux namespace 가 생성되기 때문에 Pod 가 생성될 때 무조건 생성되는 컨테이너.\n\nSess 3 - 클러스터 API §\n\n참고) Kubeadm 같은 설치툴을 Bootstrap provider 라고 한다\nOSS: Cluster API\n\n메인 클러스터에 operator 를 설치하여 다른 클러스터를 provisioning 하는 프로젝트\nv1.4.1 이 최신버전 (세미나 시점에서는…)\neksctl, 혹은 terraform 으로 iac 가 가능하지만 operator 의 reconcile 이 cluster-api 가 갖는 차별점\n\n\nMetal 3 → bare metal cluster api 프로바이더? (Metal³ - Metal Kubed)\n"},"botanicals/kubernetes/troubleshoots/Ingress-NGINX---\"upstream-sent-too-large-http2-frame-4740180\"-에러-해결기":{"title":"Ingress NGINX - \"upstream sent too large http2 frame 4740180\" 에러 해결기","links":[],"tags":["삽질록"],"content":"문제 상황 §\n\n기존에는 Deployment 를 NodePort Service 로 노출시켜서 접속하고 있었는데,\n이 앞에 NGINX Ingress Controller 를 두고 이놈을 NodePort 로 노출시켜 접속하고자 하였으나 502 에러가 출력되었다.\n\n해결 - NGINX 에의 upstream sent too large http2 frame: 4740180 에러 로그 §\n\n발생한 로그\n\nx.x.x.x - - [01/Jan/0000:00:00:00 +0000] &quot;GET / HTTP/1.1&quot; 502 150 &quot;-&quot; &quot;curl/7.87.0&quot; 197 0.002 [xxx] [] x.x.x.x:x 0 0.002 502 d4acbcddeb068470b9adb8c89c9fdbc4\n0000/01/01 00:00:00 [error] 25460#25460: *36847278 upstream sent too large http2 frame: 4740180 while reading response header from upstream, client: x.x.x.x, server: xxx, request: &quot;GET / HTTP/1.1&quot;, upstream: &quot;grpc://x.x.x.x:x&quot;, host: &quot;xxx:x&quot;\n\n\n관련 구글링\n\nAll 404’s result in 502 “upstream sent too large http2 frame” · Issue #4323 · kubernetes/ingress-nginx\nA misleading error when using gRPC with Go and nginx\n\n\n위의 글들을 읽어보면 결론은 다음과 같다.\n\nupstream protocol 이 gRPC 이기에 NGINX 는 upstream 으로 HTTP/2 요청을 보낸다.\n하지만 upstream 은 HTTP/1.1 로 응답을 보낸다\n\n이 문제는 plaintext HTTP 와 gRPC 를 같은 포트에서 제공하는 경우 흔하게 발생할 수 있다. → plaintext HTTP 는 HTTP/1.1 이고, gRPC 는 HTTP/2 이기에\n\n\nNGINX 는 이것을 받아들고 HTTP/2 로 해석을 한다.\n\n여기서 마법이 일어나게 된다.\nHTTP/2 는 메세지를 프레임별로 쪼개고 프레임 앞에 헤더를 달되 헤더의 첫 3바이트가 헤더의 크기를 나타내는 수치인데\nHTTP/1.1 은 무조건 메세지의 첫 줄로 HTTP/1.1 {{ HTTP_STATUS_CODE }} {{ HTTP_STATUS_MSG }} 를 보내기 때문에 메세지가 HTTP 버전 명시로 시작한다.\n이때 HTTP/1.1 메세지를 HTTP/2 로 분석하면 메세지 HTTP/1.1 … 의 첫 3바이트인 HTT 를 헤더의 길이로 해석한다.\nASCII 에 따르면 이 값은 4740180 이다. (!!!) → 그래서 NGINX 로그에 4740180 이라는 숫자가 찍혀있는 것.\n그리고 이것이 헤더의 길이 치고는 너무 큰값이기에 NGINX 가 에러를 내뿜는 것이다.\n\n\n\n\n해결방법\n\n알고보니 upstream 에서는 gRPC 를 사용하지 않고 있었고, 따라서 ingress annotation 에서 GRPC 를 빼주는 것으로 해결하였다.\n이외에 gRPC 를 사용할 때 위같은 에러가 발생한다면, (1) gRPC 는 다른 포트를 사용하게 하거나 (2) h2c 를 이용해서 plaintext 를 HTTP2 로 응답하게 하는 방법이 있다고 한다.\n\n\n\n기타 시도한 것들… §\n1. upstream 에서의 connection refused 의심 (upstream 의 port 에 접근을 못하고 있을거다) §\n\n하지만 NodePort 로는 접근이 잘 되고 Service 의 port 를 name 으로 지정하는 것이 아닌 port 80 으로 바꿔도 잘 되기에 네트워크 문제는 아닌 것으로 판단하였다.\n\n2. Proxy buffer size 의심 §\n\nSize 어쩌고 하길래 혹시 Proxy buffer size 가 너무 작아서인가 라고 생각해 봤으나\n하지만 NGINX ingress controller 에서 Proxy buffer 는 기본적으로 비활성화되어 있고\n\n\n\nConfigMap - Ingress-Nginx Controller#proxy-buffering\n\n\nProxy buffer size 와 count 를 늘려줘도 해결되지 않았다.\n\ningress-nginx/annotations.md at main · kubernetes/ingress-nginx\n\n\nGRPC 버퍼 사이즈 바꿔도 안된다.\n\nhttps://github.com/kubernetes/ingress-nginx/issues/9363\n\n\n\n3. NGINX HTTP2 비활성화 의심 §\n\n하지만 기본적으로 활성화 되어 있다. (Client - NGINX 간 통신시)\n\n\n\nConfigMap - Ingress-Nginx Controller#use-http2\n\n\nUpstream 으로의 통신에서는 HTTP2 가 활성화되어있지 않아서 그럴수도 있겠다고 생각했으나, GRPC 면 HTTP2 로 통신한다고 한다.\n\nkong nginx-ingress not support http2 upstream · Issue #2473 · Kong/kubernetes-ingress-controller\nupstream 으로의 HTTP2 통신은 gRPC 가 아닌 이상 비활성화된다고 한다.\n\n\n"},"botanicals/kubernetes/troubleshoots/RabbitMQ-on-Kubernetes---Troubleshooting-error-\"Command-df-timed-out\"":{"title":"RabbitMQ on Kubernetes - \"Command timed out: '/usr/bin/df -kP ...'\" 에러 해결기","links":[],"tags":["삽질록"],"content":"증상 §\n\nKubernetes 에다가 RabbitMQ 공식 이미지를 이용해 StatefulSet 으로 배포해 잘 사용하던 중, 어느날 파드가 CrashLoopBackOff 상태가 되며 작동하지 않았다고 한다.\n로그를 확인해 보니 다음과 같은 문구가 있었다: Index 들을 rebuilding 한다는 경고 뒤에, df 명령어가 시간초과 되었다는 것.\n\n0000-00-00 00:00:00.000000+00:00 [warning] &lt;0.527.0&gt; Message store &#039;something_hashy/msg_store_persistent&#039;: rebuilding indices from scratch\n0000-00-00 00:00:00.000000+00:00 [error] &lt;0.355.0&gt; Command timed out: &#039;/usr/bin/df -kP /path/to/data&#039;\n\n\n이에 장림 깊은 골로 대한 짐생 내려와 해결하니…\n\n디버깅 기록 §\n시간 초과난 명령어(/usr/bin/df -kP …) 를 직접 실행해 보자. §\n\n하지만 kubectl exec 으로 직접 실행했을 때에는 그리 오래 걸리지 않았다.\n\ntime kubectl exec -it rabbitmq-0 -- /usr/bin/df -kP /path/to/data\n에잉 얼마 안걸리지롱\n\n에러 관련 서칭: 3.10.8 버전부터 fix 되었다고 한다. §\n\nRabbitMQ Discussion #4753: Retrieving free disk space on Linux timed out\n\n위의 Discussion 에서 2가지를 알아낼 수 있었다.\n\ndf 명령어는 리소스를 많이 먹는 작업은 아니지만 싱글코어 혹은 많은 작업들이 실행되는 환경에서는 timeout 이 날 수 있다.\n이 문제는 3.10.8 버전부터 해결되었다. (관련 PR!)\n\n\n\n\n하지만 container log 를 확인해보면 3.10.7 버전인 것을 알 수 있었다.\n\nkubectl logs rabbitmq-0\n...\n  ##  ##\t  RabbitMQ 3.10.7\n  ##  ##\n  ##########  Copyright (c) 2007-2022 VMware, Inc. or its affiliates.\n  ######  ##\n  ##########  Licensed under the MPL 2.0. Website: &lt;https://rabbitmq.com&gt;\n\n  Erlang:\t  25.0.3 [jit]\n  TLS Library: OpenSSL - OpenSSL 1.1.1q  5 Jul 2022\n\n  Doc guides:  &lt;https://rabbitmq.com/documentation.html&gt;\n  Support:\t &lt;https://rabbitmq.com/contact.html&gt;\n  Tutorials:   &lt;https://rabbitmq.com/getstarted.html&gt;\n  Monitoring:  &lt;https://rabbitmq.com/monitoring.html&gt;\n\t\n  Logs: /path/to/logs\n\t\t&lt;stdout&gt;\n\n  Config file(s): /path/to/configs\n...\n\nImage 변경 &amp; LivenessProbe 비활성화 후 pod 실행 §\n\n3.10.8 버전부터 fix 되었다고 하기에, docker hub 에 올라와 있는 3.10.x 버전인 3.10.25 를 사용하기로 결정. (사용한 이미지)\n\n버전업의 Side effect 를 줄이기 위해 patch version 만 업그레이드 했다.\n\n\nkubectl edit 으로 image tag 를 변경하고, (SIGTERM 방지를 위해) LivenessProbe 도 삭제 후, pod가 정상적으로 실행될 때까지 대기…\n결과적으로는 Indice rebuild 단계에서만 50분 걸렸다 (!!!!)\n\n아래 로그만 50분동안 쳐다보고 있었다…\n\n\n\nMessage store &quot;something_hashy/msg_store_persistent&quot;: rebuilding indices from scratch\n\n\n그래도 이정도면 양반인 갑다. 이사람은 1시간 30분 걸렸다 함: “Google group conversation: msg_store_persistent: rebuilding indices from scratch” is taking a lot of time\n\nRebuild 가 정상적으로 끝났으니, 원래 상태로 되돌려 놓자. §\n\nIndice rebuild 작업이 매번 발생하는 것이 아니고 문제 상황에서만 발생하는 것이니까 원래 이미지 버전으로 되돌려 놔도 rebuild 작업 없이 정상적으로 작동하지 않을까?\n따라서 원래의 StatefulSet manifest 로 원복시킨 후, 상태 확인 -&gt; 예상대로 rebuilding 작업 없이 정상적으로 작동했다. (LivenessProbe 도 성공)\n\n향후 대처 방안 §\n문제의 원인: RabbitMQ 가 정상적으로 종료되지 않았을 때 indice 가 깨져 rebuilding 작업이 이루어진다고 한다. §\n\n여기서 그랬음 - “Google group conversation: msg_store_persistent: rebuilding indices from scratch” is taking a lot of time\n\nSIGTERM 이나 SIGKILL 로 강제종료되는 것이 원인\npod 가 종료될때는 SIGTERM 을 보내기에, indice 가 깨질 우려가 있다\n\n\n이걸 해결하기 위해 (시간이 부족해 해보진 않았다…) 두가지 정도 시도해 볼 만한 것이 있다.\n\nKubernetes preStop hook 을 이용해서 종료 전에 정상적으로 cleanup 작업이 이루어 지도록 유도할 수 있지 않을까?\n아니면, 그냥 생 StatefulSet 말고 RabbitMQ operator 를 사용하면 이런 Lifecycle 을 관리해주지 않을까?\n\n\n또한 여기서는 종료시에 디스크 기록 timeout 시간을 늘려 종료되기 전에 모든 데이터가 정상적으로 종료될 수 있게 해야 한다고 한다.\n\nRabbitMQ Issue #2324: Message indices fail to recover, even if the broker shuts down gracefully with rabbitmqctl\n\n\n\n만일 그럼에도 불구하고 rebuilding 작업이 수행되어야 할 때는, 이것을 충분히 기다려 주기 위해 StartupProbe 를 활용해 보자. §\n\n3.10.8 이전의 버전에서는 프로세스 차원에서 timeout 이 발생하므로 해당 버전 이상의 이미지를 사용해야 하고,\n또한 rebuild 도중 LivenessProbe 에 의해 종료되는 것을 막기 위해 StartupProbe 를 설정하여 이것을 기다릴 필요가 있다.\n"},"botanicals/networks/(Botanical-Garden)-Network,-Protocol":{"title":"(Botanical Garden) Network, Protocol","links":["botanicals/networks/bgp/terms/Regional-Internet-Registry,-RIR-(Network)","botanicals/networks/dns/terms/Cache-Poisoning-(DNS)","botanicals/networks/dns/terms/DNS-Tunneling-(DNS)","botanicals/networks/dns/terms/Domain-Name-System-(DNS)","botanicals/networks/dns/terms/Full-Qualified-Domain-Name,-FQDN-(DNS)","botanicals/networks/dns/terms/Nameserver-(DNS)","botanicals/networks/dns/terms/Namespace-(DNS)","botanicals/networks/dns/terms/Partially-Qualified-Domain-Name,-PQDN-(DNS)","botanicals/networks/dns/terms/Top-Level-Domain,-TLD-(DNS)","botanicals/networks/dns/terms/Zone-(DNS)","botanicals/networks/dns/terms/Zone-Delegation-(DNS)"],"tags":[],"content":"개요 §\n\n네트워크도 슬슬 심어볼 때 됐다 이제.\n\n작물들 §\n\nProtocol 별로 좀 모아서 심자\n\nBorder Gateway Protocol (BGP) §\n\nRegional Internet Registry, RIR\n\nDomain Name System (DNS) §\n\nCache Poisoning\nDNS Tunneling\nDomain Name System, DNS\nFull Qualified Domain Name, FQDN\nNameserver\nNamespace\nPartially Qualified Domain Name, PQDN\nTop Level Domain, TLD\nZone\nZone Delegation\n"},"botanicals/networks/bgp/terms/Regional-Internet-Registry,-RIR-(Network)":{"title":"Regional Internet Registry, RIR (Network)","links":["botanicals/networks/draft/Autonomous-System,-AS-(Network)"],"tags":["용어집","network"],"content":"\n\n                  \n                  참고한 것 \n                  \n                \n\n어떤 회사 RPKI 소개글\n\n\n이게 뭔데 §\n\nAS 에 대한 ASN 와 그것의 public IP 범위 (IP Prefix) 를 발급해주는 기관이다.\n전 세계적으로 (대충 대륙별로) 5개가 있다:\n\n북미: ARIN\n유럽 + 러시아: RIPE NCC\n아시아 + 태평양 인근: APNIC\n남미 (라틴아메리카): LACNIC\n아프리카: AFRINIC\n\n\n"},"botanicals/networks/dns/terms/Cache-Poisoning-(DNS)":{"title":"Cache Poisoning (DNS)","links":["botanicals/networks/draft/How-DNS-Works---Recursive-or-Iterative-(DNS)","botanicals/networks/dns/terms/Nameserver-(DNS)","botanicals/networks/draft/DNS-Security-Extension,-DNSSEC-(DNS)"],"tags":["용어집","network","dns"],"content":"\n\n                  \n                  참고한 것 \n                  \n                \n\nSurvey on DNS-Specific Security Issues and Solution Approaches\n\n\n뭔가 §\n\nDNS 캐시 (Cache) 에 독을 푸는 것 (Poisoning)\nDNS Resolver 는 매 query 마다 Authoritative Nameserver 에 물어보는 것 보다는 한번 물어보고 그 결과를 캐싱해 놓아 다음 요청에서는 물어보지 않는 방법을 사용하는데\n이때 이 캐시에 잘못된 정보가 들어가도록 하여 resolver 가 잘못된 응답을 하게 하는 것이다.\n\n일반적인 공격 방법은 캐시에 domain 에 대한 올바른 authoritative nameserver 의 ip 가 아닌 attacker 의 nameserver ip 를 저장하도록 하여\n해당 nameserver 로 query 가 왔을 때, attacker 가 만든 가짜 웹사이트 ip 를 응답해 해당 웹사이트로 접속하도록 유도하는 방법을 많이 사용한다.\n\n\n이것을 해결하기 위한 방법중 하나로 DNSSEC 이 있다.\n"},"botanicals/networks/dns/terms/DNS-Tunneling-(DNS)":{"title":"DNS Tunneling (DNS)","links":["botanicals/networks/dns/terms/Nameserver-(DNS)","botanicals/networks/dns/terms/Zone-Delegation-(DNS)","botanicals/networks/draft/How-DNS-Works---Recursive-or-Iterative-(DNS)"],"tags":["용어집","network","dns"],"content":"\n\n                  \n                  참고한 것들 \n                  \n                \n\n어떤 회사 사이트\n\n\nDNS query 를 이용해 데이터를 주고받기 §\n\nDNS Tunneling 은 다음과 같은 DNS 의 특성을 이용한다:\n\n\nDNS query 에 들어가는 URL 은 어떤 것이든 될 수 있다.\n\n가령 oh-shit.haeramk.im 으로 query 를 보낸다고 해서 문제될 것은 없다.\n즉, URL 에 어떤 데이터를 넣어 보내는 것도 가능하다는 뜻.\n\n\nDNS query 와 response 는 방화벽에 걸리지 않는다.\n\nDNS 메세지는 아주 흔하게 사용되기 때문에, 이것은 보통 방화벽 설정에서 막아놓지 않는다.\n\n\n\n작동 원리 §\n\n\n이미지 출처\n\n\n공격자는 evilsite.com 과 같은 도메인을 하나 구매한다.\n공격자는 malware 를 서버에 설치한다. (이 서버를 malserver 라고 부르자.)\n그리고 서브도메인을 생성한 후, malserver 가 authoritative nameserver 가 되도록 DNS delegation 을 수행한다.\n\n즉, 위의 예시에서는 tun.evilsite.com 을 생성한 후에 해당 zone 의 authoritative nameserver 를 malserver 로 설정하게 한 것이다.\n따라서 *.tun.evilsite.com 에 대한 DNS query 는 이 malserver 로 가게 된다.\n\n\n공격하고자 하는 네트워크 (가령 다른 회사 내부) 에 감염된 컴퓨터 (이놈을 victim 이라고 하자.) 하나를 준비한다.\n\n이건 딱히 정해진 방법이 없다. 뭐 스팸메일을 이용하건, 자기가 발로 뛰어서 직접 갖다놓던지 간에 그냥 컴퓨터 하나가 네트워크 안에 준비되어 있기만 하면 된다.\n\n\n이후에 victim 이 {data}.tun.evilsite.com 에 대한 DNS query 를 보내서 malserver 에 데이터를 보낸다. 구체적으로는:\n\n해당 DNS query 는 네트워크 안의 DNS resolver 로 가게 되고,\nDNS resolver 는 (여기 에서 설명한 일련의 과정을 거친 뒤에) 해당 query 를 malserver 에 보내게 된다.\n그럼 query 는 네트워크의 방화벽을 별 탈 없이 뚫고 malserver 에 도달하게 된다.\nmalserver 는 원하는 데이터를 담아 DNS response 를 보내게 된다.\n결과적으로, DNS resolver 를 사이에 두고 victim 과 malserver 가 데이터를 주고 받는 connection 이 생기게 된다.\n\n\n"},"botanicals/networks/dns/terms/Domain-Name-System-(DNS)":{"title":"Domain Name System (DNS)","links":[],"tags":["용어집","network"],"content":"\n\n                  \n                  참고한 것 \n                  \n                \n\n컴퓨터 네트워크 특강 (권태경 교수님 ‘24H1, SNU CSE)\nUnder attack? 회사 블로그\n\n\nDNS: Key(Domain)-Value(IP) Store §\n\nDNS 의 목표는 아주 간단하다: 문자열 형태의 domain 을 IP 로 변환하는 것.\n따라서 DNS 은 마치 하나의 거대한 Key-value store 라고 생각할 수 있다.\n이것을 구현하는 방법은 중앙집권화 (Centralized) 하는 방법과, 분산 (Distributed) 하는 방법이 있을 텐데, 실제로는 분산되어 구현되게 된다.\n\n중앙집권화 되어 있을 경우에는 다음과 같은 문제점이 있다:\n\n단일 실패점\n중앙 서버로 다수의 트래픽이 몰림\n어떤 client 에게는 가깝고 누구에게는 멀고\n확장성 문제\n\n\n\n\n\nDomain-IP 관계 §\n\n1:1 관계가 일반적이지만\n도메인 여러개가 하나의 IP 를 받을 수도 있고\n도메인 한개가 여러 IP 를 받을 수도 있다고 한다.\n"},"botanicals/networks/dns/terms/Full-Qualified-Domain-Name,-FQDN-(DNS)":{"title":"Full Qualified Domain Name, FQDN (DNS)","links":["originals/comnet.fall.2021.cse.cnu.ac.kr/11.-Application-Layer,-DNS","botanicals/networks/dns/terms/Namespace-(DNS)"],"tags":["용어집","network","dns"],"content":"\n\n                  \n                  참고한 것 \n                  \n                \n\n컴퓨터 네트워크 특강 (권태경 교수님 ‘24H1, SNU CSE)\n컴퓨터 네트워크 (김상하 교수님 ‘21H1, CNU CSE)\n\n\n이게 뭐임 §\n\n흔히 말하는 domain 이라고 생각하면 된다.\n근데 이제 DNS Namespace 의 관점에서 보자면, 어떤 한 노드를 유일하게 구분해 주는 ID 로 FQDN 을 정의할 수 있다.\n형식은 원하는 노드에서부터 시작해 root 까지 올라오며 지나친 노드들의 label 을 . 으로 연결해 주면 된다.\n\n아래 challenger.atc.fhda.edu. 예시 보면 기깔나게 이해될 것이여\n\n\n\n\n\n따라서 원래 모든 FQDN 은 . 으로 끝나야 하지만, 생략해도 된다.\n어떤 노드의 FQDN 을 알면 해당 노드의 domain namespace 내에서의 위치도 대략 알 수 있다.\n"},"botanicals/networks/dns/terms/Nameserver-(DNS)":{"title":"Nameserver (DNS)","links":["botanicals/networks/dns/terms/Domain-Name-System-(DNS)","botanicals/networks/dns/terms/Zone-(DNS)","botanicals/networks/draft/How-DNS-Works---Recursive-or-Iterative-(DNS)","botanicals/networks/dns/terms/Top-Level-Domain,-TLD-(DNS)"],"tags":["용어집","network","dns"],"content":"\n\n                  \n                  참고한 것 \n                  \n                \n\n컴퓨터 네트워크 특강 (권태경 교수님 ‘24H1, SNU CSE)\n불타는 구름\n\n\n이게 뭐임 §\n\nDNS name 와 관련된 작업을 수행하는 server 이다.\n\n조금 더 구체적으로는, 어떤 Zone 의 domain 에 대한 record 들을 저장하고, 이것에 대한 query 가 들어왔을 때 응답하는 등의 작업을 하는 server 를 말한다.\n\n\n이 사이트 에 가서 도메인을 입력하면 해당 도메인에 대한 zone 들과 해당 zone 의 nameserver 를 한눈에 볼 수 있다.\n\nMDG 의 경우에는 다음과 같다…\n\n\n\n\n종류 §\n\nDNS nameserver 는 크게 다음의 네 가지로 구분될 수 있다고 한다:\n\nRecursive Resolver §\n\nFrontend nameserver 라고 생각하면 된다.\n여러 host 들로 부터 DNS query 를 가장 먼저 받아들여서,\n자기 자신에는 많은 정보를 저장하지 않고, 다른 DNS nameserver 들로 query 를 forward 해 IP 를 받아와 host 들에게 응답하고 (이 부분은 이 문서 에서 좀 더 자세히 알아보자)\n해당 IP 를 caching 하여 다음번의 query 에 빠르게 응답하는 역할의 server 이다.\n\nRoot Nameserver §\n\nRoot zone 을 담당하는 server 를 Root Nameserver 라고 한다.\ndig 명령어에 아무 인자 없이 입력하면 이 root nameserver 들을 볼 수 있다.\n\n만일 안나온다면 dig . NS 를 입력하면 된다.\n\n\n\n\n\n위의 사진에서 확인할 수 있듯이, 전 세계적으로 [a-m].root-servers.net 총 13개의 nameserver 들이 운영되고 있다.\n\nTLD Nameserver §\n\nTLD 각각의 zone 에 대한 server 를 TLD Nameserver 라고 한다.\n대표적인 TLD 인 .com 에 대한 nameserver 들을 확인해 보자.\n\ndig com NS\n\n\n전 세계적으로 [a-m].gtld-server.net 13개의 nameserver 가 운영되는 것을 볼 수 있다.\n\nAuthoritative Nameserver §\n\n어떤 Zone 을 담당하고 있는 server 를 Authoritative Nameserver 라고 한다.\n\nAnycast in Nameserver §\n\n일단 Anycast 는 여러 서버가 같은 (ASN, IP Prefix) 를 갖고록 해서 클라이언트가 질의를 해서 BGP 를 탔을 때 이러한 서버 중에서 가장 가까운 놈이 응답을 하는 방식을 말한다.\n\nCDN 생각하면 이해가 빠르다\n\n\nRoot Nameserver 를 포함한 nameserver 들이 이런식으로 운영되고 있다.\n\nRoot Nameserver 의 경우에는, root-servers.org 에 가면 어디에서 이런 server 가 운용되는지 확인할 수 있다.\n\n\n"},"botanicals/networks/dns/terms/Namespace-(DNS)":{"title":"Namespace (DNS)","links":["botanicals/networks/dns/terms/Domain-Name-System-(DNS)","botanicals/networks/dns/terms/Zone-(DNS)","botanicals/networks/dns/terms/Full-Qualified-Domain-Name,-FQDN-(DNS)"],"tags":["용어집","network","dns"],"content":"\n\n                  \n                  참고한 것 \n                  \n                \n\n컴퓨터 네트워크 특강 (권태경 교수님 ‘24H1, SNU CSE)\n\n\nDomain Tree §\n\nDNS 는 Domain Namespace 라는 이름의 트리 자료구조 형태를 가진다.\n\n\n\n출처: 교수님 감사합니다.\n\n\n위 그림처럼, 최상단의 root node 는 . 이고, 그 아래로 node 마다 label 이 붙는 형태의 트리 전체를 domain namespace 라고 한다.\n이 트리에는 여러 특징이 있다:\n\nDomain namespace 는 여러개의 Zone 으로 나뉘어 관리되고, 모든 Zone 들이 합쳐져 domain namespace 전체를 커버한다.\n각 노드는 FQDN 이라는 포맷으로 유일하게 구분된다.\n\n\n"},"botanicals/networks/dns/terms/Partially-Qualified-Domain-Name,-PQDN-(DNS)":{"title":"Partially Qualified Domain Name, PQDN (DNS)","links":["originals/comnet.fall.2021.cse.cnu.ac.kr/11.-Application-Layer,-DNS","botanicals/networks/dns/terms/Full-Qualified-Domain-Name,-FQDN-(DNS)"],"tags":["용어집","network","dns"],"content":"\n\n                  \n                  참고한 것 \n                  \n                \n\n컴퓨터 네트워크 (김상하 교수님 ‘21H1, CNU CSE)\n\n\n용어 뜻만 간단하게 알고 지나가자 §\n\nPartially Qualified Domain Name (PQDN) 은 FQDN 에서 일부가 생략된 형태이다.\n\n뭐 가령 www.google.com 에서 www.google 로만 표현하는 등\n\n\n근데 아직 주인장은 머리에 털난 이후로 이 표현법을 쓰는 것을 본 기억이 없다.\n\n물론 FQDN 의 경우에는 마지막에 root 인 . 까지 명시하는 것이 정도를 걷는 길이나, 이거를 생략한다고 해서 FQDN 이 아니다 라고는 안한다.\n\n\n"},"botanicals/networks/dns/terms/Top-Level-Domain,-TLD-(DNS)":{"title":"Top Level Domain, TLD (DNS)","links":["botanicals/networks/dns/terms/Namespace-(DNS)","botanicals/networks/dns/terms/Full-Qualified-Domain-Name,-FQDN-(DNS)"],"tags":["용어집","network","dns"],"content":"\n\n                  \n                  참고한 것 \n                  \n                \n\n컴퓨터 네트워크 특강 (권태경 교수님 ‘24H1, SNU CSE)\n\n\n이게 뭐임 §\n\nDNS Namespace 내에서 root 바로 아래에 있는 domain 들을 Top Level Domain, TLD 라고 부른다.\n\n종류 §\nGeneric TLD (gTLD) §\n\n특정 의미를 가지고 국가 등에 상관 없이 사용할 수 있는 TLD 이다.\ncom, net, org 등이 포함된다.\n\nCountry Code TLD (ccTLD) §\n\n특정 국가에 속한 TLD 를 말한다.\n우리나라는 kr 이고, 다른 나라 중에는 uk, ca, au 등이 여기에 속하는 것\n\nOpen ccTLD §\n\n특정 국가의 TLD 이긴 하지만, 해당 국가가 아닌 곳에서도 등록할 수 있는 TLD 를 말한다.\n\n아마 도메인 장사를 국가사업으로 삼는 경우에 이 짓을 한다. 실제로 io 는 영국령 인도양 지역의 ccTLD 인데, 요즘 스타업들에서 많이 사용하며 수입이 짭짤하다고 한다.\n\n\nco, io, be, me 등이 있다.\n"},"botanicals/networks/dns/terms/Zone-(DNS)":{"title":"Zone (DNS)","links":["botanicals/networks/dns/terms/Namespace-(DNS)","botanicals/networks/dns/terms/Top-Level-Domain,-TLD-(DNS)","botanicals/networks/dns/terms/Zone-Delegation-(DNS)","botanicals/networks/dns/terms/Nameserver-(DNS)"],"tags":["용어집","network","dns"],"content":"\n\n                  \n                  참고한 것 \n                  \n                \n\n컴퓨터 네트워크 특강 (권태경 교수님 ‘24H1, SNU CSE)\n네트워크에서 빼놓을 수 없는 ‘Under attack?’ 회사 블로그\n\n\n이게뭐고 §\n\nDomain Zone 은 하나의 기관 혹은 관리자에 의해 관리되는, DNS Namespace 내의 sub-tree 이다.\n\nDNS Namespace 가 모든 domain 들에 대한 가상의 영역이라면, 특정 기관 혹은 관리자가 이 영역 중 어디를 땅따먹기 해서 관리하고 있는지 표시한 것이 Zone 인 것.\n따라서 Zone 들은 DNS namespace 를 비는 곳 없이 커버한다. (모든 Zone 의 합집합은 DNS namespace)\n가령, . (root) 와 그의 직계 자식 (TLD 라고 부른다) 은 ICANN 에서 관리하는 하나의 zone 이다.\n\n\n\n\n\n출처: 교수님 감사합니다.\n\n\nZone 에 있는 모든 도메인을 관리하는 것은 너무 힘들기 때문에, zone 을 분리해서 다른 기관(관리자) 에게 넘기는 경우가 많고, 이것을 위임 (Delegation) 한다고 한다.\n각 zone 은 해당 zone 의 담당기관(관리자) 에 의해 DNS nameserver 를 운영하며 record 와 query 에 응답할 의무가 있다.\n"},"botanicals/networks/dns/terms/Zone-Delegation-(DNS)":{"title":"Zone Delegation (DNS)","links":["botanicals/networks/dns/terms/Zone-(DNS)","botanicals/networks/draft/Resource-Record,-RR-(DNS)"],"tags":["용어집","network"],"content":"\n\n                  \n                  참고한 것: \n                  \n                \n\n어떤 회사 블로그\n\n\n이게뭐임? §\n\n말 그대로 DNS Zone 의 관리를 위임 (Delegate) 하는 것이다.\n여기서 “관리” 라는 것은 해당 DNS zone 에 대해\n\nDNS record 들을 저장하고\nDNS record 에 따라 query 에 응답하는 것이라고 생각하면 될 것 같다.\n\n\n또한 아무한테나 위임하는 것이 아니고, parent zone (예를 들어 .com.) 이 child zone (예를 들어 example.com.) 에게 위임하는 것이다.\n즉, Parent zone 은 child zone 에 대한 record 를 저장하고 query 를 응답해야 하지만, 이런 delegation 을 통해 parent 가 아닌 child 가 record 저장 및 응답을 하게 하는 것.\n\nNS Record, Glue Record §\n\n일단 DNS delegation 을 하는 과정을 살펴보면 아래와 같다.\n\n\n우선 child zone 에서 record 를 저장하고 응답하기 위해 child zone 에 DNS server 가 구성된다.\nParent zone 에는 child zone DNS server 의 이름 을 NS record type 으로 저장한다.\n\n여기서 중요한 것은 이름 을 저장한다는 것이다: DNS server 의 IP 를 저장하는 것이 아니다.\n예를 들어 example.com 의 경우에는, ns.gltd-server.net 등이 저장된다는 소리.\n\n\n근데 생각해 보면 이름 을 저장하게 되면 이놈에 대한 query 를 또 날려야 할 것이다. 이것을 방지하기 위해 parent zone 에 해당 이름 에 대한 A/AAAA record 를 같이 저장한다.\n\n이렇게 DNS server 의 이름을 저장하는 A/AAAA record 를 Glue Record 라고도 한다.\n\n\n\n\n이 NS 와 glue record 는 query 가 왔을 때 다음처럼 사용된다.\n\n\n가령 .com. 에게 www.example.com 에 대한 query 가 왔다고 해보자.\n그럼 .com. 은 자신의 record 에 example.com 에 대한 NS record 로 ns.gltd-server.net 이 있는 것을 확인할 것이다.\n또한 ns.gltd-server.net 의 A record 로 132.2.10.9 도 있는 것을 확인할 수 있을 것이다.\n그럼 .com. 은 132.2.10.9 로 다시 query 하라는 메세지를 응답해 해당 query 를 보낸 놈이 www.example.com 에 대한 query 를 example.com 의 DNS server 로 보낼 수 있게 한다.\n"},"botanicals/networks/draft/Autonomous-System,-AS-(Network)":{"title":"Autonomous System, AS (Network)","links":[],"tags":["용어집","network"],"content":"\n\n                  \n                  본 글은 #draft 상태입니다. \n                  \n                  \n                \n                \n\n 내용 정리\n\n"},"botanicals/networks/draft/Border-Gateway-Protocol,-BGP-(Network)":{"title":"Border Gateway Protocol, BGP (Network)","links":[],"tags":["용어집","network"],"content":"\n\n                  \n                  본 글은 #draft 상태입니다. \n                  \n                  \n                \n                \n\n 내용 정리\n\n"},"botanicals/networks/draft/DNS-Security-Extension,-DNSSEC-(DNS)":{"title":"DNS Security Extension, DNSSEC (DNS)","links":[],"tags":["용어집","network","dns"],"content":"\n\n                  \n                  본 글은 #draft 상태입니다. \n                  \n                  \n                \n                \n\n 내용 정리\n\n"},"botanicals/networks/draft/How-DNS-Works---Recursive-or-Iterative-(DNS)":{"title":"How DNS Works - Recursive or Iterative (DNS)","links":[],"tags":["스토리","network","dns"],"content":"\n\n                  \n                  본 글은 #draft 상태입니다. \n                  \n                  \n                \n                \n\n 내용 정리\n\n"},"botanicals/networks/draft/Resource-Record,-RR-(DNS)":{"title":"Resource Record, RR (DNS)","links":[],"tags":["용어집","network","dns"],"content":"\n\n                  \n                  본 글은 #draft 상태입니다. \n                  \n                  \n                \n                \n\n 내용 정리\n\n"},"botanicals/os/(Botanical-Garden)-Operating-Systems,-Linux":{"title":"(Botanical Garden) Operating Systems, Linux","links":["botanicals/os/papers/논문---A-Fast-File-System-for-UNIX","botanicals/os/papers/논문---F2FS---A-New-File-System-for-Flash-Storage","botanicals/os/papers/논문---Hints-for-Computer-System-Design","botanicals/os/papers/논문---The-design-and-implementation-of-a-log-structured-file-system","botanicals/os/papers/논문---The-Evolution-of-the-Unix-Time-sharing-System","botanicals/os/terms/External-Fragment-(OS)","botanicals/os/terms/Internal-Fragment-(OS)","botanicals/os/fs/Slack-Space-Recycling,-SSR-(File-System)"],"tags":[],"content":"개요 §\n\n운영체제 (주로 리눅스 계열) 한번 심어보자\n\n작물들 §\n논문 §\n\n(Draft) Marshall K. McKusick - A Fast File System for UNIX (ACM ToCS ‘84)\n(Draft) Changman Lee et al. F2FS: A New File System for Flash Storage\n(Draft) Butler W. Lampson - Hints for Computer System Design (ACM SIGOPS)\n(Draft) Mendel Rosenblum - The design and implementation of a log-structured file system (SOSP ‘91)\nDennis M. Ritchie - The Evolution of the Unix Time-sharing System\n\n용어들 §\n\nExternal Fragment\nInternal Fragment\n\nFile System §\n\nSlack Space Recycling, SSR\n"},"botanicals/os/draft/Log-structured-File-System,-LFS-(File-System)":{"title":"Log-structured File System, LFS (File System)","links":[],"tags":["용어집","os"],"content":"\n\n                  \n                  본 글은 #draft 상태입니다. \n                  \n                  \n                \n                \n\n 내용 정리\n\n"},"botanicals/os/draft/Virtual-Memory-(OS)":{"title":"Virtual Memory (OS)","links":[],"tags":["용어집","memory"],"content":"\n\n                  \n                  본 글은 #draft 상태입니다. \n                  \n                  \n                \n                \n\n 내용 정리\n\n"},"botanicals/os/fs/Slack-Space-Recycling,-SSR-(File-System)":{"title":"Slack Space Recycling, SSR (File System)","links":["botanicals/os/draft/Log-structured-File-System,-LFS-(File-System)","botanicals/storage/terms/Garbage-Collection,-GC-(Storage)"],"tags":["용어집","storage"],"content":"\n\n                  \n                  참고한 문서 \n                  \n                \n\n성균관대 논문\n\n\n이게 뭐지 §\n\n이것은 LFS 의 GC 오버헤드를 줄이기 위해 등장한 것으로, free space 가 부족할 때 GC 를 하지 않고 LFS 의 dirty segment 에 기록해 GC 를 지연시키는 방법이다.\n하지만 이것을 계속 사용하면 작은 크기의 free space 가 많아져서 random write 가 필요해 지는 문제가 있다고 한다 1.\n\nFootnotes §\n\n\n논문에서는 그렇다고 하는데, 왜 그런지는 모르겠다. 더 찾아보면 이해되겠지만 일단 지금은 패스 ↩\n\n\n"},"botanicals/os/papers/논문---A-Fast-File-System-for-UNIX":{"title":"논문 - A Fast File System for UNIX","links":["botanicals/storage/terms/Superblock-(Storage)","originals/os.bahn.ewha.kocw.net/10.-File-Systems","originals/os.bahn.ewha.kocw.net/08-2.-Physical-Memory-Allocation"],"tags":["os","snu_cse_ms_aos24s","논문"],"content":"\n\n                  \n                  본 글은 Marshall K. McKusick 의 논문 A Fast File System for UNIX (ACM TOCS &#039;84) 를 읽고 정리한 글입니다.\n                  \n                \n\n\n\n                  \n                  별도의 명시가 없는 한, 본 글의 모든 그림은 위 논문에서 가져왔습니다. \n                  \n                \n\n\n\n                  \n                  본 문서는 아직 Draft 상태입니다. 읽을 때 주의해 주세요. \n                  \n                \n\nAbstract - 개요 §\n\n기존의 UNIX 파일시스템을 더 개선시킨 “Fast File System - FFS” 에 대한 내용이다.\n\n데이터 지역성을 살려 접근 가능\n많은 주변기기들과 CPU 들에 적용될 수 있음\n\n\n이건 대략 이런 식으로 가능하다고 한다:\n\n순차적으로 접근되는 데이터들을 모으기\n큰 파일들을 빠르게 접근하는 것과 작은 파일을의 fragmentation 을 줄어주는 두 토끼를 모두 잡기 위한 두 종류의 block size\n\n\n\n1. Introduction §\n\n이 논문에는 기존의 512-byte 파일 시스템에서 개선되어 BSD 4.2 에 포함된 파일시스템에 대해 다루고 있다.\n\nOutline §\n\n크게 outline 을 잡아보면,\n\nMotivation - 왜 기존의 파일시스템을 개선하게 되었는지\nMethod - 이러한 개선점들을 적용하는데에 사용된 방법들\nRationale - 어떤 이유에서 이렇게 디자인했는지\nImplementation - 새로운 구현에 대한 설명\nConclusion - 얻어진 결과들, future plan, 프로그래머들을 위해 추가적으로 변경된 점\n\n\n\nProblem Statement §\n\n기존의 PDP-11 에서의 파일 시스템\n\nI/O 는 커널레벨에서 버퍼가 되었고\n데이터 전송 순서에 딱히 정해진 규칙은 없었다\n모든 작업은 동기적으로 이루어 졌다 - 아마 I/O 작업이 끝나기 전까지 hang 걸리는?\n디스크에는 512-byte 블럭 크기로 저장되었고, FS 의 데이터 공간 임의의 공간에 저장 가능\n디스크 용량 이외에는 제약사항이 거의 없었다\n\n\nVAX-11 에서의 파일시스템\n\n512-byte FS 로는 application 이 원하는  throughput 을 제공해주기 힘들다\n가령, 많은 파일들에 대해 작은 작업을 하는 경우 FS 에서 throughput 을 받쳐줘야 한다.\nFS 에 있는 파일을 process 의 virtual memory 에 올려서 사용해햐 하는 경우에는 paging data I/O 가 빈번하게 발생하기 때문에 마찬가지로 throughput 이 받춰줘야 한다.\n하지만 기존의 UNIX 의 FS 에서는 디스크 최대 대역폭에 비해 2%밖에 성능을 못 내고 있으며 디스크 arm 당 20Kb/s 의 throughput 밖에 안나온다고 한다.\n\n\n\nImprovement §\n\n이러한 기존 FS 의 문제점을 해결하고자 개선을 했다고 한다.\n\nUNIX FS 의 인터페이스는 사용하기 편했고 그 자체로 성능 저하를 만들어내는 것이 아니었기에, 개선에서는 인터페이스 변경 없이 기저에 깔린 구현을 변경했다.\n즉, 사용자는 이 변경에 대해 추가적으로 대응할 필요가 없는 것\n\n\n\n2. Old File System §\nTraditional File System - Bell Labs 버전 §\n\n”Traditional File System” 은 처음에 Bell Labs 에서 고안한 버전을 일컫는다.\n하나의 디스크는 여려개의 partition 으로 나뉘고, 각각의 파이션에는 하나의 FS 를 가질 수 있다.\n\nFS 는 여려개의 파티션에 나뉘어 설치될 수는 없다\n\n\nFS 내에는 Superblock 이라는 공간이 있고, 여기에 FS 에 대한 parameter 들이 들어가게 된다: (이 superblock 은 이 Superblock 과는 다른것이다.. 아마?)\n\nFS 내의 data block 의 갯수\n최대 파일 갯수\nfree list 테이블을 가리키는 pointer\nFS 내의 free block 들을 연결지어놓은 linked list\n\n\nFS 내에는 파일들이 있는데, 어떤 파일은 디렉토리로 구분된다. 디렉토리는 다른 파일에 대한 포인터들을 저장하는 파일로, 이 “다른 파일” 에는 또 다른 디렉토리가 들어갈 수 있다.\n모든 파일은 해당 파일을 설명하는 자료구조인 inode 과 연관되어 있고, 여기에는 이러한 정보들이 저장된다:\n\n파일 소유자\n마지막 변경 시간\n마지막 접근 시간\n파일들의 데이터 블록들에 대한 포인터들을 저장하는 배열\nIndirect Block\n\n\n여기서 Indirect Block 은 파일들의 데이터 블록을 계층적으로 참조하기 위한 블럭이다.\n\n“파일들의 데이터 블록들에 대한 포인터들을 저장하는 배열” 에는 파일의 첫 8개의 블록들의 포인터만 저장되기 때문에, 이 공간을 다 사용하고 나면 추가적으로 포인터들을 저장할 공간이 필요하기 때문\nSingly indirect block 에는 128 개의 data block address 가 들어간다.\nDoubly indirect block 에는 128개의 Singly indirect block 이 들어간다.\nTriply indirect block 에는 128 개의 Doubly indirect block 이 들어간다.\n이것과 관련된 내용이 기억이 안난다면, 여기 에서 복습하도록 하자.\n\n\n150-megabyte UNIX file system 은 4Mb 의 inode 와 146Mb 의 데이터로 구성된다\n이것은 inode 와 data 를 분리하게 되는데 inode 를 들렀다가 data 에 방문해야 하기 때문에 seek time 이 많이 소모되었다.\n단일 디렉토리의 파일들에 대한 inode 들은 연속된 4MB inode 공간에 할당되지 않는다. 따라서 이 파일들에 대한 작업을 수행할 때는 각 inode 들을 계속 찾아 다녀야 한다.\n\n즉, 같은 디렉토리에 속한 파일들의 inode 는 4MB inode 공간 내에 sequential 하게 배치해 놓으면 그냥 순차적으로 쭉 읽으면 되기 때문에 훨씬 빠를 것이다. 하지만 Old file system 에서는 그렇게 하지 않아 성능 저하가 발생한다는 소리.\n\n\n데이터 블럭의 할당 또한 최적화와는 거리가 멀었다고 한다. 이전의 FS 에서는 disk 에게 한 transaction 당 512byte 이상의 데이터를 보내지 않았는데, 어떠한 경우에는 다음 data block 이 같은 cylinder 에 있지 않아 transaction 사이에 seek time 이 발생하게 된다고 한다.\n\nOld File System - Berkely 버전 §\n\nBerkely 에서 시도한 방법은 reliability 와 throughput 의 관점에서 개선이 있었다.\nFS 정보들은 staging 되어 reliability 를 보장하게 되었다; 즉, 해당 데이터는 정상적으로 변경되던지 아니면 문제가 생겼을 경우에는 완전히 revert 되게 된다.\n또한 block 의 사이즈를 512byte 에서 1024byte 로 두배 늘렸다.\n이렇게 하면 디스크가 한번에 가져올 수 있는 양이 두배로 늘게 되고, inode 에서도 direct data block 에 저장되는 양이 많기 때문에 indirect data block 에 접근하는 빈도도 낮아지게 된다.\n이것은 block 사이즈를 늘리는 것은 분명 throughput 을 늘리는데 도움이 된다는 것을 보여주긴 한다.\n\n이것의 문제점… §\n\n하지만 그럼에도 불구하고, throughput 은 디스크 최대 수치의 4% (기존 2%에서 두배가 된) 에 머물게 된다.\n이것은 다음과 같은 문제점 때문이다:\n\n디스크는 처음에는 free block list 가 sequential 하게 정렬되어 있지만, 파일들이 생성되고 삭제되는 과정이 반복되다 보면 free block 들이 랜덤한 곳에 위치하게 된다.\n이것은 결국에는 파일의 데이터가 랜덤 위치의 블럭들에 저장되는 결과를 초래하고, block 들에 접근할 때 마다 seek 을 하게 된다.\n수치적으로 보자면 디스크는 처음에는 175Kb/s 의 대역폭을 가지지만 시간이 지나다 보면 30Kb/s 까지 떨어진다.\n\n\n이것은 FS 전부를 리빌딩하지 않는 이상 원래의 속도로 되돌아오지 않는다.\n\n3. New File System Organization §\nSuperblock §\n\n새로운 버전에는 이전과 동일하게 파티션별 1개의 FS 가 설치되고, drive 가 여러개의 FS 를 가지게 된다.\n각 파티션의 처음에는 해당 파티션의 FS 를 설명하는 Superblock 이 동일하게 들어간다.\n이 Superblock 은 중요하기 때문에 여러개로 복사되지만, 이 내용이 변경되지는 않기 때문에 복원 작업이 아니라면 접근되지 않는다.\n\n4096 Byte-sized Block §\n\n위에서 언급한 Berkely 버전에서, block 사이즈를 늘리면 throughput 이 늘어난다는 것을 확인했다.\n2^32 byte 짜리 파일을 단 2단계의 indirect data block 으로 구성하기 위해서는, 블럭의 사이즈가 최소 4096 byte 가 되어야 한다.\n따라서 FS 의 블럭 사이즈는 4096 byte 보다 큰 2 의 제곱승 byte 가 된다.\n이 블럭 사이즈는 superblock 에 저장되기 때문에, 시스템에서는 블럭 사이즈에 구애받지 않고 FS 를 사용할 수 있다.\n하지만 이 값은 처음에 FS 를 구성할 때에만 설정할 수 있고, 이후에 임의로 변경하는 것은 안된다; 변경하기 위해서는 FS 전체를 리빌딩해야 한다.\nFS 의 block 사이즈를 (물론 FS 초기화시에) 변경할 수 있게 되었기에, 시스템에 여러 block 사이즈들이 공존할 수 있게 되었고, 따라서 최적화된 I/O size 를 application 에 제공해주기 위해 FS 인터페이스가 확장되었다고 한다.\n\n파일의 경우에는 최적의 I/O 단위는 당연히 block 사이즈 일 것이다. 또한 파일이 아닌 pipe 나 socket 의 경우에는 최적의 I/O 단위는 버퍼의 사이즈이다.\n이러한 것들은 stdio 라이브러리에서 사용되고, 이 라이브러리는 application 에서 사용된다.\n또한 stdio 라이브러리를 사용하지 않는 경우에도 마찬가지로 이러한 기능을 사용하기에 이런 인터페이스 확장이 필요했던 것.\n\n\n4096byte block system 을 이용했을 경우에는 512byte 나 1024byte 일 때보다는 당연히 동일한 파일에 대한 data block 의 개수는 줄어들기 때문에 이것을 추적하기 위한 data block pointer array, indirect data block array 사이즈는 줄어들게 된다.\n\n다만, free block 을 추적하기 위해 필요한 공간은 늘어나기 때문에 결국에는 이러한 공간 절감은 상쇄된다.\n\n\n\nCylinder Group §\n\nCylinder Group 은 하나 이상의 인접한 실린더로 구성된 단위이고, 하나의 partition 은 이 cylinder group 들로 구성된다.\n이런 그루핑을 하는 이유는 seek time 을 줄이기 위해서다.\n\n파일을 구성하는 block 들이 인접한 cylinder 에 있으면 seek 에 걸리는 시간이 적게 걸리기 때문\n또한 파일들을 삭제하고 생성하는 과정에서 block 들이 특정한 cylinder 에서만 이동하게 한다면, 모든 cylinder 에 흩뿌려지는 것에 비해서는 당연히 시간이 흘러도 성능 저하가 적게 나타나게 된다.\n\n\n\nBookkeeping Information §\n\n각 cylinder group 에는 Bookkeeping information 이 저장되어 있다\n\n여기에는 superblock 정보의 복사본,\ninode 를 위한 공간,\nfree block bit map,\ndata block 사용 현황 같은 요약 정보들이 들어간다\n\n\nFree block bit map 은 기존 FS 의 superblock 에 저장된 free list 를 대체한다.\n\n아마 list 가 아니라 bitmap 이기 때문에 free block 정보를 관리하는데에 있어 더 적은 공간과 더 빠른 속도를 보여줄 것.\n\n\n각 cylinder group 에는 일정한 개수의 inode 들이 저장될 수 있다고 한다.\n\n기본 정책으로는 cylinder group 의 크기를 2048 byte 로 나눈 갯수만큼 inode 를 저장할 수 있다고 한다.\n물론 위 내용은 주인장이 임의로 해석한 것이다; 원본에서는 Cylinder group 에서 2048 byte 마다 하나의 inode 를 할당한다고 되어 있는데, inode 는 각 파일마다 존재하는 것이고 한 개의 block 이 4096 byte 인 점 등을 감안하면 이게 뭔소린지 잘 감이 안오기 때문\n\n\nBookkeeping information 은 각 cylinder group 의 맨 앞에 둘 수도 있지만, 그렇게 하지 않는다.\n\nCylinder 는 단순히 platter 의 한 평면이 아니고 원통형이기 때문에, 이것을 cylinder group 의 시작점에 둔다면 모든 Bookkeeping information 이 disk 맨 위의 platter 에 모여있게 될 것이고, 만약 이 상태에서 맨 위 platter 에 fail 이 발생하게 되면 모든 cylinder group 의 bookkeeping information 이 날라가기 때문\n\n\n따라서 이 정보는 각 cylinder group 마다 다른 offset 을 가지고 시작점에서 떨어진 위치에 저장되게 된다.\n대략 이렇게 계산된다고 한다:\n\n이전 cylinder group 의 offset + 현재 cylinder group 의 track size = 현재 cylinder group 의 offset\n이렇게 하면 이 정보들이 나선형으로 아래로 쭉 내려가며 저장되어 어떤 한 track 이나 cylinder, platter 의 실패도 모든 Bookkeeping information 의 손상으로 이루어지지 않게 된다.\n\n\n첫번째 cylinder group 만 제외하면, cylinder group 의 시작점부터 bookkeeping information 의 시작점까지가 data 저장 공간으로 사용된다???\n\n아니 그럼 모든 cylinder group 은 앞부분에 data block 들이 있고 뒤에 bookkeeping info 가 있는 양분된 형태인건가??\n\n\n\nOptimizing Storage Utilization §\n\n자 이렇게 4096 byte 짜리 block 들을 인접한 cylinder 에 때려박아 아주 빠른 데이터 접근 속도를 구현해 냈다.\n근데 이 경우에는 당연히 Internal Fragmentation 이 문제가 된다.\n저자의 실험에 따르면, block 사이즈를 늘림에 따라 낭비되는 공간의 크기가 점점 늘어나는 것으로 나타났다:\n\n심지어 block size 를 4096 byte 로 했을 때에는 45.6% 나 되는 양이 낭비되었다고 한다.\n\n\n\n\nFragment §\n\n이것을 해결하기 위해, 하나의 block 을 2/4/8 개로 나눠 사용하는 기법인 Fragment 라는 것이 도입되었다.\n몇개의 fragment 들로 나눌 것인지는 FS 를 구성할 때 정하게 되고\nFragment 의 최소 사이즈는 최소 sector 사이즈와 같은 512byte 이다.\n\nBlock 사이즈, fragment 수준 모두 FS 구성시에 변경이 가능하기에 fragment 의 크기 또한 초기 설정이 가능하다는 것을 잊지 말자.\n\n\n각각의 fragment 는 주소가 있어서 해당 주소로 접근이 가능하다.\n여기서 언급한 block 에 대한 bitmap 도 block 레벨이 아닌 fragment 수준으로 free 여부를 나타내게 된다.\n\n따라서 block 가 free 한지를 알기 위해서는 당연히 그 아래 수준인 fragment 까지 모두 비어있는지 확인해야 한다.\n또한 연속된 free fragment 가 충분히 큰 사이즈로 있다고 하더라도, 이들이 여러개의 block 들에 걸쳐 있다면 하나의 block 처럼 사용할 수는 없다. (잘 이해가 안된다면 아래의 예시를 보자.)\n\n\n이 fragment bitmap 에 대해서는 맥커식씨 (저자) 가 친절히 제공해 준 아래의 예시를 보며 살펴보자.\n\n\n\n일단 위 상황은 4096 byte block, 1024 byte fragment (4분할) 설정에서 데이터가 저장된 fragment 를 X, 비어있는 fragment 를 O 로 나타낸 것이다.\n\n오해하지 말자: XXXX 가 Fragment 03 을 의미하는 뭐 특별한 코드 뭐 그런게 아니라, Fragment 03 의 현재 상태가 XXXX 라는 소리다.\n\n\n위의 bitmap 을 보고서 block 3 번만이 모든 fragment 가 비어있으므로 이 block 도 비어있다고 판단하게 된다.\n또한 block 1, 2 에 걸쳐 있는 fragment 6, 7, 8, 9 는 block 의 사이즈와 같은 4096byte 지만 이 공간을 하나의 block 으로 사용하지는 못한다.\n다만 여기서 알아야 할 것은 fragment 가 미리 잘려져있지는 않다는 것이다:\n\n파일은 block 단위로 저장하게 되고, block의 남는 부분은 그때 fragment 로 바뀌어 다른 파일이 저장될 수 있게 된다.\n\n\n이렇게 fragment 를 사용했을 경우에는 fragment 사이즈와 동일한 사이즈의 block 사이즈를 사용했을 때와 유사한 양의 내부 단편화가 발생한다는 것이 실험적으로 입증되었다.\n\n즉, 4096byte block + 1024byte fragment 를 이용할 경우 1024byte block 을 이용할 경우와 유사한 내부 단편화 비율을 보여준다는 것\n\n\n즉, block 의 크기를 늘려 throughput 을 늘리는 데에도 성공하고, fragment 기법을 이용해 내부 단편화 문제도 해결하게 된 것이다. (여기까지 읽었을때는 그런 줄 알았다. 그러나…)\n\nData Expansion §\n\nwrite syscall 을 호출할 때마다 시스템은 파일에 공간을 할당하게 된다.\n또한 이때마다 시스템은 파일의 크기가 커졌는지 확인하게 되는데, 켜졌을 경우 다음의 세 조건을 따지게 된다.\n\n\n(a) 기존의 파일에 하나의 block 혹은 fragment 만 할당되어 있고, (b) 커진 파일 또한 해당 block 혹은 fragment 에 다 들어갈 사이즈라면\n\n해당 block/fragment 의 남은 부분에 쓰여진다.\n\n\n(a) 기존의 파일에 여러개의 fragment 되지 않은 block 들이 할당되어 있고, (b) 마지막 block 의 남아있는 공간에 새로운 데이터가 다 들어가지 못한다면\n\n우선 마지막 block 의 남아있는 공간에 새로운 데이터 일부를 채워 해당 block 을 모두 채우고\n남아있는 새로운 데이터 사이즈가 block 크기보다 크다면 새로운 block 을 할당해 여기에 채워넣는다. 그리고 이것을 남은 사이즈가 block 크기보다 작아질 때 까지 반복한다.\n마지막으로 남은 사이즈가 하나의 블럭까지 필요하지 않고 몇개의 fragment 들로 처리 가능하다면, 필요한 개수의 fragment 들이 할당된다. 반면 하나의 block 을 전부 줘야 한다면, 하나의 block 이 할당된다.\n\n즉, 4분할 fragment 정책에서 fragment 2개에 전부 들어간다면 fragment 2개만 할당한다는 것이고, 남아있는 데이터의 크기가 3.8 fragment 라면 그냥 하나의 block 을 할당한다는 뜻.\n\n\n\n\n(a) 기존의 파일에 여러개의 fragment 들이 할당되어 있고, (b) 해당 fragment 들에 남은 공간이 부족하다면\n\ni) 추가된 데이터의 사이즈와 기존에 fragment 에 저장된 데이터의 사이즈를 합쳤을 때 full block 사이즈보다 크다면\n\n해당 fragment 들을 반환하고 이들을 합쳐 full block 에 할당한다.\n\n여기서 생각해보아야 할 점은 해당 fragment 들은 무조건 파일의 마지막 부분이라는 것이다. 파일의 중간 부분이 fragment 에 저장될 일은 없다.\n“해당 fragment 들을 반환하고 이들을 합쳐 full block 에 할당” 을 잘 생각해 보면 왜 그런지 알 수 있다: \bfull block 사이즈를 넘치기만 해도 full block 으로 합쳐지기 때문.\n\n\n그 이후에는 (2) 번 과정과 동일하게 흘러간다.\n\n\nii) 만일 full block 보다는 작다면, 필요한 fragment 혹은 block 이 할당되게 된다.\n\n\n\n\n위와 같은 방식이 아닌 file 사이즈를 fragment 단위로 키우는 것은 해당 fragment 가 full block 이 되었을 때 데이터를 복사하는 것에서 발생하는 오버헤드가 있고, 이러한 문제는 (파일 끝부분에서 생기는 불가피한 fragment 를 제외하면) fragment 단위가 아닌 block 단위로 저장하는 것으로 최소화 될 수 있다.\n\n고 한다. 솔직히 잘 이해 안된다.\n\n\n\nFree Space Reserve §\n\n위와 같은 정책들이 실제로 성능 향상을 보여주기 위해서는, 파일 시스템이 꽉 차있으면 안된다.\n\n만일 free block 의 개수가 0에 가까워진다면, throughput 은 절반으로 떨어진다고 한다.\n이것은 공간이 부족해 지역성을 살리기 어렵기 때문, 즉, 데이터를 인접한 block 들에 저장하지 못하기 때문이다.\n\n\n따라서 FS 에는 free block 의 개수를 일정 비율 이상으로 보장해주기 위한 Free Space Reserve 란 기능이 있다.\n\n이 수준 이하로 떨어지면, 시스템 관리자만이 block 들을 할당할 수 있게 된다.\n\n\n이 값은 언제든 변경할 수 있다. FS 를 마운트하여 사용하는 와중에도 변경하는 것이 가능하다.\n만일 free block 이 부족해져서 성능이 저하되면 충분한 free block 이 생길 때 까지 파일을 지워주면 해결된다.\n또한 free block 이 부족해진 상태에서 생성된 파일의 경우에는 (아마 block 들이 여러 군데에 흩어져 있을 것이므로?) 접근에 시간이 좀 걸리게 되는 문제가 있을 수 있는데 (원문: Access rate), 이는 free block 이 확보된 다음 파일을 옮겨주는 것으로 해결할 수 있다.\n저자는 이러한 Free Space Reserve 공간도 waste 공간에 포함시켜야 한다고 말한다:\n\n즉, 결국에는 이러한 reserve 공간도 system 입장에서는 사용하지 못하는 공간이기 때문에, 낭비되는 것이라 보는 것.\n따라서 여기 에 제시된 표를 참고하자면, 4096byte block + 512byte fragment 를 사용했을 경우에 대해 waste 비율은 다음과 같이 계산될 수 있다:\n\n내부 단편화 비율은 512byte block 과 유사한 6.9%\nFree block reserve 은 5% 로 가정\n도합 11.9%\n\n\n따라서 이것은 1024byte block 을 사용했을 때의 내부 단편화 비율인 11.8% 과 유사해진다.\n\n\n\nFile System Parameterization §\n\n기존의 FS 는 free list 를 생성할 때를 제외하면 하드웨어적인 요소를 고려하지 않는다.\n\n즉, 저장 매체의 물리적인 특성이나 그 매체를 컨트롤하기 위한 하드웨어들에 대한 정보를 고려하지 않는다 이마리야\n\n\n따라서 새로운 FS 에는 이러한 저장 매체와 이것을 위한 장치들의 특성을 수치적으로 parameterize 하여 block 들이 최적의 방식으로 할당될 수 있게 한다.\n이러한 parameter 들에는 다음과 같은 것이 있다고 한다:\n\n프로세서의 속도 (HDD 내의 프로세서가 아니고 메인 CPU 이다)\n대용량 정보 전송을 위한 하드웨어적 요소들 (IO Channel)\n저장 장치의 특성\n\n\nFS 에는 특성이 다른 여러 개의 디스크가 장착될 수 있기 때문에 성능 최적화를 위해 이러한 정보들을 수치화하여 활용하는 것은 어찌보면 당연한 셈이다.\n\nRotationally Optimal §\n\nPlatter 가 회전하며 head 에 의해 block 이 읽히는 과정에서, 이 block 들을 가장 최적의 방법으로 읽을 수 있도록 배치한 것을 Rotationally Optimal 이라고 한다.\n일단 당연히 파일의 연속된 block 두개가 같은 cylinder 에 있으면 좋을 것이다.\n하지만 이러한 block 들이 cylinder 내에서 물리적으로 인접한 block 에 저장되는 것이 좋을 것 같지만, 이것이 항상 좋은 것은 아니다.\n이 차이는 프로세서의 특성에 따라 인접한 block 을 원큐에 읽을 수 없는 경우가 있기 때문이다:\n\nIO Channel 을 가진 processor 의 경우에는 block transfer request 사이에 processor 가 개입할 필요가 없기에 인접한 두 block 을 원큐에 전송하는 것이 가능하고, 이것이 효율적이다.\n하지만 IO Channel 을 가지지 않은 processor 의 경우에는 이러한 request 들 사이에 processor 가 개입하게 되어 인접한 두 block 을 원큐에 전송하는 것이 불가능하다. 따라서 두 block 사이에 일정 간격을 두는 것이 오히려 효율적인 배치가 된다.\n\n\n2번 케이스에 대해 조금 더 자세히 살펴보자.\n\nIO Channel 이 없다면 Block 하나가 전송된 뒤에는 전송 완료 interrupt 가 걸리게 되고, 따라서 processor 에서 해당 interrupt 를 처리하며 다음 block 을 전송할 수 있도록 작업을 스케줄링한다.\n연이은 block 데이터 전송 사이에는 이러한 processor 개입때문에 시간이 약간 뜨게 되는데,\n이 시간 동안 disk 는 회전하고 있으므로 몇개의 block 들은 건너뛰게 되는 것.\n따라서 이 건너뛰게 되는 block 들을 고려하여 파일의 block 을 배치하면 processor 개입이 종료된 이후에 바로 다음 block 에 접근할 수 있게 된다.\n예를 들어 processor 개입 기간 동안 5개의 block 을 지나치고, 한 track 에는 100 개의 block 이 있다고 가정했을 때,\n\n만일 파일의 block 이 5개의 block 간격을 두고 배치되어 있다면 첫번때 block 을 읽은 뒤 processor 개입 동안 5 개의 block 을 지나치고 다음 block 을 읽을 수 있을 것이다.\n하지만 파일의 block 이 연달아 배치되어 있다면, 첫번째 block 을 읽은 뒤 5개의 block 을 지나치게 되어 다음 block 을 읽기 위해서는 95 개의 block (100-1-5+1) 을 지나 한바퀴를 돈 다음, 다음 block 을 읽어야 할 것이다.\n\n\n\n\n이러한 경우에 그럼 몇개의 block 간격을 두고 배치해야 될까. 즉, 몇개의 block 들을 processor 개입 기간동안 지나치게 될까.\n이를 계산하기 위해서는 processor 의 특성과 disk 의 특성을 모두 알아야 한다.\n\nProcessor 측면에서는, interrupt 를 걸고 새로운 작업을 scheduling 하는데 걸리는 시간을 알아야 한다.\nDisk 측면에서는, track 에 몇개의 block 이 있는지와 회전 속도를 알아야 한다.\n\n\n새로운 FS 에서 이러한 시간 간격은 parameterize 되어 설정 가능하다.\n\n만일 이것이 잘못 설정된다면, 파일들의 block 들이 예상한 위치에 있지 않기 때문에 당연히 성능 저하가 나타날 것이다.\n따라서 현재의 시스템에 맞는 값으로 설정이 되어야 할 것이고,\n만일 디스크를 다른 시스템으로 옮긴다면, 해당 시스템에 맞는 값으로 조정해줘야 할 필요가 있을 것이다.\n\n만일 옮기려고 하는 시스템에 대한 정보가 없어도 옮긴 후에 조정해 주면, 조정한 이후에 배치된 block 들에 대해서는 최적화된 방식으로 작동할 수 있을 것이라 함.\n\n\n\n\n\nRotational Layout Table §\n\n이것을 위해 Superblock 내의 cylinder group summary information 에는 Rotational Layout Table 이 존재한다.\n여기에는 Rotational Position 별로 그 안의 data block 들에 대한 mapping 이 되어 있어 해당 data block 의 free 여부를 알 수 있다.\n\nRotational Position 은 “Rotationally Optimal 한 block 들의 집합” 정도로 생각하면 될 것 같다.\n\n\n따라서 allocatable block 을 찾기 위해서는\n\nRotational position 에 대한 summary (해당 rotational position 에 free block 이 몇개 있는지 나와 있음) 를 보며 rotational block 을 하나 정한다.\n그 다음 해당 rotational position 에 대한 rotational layout table 의 entry 를 찾아 그 안의 data block mapping 을 보며 free block 을 찾는 방식으로 진행된다.\n\n\n\nLayout Policies §\n\nLayout Policy 는 두 종류가 존재한다.\n끝까지 읽어봤을 때 Global Policy Routine 는 대략 cylinder group 을 선택하는 것이 목적이고, Local Allocation Routine 은 cylinder group 내에서 block 을 할당하는 것이 목적인 것 처럼 보였다.\n\nGlobal Policy Routine §\n\nGlobal Policy Routine 은 cylinder group 을 야무지게 선택해 locality of reference 를 늘리고 seek time 을 줄이는 것이 목적이다.\n이놈은 FS 전체에 대한 summary information 을 이용해서 새로운 디렉토리와 파일들의 inode 와 data block 을 어디에 할당할 지 결정한다.\n또한 rotationally optimal block layout 을 계산하여 언제 cylinder group 을 변경해 긴 seek time 을 감수할 것인지 결정한다.\n\ncylinder group 의 용량이 부족해 지면, 어쩔 수 없이 cylinder group 을 변경해야 할 필요가 있기 때문\n뭐라는겨\n\n\n연관이 있는 데이터는 유사한 cylinder group 에 배치되어야 하고, 연관성이 없는 데이터는 다른 cylinder group 에 배치되어야 한다.\n\n만일 localization 이 너무 심해지면, 즉, 연관성이 적은 데이터들이 유사한 cylinder group 에 모이게 되면, cylinder group 의 가용 공간이 줄어들 뿐 아니라 cylinder group 이 old file system 과 유사해 지게 된다.\n만일 spreading 이 너무 심해지면, 연관성이 있는 데이터들이 다른 cylinder group 에 흩뿌려지게 되고, 이것은 seek time 을 늘려 성능이 저하될 것이다.\n\n\n따라서 Global policy 는 이 두가지 사이에서 밸런스를 맞추며 성능이 향상되도록 한다.\n\nLocal Allocation Routine §\n\nGlobal routine 은 block 하나를 대충 골라 Local Allocation Routine 을 호출해 여기에 할당하라고 시킨다.\n여기서 대충 이라는 워딩에 집중할 필요가 있다:\n\nGlobal routine 입장에서 FS 전체에 대한 free block 정보를 정확하게 꿰고 있는 것은 쉽지 않기 때문에 (왜 쉽지 않은지는 설명 안해준다), 적당히 정확한 정보 (Heuristic) 을 가지고 block 을 고르게 되는 것.\n\n\n그럼 Local Allocation Routine 이 이것을 받아 실제 block 할당을 담당하게 된다.\n아래는 요청받은 block 이 free 하지 않은 경우 local routine 의 처리 과정이다:\n\n같은 cylinder group 내에서 rotationally closest 한 놈을 골라 할당한다.\n\n여기서 head switching time (platter 간 head 를 전환하는 시간?) 은 없다고 가정한다.\n아마 cylinder group 내에서는 platter 가 달라서 발생하는 접근 시간의 차이는 거의 없기 때문인듯\n하지만 그렇지 않은 경우에는 rotational layout table 을 구성하는 데에 있어 이것도 고려되어야 한다고 한다.\n\n\n만일 rotationally closest 한 놈이 없으면, 그냥 cylinder group 내에서 찾는다\n만일 cylinder group 이 완전히 차버려서 cylinder group 내에서는 free block 이 전혀 없다면, 현재의 cylinder group number 를 quadratic hash 하여 다른 cylinder group 을 정해 free block 을 찾는다\n\nQuadratic hash 는 이 글 을 참고하자\n이 방법을 사용하는 이유는 빠르기 때문이라고 한다\n\n만일 일정 free block 을 보존하도록 설정된 경우에는 이 (3) 번까지 오지도 않는다.\n(3) 까지 왔다는 것은 free block reserve 설정이 되어 있지 않아 많은 block 들이 랜덤하게 배치되어 있다는 소리이고, 따라서 이 경우에는 조금이라도 빠른게 장땡이다.\n\n\n\n\n만일 (3) 번으로도 찾지 못했다면, 모든 cylinder group 에서 free block 을 (마치 브루트포스 방법처럼) 찾는다.\n\n\n\nInode Allocation §\n\n같은 디렉토리 내에 위치하는 파일들의 inode 들은 함께 참조되는 경우가 많다\n\n뭐 ls 명령어 생각하면 맞는 말이긴 하다\n\n\n따라서 이러한 inode 들은 같은 cylinder group 에 위치하도록 한다\n하지만 디렉토리의 경우에는 다른 방식을 사용한다.\n디렉토리는 free inode 의 개수가 평균보다 많고, 디렉토리를 제일 적게 갖고 있는 cylinder group 에 배치된다\n\n아마 이것은 같은 디렉토리 내의 파일들은 모두 하나의 cylinder group 에 저장되기에 디렉토리를 배치할 때 free inode 가 많은 곳에 배치해야 앞으로 해당 디렉토리에 생성될 파일들에 대한 inode 를 감당하기 유리해서인듯\n\n\nCylinder group 내에서 inode 를 배치하는 것은 next-free 방법을 사용한다:\n\n즉, rotationally optimal 한 방법이 아닌 그냥 랜덤 배치를 한다는 소리임.\n이것은 하나의 cylinder group 에는 최대 2048 개 inode 만이 배치될 수 있기 때문에, 많아봐야 16 번의 disk read 면 cylinder group 에 있는 모든 inode 를 읽어올 수 있기 때문.\n“최대 2048개” 라는 것은 여기 에서 언급된 특성 때문이다.\n\n\n하지만 Old File System 의 경우에는 디렉토리의 파일들 inode 를 가져오는 데에 한번의 disk transfer 만 하면 된다\n\n그럼 New File System 이 더 안좋은거 아닌가?\n\n\n\nData Block Allocation §\n\n당연히 파일의 data block 은 같이 접근되는 경우가 많기 때문에, 얘들은 되도록이면 같은 cylinder group 안에서 rotationally optimal 하게 저장되도록 한다.\n하지만 이 경우 문제가 되는 것은 큰 파일의 경우이다:\n\n큰 파일이 하나의 cylinder group 에 들어가게 되면 cylinder group 의 가용 블럭을 아주 빠르게 소진해 버리기 때문\n이것은 해당 파일이 넘치는 것 뿐 아니라 다른 파일이 들어올 경우 넘치게 되는 것까지도 포함한다.\n\n\n어떤 Cylinder group 도 꽉 차지 않도록 관리하는 것이 이상적이다.\n이 문제를 해결하기 위해 파일의 크기가 48Kb 를 초과하면 다른 cylinder group 으로 넘겨버리는 방법을 사용한다.\n\n또한 다른 cylinder group 에 저장하다가도 저장한 양이 megabyte 단위가 되면 또 다른 cylinder group 을 선택하여 저장하게 된다.\n\n\n새로운 cylinder group 은 free block 개수가 평균보다 많은 cylinder group 중에서 고른다.\n넘친 이후에는 megabyte 단위로 다른 cylinder group 에 저장되기 때문에 megabyte 데이터는 긴 seek time을 가지게 된다. 하지만 이 긴 seek time 의 비용은 작다 (?)\n\n4. Performance §\n\n\n                  \n                  성능 좋겠지 뭐; 시간이 없어서 일단 패스.. \n                  \n                \n\n5. File System Functional Enhancements §\n\n지금까지 얘기한 것들은 FS 의 인터페이스를 바꾸지는 않았기에, 사용자 입장에서 FS 를 재구성해야 할 필요는 없었다.\n이 섹션에서는 (비록 FS 를 재구성해야 할 지라도) 인터페이스까지 변경을 해 더욱 성능을 향상시키는 방법에 대해 설명한다.\n\n5.1. Long File Names §\n\nFile name 은 임의의 길이를 가질 수 있다.\n디렉토리를 읽는 프로그램만이 이 개선에 영향을 받는다.\n새로운 FS 를 사용하지 않는 시스템과의 호환성을 위해, 몇개의 디렉토리 접근 routine 이 소개되었다.\n디렉토리는 chunk 라 불리는 512byte 단위에 저장된다.\n디스크에 단 한번의 작업으로 저장될 수 있게 하기 위해 이 사이즈로 결정됐다고 한다.\n이 chunk 는 가변 사이즈의 directory entry 들로 구성된다.\nDirectory entry 는 파일의 이름과 파일의 inode 를 연관짓는 정보로 구성된다\nDirectory entry 가 많아진다고 해서 chunk 사이즈보다 커질 수는 없다\nDirectory entry 는 세개의 고정 크기 필드로 시작한다\n\ninode 번호\nentry 의 크기\n파일 이름 크기\n\n\n그리고 나머지 부분은 가변 크기 필드로, 여기에 파일 이름이 들어간다.\n\n당연히 이 파일 이름의 크기는 고정 크기 필드에 명시된 파일 이름 크기와 동일해야 하고\n(C 언어 베이스이기 때문에?) null 문자로 end-of-string 이 명시되어 있으며\n이 가변크기 필드는 4byte 단위가 되도록 padding 이 들어가 있다\n현재 최대 파일 이름의 크기는 255 character 라고 한다.\n\n\n디렉토리의 공간은 여러개의 entry 로 구성되고, 그 각각은 entry 의 크기 필드에 명시된 만큼의 공간을 차지하고 있다.\n\n어떤 entry 들은  entry 의 크기 가 파일 이름 크기 와 고정 크기 필드의 크기의 합보다 큰 경우도 있으며\n이 entry 의 크기 들을 모두 더하면 정확히 디렉토리 chunk 의 크기가 된다고 한다.\n\n\nentry 가 삭제될 경우에는 해당 공간은 그 이전 entry 로 귀속된다고 한다.\n\n이것은 단순히 이전 entry 의 entry 의 크기 값을 삭제된 entry 의 크기 만큼 늘려주는 것으로 가능하다\n만일 그 이전 entry 가 없을 경우에는, 즉, 이 entry 가 유일한 entry 였다면, 해당 entry 의 inode 를 0으로 만들어 해당 공간이 사용되지 않고 있음을 명시한다.\n\n\n\n5.2. File Locking §\n\n\n                  \n                  Timeout... 시간이 없어서 이후로는 읽지 못했습니다. \n                  \n                \n"},"botanicals/os/papers/논문---F2FS---A-New-File-System-for-Flash-Storage":{"title":"논문 - F2FS - A New File System for Flash Storage","links":["botanicals/os/papers/논문---The-design-and-implementation-of-a-log-structured-file-system"],"tags":["논문","os","snu_cse_ms_aos24s"],"content":"\n\n                  \n                  본 논문은 F2FS: A New File System for Flash Storage (FAST &#039;15) 를 읽고 정리한 글입니다.\n                  \n                \n\n\n\n                  \n                  별도의 명시가 없는 한, 본 글의 모든 그림은 위 논문에서 가져왔습니다. \n                  \n                \n\n\n\n                  \n                  본 문서는 아직 Draft 상태입니다. 읽을 때 주의해 주세요. \n                  \n                \n\n1. Abstract, Introduction §\n요약 §\n\nF2FS 는 flash storage 에서 사용하기 위해 고안된 file system 이다.\nSequential write, append-only logging 을 이용한다.\n기존의 EXT4 file system 보다 더 나은 성능을 보여준다고 한다.\n\n배경 - Flash Media §\n\nFlash memory 는 erase-before-write 나 sequential write, P/E cycle 등의 특징이 있다.\n요즘은 여러개의 NAND flash chip 들을 controller 에 bus 로 연결해서 사용한다.\nController 펌웨어에는 FTL 이 들어있고, 여기에서 이런 Flash memory 의 특징들을 generic block interface 로 변환한다.\n\n기존의 문제점 §\n\n빈번한 random write 는 internal fragment 를 유발해 성능이 나빠지게 만든다.\n이러한 random write 는 실제 사용 환경에서 생각보다 자주 일어나고 특히 자원이 한정적인 모바일 환경에서 더 문제가 된다.\n실 환경을 테스트한 이전 연구에 따르면, 다음과 같은 결과가 나왔다고 한다.\n\nFacebook 앱의 경우 sequential write 에 비해 150% 더 많은 random write 를 수행한다고 한다.\n또한 전체 IO 의 80% 가 random write 였고, 70% 의 random write 가 fsync syscall 에 의해 수행된다는 것을 알았다.\n이런 fsync syscall 은 SQLite 에 의해 수행되는 경우가 많다고 한다.\n\n\n이런 random write 의 문제는 LFS 나 copy-on-write 를 사용하면 줄일 수 있다.\n\nBTRFS: copy-on-write 방식의 FS\nNILFS2: LFS 방식의 FS\n\n\n하지만 위와 같은 fs 들은 flash media 에 최적화되어 있지 않고, 따라서 다소 성능과 수명의 측면에서 비효율적이라고 한다.\n\nF2FS 란? §\n\nF2FS 는 위와 같은 문제점을 해결하기 위해, 기존의 LFS 를 flash media 에 최적화시켰다고 한다.\n또한 generic block interface 도 제공한다.\n\n디자인 고려사항 §\nFlash-friendly on-disk layout §\n\n섹션 2.1 내용\n데이터에 segment 단위로 block 을 할당해 zone 에 저장한다\ncleaning 은 section 단위로 수행한다\n이러한 단위들은 FTL 의 작업 단위에 맞춰서 불필요한 copy 과정을 줄인다.\n\nCost-effective index structure §\n\n섹션 2.2 내용\nLFS 에서는 data block 과 inode 의 index block 가 변경되었을 경우 새로운 공간에 write 한다.\n파일의 사이즈가 큰 경우, 파일 마지막 쯤의 data block 은 inode 상에서 여러 indirect block index 를 타고 내려가다가 마지막 direct block index 에 해당 data block 의 위치가 저장될 것이다.\n이때 이 파일이 수정될 경우를 inode block tree 에서 bottom-up 으로 살펴보자.\n\n일단 수정된 block 은 다른 장소에 write 될 것이다.\n그럼 이때 해당 block 의 direct index block 또한 수정하기 위해 다른 곳에 새로 write 할 것이고,\n해당 direct index block 의 indirect block 또한 수정하기 위해 다른곳에 새로 write 하는 작업이 반복될 것이다.\n\n\n따라서 많은 양의 write 가 수반되고, 이것을 wandering tree 문제라고 한다.\n이것을 막기 위해 F2FS 에서는 node address table 을 사용한다.\n\nMulti-head logging §\n\n섹션 2.4 내용\n여러개의 segment 를 사용해 하나의 segment 에만 sequential write 하는 것이 아닌 여러개에 하게 되는데\n여기서 예상되는 수정 빈도에 따라 data 와 metadata 를 다른 segment 에 저장해 hot-cold separation 을 수행한다.\n\nAdaptive Logging §\n\n섹션 2.6 내용\nF2FS 는 LFS 와 유사하게 random write 를 sequential write 로 변환하여 처리하는데\n이때의 단점은 sequential write 의 성능이 보장되기 위해서는 여유 공간이 필요하다는 것이다.\n따라서 F2FS 에서는 공간이 부족해 질 경우 성능 저하를 완화하기 위해 threaded logging 을 사용한다.\n즉, internal fragmentation 이 많은 dirty segment 의 free space 에 중간중간의 live block 을 건너뛰며 sequential write 하는 것.\n이렇게 함으로써 cleaning 에 소요되는 오버헤드를 공간이 부족한 상황에서 줄일 수 있다.\n\nfsync acceleration with roll-forward recovery §\n\n섹션 2.7 내용\nMetadata write 는 small synchronize write 로 수행되는데 이는 성능을 저하시키기에 metadata write 를 최소화하고 효율적인 roll-forward recovery mechanism 으로 복구할 수 있는 기능을 F2FS 에 추가했다고 한다.\n\n실험 방법 §\n\nF2FS 는 널리 사용되는 세 file system (EXT4 와 BTRFS, NILFS2) 와 비교하여 그의 성능을 측정했다.\n측정할 때는 mobile, server 두 부류로 나눠서 진행했다고 하며,\nServer 의 경우에는 SATA SSD 와 PCIe SSD 두 세부 부류로 또 나눠서 진행했다고 한다.\n\n2. Design and Implementation of F2FS §\n2.1. On-Disk Layout §\n단위: Segment, Section, Zone §\n\n일단 F2FS 의 모든 단위는 FTL 의 작업 단위에 맞게 설계되어 있다.\nSegment: Volume 공간 전체를 동일한 크기의 segment 로 나눈 것.\n\nSegment 는 F2FS 의 최소 관리 단위이다. 그리고 FS 초기화시에 레이아웃을 잡는 데에 사용된다.\n\n\nSection: Segment 가 모인 것\nZone: Section 이 모인 것\n\nLayout §\n\nF2FS 에서는 전체 volume 을 다음의 6개의 구역으로 구분한다:\n\n\nSuperblock (SB) §\n\n여기에는 storage partition format 시에 결정되는 (따라서 변경이 불가능한) partition information 이나 default parameter 들이 저장된다.\n\nCheckpoint (CP) §\n\n기본적으로는 LFS 의 Checkpoint region 과 유사한 기능을 한다.\n다음과 같은 것들이 저장된다:\n\nFile system 상태\nNAT, SIT 들에 대한 valid 를 나타내는 bitmap\n미아상태가 된 inode list\n현재 사용되고 있는 segment 들에 대한 summary entry\n\n\nCP 에는 두 checkpoint pack 이 저장된다.\n\nCheckpoint pack 에는 특정 시점에의 일관된 F2FS 상태가 저장되어 있고, crash recovery 에 사용된다.\n이 두 checkpoint pack 은 두 segment (0번과 1번) 에 각각 저장된다\n둘 중 하나의 checkpoint pack 에는 현재의 상태가 작성되고, 하나의 checkpoint pack 에는 이전 상태가 작성 완료된 상태로 보관된다.\n\n\n\nSegment Information Table (SIT) §\n\n이것은 기본적으로는 LFS 의 Segment Usage Table 과 유사한 역할을 한다.\n즉, Main Area 의 valid block 들에 대해 그의 개수와 bitmap 을 담고 있다.\n이러한 정보들은 Cleaning 에 사용되는 것\n\nNode Address Table (NAT) §\n\n기본적으로는 LFS 의 Inode map 과 유사하다.\n즉, inode number 를 이용해 해당 inode 가 저장된 위치를 찾을 수 있게 하는 역할이다.\n\nSegment Summary Area (SSA) §\n\n기본적으로는 LFS 의 Segment Summary Information 과 유사하다.\n즉, Main Area 의 block 들이 어느 inode 에 연결되어 있는지 (ownership) 을 매핑해 놓은 것\n이러한 정보 또한 Cleaning 에 사용된다.\n\nMain Area §\n\n여기에는 실제 데이터가 들어가는 공간으로, 4KB block 들로 구성되어 있다.\nBlock 에는 두가지 종류가 있다:\n\nNode block: 여기에는 inode 혹은 direct/indirect index 가 저장된다.\nData block: 여기에는 file 이나 directory 가 저장된다.\n\n\n하나의 section 에는 node block 과 data block 이 섞여있을 수 없다고 한다.\n\n파일을 찾는 여정 §\n\n/dir/file 을 찾는다고 해보자.\n\n\n/\n\n우선 NAT 를 이용해 / 에 대한 inode 를 찾고 1\n그 inode 에서 index block 을 따라가 내용물을 찾고\n해당 내용물에서 dir 에 대한 inode number 를 얻어낸다.\n\n\ndir\n\nNAT 와 dir 에 대한 inode number 로 inode 를 찾고\n그 inode 에서 index block 을 따라가 내용물을 찾은 뒤\n내용물에서 file 에 대한 inode number 를 얻어낸다.\n\n\nfile\n\nNAT 와 file 에 대한 inode number 로 inode 를 찾고\n그 inode 에서 index block 을 따라가 내용물을 찾으면 끝.\n\n\n\n2.2. File Structure §\nNode, Node ID, NAT §\n\nF2FS 에서는 Node 라는 것을 사용하는데, 이것을 LFS 와 비교하며 살펴보자.\nLFS 의 경우에는\n\nInode 에 direct block, indirect block 들의 포인터가 저장되고\nFile content 를 찾을 때에는 (1) Inode map 와 inode number 로 inode 를 찾고, (2) 여기 저장되어 있는 포인터로 data block 들을 찾아가는 방식을 사용한다.\n\n\n하지만 이 방식은 Wandering tree 문제가 있다.\n\nInode, indirect block 들은 block 단위로 log 에 저장되는데\nInode - indirect block - data block 이 모두 포인터로 연결되어 있어\nData block 이 변경되어 새로 append 되면 주소가 바뀌니까 indirect block 또한 변경되어야 하고,\n이것은 또 indirect block 이 append 되어 주소가 바뀌기에 이것에 영향받는 또 다른 indirect block 이나 inode 가 append 되어야 하기 때문에\n결국에는 data block 의 변경이 연관된 모든 block 을 변경을 야기하는 “Propagation” 이 일어나게 된다.\n\n\n따라서 F2FS 에서는 이것을 Node 라는 것을 도입해 해결한다.\n\n\n\n일단 문제가 되는 것이 block 들을 포인터로 연결해 놓는 것이기 때문에 포인터를 줄이고 그 대신 Node ID 와 NAT 을 이용한다.\n우선 Node 는 (1) Inode 뿐 아니라 (2) Indirect block, 그리고 (3) indirect block 의 자식으로 data block 의 포인터를 저장하는 direct block 까지를 전부 Node 라고 부른다.\n그리고 각각의 Node 에는 Node ID 가 부여되어 있고, 이 Node ID - Node addr 변환을 NAT 가 해주는 것.\n즉, Node 간의 연결을 pointer 로 바로 하기 보다는 한단게 추상화 시켜서 ID 로 연결되게 하고, 실제 주소는 NAT 로 알 수 있게 해서\nData block 가 update 되어 주소가 변경되었을 때 그에 영향받는 Node 를 전부 update 하는 것이 아닌 Direct node 와 NAT 만 update 하는 방법으로 wandering problem 을 해결한 것.\n연결방식을 정리해 보면 다음과 같다.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSRCDEST.CONNInode (direct pointer field)Data blockPonterInode (single-indirect field)Direct nodeNode ID + NATInode (double, triple-indirect field)Indirect nodeNode ID + NATDirect nodeData blockPointerIndirect nodeDirect nodeNode ID + NAT\n\n이때 변경 과정을 비교해 보자.\n\n아래의 과정은 sequential write 의 관점에서 봤을 때이다; inode map, NAT 등의 random write 는 카운트하지 않았다.\n\n\n파일의 크기가 8MB 에서 4GB 일 때, Inode 의 Single indirect field 가 사용되고, 이때 data block 이 변경되면\n\nLFS 의 경우에는 direct block -&gt; inode block 순서로 총 두개가 변경되고\nF2FS 의 경우에는 direct node 하나만 변경되면 된다.\n\n\n파일의 크기가 4GB 를 넘어가면, Inode 의 Double indirect field 가 사용되고, 이때 data block 이 변경되면\n\nLFS 의 경우에는 direct block -&gt; indirect block -&gt; inode block 순서로 총 세개가 변경되고\nF2FS 의 경우에는 마찬가지로 direct node 하나만 변경하면 된다.\n\n\n\n전체 파일 구조 §\n\n위 그림에서 보이듯이, inode 에는 다음과 같은 field 가 있다.\n\nMetadata: 뭐 파일 권한 등의 메타데이터가 저장되어 있는 공간이다.\nDirect pointers: 10개까지의 data block pointer 를 저장하는 공간이다.\nSingle-indirect: Direct node 를 한번 거쳐 data block 을 연결하는 공간이다. 여기에는 두개의 direct node ID 를 저장할 수 있다.\nDouble-indirect: Indirect node + direct node 총 두번을 거쳐 data block 을 연결하는 공간이다. 여기에는 두개의 indirect node ID 를 저장할 수 있다.\nTriple-indirect: Indirect node + indirect node + direct node 총 세번을 거쳐 data block 을 연결하는 공간이다. 여기에는 한개의 indirect node ID 를 저장할 수 있다.\n\n\n그리고 Inline 어쩌고 하는 field 가 있는데\n\nInline data:\n\nDirect pointer 에 data block 의 pointer 를 저장할 수도 있지만,\n파일 사이즈가 작다면 pointer 로 연결하지 않고 이 공간에 data 를 직접 넣을 수도 있다.\n파일 사이즈가 3692 byte 보다 작으면 이곳에 넣을 수 있다.\n\n\ninline xattrs (inline extended attributes):\n\n추가적인 임의의 attribute 2 들을 저장할 수 있는 곳이라고 한다.\nAttribute 사이즈가 200 byte 보다 작으면 이곳에 넣을 수 있다.\n\n\n\n\n\n2.3. Directory Structure §\n\n\n                  \n                  #draft 이 섹션은 추후에 다시 정리될 예정입니다. \n                  \n                \n\n\n하나의 directory file 은 여러 4KB 짜리 directory entry (dentry) 로 구성되어 있고\n여기에는 bitmap 과 slot-name pair 를 저장하는 두 array 로 구성되어 있다.\n이 bitmap 어떤 slot 에 대해 유효한지 아닌지 나타내게 되고\nslot 에는 hash, inode number, file name length, file type 이 들어간다.\ndirectory 파일은 multi-level hash table 을 이용해 이 dentry 들을 관리한다.\nF2FS 에서는 directory file 에서 file name 에 해당하는 dentry 를 찾을 때\n우선 file name 을 hash 해\ndirectory inode 안에 있는 hash table 을 level 0 부터 max level 까지 돌아다니며 찾는다.\n각 level 에서는 2개에서 4개까지의 dentry block 으로 구성된 bucket 하나를 스캔한다\nN 이 dentry 의 개수라고 할 때 O(log(N)) 의 시간이 걸린다고 한다.\ndentry 를 더 빨리 찾기 위해 bitmap, hash 값, file name 순서대로 찾는다고 한다.\nServer 와 같은 dentry 가 많이 필요한 환경에서는 dentry 를 위한 공간을 더 많이 잡아놓을 수 있다\nhash table 의 low level (level 0 에 가까운) 의 사이즈가 커지면 dentry 에 더 빨리 도달할 수 있다.\n\n2.4. Multi-head Logging §\nHot-warm-cold separation §\n\nLFS 에서는 하나의 큰 log area 만 사용했다면,\nF2FS 에서는 기본적으로 6개의 log area 를 지원하고, 데이터의 접근 빈도 (hot-cold) 에 따라 다른 log area 에 저장한다.\nF2FS 에서는 node 와 data 에 따라 다르게 접근 빈도를 hot, warm, cold 세 단계로 구분한다.\n\n\n\n우선 node 부터 보면\n\nDirect node 가 cold 가 아닌 이유는 NAT 를 사용한다 하더라도 data block 이 변경되었을 때 무조건 변경되기 때문이다.\n\n그 중에서도 directory 는 더욱 변경이 빈번하기 때문에 hot 으로,\n일반 파일은 상대적으로 덜 빈번하기 때문에 warm 으로 분류되는 것.\n\n\n그리고 indirect node 는 direct node 가 추가되거나 삭제되는 경우가 아니면 변경되지 않기에 cold 로 분류한다.\n\n\nData 의 경우에는,\n\n위에서도 말한 것처럼 directory 는 변경이 잦기 때문에 dentry block 은 hot 으로 분류,\n일반 사용자의 파일은 변경이 상대적으로 덜하므로 warm 으로 분류,\ncleaning 에서 살아남거나, 사용자에 의해 cold 라고 명시되거나 이미지나 비디오 같은 애들 (얘네는 확장자로 식별) 은 거의 안바뀌므로 cold 로 분류한다.\n\n\nLog area 는 기본적으로 6개가 구성되는데, 여기에 node 와 data 의 hot, warm, cold 이 각각 저장된다.\n이것은 4개나 2개로도 조정 가능한데,\n\n4개일 때는 warm 과 cold 를 구분하지 않고 저장하고 (node-hot, node-warm-cold, data-hot, data-warm-cold)\n2개일 때는 node 와 data 만 구분해서 저장한다.\n\n\n\nFTL Compatibility §\n\n\n                  \n                  #draft 이 섹션은 추후에 다시 정리될 예정입니다. \n                  \n                \n\n\nFTL 을 고려하지 않고 위와 같은 hot-warm-cold 구분을 해버리면 추후에 GC 가 발생해 이것이 다 섞여버릴 수 있기 때문에 F2FS 에서는 FTL 과 호환되도록 zone 을 구성한다.\nFTL 은 크게 다음과 같은 알고리즘을 사용한다.\n\nblock associative: 하나의 data flash block\nset associative: 연속된 여러개의 data flash block\nfully associative: 모든 data flash block\n\n\n최근의 FTL 들은 random write 를 처리하기 위해 fully associative 혹은 set associative 를 사용한다.\n그리고 FTL 의 GC 가 다른 log area 의 내용을 섞어버리는 것을 방지하기 위해, log 를 다른 zone 에 저장한다.\n이 방식은 set associative FTL 에 더 효과적이라고 한다.\n\n2.5. Cleaning §\n\nCleaning 은 section 단위로 흩뿌려져 있는 invalid block 들을 모아서 free 상태로 만들어 logging 이 가능한 segment 를 확보하는 작업이다.\ncleaning 은 storage 의 용량이 채워지고 나면 수행되기에, cleaning overhead 를 제한하는 것은 일관된 성능을 제공하는 것에 필수적이다.\n\n즉, 예측 가능한 성능을 제공할 수 있는 것.\n\n\nCleaning 은 두 가지로 구분될 수 있다.\n\nForeground cleaning: Free section 이 부족해졌을 때에만 수행\nBackground cleaning: 주기적으로 kernel thread 가 생성돼 수행\n\n\n\nVictim selection §\n\nCleaning 은 non-empty section 에서 cleaning 의 대상 (victim) segment 을 선정하는 것에서부터 시작한다.\n선정하는 방법은 LFS 에서의 greedy 와 cost-benefit 방식을 그대로 사용한다.\n각각의 방식을 언제 사용하는지는 정리해보면 다음과 같다.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPolicyCleaningGreedy PolicyForeground CleaningCost-benefit PolicyBackground Cleaning\nForeground Cleaning - Greedy §\n\nLFS 에서도 말했듯이, Greedy policy 는 util 이 낮은 순서대로 수행한다.\n\n이 방식의 장점은 valid block 이 적은 segment 를 선택하기에, copy 하는 오버헤드가 상대적으로 적다는 것이다.\n\n\n이 방식에서는 비교적 많은 segment 가 한번에 정리되기 때문에 application 레벨에서 느껴지는 latency 가 많이 줄어들기에 foreground 에서 수행한다고 한다.\n\n즉, Foreground cleaning 은 공간이 거의 다 찬 비상상황이기 때문에 free segment 를 빨리 마련해주기 위해 greedy 를 사용한다는 것.\n\n\nF2FS 에서는 5% 의 여유 공간을 구비해 놓아 cleaning 에서 사용될 수 있도록 한다.\n\nBackground Cleaning - Cost-benefit §\n\nBackground 에서는 age 도 고려되는 cost-benefit 을 이용한다\nSection age 는 SIT 에서 가져온 segment 마지막 변경 시간들을 평균내어 산출한다.\n이 방식이 일반 상황에서는 더 좋고, log area 내에서도 자연스럽게 hot-cold 를 나눌 수 있기에 사용하는듯.\n\nValid block identification and migration §\n\nSection 내의 valid block 식별하는 것은 SIT 내의 valid bitmap 과 SSA 의 block 참조 여부를 사용한다.\n\n우선 SIT 내에 segment 의 valid bitmap 을 사용해 valid block 을 식별해 내고,\n그 다음에는 SSA 를 참조해 해당 block 이 node 에서 참조되는지 검사한다 3.\n\n\nForeground 에서는 valid block 을 옮길 때 실제로 IO 작업을 하지는 않는다.\n\n대신 이들을 page cache 에 올려두고 dirty 로 마킹해둔다.\n이들은 page cache 에 있다가 추후에 kernel 에 의해 다시 storage 로 flush 될 것이다.\n\n이러한 방식은 lazy migration 라고 부르는데, IO 를 수행할 때의 오버헤드를 나중으로 미뤄 foreground cleaning 의 임팩트를 줄인다.\n또한 이러한 방식을 사용하면 page cache 의 small write 와 합쳐져 더 큰 단위로 IO 를 수행할 수 있게 해 성능 저하를 방지할 수 있다.\n\n\n\n\nBackground cleaning 은 foreground cleaning 이 수행될 때에는 수행되지 않는다.\n\nPost-cleaning §\n\n모든 valid block 이 옮겨지면 해당 section 은 free 가 되기 위한 이전 단계인 candidate (pre-free) 상태가 된다.\n이 상태의 section 은 checkpoint 가 생성된 이후에 free 로 바뀐다.\n이전에 생성된 checkpoint 는 여전히 이 공간을 참조하고 있기 때문에, checkpoint 이전에 free 로 바뀌면 이전의 checkpoint 에서는 참조하지 못하기 때문이다.\n\n2.6. Adaptive Logging §\n\nLFS 에서도 등장한 normal logging 과 threaded logging 두 방식을 F2FS 에서도 사용한다.\n가용 공간이 많을 때에는 normal logging 으로 작동하며, clean segment 에 random write 를 sequential write 로 변환하여 저장한다.\n하지만 가용 공간이 없을 때에는 cleaning overhead 가 점점 커지므로, 가용 공간이 특정 임계값보다 작아지게 되면 threaded logging 으로 전환된다.\n\n이 특정 임계값은 조정 가능하며, 기본으로는 전체 section 갯수의 5% 로 설정된다.\n\n\nThreaded logging 상황에서는, dirty segment 내의 invalid block (hole) 들에 logging 을 하게 된다.\n\n즉, logging 와중에 valid block 을 만나면 다음 invalid block 까지 뛰어넘은 다음에 계속 logging 되는 것.\n\n\n이 방식에서는 cleaning 가 필요하지는 않지만 중간중간 뛰어넘는 것 때문에 random write 가 발생하게 되어 normal write 에 비해 성능은 다소 떨어지게 된다.\n\n하지만 이때의 random write 는 그냥 일반적인 (LFS 계열이 아닌 FS 에서의) random write 에 비해서는 spatial locality 가 높다고 한다 4.\n\n\n\n2.7. Checkpointing and Recovery §\n\nLFS 에서와 유사하게, F2FS 도 Checkpoint 를 생성하여 crash recovery 에 사용하게 된다.\nCheckpoint 가 필요한 상황 5 (sync, umount 와 같은 syscall 이 불리거나 foreground cleaning 을 하는 등) 이 오면 다음과 같이 checkpoint 를 생성한다.\n\nFlush: Page cache 에 있던 dirty node 나 dentry block 들을 flush 한다.\nSuspend: 모든 writing (syscall 을 포함한) 을 보류한다.\nMetadata write: NAT, SIT, SSA 또한 storage 로 write 된다.\nCheckpointing: CP area 에 checkpoint pack 을 write 한다.\n\n\nCheckpoint pack 은 다음과 같은 정보를 담고 있다.\n\nHeader, footer: Checkpoint pack 앞뒤에는 header 와 footer 가 적힌다.\n\nCheckpoint pack 을 write 할 때, 우선 header 부터 적고, write 가 완료된 다음에는 footer 를 적게 되는데\n앞뒤로 적는 이유는 해당 checkpoint pack 가 write 완료되었는지 검증하기 위한 것이다.\n\n즉, footer 가 없다면 write 가 완료된 것이 아닌 것으로 판단해 recovery 에서 사용하지 않는다.\n\n\n그리고 여기에는 checkpoint version 이 들어가 최신의 checkpoint 인지 파악하는데 사용하게 된다.\n\n\nNAT, SIT bitmap: NAT 와 SIT 들 중 유효한 것을 표시하는 bitmap 이다.\n\nCheckpoint pack 생성 도중 NAT 혹은 SIT 가 변경되는 상황에 대응하기 위해 NAT 와 SIT 각각을 두개씩 사용한다 (NAT 두개, SIT 두개).\n그리고 그 두개 중에 어떤 것이 유효한지를 이 bitmap 으로 표시하게 되는데,\n만일 어떤 변경사항이 있으면 유효하지 않은 NAT 혹은 SIT 를 변경한 뒤, bitmap 을 바꿔 변경된 놈이 유효하다고 알려주게 된다.\n\n\nNAT, SIT journal: NAT 와 SIT 에서 최근에 변경된 entry 들을 적는다.\n\n만일 checkpoint pack 생성 도중 NAT 혹은 SIT 에서 적은 수의 entry 들이 빈번하게 변경된다면, 해당 entry 의 4KB block 이 빈번하게 변경될 것이다.\n이것은 checkpoint pack 생성과정을 느리게 할 것이기에, checkpoint pack 내에 마치 버퍼처럼 일정 갯수의 entry update 를 모아놓게 하여 지연을 방지한다 6.\n\n\nSummary blocks of active segments: 메모리에 적재되어 추후에 flush 될 것이었던 SSA 내용들이 적힌다.\nOrphan blocks: Orphan inode 들을 저장하는 공간이다.\n\nOrphan inode 는 inode 가 close 되기 전에 delete 되었을 때 생기게 된다.\n\n가령 두 process 가 동일한 파일을 열고 한 process 가 이것을 지우면 이렇게 된다고 한다.\n한 process 가 delete 하여 directory 에서 unlink 했을 때 나머지 한 process 말고는 이 파일에 link 한 process 나 directory 가 없다면 process 가 해당 파일을 close 한 다음에 진짜로 삭제해야 될 것이다.\n하지만 process 가 갑자기 죽어버린다면 이것이 남아있게 되기에 orphan inode 로 분류하고 recovery 시점에 날려버리는 것.\n\n\n\n\n\n\n\n\n\n                  \n                  NAT, SIT update \n                  \n                \n\n조심하자: Layout 을 참고하면 NAT 와 SIT 는 sequential write 가 아닌 random update 가 수행되는 것을 알 수 있다.\n\n\n\n완성된 checkpoint pack 를 적어도 하나는 갖고 있기 위해, checkpoint pack 은 두개를 유지한다.\n\n이렇게 해서 한 checkpoint pack 을 write 하고 있을 때 crash 가 나더라도 이전의 checkpoint pack 은 남아있기 때문에 해당 시점으로 돌아가는 것이 가능하기 때문.\n\n\n\n2.7.1. Roll-Back Recovery §\n\n갑작스러운 전원 종료 이후 F2FS 는 이 checkpoint 를 이용해 해당 시점으로 복구하게 된다.\nRecovery 하는 것은 다음처럼 진행된다.\n\n우선 두 checkpoint pack 중 유효하고 더 최신의 것을 고른다.\n\n위에서 말한 것처럼, 유효성은 header 와 footer 가 같은 version number 를 갖고 있는지 파악하는 것으로 가능하고\n최신의 것은 version number 가 더 높은 것으로 선택한다.\n\n\nOrphan inode block 이 있는지 없는지 확인하고, 있다면 처리한다.\n\nRecovery 시점에 ophan inode block 이 존재한다면, inode block 과 data block 을 전부 날려버린다.\n즉, 어디에서도 link 되어 있지 않지만 공간은 차지하고 있기 때문에 정리하는 것.\n\n\nRoll-forward 를 진행한다.\n최신의 NAT, SIT 상태로 FS 가 서비스되도록 한다.\n\n\n\n2.7.2. Roll-Forward Recovery §\n\n\n                  \n                  #draft 이 섹션은 추후에 다시 정리될 예정입니다. \n                  \n                \n\n\nSQLite 같은 db 는 주기적으로 fsync syscall 을 해 storage 에 영구적으로 반영한다.\n일반적인 fsync 과정은 checkpointing 을 수행해 fsync 시점을 완벽하게 언제든 복구 가능하게 하는 것이다.\n하지만 이것은 db 와 무관한 node 나 dentry block 을 전부 flush 하기에 아주 비효율적이다.\n따라서 F2FS 에서는 fsync 성능을 높이기 위한 효율적인 roll-forward recovery 를 사용하다.\n핵심 아이디어는 다음과 같다:\n\nfsync 를 했을 때 checkpointing 과정 전부를 수행하는 것 대신, data block 과 이것을 가리키는 direct node block 만 storage 에 write 하는 것이다.\n따라서 Checkpointing 에 수행되는 NAT, SIT, SSA 등은 write 하지 않기 때문에, fsync 에 소요되는 시간은 줄어들게 된다.\n\n\n하지만 이때 crash 가 나게 되면 storage 의 NAT 에는 이동된 direct node block 을 참조하지 않기 때문에 data block 을 찾을 수 없게 된다.\n이것을 방지하기 위해 이런 상황 (NAT 에는 반영되지 않은 direct node block 의 이동) 을 direct node block 에 플래그로 표시해 둔다.\nRoll forward 는 다음과 같은 방식으로 진행된다.\n\n만일 N 이 latest stable checkpoint pack 에 반영된 log 의 위치이고\nn 이 N 이후에 추가된 log (즉, latest stable checkpoint pack 에는 반영되지 않은 log) 라고 한다면,\n\n\nN ~ N + n 에 위치한 플래그가 표시된 direct node block 들을 전부 찾고\n해당 node 들의 정보도 전부 찾고\n그 정보들로 최근에 write 된 node block 들을 전부 page cache 로 올리고\nN + n 와 N-n 을 비교해 data indices\n둘이 다르다면 N+n 의 정보로 page cache 에 있는 N-n data indices 을 업데이트한다\nN+n 은 dirty 라고 마킹한다.\n완료된 다음에는 checkpointing 을 수행해 새로 checkpoint pack 생성되도록 한다.\n\n\n\nEvaluation §\n\n\n                  \n                  #draft 이 섹션은 추후에 작성될 예정입니다. \n                  \n                \n\n3.1. Experimental Setup §\n3.2. Results §\n3.2.1. Performance on the Mobile System §\n3.2.2 Performance on the Server System §\n3.2.3. Multi-head Logging Effect §\n3.2.4. Cleaning Cost §\n3.2.5. Adaptive Logging Performance §\n4. Related Work §\n4.1. Log-Structured File Systems §\n4.2. Flash Memory File Systems §\n4.3. FTL Optimizations §\n5. Concluding Remarks §\n\nFootnotes §\n\n\nRoot directory 에 대한 inode number 는 보통 정해져 있다. EXT4 의 경우에는 2 이다. ↩\n\n\n이게 뭔지는 잘 모르겠다. ↩\n\n\n아마 bitmap 에는 참조 여부와는 다른 정보를 담고 있는 것인지 아니면 더블체크 목적인지 모르겠다. ↩\n\n\n하나의 dirty segment 의 hole 들이 채워진 다음에 다른 dirty segment 를 찾기 때문이라고 한다. 잘 이해는 안된다. ↩\n\n\n주기적으로 checkpoint 를 생성하는지는 의문. ↩\n\n\n이렇게 하는 것이 진짜 checkpoint pack 생성과정을 빠르게 해주는 지 잘 모르겠다. 4KB block 단위로 작업하지 않기 때문인건가. ↩\n\n\n"},"botanicals/os/papers/논문---Hints-for-Computer-System-Design":{"title":"논문 - Hints for Computer System Design","links":["botanicals/os/papers/논문---Hints-for-Computer-System-Design","originals/os.bahn.ewha.kocw.net/06.-Process-Synchronize"],"tags":["os","논문","snu_cse_ms_aos24s"],"content":"\n\n                  \n                  본 글은 ACM SIGOPS 에 게재된 논문 &quot; Hints for Computer System Design&quot; 를 읽고 정리한 내용입니다. (한국어 번역본)\n                  \n                \n\n\n\n                  \n                  본 문서는 아직 Draft 상태입니다. 읽을 때 주의해 주세요. \n                  \n                \n\nAbstract §\n\n본 논문에는 저자(Butler W. Lampson) 가 여러 OS 들을 설계하고 구현하는 과정에서 얻은 노하우들을 정리해 놓았다고 한다.\n\n1. Introduction §\nOS 설계상의 어려움.. §\n\nOS 를 설계하는 데에는 이런 어려움이 있다\n\n외부 인터페이스 (External interface, 요구사항 정도로 생각하고 넘어가도 될 것 같다) 가 복잡하고 명확하지도 않고 자주 바뀔 여지가 있다\n내부 인터페이스 (Internal interface, 시스템 내부의 여러 컴포넌트들이 상호작용하기 위한 인터페이스) 가 아주 많다\n평가의 척도도 명확하지 않다\n굉장히 많은 파라미터가 있으며 어떤 선택이 어떤 영향을 미칠지 알 수가 없다\n\n\n그래서 최선의 방법은 없고 최악만 피하는 방법으로 가야 한다고 하네\n\n슬로건 §\n\n저자는 제시한 OS 설계의 모든 힌트들을 “슬로건” 의 형태로 요약했다고 한다.\n그리고 각 슬로건들을 도표 형태로 정리하면 다음과 같다\n\n\n\n가로축은 (해당 슬로건이) 시스템의 어떤 것을 좋게 하는지\n세로축은 시스템 디자인의 어느 부분에 도움이 되는지\n두 줄로 연결되어 있는 건 같은 슬로건\n한줄은 두 슬로건이 연관이 있음\n\n2. Functionality §\n\n당연하게도 시스템은 올바른 기능을 제공해야 하는데\n이것을 제공하는 힌트들을 상당 부분 interface 와 연관되어 있다\n\n당신이 아는 그 interface 맞다\n실제 implementation 과 구분돼서 두 프로그램이 상호작용하기 위한 창\n\n\nInterface 들은 assumption 들로 구성된다\n\n이들은 프로그램이 의도한대로 작동하는 것을 확인하기 위해 필요한 것? 뭐라노\n\n\n그리고 이 interface 들은 아래의 세 상충하는 요구사항을 만족시켜야 하기 때문에 설계하기 까다롭다\n\nsimple: interface 는 간단해야 한다\ncomplete: interface 는 구현된 모든 것을 제공해야 한다?\nsmall and fast implementation: 작게 구현되어야 한다 (약간 컴포넌트를 작게 나눠서 모듈화하는 것과 비슷한 맥락인듯)\n\n\nInterface 는 그 자체로 프로그래밍 언어와 유사한 면이 있다\n\n일련의 오브젝트들과 그들을 조작하는 작동들을 포함하기 때문\n이러한 면에서 Hoare 의 프로그래밍 언어 디자인 가이드 는 interface 디자인에 도움이 될거라고 하네\n\n\n이 섹션은 대략 아래와 같이 구성되어 있다\n\n2.1, 2.2, 2.3 은 Interface 에 대한 내용\n2.4 는 Implementation 에 대한 내용\n2.5 는 Completeness 에 대한 내용\n\n\n\n2.1. Keep it simple §\nDo one thing well, Don’t generalize §\n\n일단 나열부터 해보자고\nInterface 는 추상화의 최소한만 담아야 한다\n인터페이스에 너무나 많은 것이 담기면, 구현은 당연히 크고 복잡해진다\n인터페이스는 특정 양의 서비스만 제공하는 계약과 같다?\n인터페이스의 사용자는 해당 인터페이스가 제공하는 기능과 그 기능을 제공하는데 소요되는 자원에 의존하게 된다\n\n기능은 보통 문서화되지만\n자원은 보통 문서화되지 않는다\n\n\n인터페이스는 어떻게 구현할 지 확실하게 알지 못하는 것을 제공해서는 안되고\n혹은 소수의 사용자만이 사용하는 것을 제공하면 안된다\n\n다른 컴포넌트에 영향을 주지 않고도 구현할 수 있는 방법을 알고 있을지라도 나중에 해당 문제가 명확해질 때 (많은 사람들이 사용하게 될 때) 까지 미루는 것이 낫다고 한다.\n\n\n\n\nFor example, PL/1 got into serious trouble by attempting to provide consistent meanings for a large number of generic operations across a wide variety of data types. Early implementations tended to handle all the cases inefficiently, but even with the optimizing compilers of 15 years later, it is hard for the programmer to tell what will be fast and what will be slow (31). A language like Pascal or C is much easier to use, because every construct has a roughly constant cost that is independent of context or arguments, and in fact most constructs have about the same cost.\n\n\n이러한 관점(?) 은 자주 사용되는 기능들에 적용될 수 있고, 잘 사용되지 않는 기능은 기능을 위해서 성능을 어느정도 희생할 수 있다\n더 나은 구현을 위한 연구에는 이런 것들 (?) 이 적용되지 않을 수 있지만, 이 연구는 실패할 수도 있기에 여기에 의존하면 안된다\n\n\nThe Alto operating system (29) has an ordinary read/write-n-bytes interface to files, and was extended for Interlisp-D (7) with an ordinary paging system that stores each virtual page on a dedicated disk page. Both have small implementations (about 900 lines of code for files, 500 for paging) and are fast (a page fault takes one disk access and has a constant computing cost that is a small fraction of the disk access time, and the client Hints for Computer System Design July 1983 5 can fairly easily run the disk at full speed). The Pilot system (42) which succeeded the Alto OS follows Multics and several other systems in allowing virtual pages to be mapped to file pages, thus subsuming file input/output within the virtual memory system. The implementation is much larger (about 11,000 lines of code) and slower (it often incurs two disk accesses to handle a page fault and cannot run the disk at full speed).\n\n\n이러한 인터페이스를 구현하는 것이 불가능한 것은 아니지만, 일반적으로 아주 힘들다.\n위에서 제시된 예시 또한 아주 특출난 사람들이 구현했지만 실패했고, 이것을 해결하는 여러 방법이 알려져 있지만 보통 많은 자원을 필요로 하고 복잡하다고 한다…\n\nTenex system 예시 - unassigned page reference 를 주는 syscall 이 있는데, 이를 이용해서 디렉토리의 비밀번호를 적은 시도횟수로 알아낼 수 있고, interface 가 복잡해서 이런 버그가 있는지 오랜 기간 동안 사람들이 몰랐다고 한다\n\n\n간결하고 강력한 인터페이스와 이것에 대한 빠른 성능을 제공하는 구현을 하기 위해 엄청난 양의 노력을 투입하는 것은 가치가 있다라고 생각하던 때가 있었으나, 이것은 해당 인터페이스가 중요하다는 것이 경험적으로 보장되고 빠른 성능을 제공하는 구현 방법을 이미 알 때에나 시도하는 것이 좋다라고 한다\n\nBitBit, RasterOP 예시 - 오랜 기간 동안 공들여서 구현했으나 이전에 구현된 것과 큰 성능차이가 없을 뿐 아니라 interface 의 generality 때문에 display application 의 개발에도 큰 (그리고 아마 그닥 좋지 않은) 변화를 만들어 냈다고 한다\nDorado memory system 예시 - 디자인에 아주 오랜 기간이 걸려서 빠른 IO 를 위한 캐시와 고대역폭의 버스를 제공하는 인터페이스를 고안, 구현했으나 (아마 캐시가 아닌) 메모리 접근이 주된 성능 저하였다는 것, 그리고 고대역폭의 IO 가 생각보다 소모하는 자원에 비해 비효율적이라는 지식만을 남겼다\n\n\n\nGet it right §\n\nAbstraction 이나 Simplicity 가 “정상적으로 작동함” 을 보장하지는 않는다 - 오히러 이들이 심각한 문제를 초래할 수 있다\n\nWord processing 예시…\n\n\n\n2.2. Corollaries §\nMake it fast §\n\n모든 기능을 제공하는 느리지만 강력한 한가지보다는 하나의 기능만 제공하는 빠른 한가지가 훨씬 낫다\n\n하나만 하는 빠른 것을 만들어 놓으면 client 들이 이것을 사용하며 다양한 기능들을 구현할 수 있다\n이런 식으로 모든 기능을 커버칠 수 있는 것\n또한 모든 기능을 제공하는 놈을 만들어 놓게 되면 한가지 기능만을 원하는 client 가 그것을 느리게 사용할 수 밖에 없다\n\n\n가령, 느리지만 강력한 instruction set 을 제공하는 VAX 같은 머신보다 단순한 작업을 빠르게 해내는 instruction set 을 제공하는 801 이나 RISC 가 실제로도 더 빠르게 작동한다고 한다\n코드 실행 중 어느 부분에서 느리게 작동하는지 분석하는 툴이 있으면 좋다고 한다..\n\n\nTo find the places where time is being spent in a large system, it is necessary to have measurement tools that will pinpoint the time-consuming code. Few systems are well enough understood to be properly tuned without such tools; it is normal for 80% of the time to be spent in 20% of the code, but a priori analysis or intuition usually can’t find the 20% with any certainty. The performance tuning of Interlisp-D sped it up by a factor of 10 using one set of effective tools (7).\n\nDon’t hide power §\n\n적게 추상화를 해서 빠르게 작동할 수 있는 무언가를 만들었다면, 그것을 많이 추상화하고자 할 때에는 숨겨놓지 마라\n추상화는 공개하기에 바람직하지 못한 것을 숨기기 위한 것이지 공개해야 마땅한 것을 숨기기 위한 것이 아니다\n다만 추상화라는 것은 “통합” 의 개념이 있기 때문에 어느정도의 성능 감소가 있을 수는 있지만 성능 감소를 최소화 하면서 단일의 client 에게 제공하는 것은 거의 대부분 가능하다\nAlto disk hardware 예시 - 강력한 기능에 대한 높은 추상화를 적은 손실만을 보며 제공한 사례\n대충 적은 추상화가 제공하는 강력한 기능을 높은 추상화에서도 충분히 사용할 수 있도록 인터페이스를 짜라… 라는 의미인 것 같은데\n\nUse procedure arguments §\n\n약간 함수형 프로그래밍의 느낌 생각하면 된다\nfilter 함수에 인자로 함수를 전달해서 인자 함수의 결과값에 따라 배열 원소를 필터링 하는 것 처럼\nInterface 가 Procedure 를 인자로 받도록 하면 인터페이스를 유연하게 설계할 수 있다\n\nBerkeley spy system monitoring 예시 - 몰?루\nFRETURN 예시 - 일반적인 경우에는 C 로 작동하다가 문제가 생겼을 경우 failure handler 로 넘기는 CF operation 을 사용해 C 의 빠른 성능과 Failure handler 의 유연성을 모두 챙긴.. 뭐라노\n\n\n\nLeave it to the client §\n\n한가지 작업만 하고 나머지는 client 에 맡기는 것이 simplicity, flexibility, high-performance 모두를 챙길 수 있다고 한다\n\n가령 많은 (프로그래밍 언어에서의) 파서의 경우 문맥에 구애받지 않는 파싱을 제공해주고 client 쪽에서 파싱의 결과를 저장도록 해서 client 가 생성된 파스 트리를 확인할 수 있도록 한다고 한다더라\n동시성을 위한 Monitor 기능 또한 이러한 방법으로 구현되어 있다 - Lock 을 걸고 Signal 을 보내 푸는 단순한 작동만을 제공해주고 나머지는 Client program 에서 처리하도록 하여 간편하고 빠른 구현체를 제공할 수 있게 한다\nUNIX 에서도 한개 이상의 문자열을 받아 한개 이상의 문자열을 반환하는 단 한가지의 일을 하는 작은 프로그램을 짜도록 권고한다. 결국에는 client 가 이들을 모아 원하는 방식대로 빠르게 작동하는 구현체를 만들게 될 것이다\n\n\n\n2.3. Continuity §\n\n디자인을 개선하는 것과 안정성있게 작동하는 것 사이에는 trade-off 가 있다:\n\n디자인을 개선하는 것은 안정적으로 작동하는 기능의 안정성을 깰 가능성이 충분히 있기 때문\n\n\n\nKeep basic interfaces stable §\n\n인터페이스라는 것은 많은 외부 컴포넌트들과 연관되어 있기 때문에 인터페이스를 바꾸는 것은 정말 큰 문제를 초래할 수 있다\n더군다나 타입체크가 없는 프로그래밍 언어를 사용할 때에는 client 입장에서 인터페이스가 변경되었다는 것을 알기 정말 어렵기 때문에 권고되지 않는다\nMesa 같은 빡센 타입체킹이 들어가 있는 프로그래밍 언어를 사용하면 인터페이스 변경을 감지하는 것이 한층 편하지만 그럼에도 불구하고 assumption 을 맞춰야 됨에는 변화가 없다\n또한 25만 줄에 달하는 코드로 이루어진 시스템의 경우에는 변경에 시간이 너무 오래 걸려 바꾸지 못하기도 한다\n\nKeep a place to stand §\n\n서있을 수 있는 장소를 냅둬라… 인터페이스를 변경하고자 한다면 이전 인터페이스도 기능을 하게 하라는 뜻인 것 같다\nCompatibility package - Backward compatibility 를 위해서 새 인터페이스와 기존의 인터페이스를 모두 냅두고 구현을 새로 하는 방법으로 생각하면 될 것 같다\n\nTenex 나 Cal 운영체제에서 이전 버전 호환성을 위해 simulator 를 구현하거나\nIBM 360/370 운영체제에서 emulator 를 구현하거나\nVM 으로 이런 비슷한 기능을 제공하는 등\n\n\nWorld-swap debugger - HDD 같은 secondary storage 에다가 타겟 시스템의 physical memory 전부를 덤프해놓고 그 위에서 디버거를 작동 + address mapping 을 해서 사용자가 직접 접근할 수 있게 하는 방법 (인 것 같다)\n\n옛 시스템을 아주 저수준에서 손쉽게 디버깅해 볼 수 있다는 장점?\n\n\n\n2.4. Making implementations work §\nPlan to throw one away §\n\n어떤 새로운 것이 있어서 이것을 추가로 구현하려면, 정상적으로 작동시키기 위해 이전에 구현할 때 했던 작업을 또 해야 할 수도 있는데, 이것은 프로토타입을 활용할 계획을 세우면 훨씬 수월할 수 있다\n그리고 이전에 구현된 것들을 최대한 활용하면 좋다?\n아니 뭔가 말이 이상한데\n\nKeep secrets §\n\nSecret 이란 건 Client program 이 생성해서는 안될 assumption 이다\n그리고 따라서, 이 정보는 언제든 바뀔 수 있는 값이다\n\n이건 인터페이스와는 다소 대조적임; 인터페이스는 (특별한 경우가 아니라면) 변경되어서는 안될 정보이다\n\n\nassumption 이 적으면 프로그램의 구현 혹은 변경이 용이하지만 여러 문제점이 있다\n\n시스템을 디자인하기가 어려워진다 - Don’t hide power 원칙을 적용해서 interface 에서 power 를 숨기지 않으면 그만큼 assumption 은 늘어나기 때문\n그리고 assumption 이 늘어나 코드 재사용성이 높아지면 성능도 더 빨라진다… 라고 말하고 싶어하는 듯\n\n\n\nDivide and conquer §\n\n너가 아는 그거 맞다 - 작은 문제로 나눠서 해결한 다음 합치는 것\n\nAlto 의 Scavenger program 예시 - fs 의 인덱스를 리빌딩할 때 인덱스 문제가 있는 파일을 binary search 처럼 찾아간다\nDover raster printer 예시 - 3300 * 4200 짜리 bit array 를 처리할 때 이것이 메모리에 전부 적재되지 않으므로 16 * 4200 짜리 버퍼 (band) 에 넣어 나눠서 처리하는 방식\n\n\n이런식으로 의도적으로 fixed-size 유닛으로 나눠서 처리하는 것이 효율적일 때가 있다더라\n\nUse a good idea again §\n\n범용적인 구현보다는 구체적인 구현을 한 뒤, 이것을 재사용해라\n\nData replication 예시: 작은 데이터를 replication 하는 간단하지만 빠른 컴포넌트를 만들고, 이것을 이용해 transactional storage 를 만든 뒤, 이것으로 큰 데이터를 replication 하는 시스템을 만드는 것\nStar office system 예시: 뭐 이것도 텍스트 입력, 삭제, 복사 등과 같은 단순한 몇가지의 기능만을 만든 뒤에 이것을을 조합해 더 많은 기능들을 구현하는 예시인듯\n\n\n\n2.5. Handling all the cases §\nHandle normal and worst case separately §\n\nNormal case 와 worst case 는 다소 성격이 다르고, 따라서 다르게 처리되어야 한다\n\nNormal case 의 경우에는 빠르게 작동해야 하고\nWorst case 의 경우에는 진전이 있어야 한다 (make some progress - deadlock 처럼 멈춰있으면 안된다 이정도의 의미인듯)\n\n\n특정 프로세스에 자원을 불공평 혹은 아예 주지 않거나, 데드락이 걸리는 상황은 자주 발생하지 않고 이것을 감지할 수만 있다면 대부분의 시스템에서 크게 문제되지 않는다\n특정 프로세스 혹은 시스템 전체를 crash 하는 것은 (비록 어감은 별로 안좋지만) 흔한 복구 방법이다\n\nInterlisp-D, Cedar 예시 - GC 를 위한 referencing-counting 기법은 GC 절차를 상당부분 최적화 시켰지만 (normal case 에는 빠르게), 이 방법을 사용할 경우 (아마 gc 로 인해) reference 가 끊어진 circular structure 를 reclaim 할 방법이 없다. 그래서 trace-and-sweep 라는 것을 추가적으로 도입해, 이러한 문제 (비록 드물지만) 가 발생했을 때 시스템 전체를 몇초간 멈춰서 끊어진 연결고리를 찾는 방안을 마련했다.. (worst case 에는 어떻게든 문제가 해결되도록)\n그 다음에 referencing-counting 관련 문제점이 하나 더 소개되지만 슬로건과는 약간 무관해보임,,\nResource allocation and free 예시 - item 을 free 하기 위해 임시 page 가 필요한데, 일반적으로는 cusion (- 별도의 노력 없이 free 할 수 있는 clean page) 을 이용하면 되나 드물게 이러한 것이 없을 때에도 있다. 이때를 대비해 cusion 보다는 작은 공간을 평소에도 비워놓았다가 cusion 이 없을 때 사용할 수 있다. 이것은 cusion 을 이용하는 방법보다는 당연히 느리지만 그래도 다소 시간이 걸리더라도 문제 해결이 진행되긴 한다\n\n\nNormal case 와 worst case 에 아주 다른 전략을 사용하기도 한다\n\nBravo editor 예시 - 간단하게 말하면 Normal case 인 문자열 중간에 문자를 입력하는 것과 지우는 것은 piece (문자열을 가리키는 포인터와 문자열의 길이를 가지는 구조체 정도로 생각하면 될듯) 를 나누는 방식으로 작동하지만, worst case 인 이런 piece 들이 너무나 많아져서 느려지는  경우에는 clean up 이라는 처리를 해서 이 piece 들을 하나로 합치는 작업을 한다\n\n\n\n3. Speed §\nSplit resources §\n\n자원을 나눠서 독점하도록 해라 - 자원을 공유하는 것 보다는 독점하는 것이 일반적으로는 더 빠르게 작동하고, 자원을 독점해서 발생하는 총 자원 사용량 증가 문제는 생각보다 크지 않다\n\nRegister 예시\nIO Channel floating-point co-processor 예시\nInterlisp virtual memory system 예시 - virtual memory 기능을 지원하기 위한 disk address 와 virtual address 의 연결관계 mapping 은 real memory 공간에 독점적으로 저장된다 (이 또한 virtual memory 에 저장된다면 circulation 문제가 발생)\n\n\n\nUse static analysis §\n\nStatic analysis 를 수행하는 것은 일반적으로 performance 를 증진시킨다고 알려져 있다. 다만 좋은 static analysis 가 불가능할 수도 있기 때문에 가능하다면 수행하는 것이 좋고, 좋은 static analysis 가 불가능하다면 나쁜 static analysis 를 수행하기 보다는 dynamic analysis 를 사용해 볼 수 있다.\n\nRegister allocation for compilers 예시 - Compiler 입장에서 register 할당을 최적화하는 것은 static analysis 만으로는 어려운 점이 많고, dynamic analysis 의 힘을 조금 빌리는 것도 좋다\nSequential read 예시\n\n\n\nDynamic translation §\n\n편리한 표현 (간결하거나, 수정이 용이한) 표현에서 빠르게 해석될 수 있는 표현으로 동적 번역하는 방법을 사용하면 좋다고 한다\n\n편리한 표현을 통해 유지보수성을 늘리고 이것을 동적으로 빠른 표현으로 바꿔서 성능도 챙기는 느낌인듯\nMitchell 의 연구는 요청할 때에만 조금씩 번역하고, 그 결과를 캐시에 저장하는 방법을 통해 이런 용이성과 성능을 모두 챙길 수 있다고 한다.\nSmalltalk 예시\nC-machine 예시\n\n\n\nCache answers §\n\n비싼 연산의 경우에는 캐싱을 활용하자\n\nf(x) 의 결과를 (f, x) -&gt; (f(x)) 로 캐싱해 놓으면 이 f(x) 연산을 추가적으로 할 필요가 없으므로 당연히 빨라진다\n\n\n\nUse hints §\n\n힌트는 캐시랑 유사하게 이전에 계산된 값을 리턴하는 것이지만, 캐시와는 다르게 이 값이 정확하다는 것을 보장하지는 않는다\n\n따라서 이 힌트가 정확한 값인가를 판단하기 위한 장치가 필요하다\n\n\n\nWhen it doubt, use brute force §\n\n하드웨어 비용이 점점 낮아지면서 소요되는 사이클 수는 높지만 간단하고 쉽게 분석할 수 있는 솔루션이 사이클 수는 낮지만 복잡하고 작동이 보장되지 않는 솔루션보다는 낫다\n\n4. Fault-tolerance §\n5. Conclusion §\n\nTerminology - 나름 정리해본 용어들 §\nassumption §\n\nInterface 를 통해 상호작용하는 두 프로그램 간의 합의? Synchronize? 정도로 생각하면 될듯 싶다\n"},"botanicals/os/papers/논문---The-Evolution-of-the-Unix-Time-sharing-System":{"title":"논문 - The Evolution of the Unix Time-sharing System","links":[],"tags":["os","논문","snu_cse_ms_aos24s"],"content":"\n\n                  \n                  본 글은 Bell Labs 의 Dennis M. Ritchie 의 논문 The Evolution of the Unix Time-sharing System 를 읽고 정리한 글입니다.\n                  \n                \n\n\n\n                  \n                  주인장의 실력이 미천하기에 다소 잘못된 내용이 포함되어 있을 수 있습니다. \n                  \n                \n\nIntroduction §\n\nAT&amp;T 의 Bell Labs 에서 만든 UNIX 운영체제에 대한 간략한 역사와 발전 과정을 서술했다고 한다.\nUNIX 는 1969 년에 제작되었고, 1974 년에 처음으로 논문 으로 발표됐으며 본 논문은 1979 년에 발표되었다고 한다. UNIX 시스템에 대한 그간의 발전 과정은 많은 교훈을 주기에 본 논문을 저술했다고 하더라.\n\nOrigins - UNIX 가 발명되기까지 (~1969년) 의 Bell Labs 의 상황 §\n\n1968-1969 까지의 AT&amp;T 의 Bell Labs 의 상황은 다소 어수선했다고 한다.\n\n기존에 진행하던 Multics 운영체제 프로젝트가 점점 망해가고 있었고\nBell Labs 의 컴퓨터 센터 (Murray Hil Computer Center) 는 GE645 를 운용중이었는데, GE635 에서 Multics 를 지원하기 위한 이 컴퓨터는 부족한 점이 많았으며\n연구소가 “Computing Service” 와 “Computing Research” 두 분야로 조직개편을 했다고 한다.\n\n\n저자 및 그의 동료들 (Thompson, Ritchie, Ossanna 등) 은 Multics 에 대해 마지막까지 희망의 끈을 놓지 않고 있었다.\n\n하지만 Multics 가 제공하기로 한 편리한 사용 환경은 나중에 보니 아주 제한된 사용자들에게만 (아마 저자 및 그의 동료들에게만?) 편리한 기능이었고\n이외 여러 문제가 있어서 Multics 프로젝트가 엎어진듯..\n\n\n결국에는 Multics 를 대체하기 위한 다른 것을 찾아야 했다고 한다. 이를 위해 여러 컴퓨팅 장비들을 물색해야만 했고 그것들을 구매하기 위해 노력을 많이 했으나 결국에는 기각되었다.\n\n이것은 그들이 회상해 봤을 때 너무나 많은 돈을 너무나 소규모의 조직에 쏟아 붓기를 제안했기 때문이었다.\n또한 연구소 입장에서는 운영체제 개발은 더이상 흥미가 느껴지지 않는 분야였고 연구소 내부에 computing center 를 더이상 운용하고 싶어했지 않았다.\n따라서 이런 장비를 구입하는 것은 연구소가 보기에 Multics 와 같은 또 다른 실패작을 만들어 낼 것이라고 생각했고 성공적인 무언가를 만들어낸다 하더라도 computing center 를 계속 운용해야 했기에 부담이 있었을 것이라고 했다.\n\n\n그럼에도 불구하고 1969년에는 여러 기술적인 진보가 있었는데..\n\nUNIX 파일시스템의 기본적인 설계를 스케치 했었고\n스케치한 파일시스템의 성능을 시뮬레이션하기도 했으며\nGE645 를 위한 새로운 운영체제를 기초적인 부분까지 완성했었다고 한다.\n\n웰컴메세지를 출력하는 기능까지 개발이 되었으나, GE645 의 수명이 몇달 안남았다고 결론이 났기에 여기까지만 하고 중단되었다.\n\n\n\n\n또한 1969년에 사용자가 우주선을 태양계의 이곳 저곳으로 움직이며 플레이하는 Space Travel 이란 게임을 만들었다.\n\n처음에는 Fortran 언어를 사용해 GECOS (GE635 에서 사용하는 운영체제) 에서 작동하도록 개발되었으나\n조작이 불편했고 GE635 를 사용할 경우 시간당 $75 의 금액이 부과되었기에 PDP-7 머신으로 갈아타게 되었다.\nPDP-7 용의 버전은 기존의 GECOS 용 버전에서 플로팅 포인트 사칙연산 패키지나 디버깅 시스템 등 많은 부분을 개선했다고 한다.\n개발은 GECOS 에서 PDP-7 용으로 cross-assembly 하는 방식으로 진행됐다고 한다.\n\n\nSpace Travel 은 단순한 게임일 뿐이었지만, PDP-7 용 운영체제를 위한 많은 개념들을 제시해 주었다고 한다.\n\n이전에 스케치한 파일시스템을 실제로 구현했고\n파일시스템이 실제로 실행될 수 있도록 프로세스의 개념을 추가했으며\n복사 붙여넣기, 쉘 등의 사용자를 위한 유틸리티들이 추가되었다.\n\n\n여기까지 온 뒤에는 더이상 GECOS 에서 cross-assembly 하기 보다는 PDP-7 에서 직접 assembly 하는 것이 가능해졌고, 이후에 Brian Kernighan 이 “UNIX” 란 이름을 붙이며 우리에게 널리 알려진 UNIX 운영체제가 탄생하게 되었다.\n\nPDP-7 UNIX File System §\n현재 UNIX File System 과의 공통점과 차이점 §\n\n구조적으로 볼때, PDP-7 UNIX File System 은 지금의 파일시스템과 거의 동일하다:\n\n파일시스템은 i-node 로 구성된 배열인 i-list 자료구조 형태이다:\n\n파일의 권한, 사이즈, 디스크에의 저장 위치 (list of physical blocks) 의 정보를 담은 i-node\ni-node 들의 배열인 i-list\n\n\n그리고 파일은 일반적인 텍스트 파일 이외에도 다음의 두 종류의 파일이 더 존재한다:\n\n파일들의 i-number (i-node 의 ID) 와 파일들의 이름을 저장하고 있는 특별한 파일인 directory\nDevice 를 대변하는 특별한 파일\n\n이것은 특정 i-number 는 특정 device 를 의미하는 것으로 구현되어 있다\n약간 fd/0 이 stdin 인 것과 유사한 느낌인듯\n\n\n\n\nRead, Write, Open, Create 와 같은 Syscall 도 PDP-7 에도 마찬가지로 구현되어 있었다.\n\n\n지금의 파일시스템과 다른점은 아래와 같다:\n\nPDP-7 은 word-addressed machine 이기에 (이 말인 즉슨, 모든 instruction 이 고정된 크기를 가진다는 소리이다. 이 고정크기의 단위로 word 란 표현을 쓰는 것) IO 의 단위도 byte 가 아니라 word 이다.\nErase 와 Kill 기능이 터미널에 없다고 한다. Erase 는 파일을 지우는 것 일거 같은데 Kill 은 모르겠네\n또한 path name 이 없었다고 한다. (!!)\n\n모든 파일은 ”/” 없이 현재 디렉토리를 기준으로 한 상대 위치를 통해 접근할 수 있다고 한다.\n\n\n\n\n\n현재 디렉토리 바꾸기 (chdir) §\n\n그럼 다른 디렉토리의 파일은 어떻게 접근하냐: dd 라는 특별한 디렉토리를 통해 접근할 수 있다.\n\ndd 에는 각 사용자들이 사용하는 디렉토리들이 모여있다: 약간 지금의 /home 과 비슷한 놈이라고 생각해도 될 것 같다.\n따라서 만약 kim 사용자의 디렉토리로 현재 디렉토리를 변경하고 싶다면, 다음과 같이 하면 된다.\n\n\n\nchdir dd kim\n\n\n당시의 chdir 는 지금의 chdir 와는 좀 다르다: 이 명령어는 인자를 여러개 받을 수 있고, 명시한 순서대로 디렉토리에 접근하게 된다.\n\n즉, 위의 명령어는 지금의 chdir 로 따지면 아래와 같다.\n\n\n\nchdir dd\nchdir kim\n\nLink (Symlink) §\n\nLink 기능도 초기 UNIX 에 포함되어 있었다고 한다. 문법은 다음과 같다:\n\ndir 은 현재 디렉토리 내의 디렉토리 이름\nfile 은 dir 디렉토리 내의 파일\nnewname 은 현재 디렉토리에 생성할 link 파일의 이름\n\n\n\nlink(dir, file, newname)\n\n\n현재의 UNIX 에는 directory 를 link 하는 것은 금지되어 있었지만, 초기에는 가능했다고 한다.\n위의 dd 를 이용해 좀 복잡한 사용 예시를 들어보면, kim 이란 사용자의 디렉토리 내의 파일 x 를 현재 디렉토리에 link 거는 것은 다음처럼 할 수 있다:\n\nln dd kim kim\nln kim x x\nrm kim\n\n단점들 §\n\n상상이 잘 안되겠지만, directory 와 device 는 disk 가 재생성될 때에만 생성될 수 있다고 한다.\n\n따라서 subdirectory 는 실생활에서는 거의 사용되지 않았으며\nDevice 를 추가하는 것 또한 매우 힘든 작업이었고\nRemovable disk pack (USB 같은?) 것은 꿈도 못꾸는 것이었다고 한다.\n\n\n초기의 UNIX 은 현재의 UNIX 시스템에 비하면 당연히 아주 단순화된 모습이었다.\n\n그의 일례로, Multi-programming 을 지원하지 않았기에 디스크에서 데이터를 읽어올 때에는 다른 작업이 불가능 했다.\n\n사용자에게로 control 이 전환되지 않는 것은 물론이고, 시스템 코드도 작동하지 않았다고 한다.\n지금의 버퍼링 시스템의 전신이 구현돼 있긴 했지만, Disk IO 와 CPU 연산 작업이 동시에 이루어지지는 않았다고 한다..\n\n\n\n\n\nProcess Control §\n초기와 현대의 UNIX Process Control 방식 차이 §\n\nFile system 의 경우에는 핵심적인 구조는 이전이나 지금이나 크게 바뀌지 않았지만, Process control 의 경우에는 많은 것이 바뀌었다.\n지금의 UNIX 운영체제는 다음과 같이 프로세스들을 실행한다:\n\nShell 은 terminal 로부터 command line 을 파일로 읽어들인다.\nShell 이 fork 을 해 child process 를 만든다.\nChild process 는 파일에 있던 command 를 exec 한다.\n그동안은 parent process (shell) 은 child process 가 exit 을 하여 종료될 때까지 wait 한다.\n1번 과정을 반복한다.\n\n\n하지만 초기의 UNIX 운영체제에는 Process 의 개념은 있었지만 fork, wait, exec 은 없었고 exit 도 지금과는 살짝 달랐다.\n초기의 UNIX 운영체제는 다음과 같이 작동하였다.\n\nShell 은 기존에 open 되어 있던 파일들을 전부 close 하고, stdin 과 stdout 두개의 파일을 연다.\nShell 은 terminal 로부터 command line 을 파일로 읽어들인다.\nShell 은 command 파일을 열고, 메모리 상단에 자그마한 bootstrap program 을 적재한 후, bootstrap program 으로 점프한다. 이 boottrap program 은 command 파일의 내용을 shell code 위에 overwrite 하고, 그쪽으로 jump 를 해 command 를 실행한다.\nCommand 가 완료된 다음 exit 을 호출하면, os 가 command code 위에 새로운 shell code 를 overwrite 하고, 실행시킨다.\n\n\n위의 초기 UNIX 구현에서 짚고 넘어가야 할 것은 추후에 추가되어야 할 기능들이 어느정도 예측되어서 구현에 반영되었다는 것이다.\n\n백그라운드 프로세스나 파이프 등이 구현되어 있지는 않았지만,\nIO redirection 은 stdout 과 stdin 을 그냥 다른 파일로 대체하면 된다는 점에서 어렵지 않게 구현될 수 있었고\nShell 을 kernel 의 일부가 아닌 user level program 으로 구현하는 것도 가능하게 했다.\n\n\n따라서 parent/child process 같은 개념이 없었기 때문에, terminal 당 process 는 1개였다.\n\n그리고 초기의 UNIX 는 terminal 을 2개 지원했기에, 총 두개의 프로세스가 작동된다고 할 수 있다.\n이것은 UNIX 이전의 Multics 나 CTSS 같은 운영체제의 영향을 받은 것이었다.\n\n\nTerminal 당 process 가 하나인 것은 여러모로 문제를 일으켰다.\n\nShell 이 매번 실행될 때마다 모든 파일을 닫았기에, stdin 과 stdout 은 매번 다시 열어줘야 했다.\n매번 fresh shell process 가 실행되었기에, command 실행 간에 메모리 상태를 유지하는 것도 불가능 했다.\n또한 각 디렉토리에 tty 라는 특별한 파일을 가지는 것이 요구되었다.\n\n이 파일은 디렉토리를 연 터미널을 참조하도록 되어 있고 만일 이 파일이 없다면 shell 은 무한루프에 빠지게 된다… 왜그런지는 모르겠다.\n\n\n\n\n\n초기 UNIX 에서의 개선 과정 §\nfork 와 exec 구현하기 §\n\n놀라운 점은 기존의 Process control 지금의 그것 (fork 를 활용하는) 것으로 개선하는 것은 설계와 구현까지 단 며칠밖에 걸리지 않았다는 점이다.\n이것은 아래의 세가지 사실을 적절히 활용한 것이라 생각할 수 있을 것이다:\n\n앞에서도 언급했다시피, 하나의 process 에서 code 만 바꿔 프로그램을 exec 하는 것은 당시에는 흔한 방법이었다.\nThompson 은 이미 기존의 Berkeley Time-sharing System 에서 fork 와 exec 을 분리하여 프로세스를 관리한다는 것을 잘 알고 있었다.\n기존의 UNIX 에서는 이미 두개의 터미널에서 각각 프로세스를 돌리고 있었기 때문에 프로세스를 여러개 돌리는 것에 대비가 되어 있었던 상황이었다.\n\n\n따라서 이것은 이렇게 활용될 수 있었다:\n\n(2) 번을 이용해 Process 관리에 fork 와 exec 을 분리하는 아이디어를 얻고\n(3) 번에서 2개의 프로세스를 실행시키는 것을 그보다 더 많은 프로세스를 실행시키는 것으로 확장하여 fork 를 구현했으며\nfork 를 통해 parent process 와 동일한 process 를 생성한 뒤에 (1) 번에서 했던 것처럼 code 만 바꿔 프로그램을 실행하는 식으로 exec 을 구현했다.\n즉, fork 를 구현할 때에는 다음의 두 가지만 요구되었었다.\n\n기존의 Process table 을 확장하고\n기존의 swap IO 방식 (두 개의 process 를 와리가리하기 위해 swapping 하던 것) 을 그대로 사용해 현재의 process 를 disk swap area 에 복사하고 process table 을 수정하는 방식으로 fork 함수를 구현하는 것\n\n\n\n\n위와 같은 방법으로 단 27줄의 assembly code 만을 추가해 fork-exec 기능을 구현해 냈다.\n\nexit 구현하기 §\n\n이전에는 새 shell code 를 현재 process code 에 overwrite 하는 방식이었다면,\n새로운 exit 을 구현하는 것은 보다 더 단순했다:\n\n그냥 Process table entry 를 비워버리고,\nCPU 점유를 포기해 버리면 되었기 때문\n\n\n\nwait 구현하기 §\n\n초기 UNIX 에는 다음의 두 함수가 있었다:\n\nsmes(pid, message): 이것은 특정 pid 에 message 를 보내고 수신자가 메세지를 읽을 때까지 기다린다.\n(pid, message) = rmes(): 메세지가 올때가지 기다리고, 메세지가 오면 해당 메세지의 송신자 (pid) 와 내용 (message) 를 반환한다.\n\n\n따라서 smes 을 이용하면 wait 은 다음과 같은 방식으로 구현될 수 있었다:\n\nParent process 가 child process 를 fork 한다.\nParent process 에서 실행한 fork 함수는 child process 의 pid 를 반환하고, parent process 는 이 pid 와 smes 를 이용해 child process 에게 메세지를 보낸다.\nChild process 는 이 메세지를 읽지 않고 command 를 실행한 뒤, 종료된다.\n그럼 parent process 의 입장에서는 child process 가 실행되던 중에는 계속 대기하다가, child process 가 종료되면 process 를 찾을 수 없다는 에러를 반환한다.\nParent process 가 기다리게 하기 위해 child process 에서 의도적으로 메세지를 읽지 않은 것이기 때문에, 위의 에러는 무시한다.\n\n\nrmes 를 이용하면 init process 의 wait 과정도 구현할 수 있다:\n\nInit process 는 터미널 당 두개의 shell process 를 생성한다.\n그리고 rmes 를 걸어 놓는다.\n각 shell 은 명령어 file 을 실행한 뒤에, init process 에게 I am terminating 이라는 메세지를 smes 로 보낸다.\n\nInit process 의 pid 는 무조건 1 이기 때문에, shell 은 init process 의 pid 를 알아내야할 필요가 없다.\n\n\nInit process 는 메세지를 받은 후 대기가 풀리고, 다시 해당 터미널에 대해 shell 프로세스를 실행하고 2번 과정을 반복한다.\n\n\nsmes 와 rmes 가 더 범용적인 기능을 제공하기는 하지만, 지금은 wait 만 있고 이 두 기능은 사라졌다.\n\n왜냐면 smes 와 rmes 가 이 wait 기능을 구현하는 것 이외에로는 사용되지 않았기에, 덜 범용적이지만 목적이 확실한 wait 로 인터페이스를 축소시키는 것이 좋았고\n\n아마 wait 을 구현하는 데에는 사용되지만 process 에서 smes, rmes 를 syscall 같은 것으로 호출하지는 못한다 정도의 의미인 것 같다.\n\n\nShell 이 smes 로 child process 를 기다리고 있었는데, child process 에서 어떤 이유로든 rmes 를 사용하면 smes 로 보낸 메세지가 읽히기 때문에 shell 이 다른 command 를 읽어 들여 child process 가 비정상적으로 종료되는 문제가 있기 때문이다.\n\n\n이런 wait 구현 방식은 background process 등의 기능도 아주 손쉽게 구현할 수 있도록 해주었다고 한다.\n\nAftereffects: 구현 이후의 부작용들 §\nchdir 문제 §\n\nProcess control 방식을 바꾼 뒤 발견한 첫번째 문제는 chdir 명령어를 실행해도 현재 디렉토리가 바뀌지 않는다는 것이었다.\n이것은 좀만 생각해 보면 당연한 일이다:\n\nchdir 을 실행할 때 child process 가 fork 될 것이고\n해당 프로세스는 현재 문맥에서 디렉토리를 변경하기 때문에\nchdir 을 실행한 parent process 에서는 디렉토리가 변경되지 않는다.\n\n\n따라서 이와 비슷한 현상을 보이는 명령어들은 새로운 프로세스가 fork 되지 않고 shell 내부에서 처리되도록 변경되었다고 한다.\n\nI/O redirection 문제 §\n\n두번째로 발견한 문제는, 여러개의 command 들을 파일에 작성해서 실행시키고, 그 결과를 redirect 할 때 stdout 이 씹히는 것이었다.\n가령, 다음과 같은 script (파일 이름: comfile) 를 작성했다고 해보자.\n\nls\nwho\n\n이때, 다음과 같이 실행할 경우 ls 의 결과가 output 파일에 저장되지 않는 문제가 있었다.\n\nsh comfile &gt; output\n\n문제의 원인은 파일을 열었을 때 파일에 대한 read/write pointer 가 파일을 연 프로세스에 귀속된다는 것이었다.\n문제의 원인은 다음과 같았다:\n\n메인 shell 은 child process (1) 을 생성한다.\n\nChild process (1) 은 comfile 이 실행되는 shell process 이다.\n\n\nChild process (1) 는 stdout 을 리다이렉트하기 위해 outfile 을 open 한다.\n\n즉, outfile 에 대한 r/w pointer 는 child process (1) 에 귀속된다.\n\n\nChild process (1) 은 새로운 child process (2) 를 fork 한다.\n\nChild process (2) 는 ls process 이다.\n\n\nChild process (2) 는 child process (1) 로 부터 r/w pointer 를 상속받아 outfile 에 결과를 입력한 뒤, 종료된다.\nChild process (1) 은 새로운 child process (3) 을 fork 한다.\n\nChild process (3) 은 who process 이다.\n\n\n마찬가지로 child process (3) 도 child process (1) 로 부터 r/w pointer 를 상속받아 outfile 에 결과를 입력해야 하는데 이런 시상에! child process (3) 의 결과는 child process (2) 의 결과를 덮어쓰게 된다.\n\n이것은 child process (2) 가 outfile 에 입력하며 write pointer 를 옮겼지만, child process (1) 한테는 반영이 안되기 때문에, child process (3) 은 옮겨지지 않은 write pointer 를 상속받았기 때문이다.\n\n\n\n\n따라서 위와 같은 문제를 해결하기 위해 r/w pointer 를 파일을 open 한 프로세스에 귀속시키지 않고 system level 에서 관리하기 위해 IO pointer 들을 담은 system table 을 추가했다고 한다.\n\nI/O Redirection §\n\n&gt; 와 &lt; 를 사용한 I/O redirection 은 초기에는 UNIX 에 존재하지 않았지만, 머지않아 개발되었다고 한다.\n일단 I/O redirection 의 아이디어는 Multics 에서 가져온 것이다.\n\nMultics 에서는 named I/O redirection 을 지원하는 더 범용적인 기능이 있었다고 한다.\n\n\n간단히 UNIX 와 Multics 에서의 I/O redirection 방식을 비교해 보자면,\nUNIX 에서 다음과 같은 명령어가\n\nls &gt; xx\n\nMultics 에서는 다음과 같이 사용했어야 했다.\n\niocall attach user_output file xx\nlist\niocall attach user_output syn user_i/o\n\n논문에서는 간단하게 이놈과 관련된 썰을 하나 풀고 간다:\nMultics 에서는 이 iocall 이 자주 사용되었음에도 불구하고, 이 기능을 shell 에 통합시킬 생각을 아무도 하지 못했다고 한다.\n\n왜냐면 Multics 의 IO system 은 Bell Labs 에서 만들었고, Shell 은 MIT 에서 만들었기 때문.\n코드의 주인이 저자가 아니었기 때문에 저자는 이것을 shell 에 통합시킬 생각을 못했고, MIT 에서는 이 기능을 많이 사용하는지 알지 못했기 때문에 shell 에 이러한 기능이 통합되지 않았다고 하더라.\n\n\n근데 UNIX 의 IO system 과 shell 모두 Thompson 의 손바닥 안이었기 때문에, UNIX 에서는 이 기능이 shell 에 아주 사용하기 편한 방식으로 제공되게 되었다.\n\nThe advent of the PDP-11, and the first PDP-11 system §\n\n1970 년이 되자 PDP-7 UNIX 는 대체제가 없긴 했지만 PDP-7 머신이 점점 낡아져 감에 따라 저자는 새로은 PDP-11 을 사달라고 졸랐다고 한다.\n이번의 조름은 이전의 징징보다 두가지 관점에서 달랐다고 한다.\n\n일단 PDP-11 은 이전에 사달라고 했던 것보다 가격이 훨씬 저렴했다.\n또한 장비의 구매 목적을 그냥 알수 없는 OS 개발이 아닌 워드프로세서 개발로 특정했다.\n\n\n처음에는 연구소에서 탐탁치 않게 여겼지만, 결국에는 구매하게 되어 1971년 5월에 입고되게 된다.\n\n다만, 너무 최신의 컴퓨터라 이에 맞는 디스크가 시장에 존재하지 않았고, 저자와 친구들은 12월까지 기다려야 했다고 한다.\n\n\nPDP-11 에서 처음에 새로운 UNIX 를 실행했을 때에는 첫번째 버전과 성능 차이가 별로 나지 않았다고 한다.\n하지만 파일의 full path name 을 표시하고, 새로운 방식의 exec 과 wait 이 들어갔으며, 텍스트 출력 면에서 여러가지 개선이 이루어 졌고\n결과적으로는 미 특허청에 납품되어 성공을 이루게 되었다는 감동실화\n\nPipes §\n초기 구상 §\n\nPipeline 은 coroutine 의 특별한 형태일 뿐, UNIX 에서 처음으로 도입한 것은 아니었다.\n\nDartmouth Time-sharing System 에서도 “Communication Files” 이란 이름으로 지금의 UNIX pipe 와 거의 유사한 기능을 제공해 주긴 했다.\n다만 이것을 제대로 제공해 주지는 못했고, 따라서 UNIX 에서 | 의 문법을 이용한 간편한 사용법으로 널리 알려지게 된듯\n\n\nPipe 는 매클로이 아저씨 의 아이디어었는데, 그는 명령어가 마치 이항연산자처럼 명령어의 input 이 왼쪽에 output 이 오른쪽에 들어가야 한다고 제안했다고 한다.\n즉, 어떤 input 을 정렬 (sort) 한다음, 페이지를 매기고 (paginate - pr), 프린트를 하는 것 (offline-print - opr) 은 다음과 같이 쓸 수 있을 것이다.\n\ninput sort pr opr\n\n위는 지금의 UNIX 표현으로 하자면 다음과 같다:\n\nsort input | pr | opr\n\n이 아이디어는 좋았지만 바로 구현에 들어가지는 못했다고 한다:\n\ncommand input output 의 형태 (마치 cp x y 처럼) 에 너무 익숙해져 있었고\n이게 command arg 인지 input 혹은 output 인지 구분하는 게 힘들었기 때문\n\n\n하지만 시간이 좀 흐른 후, 매클로이 아저씨가 이것을 구현하여 UNIX 에 포함시키게 되었다.\n처음의 pipeline 은 지금의 | 가 아닌 I/O redirect 와 동일한 &gt; 를 사용했다고 한다.\n즉, 위의 예시는 다음처럼 표현되게 된다:\n\nsort input &gt;pr&gt;opr&gt;\n\n따라서 위와 같은 구현에서는, &gt; 가 두가지의 역할을 하게 된다:\n\n명령어의 stdout 을 &gt; 뒤에 나오는 파일로 redirect 하거나,\n명령어의 stdout 을 &gt; 뒤에 나오는 command 로 pipe 하거나.\n\n\n위 구문에서 맨 마지막에 &gt; 가 붙는지 의아할 수 있는데, 이것은 opr 이 명령어임을 나타낸다.\n\n즉, opr 뒤에 &gt; 를 붙이지 않았다면, pr 의 stdout 이 ”opr” 란 이름의 파일에 저장될 것이기 때문.\n\n\n\n개선 1 - Quote 활용 §\n\n이러한 용법이 나온 이후에, 여러가지 개선이 이루어 졌는데, 이루어진 첫번째 개선은 whitespace 에 관한 것이었다.\n\n&gt; 뒤에서는 whitespace 를 기준으로 command string 으로 잘라 처리하게 되는데, command arg 또한 whitespace 를 이용해 구분짓기 때문에, 혼동이 오는 것.\n\n\n가령 위의 예시에서 pr 명령어에 -2 옵션을 주고자 아래와 같이 사용하면:\n\nsort input &gt;pr -2&gt;opr&gt;\n\n-2 를 명령어로 인식해 이러한 명령어는 없다고 징징댈 것이다.\n이를 개선하기 위해, 이런 경우에는 큰따옴표를 이용해 하나의 명령어로 인식하도록 했다.\n\n즉, 아래와 같이 하면 정상적으로 작동하게 된다.\n\n\n\nsort input &gt;&quot;pr -2&quot;&gt;opr&gt;\n개선 2 - &gt; 뿐 아니라 &lt; 도 지원하기 §\n\n조금 더 문법을 확장하고자, 왼쪽에서 오른쪽으로 진행해 가는 &gt; 에 추가적으로 반대방향인 &lt; 도 추가되었다.\n즉, 위에서의 예시는 다음과 같이 표현할 수도 있었다:\n\n opr &lt;&quot;pr -2&quot;&lt;&quot;sort input&quot;&lt;\n\n&quot;sort input&quot; 뒤에 &lt; 이 붙는 것도 해당 문자열을 파일이 아닌 명령어로 받아들이게 하기 위함이다.\n&gt; 와 &lt; 를 섞어 사용하면 아래와 같이 사용하는 것도 가능하다:\n\npr &lt;&quot;sort input&quot;&lt; &gt;opr&gt;\n\n이것은 차근차근 읽어보면 다음과 같다:\n\nsort input 의 결과를 (&quot;sort input&quot;&lt;)\npr 로 보내고, (pr &lt;&quot;sort input&quot;&lt;)\n또 그 결과를 opr 로 보낸 뒤 그 결과는 그냥 stdout 으로 보내는 것 (pr &lt;&quot;sort input&quot;&lt; &gt;opr&gt;)\n\n\n\n개선 3 - | 이용하기 §\n\n위와 같은 &gt;, &lt; 식의 표현은 얼마 간은 지속됐지만 결국에는 현재의 | 방식으로 굳어졌다고 한다.\n물론 | 를 사용하는 방식이 문제가 없는 것은 아니다.\n\n가령 여러개의 stream 에서 input 을 받으려고 할 때는, stdout-stdin 을 다이렉트로 연결짓는 | 방식으로는 불가능하기 때문.\n\n\n\nMultics 의 redirection 과의 차이점은? §\n\nMultics 에서도 IO stream 을 process 로 전달하는 redirection 이 가능했기에, UNIX pipe 가 이것의 개선버전이라고 생각할 수 있지만,\n저자는 그렇게 생각하지 않는다고 한다:\n\nMultics 에서의 IO stream 은 program 이 IO stream 을 지원하기 위한 방식으로만 코드가 작성되어야 하지만\nUNIX pipe 는 stdin 과 stdout 을 이용하기에 코드에 큰 변화를 주지 않아도 된다는 의미인듯\n\n\n\nHigh-level languages §\nB Programming Language §\n\n처음의 PDP-7 에서의 UNIX 는 날것의 assembly 언어로 되어 있었다고 한다.\n그러다가 나중에는 매클로이 아저씨가 TMG 라는 컴파일러를 UNIX 에서 작동하도록 만들었는데\n똠쓴씨가 Fortran 을 TMG 로 컴파일하도록 일주일정도 노력했지만 결과적으로는 이것은 B 언어의 탄생으로 이어졌다.\n\nB 언어는 인터프리팅 방식이어서 다소 느리긴 했지만, 그래도 개발이 더 편해졌다고 하더라\n또한 syscall 을 호출하는 인터페이스도 추가돼서 system programming 도 가능해 졌다 하더라\n\n\n추후에는 PDP-7 에서 PDP-11 을 개발하기 위한 cross-compiler 도 B 로 개발되었고 TMG 를 대체할 PDP-7 에서의 B compiler 도 B 로 개발되었다.\n\nC Programming Language §\n\n하지만 PDP-11 UNIX 혹은 유틸리티들을 B 로 작성하는 것은 고려되긴 했지만 실제로 수행되지는 않았다.\n\n왜냐면 B 는 인터프리팅 언어이기에 다소 느렸기 때문.\n\n\n따라서 이러한 문제를 해결하기 위해 C 언어가 개발되었다.\n1973년에 이르러서는 UNIX 의 커널도 C로 다시 개발되며 현대적인 형태를 갖추게 되었다.\n\nMulti-programming 도 도입되었고\n내부 시스템의 구조도 더 다듬어졌다고 한다.\n\n\n현재에는 assembler 이외에는 UNIX 의 커널 및 유틸리티 거의 전부가 C 로 개발되어 있다고 한다.\n"},"botanicals/os/papers/논문---The-design-and-implementation-of-a-log-structured-file-system":{"title":"논문 - The design and implementation of a log-structured file system","links":["botanicals/os/draft/Log-structured-File-System,-LFS-(File-System)","botanicals/storage/terms/Hot-Cold-Separation-(Storage)","botanicals/os/papers/논문---A-Fast-File-System-for-UNIX"],"tags":["논문","os","snu_cse_ms_aos24s"],"content":"\n\n                  \n                  본 작물은 The design and implementation of a log-structured file system (SOSP &#039;91) 논문을 읽고 정리한 글입니다.\n                  \n                \n\n\n\n                  \n                  별도의 명시가 없는 한, 본 글의 모든 그림은 위 논문에서 가져왔습니다. \n                  \n                \n\n\n\n                  \n                  본 문서는 아직 Draft 상태입니다. 읽을 때 주의해 주세요. \n                  \n                \n\n1. Abstract &amp; Introduction §\nProblem Statement §\n\nCPU 속도는 음청나게 빨라지는 반면, disk 속도는 거의 그대로이고, 따라서 disk 속도가 여러 application 에서 병목이 되고 있다.\n이 문제를 해결하기 위해 저자들은 (특히 다수의 작은 파일들을 처리할 때 더 특출난) LFS 라는 새로운 file system 을 개발했다.\n\nLog Structure §\n\n파일들은 메모리 상에 캐싱되기에 read 작업은 메모리 사이즈에 주로 영향을 받는다는 것을 전제로 깔고 간다.\n이렇게 되면 (read 는 메모리에 더 의존하기 때문에) disk traffic 의 대부분은 write 가 차지하게 된다.\nLFS 는 모든 새로운 혹은 변경된 사항들을 log 의 형태로 sequential 하게 disk 에 저장한다.\n이 방법을 사용하면 write performance 를 극적으로 늘릴 수 있고, seek time 을 거의 없애버릴 수 있다.\n\n어떻게 이것이 가능한지는 뒤에 나올것이니 조급해지지 말어라\n\n\n또한 이러한 sequential write 는 crash recovery 에도 도움을 준다.\n\n기존의 UNIX file system 은 crash recovery 를 하기 위해 storage 전체를 다 훑어서 복구를 하지만, LFS 의 경우에는 log 의 마지막 일부분만 사용하면 되기 때문.\n이것도 아마 뒤에 더 구체적인 설명이 나올 것이다.\n\n\nLog 를 사용하는 방법은 기존에도 있었지만, 기존에는 log 를 단순히 데이터의 임시 보관으로만 활용했고, 기존의 random write 방식을 메인으로 사용했다고 한다.\n하지만 LFS 의 경우에는 모든 데이터를 log 로 저장하고, 다른 저장 방식은 없다.\n\nIndexing Information §\n\n이 방식은 read 시에 성능 저하를 가져올 수 있다: new or updated data 가 log 에 저장되므로 이전에 write 된 데이터를 읽어오기 위해서는 옛날 데이터로 거슬러 올라가야 하기 때문.\n하지만 LFS 에서는 이것을 indexing information 을 이용해 해결했다:\n\n옛날 데이터로 선형적으로 거슬러 올라가며 원하는 데이터를 찾도록 하는 것이 아닌, 해당 데이터의 위치를 log 에 남겨 한번의 indirection 으로 바로 해당 데이터를 찾을 수 있게 한 것.\n예를 들어보자면: A, B 중 B 만 변경되면 마지막 log 에는 B 의 변경사항만 적혀 있고 A 의 데이터를 읽기 위해서는 이전 log 를 봐야 한다.\n하지만 만약에 마지막 log 에 A 데이터는 어디에서 확인할 수 있습니다 라는 indexing information 까지 적혀 있다면, 더 빠르게 해당 데이터를 읽어올 수 있는 것.\n\n\n\nSegment, Segment Cleaning §\n\nLFS 가 빠르고 효율적으로 작동하기 위해서는, storage 에 free space 가 많이 남아 있어야 한다.\n하지만 LFS 의 경우에는 sequential write 를 하기 때문에, 아무런 조치도 취하지 않으면 free space 가 다 없어져 정상적으로 작동하지 않을 것이다.\n이를 위해서 LFS 에서는 log 를 잘게 나눈 Segment 라는 단위와 이 segment 들을 정리해서 free space 를 확보하는 Segment Cleaning 이라는 방식을 사용한다.\n\nSegment Cleaning 을 통해 잘게 나뉘어진 segment 들을 압축해서 free space 를 확보하는 것\n아마 이후의 log 에서 변경되어서 더이상 유효한 정보를 갖고 있지 않은 segment 들이 이때 정리될 것이다.\n\n\n저자들은 여러 cleaning policy 들을 실험하였고, cost 와 benefit 에서 적절한 타협점을 찾은 효율적인 cleaning policy 를 찾아냈다고 한다.\n\n결론부터 말하면 잘 변경되지 않는 데이터와 변경이 잦은 데이터들을 나눠서 cleaning 을 한다.\nHot cold separation 과 유사한 방법인 셈.\n\n\n\nSprite LFS §\n\n저자는 Sprite LFS 이라는 프로토타입을 만들었고, Sprite Network Operating System 에서 실제로 사용하고 있다고 한다.\n벤치마킹을 돌려본 결과, 다수의 작은 파일들을 write 하는 작업이 기존의 UNIX FS 에 비해 월등히 빨랐다고 한다.\n이외의 read, large file write 작업의 경우에도 기존의 UNIX FS 와 비슷하거나 더욱 빠른 속도를 보여줬다고 한다.\n\n다만 random write 이후 sequential read 를 하는 한가지 경우에 있어서만 UNIX FS 가 더 빨랐다고 한다.\n\n\n실험 결과, LFS write operation 의 대역폭이 디스크 최대 대역폭의 65~75% 에 달하는 것으로 확인됐다.\n\n나머지는 cleaning operation 에 사용됐다고 한다.\n이것은 기존 UNIX FS 에서 write operation 대역폭이 5~10% 밖에 안나오는 것에 비하면 아주 극적인 성능 향상인 셈.\n\n\n\n2. Design for file systems of the 1990s §\n\n파일시스템 디자인은 두가지 요소에 영향을 받는다:\n\nTechnology: 하드웨어 측면에서의 기술의 발전\nWorkload: Process 가 수행하는 작업의 특성\n\n\n\n2.1. Technology §\nCPU §\n\n파일시스템에서 CPU 와 Disk, Memory 의 기술 발전은 아주 큰 영향을 가져온다.\n지난 날들 동안 CPU 는 아주 빠르게 발전해 왔고, 이를 최대로 활용하려면 Disk 와 Memory 도 그에 맞는 속도로 발전해 와야 할 것이야\n근데 특히 Disk 는 발전속도가 아주 더디고, 이것이 결국에는 발목을 잡고 있는 것이 현재 상황이라고 한다.\n\nDisk §\n\nDisk 가 그렇다고 해서 발전이 없는 것은 아니다; 이놈도 지난 세월동안 아주 많은 발전을 해왔다.\n하지만 진행되온 주된 발전은 금액을 낮추고 용량을 크게 하는 것이었고, 속도를 더욱 빠르게 하는 것은 발전하긴 했지만 CPU 의 발전 속도를 쫒아가기에는 역부족이었다.\n그 이유에 대해 좀 더 분석해 보자: 디스크의 성능을 높이는 것은 크게 (1) 전송 대역폭과 (2) 접근 시간과 관련이 있다.\n이때 전송 대역폭의 경우에는 여러개의 disk (여기서 disk 는 HDD 내의 원판을 말하는 것인듯) 혹은 head 를 사용하는 방법으로 개선이 가능하다.\n하지만 access time 의 경우에는 결국에는 disk 를 돌리고 head 를 움직이는 다소 기계적인 작업이기 때문에, 발전 속도에 제한이 있다.\n따라서 만약 application 이 다수의 파일들을 seek time 을 곁들여서 접근해야 한다면, 해당 application 은 CPU 가 발전하면 뭐하노 데이터를 읽어오지를 못하는데\n\nMemory §\n\nMemory 같은 경우에는 발전을 거듭하며 크기가 점점 커지고 있다.\nDisk 에서는 속도에 비해 크기의 발전이 주되게 일어나는 것이 골칫거리였다면, memory 는 이 크기가 커지는 것이 전반적인 성능 향상까지 같이 이끌어 내게 된다.\n이것은 메모리가 캐시로 사용되기 때문 - 현대의 FS 는 최근에 사용된 데이터를 메모리에 캐싱하는 방법을 사용하기에, 메모리의 크기가 커진다는 것은 그만큼 더 많은 데이터를 캐싱할 수 있다는 얘기와 같다.\n이것은 두가지 영향을 가져온다.\n첫째는, 더 많은 데이터를 메모리에 올려 놓을 수 있기 때문에, read 작업이 disk 에 덜 의존한다는 것이다.\n\n하지만 write 의 경우에는 결국에는 disk 에 반영되기 때문에 상대적으로 disk 의존하는 비중이 크다.\n\n\n둘째는, 메모리를 버퍼로 사용해 데이터들을 메모리에 모아 한번에 disk 로 write 할 수 있다는 것이다.\n\n버퍼링은 더욱 더 효율적으로 write 할 수 있게 해준다.\n\n이렇게 생각하면 된다: 만일 5MB 가 버퍼링되고 10MB 를 write 해야 한다면, 두번의 write 가 필요하고, write 할 위치를 seek 하여 write 를 한 후에는 새로운 위치를 seek 하여 이어서 write 해야 할 수도 있다. (즉, 2번의 seek)\n하지만 10MB 가 버퍼링된다면 write 전 한번의 seek 으로도 가능하기에, 더욱 더 효율적이 되는 것\n\n\n\n\n물론 버퍼링이 항상 좋은 것은 아니다; 버퍼링을 하게 되면 crash 상황에서 데이터가 날아갈 가능성이 더 커지게 된다.\n\n본 논문에서는 crash 에 대해 언제든지 예상치 못하게 발생할 수 있고, 이를 해결하기 위해 최대 분단위의 downtime 까지는 인정하는 것으로 가정했다고 한다.\n\n\n\n2.2. Workloads §\n\n저자는 Workload 를 크게 두 분류로 나누어 접근했다: 크기가 작은 파일과 큰 파일\n\n그리고 결론부터 말하자면, LFS 은 크기가 작은 파일의 성능 향상에 초점을 맞췄다고 한다.\n\n\n\nSmall files §\n\n크기가 작은 파일들은 FS 에서 다루기 까다로운 반면, 실생활에서는 아주 자주 사용되는 형태이다.\n\n가령 사무실에서 사용되는 word processor 와 같은 파일들의 경우에도, 조사 결과 KB 단위의 아주 작은 파일들이었다.\n\n\n이 파일들은 small random IO 를 유발하고, 이들을 생성하거나 삭제하는 것도 파일의 metadata (inode 와 같은) 를 건드려야 하기 때문에 마찬가지로 small random IO 가 발생한다.\n\nLarge files §\n\n슈퍼컴퓨팅 분야에서는 큰 사이즈의 파일들에 대한 sequential access 가 필요한데, 이들의 성능 저하는 file system design 에 있지는 않다.\n이러한 파일들을 인접한 cylinder 에 배치해 적은 seek time 으로 sequential 하게 접근하게 해주는 기술은 이미 존재한다. (아마 FAST FS 도 이것의 일종일듯)\n이들의 성능을 좌우하는 것은 대역폭과 많이 연관되어 있고, 따라서 LFS 에서는 큰 파일들에 대한 성능 향상은 하드웨어에 맡기고, 작은 파일들에 대한 성능 향상에만 집중했다고 한다.\n\n2.3. Problems with existing file systems §\n\n당시의 FS 는 두 가지 문제점이 있었다고 한다:\n\n데이터들이 디스크에 너무 흩뿌려져 있어서 small access 가 많이 발생했고\nWrite 가 다소 동기적으로 (synchronous) 수행된 것\n\n\n저자는 UNIX FFS 를 대표적인 prior work 으로 잡고 비교를 했으나, 다른 FS 에도 동일하게 적용되는 문제점이었다고 한다.\n\nSpread information §\n\n위에서 말한 것 처럼, 당시의 FS 들은 데이터들을 디스크에 흩뿌려 놓았고, 따라서 small access 가 너무나 많이 발생했다고 한다.\n가령 UNIX FFS 의 경우에는 cylinder group 개념을 이용해 데이터들을 sequential 하게 배치하기는 하였으나, 다른 파일의 경우에는 (아마 다른 cylinder group 에 배치되어?) 물리적으로 다른 위치에 배치되도록 하였다.\n또한 UNIX FFS 는 inode 와 (directory 내에 있는) file name,  file content 를 모두 격리시켜 놓았다.\n\n따라서 UNIX FFS 에서는 하나의 파일을 생성하기 위해서는 적어도 5번의 access 가 필요하다.\n\ninode\n파일 데이터\ndirectory entry\ndirectory inode\n(하나는 모르겠음..)\n\n\n\n\n따라서 small file 하나\u001d를 생성할 때에는 max bandwidth 의 5% 밖에 사용하지 못하고, 나머지는 전부 seek time 에 소모된다.\n\nSynchronous writes §\n\n나머지 하나의 문제는 write 작업이 synchronous 하게 이루어진다는 것이다.\n\n좀 더 쉽게 말하면, 하나의 작업을 시작하기 위해서는 이전 작업이 끝나기를 기다려야 한다는 것이다.\n반대인 asynchronous 는 write 작업을 background 에서 수행되도록 맡겨 놓고, 다음 작업을 받는 것을 의미한다.\n\n\n또 다시 UNIX FFS 를 꺼내오자면 여기에서는 file data 는 asynchronous 하게 write 가 이루어지지만 inode 나 directory 같은 경우에는 synchronous 하게 이루어진다.\n따라서 small file write 의 경우에는 어차피 file data 의 크기는 얼마 안되기 때문에 이러한 inode, directory 에 대한 synchronous write 에 모든 정신이 팔려버린다는 것.\n이러한 단점때문에 결국에는 좋아진 CPU 성능이나 memory cache 의 장점들이 모두 쓸모 없게 되어 버린다.\n심지어 NFS 의 경우에는 기존에는 없었던 synchronous 작업까지 추가했고, crash recovery 기능이 있기는 하지만 이 기능때문에 성능이 더욱 더 저하되는 등의 문제점이 있었다고 한다.\n\n3. Log-structured file system §\n\nLFS 의 위와 같은 문제점을 해결하기 위한 가장 핵심 키워드는 이것 두개이다:\n\nMemory cache 에 변경사항들을 sequential 하게 buffering\n모든 변경사항을 한번의 writing operation 에서 디스크에 sequential 하게 write\n\n\n이러한 방법을 이용해 LFS 는 random synchronous small write 를 sequential asynchronous large-amount write 로 변환하고, 결과적으로 대역폭을 최대로 활용할 수 있게 한다.\n원리는 간단하긴 하지만 이로인해 발생하는 두가지 문제점이 있고, 이들을 3번 섹션 에서 다루고자 한다.\n\n어떻게 sequential update log 에서 원하는 데이터를 읽어올 수 있을까? - 3.1 섹션\n어떻게 sequential write 에 필요한 free space 들을 확보할 수 있을까? 3.2, 3.3, 3.4, 3.5, 3.6 섹션\n\n\n\n3.1. File location and reading §\n\nLog-structured 에서는 새롭거나 변경된 데이터가 log 에 기록되기 때문에 log 에서 원하는 데이터를 읽어들이기 위해서는 선형 탐색 (아마 최신 log 부터 거슬러 올라가는 방식으로) 을 해야 될 것 같으나, LFS 는 그런식으로 구현되지 않았다.\nLFS 는 기존의 FFS 와 거의 비슷하거나 조금 더 빠르게 데이터를 읽어들이는 것을 목표로 한다.\nLFS 에서 random access read 를 지원하기 위해 도입한 것이 index structure 이다.\n\nIndex structure - inode map §\n\n일단 LFS 나 FFS 나 기본적인 데이터 구조는 동일하다:\n\n동일하게 inode 를 사용하고,\n여기에는 권한같은 metadata 와\ndirect, indirect block 들의 주소가 저장됨\n\n\n따라서 inode 를 찾은 이후에는 (direct 혹은 indirect block 을 따라가서 read 하면 되므로) IO 횟수는 LFS 나 FFS 나 동일하다.\n그럼 이제 LFS 의 read 성능을 FFS 와 비슷하게 유지하려면 inode 를 어떻게 찾냐가 관건일 것이다:\n\n일단 FFS 에서는 inode 의 위치가 정해져 있었다. inode number 를 이용해 간단한 계산으로 inode 의 주소를 계산해 낼 수 있었다.\n하지만 LFS 에서는 inode 가 정해진 위치에 저장되지 않고 log 내의 어딘가에 저장된다.\n이것이 LFS 에서 inode map 을 도입한 이유이다:\n\n==inode map 은 file id number 와 inode 주소를 연결지어 놓은 테이블==이다.\n따라서 file id number 를 알면 inode map 을 통해 inode 가 어디에 있는지 바로 알 수 있다.\n\n\n그럼 이 inode map 은 어디에 있는가\n\n일단 이놈은 block 단위로 쪼개어져 log 에 포함되게 되고\n이 inode map 을 구성하는 block 들의 위치는 Checkpoint Region 이라 불리는 log 밖의 고정된 위치에 저장되게 된다.\n\n\ninode map 은 생각보다 작고, 따라서 (물론 전부가 memory 에 올라가지는 못하더라도) inode map 의 active portion 1 은 memory 에 캐싱되어 inode map 을 접근하는 과정은 disk 에 거의 접근하지 않는다고 한다.\n\n\n정리하자면, checkpoint region 을 통해 inode map 의 block 을 찾고, 이걸 통해 inode 를 찾은 후에는 FFS 와 동일하게 작동하는 것이다.\n아래 그림은 LFS 와 FFS 의 작동 data lookup 과정을 그린 것이다.\n\nLFS 에서 inode map 으로 inode 를 찾아가는 점선 화살표를 제외하면 양쪽은 동일한 과정을 거쳐서 data block 을 찾게 된다.\n하지만 차이점이라면, FFS 보다 LFS 가 더 공간을 컴팩트하게 활용하고 있다는 것이다.\n\n\n\n\n3.2. Free space management: segments §\n\n시간이 흐르면 log 가 점점 쌓여서 더 이상 공간이 없게 되고 이때 free space 는 유효한 데이터와 더불어 삭제되었거나 변경된 파일들로 채워지게 된다.\n따라서 모종의 작업을 하여 이 free space 를 확보하는 것이 필요하다.\n이것을 위해서는 Threading 과 Copying 두가지 방법을 사용할 수 있다고 한다.\n\nThreading §\n\n\n위 그림에서 New data block 이랑 Previously deleted block 이 잘 구분 안되긴 한데\nThreading 이란 live data 를 그냥 냅둔 상태로 sequential write 시에 live data block 을 만나면 건너뛰는 것이다.\n\n그리고 이때 log block 사이의 pointer 는 유지되어 crash recovery 에 사용된다 2.\n\n\n장점은 당연히 cost 가 적다는 것이다: 데이터를 복사하는 과정이 없기 때문에 당연히 적은 비용으로 수행할 수 있다.\n단점은 benefit 이 적다는 것이다: live data block 이 모여있지 않고 듬성듬성 있기 때문에, free space 들이 파편화되게 되고, 따라서 큰 파일을 write 하는 것이 불가능하거나 3 기존의 FS 에 비해 성능 개선이 많이 이루어지지 않게 된다.\n\nCopying §\n\n\n다음 방법은 Copying 으로, 이것은 live data block 들을 압축하여 log 의 시작점으로 옮기는 방법을 의미한다.\n\n물론 log 시작점이 아니라 다른 FS 나 다른 LFS 로 옮길 수도 있다고 한다.\n\n\n장단점은 Threading 의 반대이다.\n즉, 장점은 live data 들이 압축되어 log 시작점이 모이기 때문에 비교적 큰 크기의 free space 를 확보하는 것이 가능하기에 성능 저하가 적은 (benefit 이 많은) 것이지만\n단점으로는 live data 를 복사해야 되기 때문에 여기서 발생하는 overhead 가 있어 cost 가 크다는 것이다.\n\n특히 long-lived data 에 대해서는 이러한 문제가 더 심하게 발생한다 4.\n\n\n\nHybrid (Segment) §\n\nLFS 는 Segment 라는 단위에 대해 위 방법 둘 모두를 이용해서 trade-off 상황에 대한 타협점을 찾는다.\n디스크 전체를 고정크기에 sequential write 만 가능한 Segment 로 나누고, segment 내에서는 copying 을 수행한다.\n\n즉, segment 내의 live data 들은 압축되어 복사된다.\n\n\n그리고 segment 외부적으로는 threading 을 수행한다.\n\n만일 하나의 segment 에 대해 live data 로 전부 채워져 있다면, 해당 segment 는 건너뛰는 것.\n\n\nSegment 는 크기가 꽤 크다. (512KB ~ 1MB) 따라서 segment 에 대한 seek time 은 segment 의 데이터를 read/write 하는 시간에 비해 상대적으로 작아지고, 따라서 대역폭을 최대로 활용할 수 있게 된다.\n\n3.3. Segment cleaning mechanism §\n\nSegment 에 대해 copying 작업을 수행하는 것을 Segment Cleaning 이라고 한다.\n세 단계에 의해 이루어 진다:\n\n여러 개의 segment 들을 메모리로 읽어들인 뒤,\n그 안에서 live data 를 선별해 내고\n더 적은 수의 segment 들로 이 live data 를 복사해 넣고 읽어들인 segment 들은 clean 으로 마킹해 놓는다.\n\n\n\nSegment summary information §\n\nSegment cleaning 과정에는 이 두 문제점이 있다:\n\n어떻게 live data 를 구별해 낼 것인가?\n어떻게 live data 의 소속 (해당 live data 를 소유한 file) 을 알아내 주소가 변경되었음을 inode 에 반영할 것인가?\n\n\nLFS 에서는 이 문제를 segment 별로 Segment Summary Information 을 유지하는 것으로 해결했다.\n여기에는 segment 의 block number 와 file number 간의 mapping 이 되어 있다.\n\n이렇게 하면 일단 문제점 (2) 는 해결된다: block number 를 통해 file number 를 알 수 있고, 따라서 inode map 을 통해 inode 를 찾을 수 있게 됨.\n\n\n이 segment summary information 으로 live data 를 식별해 내는 것은 다음과 같이 할 수 있다.\n\n우선 이것으로 한 block 에 대한 inode 를 찾은 다음\ninode 의 direct, indirect block 이 해당 block 을 여전히 참조하고 있는지 확인하면 되기 때문.\n\n\nSegment summary information 은 segment 당 하나씩 들어가고, 가끔 하나 이상이 들어갈 때도 있다.\n\n이것은 segment 하나를 채우기 위해 하나 이상의 log 가 필요할 때 인데,\nMemory cache 로 부터 들어온 dirty block 들로 하나의 segment 를 채우기는 힘들 때 이런 일이 발생한다고 한다 5.\n\n\nSegment summary information 은 write 작업에 부과하는 overhead 도 적고, crash recovery 등에서도 사용될 수 있어 아주 유용하다고 하네\n\nInode map version number field §\n\nSegment summary information 으로 live data 를 선별해 내는 과정은 inode map 에 version number 필드를 추가하는 것으로 최적화가 가능하다.\n해당 필드의 값은 파일이 삭제되거나 파일 사이즈가 0이 되면 증가한다.\n\n라고 저자는 말하고 있지만 일단은 그냥 말의 의미에 충실하게 파일 데이터가 변경되면 version number 도 올라가는 것으로 생각하자.\n\n\nFile number 와 version number 를 합친 것을 UID (Unique ID) 라고 하고, 이놈을 이용해 liva data 를 더욱 빠르게 선별해 낼 수 있다.\n\n일단 segment summary information 에 file number 가 아닌 UID 와 block number 를 매칭시켜 놓는다면\n해당 block 이 어떤 file 의 어떤 version 에 mapping 되어 있는지 저장되어 있는 셈이다.\n이때 inode map 에 있는 file number + version number 와 비교해 봤을 때, 일치한다면 변경점이 없다는 의미이기 때문에 live data 인 것이고,\n반대로 일치하지 않는다면 변경된 것이 있다는 의미이기 때문에 live data 가 아닌 것으로 판단할 수 있는 것.\n\n\n여기까지 본다면 LFS 에는 free space 를 위한 list 나 bitmap 이 없다는 것을 알 수 있을 것이다.\n\n얘네들은 추가적인 memory 와 저장공간을 필요로 하고 crash recovery 를 어렵게 만들기에, 이것을 없애는 것은 분명한 개선이다.\n만일 쟤네들이 있었다면, 이것의 crash recovery 를 위한 추가적인 parity 도 필요했을 것이다.\n\n\n\n3.4. Segment cleaning policies §\n\nSegment Cleaning 을 위해서는 다음의 네 가지 정책이 필요하다:\n\n언제 segment cleaning 을 진행할까? 낮은 우선순위의 background 로? 아니면 밤에? 아니면 공간이 없을 때?\n한번에 얼마나 많은 segment 들을 clean 해야 할 까? 더 많이 clean 하면 당연히 free space 도 많이 생기겠지만 그만큼 cleaning cost 도 늘어날 것이다.\n어떻게 cleaning 할 segment 를 선정할까? 가장 파편화가 많이 진행된 segment 가 적절해 보이지만 이것이 정답은 아니었다.\n새로운 Segment 내의 block 들은 어떻게 배치할까? 지역성을 살려서? (가령 같은 디렉토리의 파일 등) 아니면 마지막 변경 시각을 기준으로 정렬해서?\n\n\n저자는 (1) 번과 (2) 번 policy 에 대해서는 크게 다루지 않았다고 한다. 얘네들은 LFS 의 성능에 크게 영향을 끼치지 않았기 때문.\n\n일단 segment cleaning 은 clean segment 가 10 개정도보다 적어지면 진행한다.\n그리고 한번에 10 개정도씩 cleaning 을 진행하고, 50~100 개정도의 clean segment 가 확보되면 멈춘다.\n\n\n반면에, (3) 번과 (4) 번 policy 에 대해서는 LFS 의 성능과 직결되었기 때문에, 면밀한 분석을 진행했다고 한다.\n\nWrite Cost §\n\n일단 이름에서부터 알다시피 클수록 안좋은 값이다.\n정의는 “새로운 데이터 1 바이트를 write 하는 데 걸리는 시간” 이다.\n\n“시간” 이기 때문에 cleaning overhead 뿐 아니라 seek time 등 모든 것을 포함한 모든 것이 고려된다.\n\n\n이 값은 대역폭으로 환산하면 어떤 값인지 더욱 이해가 잘 될것이다: bandwidthRate=1/writeCost 정도로 대역폭으로 환산된다.\n\n즉, writeCost 가 1 이라면 new data write 에 100% 의 대역폭을 활용하고 있는 것이고\n10 이라면 10% 의 대역폭을 활용하고 있는 셈.\n나머지는 cleaning 등에 사용되고 있는 것이다.\n\n\n결론부터 말하자면, LFS segment cleaning 의 writeCost 는 다음과 같이 계산된다:\n\n\n\n이제 왜 저렇게 되는지 살펴보자.\nLFS 의 경우에는 segment 의 크기가 크기 때문에, seek time 과 latency time 등은 무시된다.\n\n위에서 말한 것처럼, r/w 에 걸리는 시간이 더 크기 때문.\n\n\n따라서 write cost 를 다음과 같이 추산할 수 있다.\n\nwriteCost=totalWriteTime/writeNew 에서\ntotalWriteTime 에 (1) seek time, (2) latency time, (3) cleaning 에서의 segment 를 읽는 시간, (4) cleaning 에서의 live data 를 write 하는 시간, (5) 새로운 데이터에 대한 write time 이 포함되는데,\n(1) 과 (2) 는 무시할 수 있으므로 나머지 (3 + 4 + 5) 를 새로운 데이터에 대한 write 시간 (5) 로 나눈 값이 writeCost 이다.\n즉, writeCost=(readSegs+writeLive+writeNew)/writeNew 가 되는 것.\n\n\n여기서 segment utilization factor 를 u 라고 하자.\n\n이 값은 cleaning 을 하려고 하는 segment 들에 대해 live data 가 차지하고 있는 비중 (0 ≤ u ≤ 1) 이다.\n즉, 이 값은 cleaning 이후에 남아있게 되는 data 의 양이라고 생각할 수 있다.\n\n\n그리고 segment 들의 byte 크기를 N 라고 하자.\n그럼 각각의 값들은 u 와 N 으로 표현된다 6:\n\nreadSegs=N : cleaning 작업에 segment 전체를 읽는다는 가정하에, N byte 를 읽어들임\nwriteLive=N∗u : cleaning 작업에서 live data 만이 복사되어 write 되기 때문에, segment 크기에서 live data 가 차지하는 비중만이 write 됨\nwriteNew=N∗(1−u) : cleaning 의 결과로 확보된 나머지 공간에 새로 write 가 가능하기 때문에 전체 사이즈에서 live data 가 차지하는 사이즈를 뺌\n\n\n결국에는 위의 그림과 동일하게 되는 것이다.\n\n다만, 몇가지 예외? 랄 것이 있다.\n만약 live data 가 하나도 없을 때에는 cleaning 이 발생할 필요가 없기 때문에, writeCost 는 1이다.\n\n\n\nChoosing a segment to clean §\n\n\n위 그래프는 FFS today (기존의 UNIX FFS) 와 FFS improved (logging 및 delay writing 을 도입한 UNIX FFS 의 개선판) 에서의 write cost 에 대한 그래프이다\n\n실선이 LFS 에 대한 u - writeCost 관계\n굵은 점선은 FFS today 에 대한 u - writeCost 관계\n얇은 점선은 FFS improved 에 대한 u - writeCost 관계\n\n\n보면 FFS today 는 write cost 가 10 (대역폭이 10%) 정도 나오고, FFS improved 는 write cost 가 4 (대역폭이 25%) 정도 나오는 것을 볼 수 있다.\n이것을 기준으로 LFS 에서 어떤 segment 를 cleaning 할 지 정해보자.\n\n만약에 LFS 가 FFS today 보다 나은 성능을 보여주고 싶다면, u 가 0.8 인 segment 를 clean 하면 될 것이다.\n그리고 FFS improved 보다 나은 성능을 보여주고 싶다면, u 가 0.5 인 segment 를 clean 하면 된다.\n\n\n근데 여기서 관심을 가지는 utilization 이 disk 전체가 아니라 cleaning 하고자 하는 segment 이기 때문에, 어떤 segment 는 평균보다 낮은 utilization 을 보여줄 수도 있고, 이때에는 제일 under-utilized 한 segment 를 선택할수도 있다 한다…\n여기에서도 cost 와 benefit 사이에 trade-off 가 있다.\n\nUtilization 이 낮아지면 대역폭은 올라가 더 성능은 좋아지지만\n말 그대로 사용하는 비율이 적어지는 것이기에 저장할 수 있는 데이터의 양은 더 적어진다.\n하지만 이러한 경향성은 LFS 에만 적용되는 것은 아니다; FFS 도 최대 90% 만 사용하게 하는 제한이 걸려 있다.\n\n\n이 trade-off 를 상쇄하기 위해서 특정 segment 는 거의 빈 상태로 놔두고 나머지 segment 들을 거의 다 채울 수 있게 하는 bimodal segment distribution 전략을 취할 수 있다. (이 내용이 다음 문단 부터 나온다.)\n\n3.5. Simulation results §\n실험 방법 §\n\n저자는 locality 를 고려했을 때 어떤 cleaning policy 를 선택해야 cost 가 적게 나오는지 분석하기 위해 간단한 시뮬레이터를 만들었다고 한다.\n\n실험 환경은 실제 사용환경보다는 더욱 더 혹독하지만 locality 분석에 많은 도움이 되었다네\n\n\n이 실험은 다음과 같은 방식으로 진행됐다:\n\n디스크 용량의 일정 비율 (Disk capacity utilization) 이 채워지도록 FS 에 4KB 파일들을 생성한다.\n\n만일 디스크 용량이 2MB 이고, disk capacity utilization 을 0.5 로 정했다면, 1MB 를 채우기 위해 4KB 파일을 250개 생성한 것.\n\n\n해당 파일들을 지속적으로 overwrite 한다.\nOverwrite 로 인해 모든 clean segment 들이 소진된다면, segment 들이 다시 확보될때까지 segment cleaning 을 한다.\nWrite cost 가 안정화되면 실험을 종료한다.\n위의 작업을 disk capacity utilization 을 변화시키며 반복한다.\n\n\n이때, overwrite 와 segment cleaning 은 아래와 같은 두 가지 방식 (Uniform, Hot-and-cold) 을 이용한다:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUniformHot-and-coldAccess rate모든 파일에 대해 동일한 확률로 overwrite차등적인 확률로 overwrite (10% 의 파일들에 대해서는 90% 의 확률로 overwrite 하고 - hot, 나머지 90% 의 파일들에 대해서는 10% 의 확률로 overwrite 함 - cold)Cleaning policyGreedy - Utilization 이 가장 낮은 segment 부터 cleaning(마찬가지로 greedy 하게)Live block reorganizeRead 한 순서 그대로 write 함Age 에 따라 정렬해서 write 함\n\n여기서 hot-and-cold 에서 age 에 따라 정렬해서 write 하게 되면 자연스럽게 segment 단위로 hot data 와 cold data 가 분리되는 효과를 가진다.\n\n즉, hot segment 와 cold segment 가 나뉘게 되는 것\n\n\n추가적으로, 편의를 위해 다음의 것은 고려하지 않았다고 한다..\n\nread traffic\ncold start 7\n\n\n\n실험 결과… §\n\n\n일단 각 선들이 어떤 의미를 가지는지 부터 살펴보자.\n\n점선 (널찍): FFS today - 기존의 UNIX FFS\n점선 (촘촘): FFS improved - 기존의 UNIX FFS 에서 조금 더 개선된 버전\n실선 (얇): No variance 방식 - 모든 segment 들이 동일한 utilization 을 가진다고 가정했을 때, write cost 의 변화\n실선 (굵): Uniform 방식을 사용했을 때\n점선 (널찍-촘촘): Hot-and-cold 방식을 사용했을 때\n\n\n그래프가 오른쪽 아래로 깔릴수록 더 좋다 - disk capacity util 이 늘어나도 성능 방어를 잘 해 write cost 가 많이 늘어나지 않는다는 의미이기 때문\n\n\n\n                  \n                  논문에서의 75%, 55% 의 의미 \n                  \n                \n\n본문에는 “For example, at 75% overall disk capacity utilization, the segments cleaned have an average utilization of only 55%.” 라는 문장이 나온다.\n이것은 말 그대로 disk capacity util 을 75% 로 설정했을 때 segment util 은 그보다 작은 55% 가 나온다는 소리이다. 즉, segment util 은 적을수록 write cost 가 적어지므로 더 좋다는 의미.\n근데 저 수치는 어떻게 나온 것이냐: 75% 의 disk capacity util 일때 LFS Uniform 의 write cost 값을 No variance 그래프를 이용해 util 로 바꿔보면 55% 가 나온다. (위 그래프에서 빨간색 점선)\n\n\n\n일단 uniform 방식이나 hot-and-cold 방식을 이용할 때나 모두 no variance 일때보다 write cost 가 적게 나왔다.\n\nUtil 이 20% 아래로 떨어졌을 때에는 write cost 가 2 아래로 떨어진다; 이것은 live block 이 아예 없는 segment 가 존재해 cleaning 이 발생하지 않아 write cost 가 1 이 되기 때문.\n\n\n근데 여기서 문제점은 locality 가 고려되면 더 성능이 좋아질 줄 알았는데 locality 가 고려되지 않은 uniform 이 더 결과가 좋았다.\n\n즉, 같은 data capacity util 기준 uniform 에서보다 hot-and-cold 에서 write cost 가 더 높게 나왔다.\n\n\n\n결과가 예상대로 나오지 않은 이유 §\n현상 - 많은 cold segment 들이 cleaning 되고 있지 않다. §\n\nGreedy policy 에서는 segment 의 util 이 다른 segment 보다 작아져야 cleaning 이 진행된다.\n따라서 cold segment 를 포함한 모든 segment 의 util 이 cleaning threshold 까지 떨어지게 된다.\n\n\n\n                  \n                  논문에서의 &quot;Cleaning Threshold&quot; 의 의미 \n                  \n                \n\n여기서 cleaning threshold 는 특별하게 설정된 값은 아닌 것으로 보인다.\nGreedy policy 에서 cleaning 의 대상으로 선정되는 segment 의 util 최소값이 threshold 인 것.\n\n\n\n하지만 cold segment 는 util 이 아주 천천히 떨어지기 때문에, 대부분의 cold segment 들이 threshold 근처에서 cleaning 되지 않고 오랜 기간 머물게 된다.\n\n다르게 말하면, cold segment 가 hot segment 보다 utli 이 천천히 떨어지기에 cleaning 대상 선정 경쟁에서 밀리게 되는 것.\n\n\n결과적으로 cold segment 들은 outdated block 들을 오랜 기간동안 품고 놔주지 않게 된다.\n이것을 그래프로 확인해 보면 아래와 같다:\n\n\n\n위 그래프는 모든 segment 들에 대한 segment util 별 분포도이다.\n\n뭐 대략 특정 segment util 을 갖는 segment 의 개수 (물론 개수는 아니긴 하지만 8) 라고 생각하고 넘어가자\nDisk cap util 이 75% 인 상황을 시뮬레이션하던 중에, cleaning 이 시작되었을 때 집계한 것이라고 한다.\n\n\n그래프를 보면 seg util 이 55% 정도가 될 때 cleaning 이 시작되는 threshold 가 형성된다고 볼 수 있는데\nUniform 일 때보다 hot-and-cold 일 때 threshold 근처에 더 많은 segment 들이 몰려있는 것을 볼 수 있다.\n\nhot segment 보다 cold segment 의 개수가 훨씬 더 많고,\n이런 많은 cold segment 들이 threshold 근처에 잔류하고 있기 때문에 위와 같은 모양이 되는 것.\n\n\n\n이런 현상이 어떻게 결과로 이어질까? §\n\nCold segment 와 hot segment 의 util 감소 속도를 생각해 보면, cold 와 hot 에서의 outdated block 이 가지는 가치가 다르다는 것을 알 수 있다.\n\nHot 의 경우에는 어차피 outdated block 을 clean 해 봤자 조만간 다시 write - overwrite 되어 outdated 될 것이고\nCold 의 경우에는 outdated block 가 잘 생성되지 않고 해당 outdated block 을 clean 했을 때 다시 outdated 로 돌아오기에는 시간이 꽤 걸릴 것이기 때문.\n\n\n하지만 가치가 낮은 hot segment 들의 outdated block 이 경쟁에서 이겨 지속적으로 cleaning 되고 있으니 더 안좋은 결과가 나오는 것 9.\n\n이것을 어떻게 하면 해결할 수 있을까? §\n\n결론적으로는, block 의 stability 가 value 에 영향을 미치고, 이러한 value 를 고려해서 cleaning 을 진행해야 한다.\n\nValue 가 높은 cold segment 의 outdated block 은 조금만 생겨도 cleaning 을 하고, value 가 낮은 hot segment 의 outdated block 은 많이 생길때 까지 기다렸다가 cleaning 을 하면 되는 것\n\n\n하지만 실제 상황에서는 미래의 block 접근 패턴을 알기 어렵기 때문에, stability 을 산출하는 것은 어려움이 있다.\nLFS 에서는 stability 의 척도로 age 를 사용한다.\n\n즉, segment 의 block 나이가 많을수록 앞으로도 변경 가능성이 낮다고 보는 것.\n\n\n이것을 수치적으로 policy 에 반영한 것이 Cost-Benefit Policy 이다.\n\nCost-benefit policy §\n\nCost-benefit policy 에서는 아래의 수식으로 cleaning 할 segment 를 선정한다.\n\n\n\n이 수식의 의미를 씹뜯맛 해보자.\n일단 cost-benefit policy 에서는 benefit 이 cost 에 비해 큰 순서대로 cleaning 을 진행한다.\n\n즉, benefit/cost 의 값이 큰 순서대로 cleaning 을 진행하는 것.\n\n\n우선 benefit 부터 살펴보자면,\n\n한번의 cleaning 에 많은 free block 들이 생성될 때, 즉 outdated block 이 많을 수록 cleaning 의 효과가 좋을 것이다.\n\n이것은 segment 에서 live block 이 차지하는 비중을 뺀 것이기에, 1−u 로 계산할 수 있을 것이다.\n\n\n또한, 위에서의 가정에 따라 나이가 많을 수록 stability 가 높아져 cleaning 의 효과도 좋을 것이다\n\n이것은 age 값 으로 반영되고, 해당 segment 에서 가장 최근의 변경 시간을 기준으로 한다.\n\n\n따라서 benefit=(1−u)∗age 가 된다.\n\n\n그리고 cost 를 살펴보자.\n\ncost 는 cleaning 과정 중에 수행되는 read 와 write 의 양으로 계산된다.\n\nCleaning 중에는 segment 전체를 read 하고 (1), live block 을 write 할 것이기에 (u), 이 둘을 더한 값 (1+u) 가 cost 가 된다.\n\n\n\n\n이렇게 함으로써 cold segment 는 age 가 올라가게 되어 u 가 작아도 (즉, seg util 이 높아도) cleaning 대상으로 선정되게 된다.\n\n재실험 §\n\nGreedy 대신 cost-benefit policy 를 적용한 결과, 성능이 눈에 띄게 좋아졌다:\n\nCleaning policy 만 변경되었고, reorganize policy 는 age-sorting 으로 동일하게 유지되었다.\n\n\n\n\n\n성능 좋아졌다는 것 이제 말 안해도 아시겠죠?\n그리고 이때 segment 분포는 다음과 같았다.\n\n\n\n보면 cold segment 는 seg util 75% 정도에서 cleaning 이 되었고, hot segment 는 15% 정도에서 cleaning 이 되는 것을 확인할 수 있었다.\n\n3.6. Segment usage table §\n\n\n                  \n                  Draft 입니다. \n                  \n                \n\n\nCost-benefit policy 를 지원하기 위해, Segment Usage Table 이 추가되었다\nsegment usage table 에는 segment 의 live byte count 와 last modified time 이 들어간다\n\n이 값들은 segment 에 write 되기 시작할 때 채워지고, 데이터가 삭제/변경되며 live byte count 가 내려간다\nlive byte cound 가 0 이 되면 clean 없이 사용 가능\n\n\nsegment usage table 의 block 들은 log 에 저장되고 checkpoint 에 해당 block 들이 어디에 있는지 저장된다\nSegment summary information 에는 가장 어린 block 의 나이를 기록한다.\n\nLFS 에서는 file 을 block 단위로 modify time 을 체크하지는 않는다.\n대신 파일 전체 단위로 modify time 을 체크하기에 전부가 바뀌는 것이 아닌 일부 block 만 바뀌는 경우에는 이 시간이 변경되지 않는다.\n따라서 추후에는 block 단위 modify time 을 넣으려고 한다고 한다.\n\n\n\n4. Crash Recovery §\n\n\n                  \n                  Draft 입니다. \n                  \n                \n\n\n일반적으로 crash 가 발생하게 되면 reboot 중에 이것을 다 고치게 되는데\nLogging 기능이 없던 UNIX FS 의 경우에는 어쩔 수 없이 모든 metadata 를 뒤지며 파일이 정상적으로 존재하는지, 누락된 데이터는 없는 지 등을 체크한다.\n하지만 이것은 몇십분이나 되는 시간을 먹게 되는 문제점이 있었다\n하지만 LFS 에서는 마지막 로그에 마지막 작업이 남아있기 때문에 문제가 생겼을 만한 데이터의 범위를 쉽게 좁힐 수 있고, 따라서 빠르게 복구가 가능하다\nCrash recovery 를 위해서는 checkpoint 와 roll-forward 기술이 사용된다.\n\n4.1. Checkpoints §\n\n\n                  \n                  Draft 입니다. \n                  \n                \n\n\nCheckpoint 는 한 시점에서의 로그를 가리키고, 이 시점에서는 모든 FS 의 구조와 데이터들이 일관되고 완료되었다는 의미를 가진다.\n\n말이 좀 모호하긴 한데 이상하게 생각할 것은 없다; 그냥 언제든 이 시점으로 돌아와도 정상작동한다고 정도로 생각하자\n\n\n모든 변경사항들을 log 에 적고\n위에서도 여러번 언급한 checkpoint region 을 디스크의 특정한 위치에 적는다.\n\ninode map, segment usage table 들의 block 위치\n현재 시간\n마지막 segment 의 위치\n\n\n재부팅 중에 이 checkpoint region 을 읽어서 메인 메모리 데이터 구조를 초기화함\nHA 를 위해 두개의 checkpoint region 을 갖고 있다\ncheckpoint operation 에서 두개의 checkpoint region 을 바꾼다?\ncheckpoint time 은 checkpoint region 의 마지막 block 에 있기 때문에 checkpoint operation 이 실패할 경우 이 시간이 업데이트되지 않는다\ncheckpoint operation 에서는 두 checkpoint region 을 모두 확인하고 더 일찍 생성된 놈을 사용한다.\n주기적, fs unmount, system shutdown 때 이 checkpoint 를 생성한다\n이 주기가 짧으면 recovery 시 더 최신의 checkpoint 가 사용되기에 더욱 신뢰성이 있지만, 생성의 오버헤드가 있고 주기가 긴 경우에는 반대\n보통 LFS 에서는 30초로 설정\n이것도 너무 길다\n대안으로는 특정 양의 새로운 데이터가 작성되었을 때 수행하는 것\n이것은 recovery time 을 일정하게 유지하고 checkpoint overhead 를 줄일 수 있다\n\n4.2. Roll-forward §\n\n\n                  \n                  Draft 입니다. \n                  \n                \n\n\n문제가 생겼을 때 재부팅을 해서 checkpoint 로 돌아가는 것은 간단하고 빠른 해결방법이지만 checkpoint 이후의 데이터는 손실될 가능성이 있다\n따라서 마지막 checkpoint 이후의 log 를 보면서 추가적인 복구를 하는 것이 roll-forward 이다\nsegment summary information 을 보면서 최근에 write 된 block 을 찾고\n만약 해당 block 이 inode 라면 그것을 inode map 에 추가한다\n\n이것은 해당 inode 와 연결된 data block 까지 복구되는 효과를 가진다\n\n\n만약 해당 block 이 data block 이고, 연결된 inode 가 없다면 해당 write 가 완료되지 않은 것으로 간주해 복구하지 않는다. (아무짓도 안함)\nroll-forward 작업에서는 checkpoint region 의 segment usage table 의 utilization 값도 재조정한다.\n\ncheckpoint 이후에 추가된 데이터에 대한 segment util 은 0으로 표기되어 있을 것이기에, 재조정\n마찬가지로 checkpoint 이후에 삭제/변경된 데이터에 대한 segment util 로 재조정\n\n\n\nDirectory operation log §\n\n\n                  \n                  Draft 입니다. \n                  \n                \n\n\ndirectory 내용이 변경되었을 경우 LFS 는 Directory Operation Log 라는 특별한 record 를 log 에 추가한다.\n\n어떤 작업인지 (operation code)\n변경된 directory entry 의 위치 (directory 에 대한 inode number 및 directory 내에서의 index)\n변경된 directory entry 내용 (파일의 inode number 및 파일 이름)\n변경된 directory entry 에 해당하는 파일의 inode reference count\n\n\n이 정보들을 이용해 directory entry 와 inode 간에 일관성을 유지한다.\n\ndirectory entry 변경에 대한 log 는 있지만 inode 나 directory block 가 없다면, roll-forward 시에 directory 혹은 inode 를 생성한다.\n\n\n\n\n5. Experience with the Sprite LFS §\n\nLFS 는 1989 년부터 개발되기 시작해 1990 년 중반에 이르러서는 Sprite network OS 에서 사용되기 시작했다고 한다.\n1990년 후반에는 5개의 디스크 파티션을 관리하며 30여명의 사용자들이 사용했다.\n이때 당시에는 위에 기술된 내용 중 거의 모든 기능들이 구현되었다고 한다.\n\n단지 Roll-forward 만 구현이 안되어 있었다.\n따라서 30초 간격으로 Checkpoint 를 생성하게 되고, Reboot 이후에는 checkpoint 에 저장된 내용외에는 전부 다 날라간다.\n\n\n처음에 개발을 시작할 때에만 해도 LFS 의 구현이 FFS 보다 어려울 것으로 생각했지만, 결과적으로는 그렇지 않았다.\n\nSegment cleaning 의 구현이 까다롭기는 했지만, FFS 의 Bitmap 이 제거되었기에 이것이 상쇄되었고\nCheckpoint 와 roll-forward 는 FFS 의 crash recovery 를 위한 툴인 fsck 에 비해 구현이 어렵지 않았다고 한다.\n\n\n실 production 환경에서는 성능 향상이 그렇게 드라마틱하게 나타나지 않았는데, 이것은 해당 환경에서 디스크에 병목이 생기는 것이 아닌 cpu, mem 측면에서 속도가 나오지 않았기 때문이었다고 한다.\n\n5.1. Micro-benchmarks §\n\nSprite LFS 는 UNIX FFS 가 돌고 있는 SunOS 4.0.3 과 비교해서 벤치마크를 돌렸다.\n\n물론 이 벤치마크들은 실 사용환경과는 차이가 있긴 하지만, 둘 간의 차이점을 극명하게 보여줬다고 한다.\n\n\n작동 환경은:\n\nSun-4/260 머신 + 32MB 메모리 + Wren 4 디스크 (1.3Mbyte/s 대역폭 + 17.5밀리초의 seek time)\n각 디스크는 300MB 정도의 공간을 사용할 수 있도록 포맷\nSunOS 는 8KB block, LFS 는 4KB block + 1MB segment 를 사용\n여러명의 유저가 사용\nLFS 의 경우 실험 도중에는 cleaning 이 작동하지 않음 - 최대의 성능이 나오는 상태\n\n\n\nSmall file benchmark §\n\n\n위 그래프는 작은 파일들을 create, read, delete 했을 때의 결과다.\n\n왼쪽이 측정 결과, 오른쪽이 예상\n\n\n보면 create 와 delete 시 SunOS 에 비해 10배정도 더 빨랐다.\n또한 read 의 경우에도 더 빨랐다\n\n생성된 순서로 read 를 했고, 여기 에서 설명한 것처럼 파일을 더 밀집해서 저장하기 때문\n\n\nCreate 실험 당시에 LFS 는 총 실험 시간 중 17% 의 시간에 디스크 부하가 걸린 반면 CPU 는 최대로 사용했다.\n\n반면, SunOS FFS 의 경우에는 85% 가 부하가 걸렸고, 디스크 대역폭의 1.2% 밖에 사용하지 못했다.\n\n\nLFS 의 실험 결과는 CPU 때문에 디스크에 17%밖에 부하가 걸리지 않았기에 만일 CPU 가 더 빨라진다면 성능이 더욱 개선될 것으로 보였다.\n\nLarge file benchmark §\n\n\nLFS 는 small file 접근에 특화되어 있었지만, large file 에도 꿀리지 않는 성능을 보여줬다.\nWrite 의 경우에는, random/sequential 모두 대역폭이 향상되었다.\n\n특히 random write 에서 큰 성능 향상이 있었는데, 이것은 random write 를 LFS 가 sequential write 로 변환하기 때문이었다.\n또한 Sequential write 에서 성능 향상을 보인 것은 SunOS FFS 에서는 각 block 에 대해 IO 가 처리되지만 LFS 에서는 memory 에 많은 블럭을 버퍼링해서 하나의 IO 으로 처리하기 때문이었다.\n물론 최신의 SunOS 에서도 이러한 버퍼링 기능을 지원하고, 따라서 이 경우에는 성능이 비슷할 것이다.\n\n\nRead 의 경우에는 비슷한 성능을 보였으나 random write 이후 sequential read 를 하는 경우 (Reread sequential) 은 큰 성능 저하를 보였다.\n\n이것은 LFS 에서는 이 상황에서 read seek 이 들어가기 때문이라고 한다 10.\n\n\n\nFFS vs LFS §\n\nFFS 의 locality 방식은 Logical locality 라고 할 수 있다:\n\n이 말인 즉슨, FFS 에서는 사용자들의 일반적인 파일의 접근 패턴에 맞게 데이터를 인접하게 배치 하여 locality 를 구현한다.\nDirectory 의 파일들을 하나의 cylinder group 에 넣어놓는 것을 예시로 들 수 있다: directory 의 파일들은 같이 접근하는 경우가 빈번하다는 접근 패턴을 이용한 것.\n따라서 FFS 에서는 이 패턴에 맞게 데이터를 배치하기 위해 추가적인 write 도 감당한다.\n\n\n반면, LFS 의 locality 방식은 Temporal locality 라고 할 수 있다:\n\n즉, 한번 접근한 데이터는 곧 다시 접근할 확률이 높다는 가정 하에 생성/변경 시간이 유사한 데이터를 인접하게 배치 하는 locality 방식이다.\n\n\n이런 방식의 차이는 둘 간의 장단점을 명확하게 보여준다 (!정리 필요):\n\n만일 logical locality 와 temporal locality 가 일치된다면 (= 생성/변경된 순서대로 데이터에 접근 = 가령, sequential write + sequential read), LFS 와 FFS 는 동일한 성능을 보인다.\n그리고 이것이 일치되지 않는다면 (= 생성/변경된 순서와 다르게 데이터에 접근 = random write + sequential read 혹은 sequential write + random read) 다른 성능을 보일 것이다.\nSprite LFS 는 random write 를 sequential 로 변환하기에 더 효율적으로 처리한다.\nSunOS FFS 는 logical locality 를 위해 추가적인 비용을 들이며 random write 를 구현한다.\n따라서 SunOS FFS 의 경우에 sequential re-read 를 더 효율적으로 처리하는 것\n하지만 non-sequential read 가 non-sequential write 와 동일한 순서로 요청되면 (순서가 동일하기 때문에) Sprite LFS 가 더 효율적이다.\n\n\n\n5.2. Cleaning overheads §\n\n\n                  \n                  Draft 입니다. \n                  \n                \n\n\n5.1 섹션에서의 벤치마크는 cleaning 이 돌지 않았기에, write cost 가 1인 최적의 상태를 보여줬다.\n\n따라서 이 벤치마크는 “Optimistic benchmark” 라고 할 수 있다.\n\n\n이에 대조적으로, cleaning 성능을 보기 위해 저자는 몇달에 걸친 실사용 벤치마크를 수행했다.\n\n이 벤치마크는 “Pessimistic benchnark” 인 셈이다.\n\n\n벤치마크는 다음과 같이 수행되었다고 한다:\n\n5개의 디렉토리 모니터링\n\n/user6: 사용자들이 사용하는 홈 디렉토리. 여기서 사용자들은 프로그램 개발, 문서작성, 시뮬레이션 등을 수행한다고 한다.\n/pcs: 병렬처리 등을 연구하는 용도의 디렉토리.\n/src/kernel: Sprite kernel 의 소스코드와 바이너리\n/swap2: Sprite client workstation (아마 시스템에 원격으로 접속해서 사용하는 것) 에 대한 swap 파일들. 여기에서는 virtual memory swap 파일이 주로 저장되고, 보통 큰 사이즈에 non-sequential access 가 수행된다.\n/tmp: 임시 파일들\n\n\n세팅 직후 초기상태에서의 영향을 없애기 위해 몇달 기다린 후 측정 시작해서 몇달에 걸쳐 측정함.\n\n\n벤치마크 결과 3.5 섹션에서의 시뮬레이션보다 더 좋았다고 한다.\n\n벤치마크 동안 disk cap util 은 11%75% 정도로 유지되었는데, 시뮬레이션 결과 에 비춰보면 write cost 는 2.53 정도로 예상되었다.\n하지만 실제로는 1.2~1.6 이라는 놀라운 결과가 나왔다.\n\nSegment cleaning 수행시, 절반이 넘는 segment 들이 완벽하게 비워진 상태로 종료되었고,\n완벽하게 지워지지 않고 live block 을 담고 있는 segment 들도 seg util 이 평균 disk util 보다 훨씬 적었기에 이런 결과가 나온 것.\n\n\n\n\n이러한 결과가 나온 이유는 다음과 같다:\n\n일단 파일의 크기가 시뮬레이션에 비해 더 크다. 시뮬레이션의 경우에는 1 block 사이즈의 동일한 파일들이었다면, 실 사용에서는 수 block, 심지어 segment 보다도 큰 파일들이 생성되다 보니 통으로 write-overwrite-clean 되는 경우가 많았고, 더 좋은 locality 도 보여주었다.\nCold 와 hot 간의 access 빈도가 더 극명했다. 시뮬레이션에서는 1:9 의 비율이었지만, 실제로는 아예 overwrite 가 되지 않아 clean 이 한번도 이루어지지 않은 파일들도 존재했다.\n\n\n이 벤치마크를 통해 몇가지 추가적으로 개선할 수 있는 것들은:\n\n밤이나 한가한 시간에 cleaning 을 진행해서 사용량이 많은 시간대에 cleaning 이 발생되지 않게 하는 방법도 가능\n\n\n\n5.3. Crash recovery §\n\n\n                  \n                  Draft 입니다. \n                  \n                \n\n5.4. Other overheads in Sprite LFS §\n\n\n                  \n                  Draft 입니다. \n                  \n                \n\n6. Related work §\n\n\n                  \n                  Draft 입니다. \n                  \n                \n\n7. Conclusion §\n\n\n                  \n                  Draft 입니다. \n                  \n                \n\n\n\n                  \n                  Quiz \n                  \n                  \n                \n                \n\nDisk traffic will become more and more dominated by (writes)\nToo many (small access)\nThe disk traffic is dominated by (synchronous) metadata writes\nWrite all the changes to disk in a sequential structure called the (log)\nThe sequential nature of logs permits much faster (crash recovery)\nThe locations of the inode map blocks are kept in a fixed (checkpoint region) on disk\nThe log can be (rewritable) through clean segments\nThe transfer time to read/write a whole segment should be much greater than the cost of a (seek to the begining of the segment)\nLive if the block is still pointed by (direct/indirect block in inode)\nNot live if the file’s version number (in the segment summary block) does not match the version number stored in (inode map)\nChoose the (least utilized) segments\nChoose the segment with the (highest) ratio of benefit to cost\nFree space in a (cold) segment is more valuable than free space in a (hot) segment\nProduces the (bimodal) distribution of segments\nThe addresses of all the blocks in (inode map) and (segment usage table)\nAdjust the utilizations in the (segment usage table)\n(directory operation log) for each directory change\n\n\nFootnotes §\n\n\n이게 정확히 어떤 것을 의미하는 지는 잘 모르겠음. ↩\n\n\n뭔소린지 모르겠다. ↩\n\n\n이것도 모르겠다. Live data block 을 skip 한다면 결국엔 상관없는 것 아닌가. ↩\n\n\n본문에서는 long-lived data 에서의 문제에 대해 다음과 같은 예시로 설명하지만, 뭔소린지 모르겠다: “In the simplest case where the log works circularly across the disk and live data is copied back into the log, all of the longlived files will have to be copied in every pass of the log across the disk.” ↩\n\n\n어떤 상황인지 잘 감이 안오긴 한다 그쵸? ↩\n\n\n어느샌가 time 에서 byte 로 단위가 바꿔었는데 그냥 그런갑다 하자. ↩\n\n\n이게 뭔지는 잘 모르겠음. Disk capacity utilization 을 바꿨을 때 cold start 를 하지 않는다는 것인가? ↩\n\n\n세로축 “Fraction of segments” 뭔지 모르겠음. ↩\n\n\n많은 cold segment 가 threshold 근처에 잔류하는 것과 write cost 가 올라가는 것에 대해 대강 감은 오지만 아직 명확하게 어떤 연관성이 있는지는 와닿지 않는다. ↩\n\n\n왜 seek 이 들어가지? ↩\n\n\n"},"botanicals/os/terms/External-Fragment-(OS)":{"title":"External Fragment (OS)","links":[],"tags":["용어집","os"],"content":"외부 단편화, External Fragment §\n\n이것은 어떤 공간이 free 상태가 됐다가 해당 자리에 더 작은 데이터가 들어와서 남는 공간을 말한다.\n이렇게 말하니까 원래 알던 사람 아니면 뭔소린지 모를 것 같긴 하다.\n\n예를 들어 4KB 파일 + 5KB 파일 + 6KB 파일이 순차적으로 디스크에 저장되어 있었다고 해보자.\n그리고 이때 5KB 파일이 지워지고, 해당 자리에 3KB 파일이 저장되었다고 해보자.\n그럼 여기에는 2KB 만큼의 구멍이 뚫리게 되고, 2KB 보다 작은 파일만 저장이 가능해 질 것이다.\n이런 것을 외부 단편화라고 하는 것.\n\n\n위의 예시에서는 크기가 크니까 별 문제가 아닌것 처럼 보이지만, 이건 빵꾸가 쫌쫌따리로 많이 생기다 보면 결국에는 합쳐봤을 때 생각보다 많은 공간을 사용하지 못하게 된다.\n옛날 windows xp 시절에 있었던 “디스크 조각 모음” 이 데이터를 빈공간이 없어지게끔 밀어 빵꾸를 합쳐 큰 빵구로 만드는 기능이다.\n"},"botanicals/os/terms/Internal-Fragment-(OS)":{"title":"Internal Fragment (OS)","links":["botanicals/os/draft/Virtual-Memory-(OS)","botanicals/storage/terms/Logical-Block-Addressing,-LBA-(Storage)","botanicals/os/terms/External-Fragment-(OS)"],"tags":["용어집","os"],"content":"내부단편화, Internal Fragment §\n\n이것은 어떤 “고정된 크기의 공간” 을 전부 사용하지 못해 해당 공간 내에 “사용하지 않고 비는 공간” 을 의미한다.\n\n가령 Virtual memory 의 page 나\nLBA 에서의 block 에서 발생하는 문제.\n\n\n반대? 는 아니고 유사 반대 개념으로는 외부 단편화 가 있다.\n"},"botanicals/shellscript/(Botanical-Garden)-Shell-Script":{"title":"(Botanical Garden) Shell Script","links":["botanicals/shellscript/story/Shell-story---디스크-마운트하기","botanicals/shellscript/bash/alias/bash---alias-설정","botanicals/shellscript/bash/alias/bash---alias-해제","botanicals/shellscript/bash/conditional/bash---조건문-문법","botanicals/shellscript/bash/conditional/bash---조건문으로-파일-혹은-디렉토리-존재-확인하기","botanicals/shellscript/bash/env/bash---파일에서-환경변수-읽어오기","botanicals/shellscript/bash/substitution/bash---Substitution-으로-접미어-지우기","botanicals/shellscript/bash/substitution/bash---Substitution-으로-변수-기본값-설정하기","botanicals/shellscript/bash/substitution/bash---Substitution-으로-변수-미설정-에러-출력하기","botanicals/shellscript/apt/apt---설치된-패키지-확인하기","botanicals/shellscript/apt/apt---패키지-깔끔하게-지우기","botanicals/shellscript/apt/apt---패키지-레포지토리-알아내기","botanicals/shellscript/apt/apt---패키지-하나만-버전-업그레이드하기","botanicals/shellscript/arp/arp---ARP-테이블-요소-삭제하기","botanicals/shellscript/arp/arp---ARP-테이블-확인하기","botanicals/shellscript/ca-certificates/ca-certificates---인증서-신뢰하기","botanicals/shellscript/curl/curl---기본-사용법","botanicals/shellscript/curl/curl---Redirect-하기","botanicals/shellscript/curl/curl---타임아웃-설정하기","botanicals/shellscript/curl/curl---Progress-bar-지우기","botanicals/shellscript/df/df---마운트-현황-출력하기","botanicals/shellscript/df/df---inode-현황-출력하기","botanicals/shellscript/expr/expr---사칙연산하기","botanicals/shellscript/fdisk/fdisk---디스크-확인하기","botanicals/shellscript/openssl/openssl---Server-인증서-다운로드-하기","botanicals/shellscript/openssl/openssl---인증서-상세-정보-확인하기","botanicals/shellscript/openssl/openssl---인증서가-어떤-CA-인증서에-의해-서명되었는지-확인하기","botanicals/shellscript/openssl/openssl---인증서에서-CSR-(Certificate-Signing-Request)-뽑아내기","botanicals/shellscript/tar/TAR-vs-GZIP---뭔차이지-q","botanicals/shellscript/tar/tar---파일-압축하기","botanicals/shellscript/tar/tar---파일-압축-풀기","botanicals/shellscript/tr/tr---문자-지우기","botanicals/shellscript/tr/tr---문자-대체하기","botanicals/shellscript/tcpdump/tcpdump---인터페이스-지정하기","botanicals/shellscript/tcpdump/tcpdump---포트-지정하기","botanicals/shellscript/watch/watch---김해람의-꿀조합"],"tags":[],"content":"\nMark Farina - mu.sh room jazz\n\n개요 §\n\n쉘 스크립트 창고\n기존에는 SH-IT!! 에서 쉘 스크립트 관련 꿀 / 예시들을 저장했는데, 이제 이쪽으로 마이그레이션 하려고 합니당.\n\n물론 깃허브 레포지토리 이름이 맘에 들어서 아쉽긴 하지만.\n\n\n쉘 스크립트 관련 식물들이기에, 아마 짤막짤막한 토막글들로 채워질 것 같습니다.\n\n식물들 §\n스토리 §\n\n새로 구매한 디스크 마운트하기\n\nbash 내장 기능 §\nAlias §\n\n설정하기\n해제하기\n\n조건문 §\n\n기본 문법\n파일 혹은 디렉토리 존재 확인하기\n\n환경 변수 §\n\n파일에서 환경변수 읽어오기\n\nSubstitution §\n\n접미어 지우기\n변수 기본값 설정하기\n변수 미설정 에러 출력하기\n\n명령어 사용법 §\n\bapt §\n\n설치된 패키지 확인하기\n패키지 깔끔하게 지우기\n패키지 레포지토리 알아내기\n패키지 하나만 버전 업그레이드하기\n\n\barp §\n\nARP 테이블 요소 삭제하기\nARP 테이블 확인하기\n\ncurl §\n\n인증서 신뢰하기\n\ncurl §\n\n기본 사용법\nRedirect 하기\n타임아웃 설정하기\nProgress bar 지우기\n\ndf §\n\n마운트 현황 출력하기\ninode 현황 출력하기\n\nexpr §\n\n사칙연산하기\n\nfdisk §\n\n디스크 확인하기\n\nopenssl §\n\nServer 인증서 다운로드 하기\n인증서 상세 정보 확인하기\n인증서가 어떤 CA 인증서에 의해 서명되었는지 확인하기\n인증서에서 CSR (Certificate Signing Request) 뽑아내기\n\ntar §\n\nTAR vs GZIP - 뭔차이지?\n파일 압축하기\n파일 압축 풀기\n\ntr §\n\n문자 지우기\n문자 대체하기\n\ntcpdump §\n\n인터페이스 지정하기\n포트 지정하기\n\nwatch §\n\n기본 사용법\n"},"botanicals/shellscript/apt/apt---설치된-패키지-확인하기":{"title":"apt - 설치된 패키지 확인하기","links":[],"tags":["쉘스크립트"],"content":"\n\n                  \n                  Info 출처\n                  \n                \n\n개요 §\n\n서버에 설치된 모든 패키지 확인\n혹은, 서버에 특정 패키지가 설치되어있는지 확인 하는 용도로 사용할 수 있다.\n\nTL;DR §\nsudo apt list --installed\n\n기본적으로는 모든 설치된 패키지가 출력되고, 특정 패키지로 필터링하고 싶으면 명령어 뒤에 적어주거나 아니면 grep 을 사용하면 된다.\n"},"botanicals/shellscript/apt/apt---패키지-깔끔하게-지우기":{"title":"apt - 패키지 깔끔하게 지우기","links":[],"tags":["쉘스크립트"],"content":"개요 §\n\napt 로 패키지 지우는 방법\n\n을 왜 굳이 메모를 해놓냐 -&gt; apt, yum, brew 등등 여러 패키지 관리자 사용하다 보면 문법이 헷갈리거등 이게\n\n\n\nTL;DR §\nsudo apt-get remove --purge -y ${패키지} \\\n    &amp;&amp; sudo apt-get autoremove --purge -y"},"botanicals/shellscript/apt/apt---패키지-레포지토리-알아내기":{"title":"apt - 패키지 레포지토리 알아내기","links":[],"tags":["쉘스크립트"],"content":"\n\n                  \n                  Info 출처\n                  \n                \n\n개요 §\n\n패키지가 여러 레포지토리를 통해 배포될 때, 가끔씩 설치된 패키지가 어느 레포지토리에서 왔는지 확인해야될 때가 있다.\n\n주인장은 GPU 서버에 설치된 NVIDIA 드라이버가 ubuntu 레포인지 cuda 레포인지 확인하느라 찾아봤었다.\n\n\n\nTL;DR §\napt-cache policy ${패키지}"},"botanicals/shellscript/apt/apt---패키지-하나만-버전-업그레이드하기":{"title":"apt - 패키지 하나만 버전 업그레이드하기","links":[],"tags":["쉘스크립트"],"content":"\n\n                  \n                  Info 출처\n                  \n                \n\n개요 §\n\n물론 apt upgrade 를 하면 버전업이 되지만, 모든 패키지 버전이 업그레이드 되니까 이걸 치기에는 손발이 후달린다.\n이럴때 패키지 하나만 버전업하는 방법.\n\nTL;DR §\nsudo apt-get install --only-upgrade ${패키지명}=${패키지버전}"},"botanicals/shellscript/arp/arp---ARP-테이블-요소-삭제하기":{"title":"arp - ARP 테이블 요소 삭제하기","links":["originals/datacommunication.spring.2021.cse.cnu.ac.kr/13.-Routing"],"tags":["쉘스크립트"],"content":"개요 §\n\n새로 ARP 를 보내 MAC 주소를 새로고침하는 등의 상황에서, ARP 캐시 테이블에 있는 데이터를 지우는 방법\n\nTL;DR §\narp -d ${IP주소}"},"botanicals/shellscript/arp/arp---ARP-테이블-확인하기":{"title":"arp - ARP 테이블 확인하기","links":["originals/datacommunication.spring.2021.cse.cnu.ac.kr/13.-Routing"],"tags":["쉘스크립트"],"content":"개요 §\n\nARP 캐시 테이블 확인하기\n\nTL;DR §\narp"},"botanicals/shellscript/bash/alias/bash---alias-설정":{"title":"bash - alias 설정","links":[],"tags":["쉘스크립트"],"content":"개요 §\n\n특정 명령어를 alias 로 만들어 쉽게 사용해보자.\n주인장 공식 추천 zshrc 파일 (alias 등) 은 여기 에서 확인할 수 있다.\n\nTL;DR! §\nalias=&quot;$COMMANDS&quot;"},"botanicals/shellscript/bash/alias/bash---alias-해제":{"title":"bash - alias 해제","links":["botanicals/shellscript/bash/alias/bash---alias-설정"],"tags":["쉘스크립트"],"content":"\n\n                  \n                  Info 출처\n                  \n                \n\n개요 §\n\n설정한 alias 를 해제하는 방법을 알아보자.\n\nTL;DR! §\nunalias ${ALIAS_NAME}"},"botanicals/shellscript/bash/conditional/bash---조건문-문법":{"title":"bash - 조건문 문법","links":[],"tags":["쉘스크립트"],"content":"\n\n                  \n                  Info 출처\n                  \n                \n\n개요 §\n\n조건문 문법 자꾸 까먹는다\n\nTL;DR! §\nif $CONDITION; then\n    $IF_EXPRS\nelif $CONDITION; then\n    $ELSE_IF_EXPRS\nelse\n    $ELSE_EXPRS\nfi"},"botanicals/shellscript/bash/conditional/bash---조건문으로-파일-혹은-디렉토리-존재-확인하기":{"title":"bash - 조건문으로 파일 혹은 디렉토리 존재 확인하기","links":[],"tags":["쉘스크립트"],"content":"개요 §\n\n파일(혹은 디렉토리) 가 존재하는지 조건문에서 검사하기\n\nTL;DR! §\n파일 존재 확인 §\n\n아래 세 가지 방법 중 하나 사용하면 되니다\n\nif test -f $FILE_PATH; then\n    echo exists\nfi\nif [ -f $FILE_PATH ]; then\n    echo exists\nfi\nif [[ -f $FILE_PATH ]]; then\n    echo exists\nfi\n디렉토리 존재 확인 §\n\n마찬가지로 아래 세 가지 방법 중 하나 사용하면 된다\n\nif test -d $FILE_PATH; then\n    echo exists\nfi\nif [ -d $FILE_PATH ]; then\n    echo exists\nfi\nif [[ -d $FILE_PATH ]]; then\n    echo exists\nfi"},"botanicals/shellscript/bash/env/bash---파일에서-환경변수-읽어오기":{"title":"bash - 파일에서 환경변수 읽어오기","links":[],"tags":["쉘스크립트"],"content":"개요 §\n\n파일에서 환경변수 읽어오기\n\nTL;DR! §\n\n. 는 환경 변수 혹은 함수들을 import 하는 POSIX 표준이다\n\n. ./cat $FILE\n\nsource 는 . 의 alias 이다 (bash 와 zsh 등에서는 가능, sh 에서는 안됨)\n\nsource ./$FILE"},"botanicals/shellscript/bash/substitution/bash---Substitution-으로-변수-기본값-설정하기":{"title":"bash - Substitution 으로 변수 기본값 설정하기","links":[],"tags":["쉘스크립트"],"content":"\n\n                  \n                  Info 출처\n                  \n                \n\n개요 §\n\n이거 진짜 편함\n\nTL;DR! §\nunset TEST\necho ${TEST}         # STDOUT: null\necho ${TEST:=&#039;good&#039;} # STDOUT: &#039;good&#039;\necho ${TEST}         # STDOUT: &#039;good&#039;\n여러 차이점들,, §\n\n뭐 출처 에 따르면 =, :=, -, :- 모두 살짝은 다르게 작동한다고 한다\n근데 주인장은 그냥 Go 문법 과 비슷한 := 를 많이 사용함\n더 자세한 차이점을 알고 싶으면 출처 를 읽어 보시라\n"},"botanicals/shellscript/bash/substitution/bash---Substitution-으로-변수-미설정-에러-출력하기":{"title":"bash - Substitution 으로 변수 미설정 에러 출력하기","links":[],"tags":["쉘스크립트"],"content":"\n\n                  \n                  Info 출처\n                  \n                \n\n개요 §\n\n이것도 진짜 편함\n\nTL;DR! §\nunset TEST\necho &quot;${TEST?&#039;error: variable TEST not set&#039;}&quot; # STDERR: &#039;bash: TEST: error: variable TEST not set&#039;"},"botanicals/shellscript/bash/substitution/bash---Substitution-으로-접미어-지우기":{"title":"bash - Substitution 으로 접미어 지우기","links":["botanicals/shellscript/tr/tr---문자-지우기"],"tags":["쉘스크립트"],"content":"\n\n                  \n                  Info 출처\n                  \n                \n\n개요 §\n\n문자열의 접미어를 지워보자\n\n물론 tr 같은 명령어를 사용할 수도 있지만\nBash substitution 에도 이런 기능을 제공한다\n\n\n\nTL;DR! §\nTEST=&#039;example/&#039;\necho &quot;${TEST%/}&quot; # STDOUT: &#039;example&#039;\n좀 더 자세히? §\n\n% 는 매칭되는 “가장 짧은” 접미어를 지운다\n\n\n**{var%Pattern}** Remove from var the shortest part of Pattern thatmatchesthe b​ackend ​of var.\n\nTEST=&#039;foo&#039;\necho &quot;${TEST%o*}&quot; # STDOUT: &#039;fo&#039;\n\n%% 는 매칭되는 “가장 긴” 접미어를 지운다\n\n\n**{var%%Pattern}** Remove from var the longest part of Pattern thatmatchesthe b​ackend ​of var.\n\nTEST=&#039;foo&#039;\necho &quot;${TEST%%o*}&quot; # STDOUT: &#039;f&#039;"},"botanicals/shellscript/ca-certificates/ca-certificates---인증서-신뢰하기":{"title":"ca-certificates - 인증서 신뢰하기","links":[],"tags":["쉘스크립트"],"content":"\n\n                  \n                  Info 출처\n                  \n                \n\n개요 §\n\nca-certificates 패키지를 이용해 인증서를 신뢰해보자\n(잘은 모르겠지만) 이 패키지는 Debian 계열에서 제공하는 패키지인듯… RHEL 에 있는지는 모르겠음\n\nTL;DR! §\ncp $TRUST_CERT.crt /usr/local/shared/ca-certificates/\nsudo update-ca-certificates"},"botanicals/shellscript/curl/curl---Progress-bar-지우기":{"title":"curl - Progress bar 지우기","links":["botanicals/shellscript/curl/curl---기본-사용법","botanicals/shellscript/watch/watch---김해람의-꿀조합"],"tags":["쉘스크립트"],"content":"\n\n                  \n                  Info 출처\n                  \n                \n\n개요 §\n\ncurl 을 그냥 사용하면 상관없는데,\n파일로 리다이렉트 시키거나 watch 같은 걸로 돌리면 Progress bar 가 나오곤 한다.\n\n뭐 이런식으로\n\n\n\n\n\n근데 이게 거슬리다면, 요렇게 하면 된다.\n\nTL;DR! §\ncurl -s ${URL}\n\n만약 위의 방법이 안먹히면, Progress bar 는 표준에러로 출력되므로 이걸 죽여주면 된다.\n\ncurl ${URL} 2&gt; /dev/null"},"botanicals/shellscript/curl/curl---Redirect-하기":{"title":"curl - Redirect 하기","links":["botanicals/shellscript/curl/curl---기본-사용법"],"tags":["쉘스크립트"],"content":"\n\n                  \n                  Info 출처\n                  \n                \n\n개요 §\n\n일반적인 웹 브라우져와는 다르게, curl 는 기본적으로 Redirect 를 하지 않는다.\n\n즉, HTTP 300번대 응답이 와도 그냥 그러려니 하지 여기서 추가적으로 Redirect 를 따라가지 않는다.\n\n\n그래서 Redirect 응답을 따라가려면 요래 하면 된다.\n\nTL;DR! §\ncurl -L www.example.com"},"botanicals/shellscript/curl/curl---기본-사용법":{"title":"curl - 기본 사용법","links":[],"tags":["쉘스크립트"],"content":"\n\n                  \n                  Info cURL 공홈\n                  \n                \n\n개요 §\n\n뭐 이런것까지 포스팅하냐.. 싶겠지만\n그냥 cURL 소개 페이지라고 생각해주라\n\ncURL? §\n\nURL 을 이용해 데이터를 주고 받는 CLI 툴 이라고 한다.\n1998년부터 개발되어 왔다고 한다. 와우\n소스코드는 깃허브 에서 관리되고 있는 것 같다 (미러가 아닌 것 같음).\n\n2024-01-29 기준, 거의 매일 commit 이 되고 있다.\n\n\n\n사용법 §\n\n별거 없다; URL 만 적으면 된다.\n\ncurl www.example.com\n\n-v: 근데 이제 좀 더 자세한 정보를 곁들인\n\n이 Verbose 옵션을 이용해 HTTP 상태, 헤더, TLS 처리 상태 등을 확인할 수 있다.\n\n\n\ncurl -v www.example.com"},"botanicals/shellscript/curl/curl---타임아웃-설정하기":{"title":"curl - 타임아웃 설정하기","links":["botanicals/shellscript/curl/curl---기본-사용법","botanicals/shellscript/watch/watch---김해람의-꿀조합"],"tags":["쉘스크립트"],"content":"\n\n                  \n                  Info 출처\n                  \n                \n\n개요 §\n\ncurl 을 사용하다 보면 장애 디버깅할 때 진짜 한없이 기다린다.\n\n그래서 watch 같은 것으로 모니터링 걸어놓을 때 한번 장애나면 걍 멈춰있는다.\n\n\n타임아웃을 걸어 문제가 생겨도 멈추게 해보자.\n\nTL;DR! §\ncurl --max-time $SEC $URL\n\n혹은\n\ncurl --connect-timeout $SEC $URL"},"botanicals/shellscript/df/df---inode-현황-출력하기":{"title":"df - inode 현황 출력하기","links":[],"tags":["쉘스크립트"],"content":"개요 §\n\n가끔 리눅스 시스템을 오랜 기간 동안 운영하다 보면 inode 가 부족하다고 징징댈 때가 있다. 이때 상태를 보기 위해 inode 현황을 출력해 보자.\n\nTL;DR! §\ndf -hi\n\n-i, --inodes 옵션은 마운트 된 파일시스템의 크기/사용/잔여 정보 대신, 파일시스템의 inode 크기/사용/잔여 정보를 보여준다.\n"},"botanicals/shellscript/df/df---마운트-현황-출력하기":{"title":"df - 마운트 현황 출력하기","links":[],"tags":["쉘스크립트"],"content":"개요 §\n\ndf 명령어로 마운트 현황을 출력해보자.\n\nTL;DR! §\ndf -h\n\n-h 는 --human-readable 의 단축옵션으로, 단위를 MiB, GiB 등으로 변환하여 보여준다. (이 옵션을 안주면 KiB 단위로만 크기를 보여준다.)\n\n더 많은 옵션들.. §\n-H §\n\n-h 대신 -H 을 사용하면 SI 단위로 보여준다. 즉, 1MiB = 1024KiB 처럼 1024 로 단위변환을 하는 것이 아니고, 1MB = 1000KB 처럼 1000 로 단위변환을 하는 SI 표준을 따르는 것.\n\ndf -H\n-T §\n\n파일시스템 타입도 같이 보여준다.\n\ndf -hT\n-a §\n\n접근할 수 없거나 중복된 정보도 모두 출력한다.\n\ndf -ah\n인자 §\n\n뒤에 경로를 입력하면 해당 경로에 대한 마운트 정보만 보여준다.\n\ndf -h /path/to/mount"},"botanicals/shellscript/expr/expr---사칙연산하기":{"title":"expr - 사칙연산하기","links":[],"tags":["쉘스크립트"],"content":"\n\n                  \n                  Info 출처\n                  \n                \n\n개요 §\n\n제곧내\n\nTL;DR! §\n\n표준 출력으로 보내기\n\nexpr 10 + 30\nexpr 30 % 9\n\n변수에 저장하기\n\nmyVal1=`expr 30 / 10`\nmyVal2=$( expr 30 - 10 )\n조심할 점 §\n\nexpr 은 arg 로 입력을 받기에, 문자열 (&#039;&#039;, &quot;&quot;) 로 입력하거나 띄어쓰기 없이 입력하면 안된다.\n즉, 아래처럼 하면 안된다는 것\n\nexpr &#039;10 + 30&#039;  # STDOUT: &#039;10 + 30&#039;\nexpr &quot;10 + 30&quot;  # STDOUT: &#039;10 + 30&#039;\nexpr 10+30      # STDOUT: &#039;10+30&#039;"},"botanicals/shellscript/fdisk/fdisk---디스크-확인하기":{"title":"fdisk - 디스크 확인하기","links":[],"tags":["쉘스크립트"],"content":"개요 §\n\nfdisk 명령어로 디스크 (파티션 테이블) 을 확인하는 방법\n\nTL;DR! §\n\n리스트 보기:\n\nsudo fdisk -l\n\n좀 더 자세히 보기:\n\nsudo fdisk -x"},"botanicals/shellscript/openssl/openssl---Server-인증서-다운로드-하기":{"title":"openssl - Server 인증서 다운로드 하기","links":["botanicals/shellscript/openssl/openssl---인증서-상세-정보-확인하기"],"tags":["쉘스크립트"],"content":"개요 §\n\n내가 Server 를 설정하는 입장이 아니라 Client 로 Server 에 접속하는 입장이라면, Server 가 어떤 인증서를 제시하는지 확인하는 방법을 알아두면 디버깅시 활용할 수 있당.\n\nTL;DR! §\n\n서버에 접속해서 인증서 다운로드:\n\nopenssl s_client -showcerts -connect $IP:$PORT &lt;/dev/null 2&gt;/dev/null \\\n\t| openssl x509 -outform PEM \\\n\t&gt; $FILENAME.crt\n\n인증서 뿐 아니라 연결 상태 등도 같이 체크하고 싶을 때는 openssl s_client ... 만 실행하면 된다.\n\nopenssl x509 -outform PEM 은 그냥 인증서 PEM 만 추출하는 것.\n\n\nPEM 을 추출하지 않고 다른 명령어로 연계하는 것도 가능하다.\n\n예를 들어, 인증서 상세 정보 확인하는 방법 처럼 openssl x509 -outform PEM 대신 openssl x509 -text 로 하면 인증서 자체에 대한 inspect 도 가능하다.\n\n\n"},"botanicals/shellscript/openssl/openssl---인증서-상세-정보-확인하기":{"title":"openssl - 인증서 상세 정보 확인하기","links":[],"tags":["쉘스크립트"],"content":"개요 §\n\n인증서의 상세 정보를 확인하는 방법이다\n\nTL;DR! §\n\n인증서 입력은 기본적으로 표준입력이다:\n\necho &quot;@@@ 인증서 PEM 어쩌고저쩌고 @@@&quot; | openssl x509 -text -noout\n\n아니면 -in 옵션으로 인증서 파일을 지정해 줄 수도 있다:\n\nopenssl x509 -text -noout -in $CERT_FILE.crt"},"botanicals/shellscript/openssl/openssl---인증서가-어떤-CA-인증서에-의해-서명되었는지-확인하기":{"title":"openssl - 인증서가 어떤 CA 인증서에 의해 서명되었는지 확인하기","links":["botanicals/cybersecurity/terms/Certificate-Authority,-CA-(PKIX)"],"tags":["쉘스크립트"],"content":"\n\n                  \n                  Info 출처\n                  \n                \n\n개요 §\n\n어떤 인증서가 있는데, 이 인증서가 어떤 CA 인증서에 의해 서명되었는지 확인하고 싶을 때 사용하면 된다.\n\nTL;DR §\nopenssl verify -verbose -CAfile ${\bCA인증서경로} ${검증하고자하는인증서}"},"botanicals/shellscript/openssl/openssl---인증서에서-CSR-(Certificate-Signing-Request)-뽑아내기":{"title":"openssl - 인증서에서 CSR (Certificate Signing Request) 뽑아내기","links":["botanicals/cybersecurity/terms/Certificate-Signing-Request,-CSR-(PKIX)"],"tags":["쉘스크립트"],"content":"\n\n                  \n                  Info 출처\n                  \n                \n\n개요 §\n\n보통은 CSR 을 만들고 그걸로 인증서를 생성하는데,\n인증서를 재발급해서 교체하는 등의 작업을 할 때 역으로 인증서에서 CSR 를 빼내야 할 때가 있다.\n\nTL;DR §\nopenssl x509 -x509toreq \\\n    -in ${인증서파일} \\\n    -signkey ${개인키파일}\n\n간단하죠?\n기본적으로 표준출력으로 결과가 반환되고, 파일로 저장하고싶으면 &gt; 로 리다이렉트하던지 아니면 -out 옵션을 이용하면 된다.\n"},"botanicals/shellscript/story/Shell-story---디스크-마운트하기":{"title":"Shell story - 디스크 마운트하기","links":["botanicals/shellscript/fdisk/fdisk---디스크-확인하기","botanicals/shellscript/story/Shell-story---디스크-마운트하기","botanicals/shellscript/df/df---마운트-현황-출력하기"],"tags":["쉘스크립트"],"content":"\n\n                  \n                  Info 출처\n                  \n                \n\n개요 §\n\n제곧내 - 디스크를 마운트 해보자\n\n어떻게? §\n1. 일단 fdisk 로 디스크가 어디에 인식되었는지 확인한다. §\nsudo fdisk -l\n\n그럼 다음처럼 디스크가 인식되었는지, 어느 경로에 있는지 확인이 가능하다:\n\nDisk /dev/sdb: 3.49 TiB, 3840755982336 bytes, 7501476528 sectors\nDisk model: INTEL SSDXXXXXX\nUnits: sectors of 1 * 512 = 512 bytes\nSector size (logical/physical): 512 bytes / 4096 bytes\nI/O size (minimum/optimal): 4096 bytes / 4096 bytes\n\n2. 그다음 마운트… §\nsudo mount /dev/sdb /path/to/mount\n\n물론 /dev/sdb 는 예시이고, 위 에서 확인한 경로를 사용하면 된다.\n\n2.1. 마운트시 에러난다면? §\n\n마운트 했을 때 아래와 같은 에러가 날 수도 있다:\n\nmount: /path/to/mount: wrong fs type, bad option, bad superblock on /dev/sdb, missing codepage or helper program, or other error.\n\n\n그럼 디스크의 파일시스템이 없거나 잘못되었다는 얘기이다. 리눅스에서는 ext4 을 사용하므로 다음의 명령어로 파일시스템을 생성해준다:\n\nsudo mkfs.ext4 /dev/sdb\n3. 잘 됐나? §\n\ndf - 마운트 현황 출력하기 를 통해 잘 마운트 됐나 확인한다.\n\ndf -hT /dev/sdb\n\n다음처럼 나오면 성공:\n\nFilesystem     Type  Size  Used Avail Use% Mounted on\n/dev/sdb       ext4  3.5T   20G  3.3T   1% /path/to/mount\n"},"botanicals/shellscript/tar/TAR-vs-GZIP---뭔차이지-q":{"title":"TAR vs GZIP - 뭔차이지?","links":[],"tags":[],"content":"\n\n                  \n                  Info 출처\n                  \n                \n\n.tar.gz 의 정체 §\n\n리눅스 시스템을 사용하다 보면 .tar.gz 란 압축파일을 자주 보게 된다.\n근데 그냥 .zip 도 아니고 뭔 이런 복잡한 확장자가 다 있나 싶을텐데\n\n그것을 알려드림 §\n\n결론부터 말하자면,\n\nTAR 는 여러개의 파일을 하나로 묶어주는 역할을 한다. 즉, 파일의 사이즈를 줄이는 “압축” 의 기능은 없다.\nGZIP 은 하나의 파일을 압축해서 사이즈를 줄이는 역할을 한다.\n\n\n따라서 보통 이 둘을 같이 쓰게 되는 것.\n\n여러개의 파일을 압축하려고 할 때,\nTAR 로 일단 파일들을 하나의 파일로 묶고\n그 하나의 파일을 GZIP 으로 압축해서 사이즈를 줄이는 것.\n\n\n"},"botanicals/shellscript/tar/tar---파일-압축-풀기":{"title":"tar - 파일 압축 풀기","links":["botanicals/shellscript/tar/TAR-vs-GZIP---뭔차이지-q"],"tags":["쉘스크립트"],"content":"개요 §\n\ntar 로 .tar.gz 압축파일을 압축 해제해 보자.\n\nTL;DR! §\ntar -xzvf {압축파일이름}.tar.gz -C ${압축 풀 경로}\n\n옵션 설명\n\n-x: Extract 의 x\n-z: GZIP 파일을 압축 해제 (왜?)\n-v: Verbose 의 v\n-f: Input file 을 지정\n-C: 압축 해제 경로 (기본값은 현재 경로이다.)\n\n\n"},"botanicals/shellscript/tar/tar---파일-압축하기":{"title":"tar - 파일 압축하기","links":["botanicals/shellscript/tar/TAR-vs-GZIP---뭔차이지-q"],"tags":["쉘스크립트"],"content":"개요 §\n\ntar 로 파일들을 압축해 .tar.gz 압축파일로 만들어 보자.\n\nTL;DR! §\ntar -czvf ${압축파일이름}.tar.gz ${파일들 혹은 디렉토리}\n\n옵션 설명\n\n-c: Compress 의 c\n-z: GZIP 으로 압축 (왜?)\n-v: Verbose 의 v\n-f: Input file 을 지정\n\n\n"},"botanicals/shellscript/tcpdump/tcpdump---인터페이스-지정하기":{"title":"tcpdump - 인터페이스 지정하기","links":[],"tags":["쉘스크립트"],"content":"\n\n                  \n                  Info 출처\n                  \n                \n\n개요 §\n\ntcpdump 에서 별도 인터페이스를 지정지 않으면 기본 인터페이스로 설정된다.\n하지만 인터페이스가 여러개여서 그중 특정 인터페이스를 캡쳐하고 싶거나, 모든 인터페이스를 캡쳐하고 싶다면 요래 하면 된다.\n\nTL;DR! §\ntcpdump -i ${INTERFACE_NAME}\n\n만약 모든 인터페이스를 캡쳐하고 싶다면,\n\ntcpdump -i any\n\n요렇게 하면 된다.\n"},"botanicals/shellscript/tcpdump/tcpdump---포트-지정하기":{"title":"tcpdump - 포트 지정하기","links":[],"tags":["쉘스크립트"],"content":"\n\n                  \n                  Info 출처\n                  \n                \n\n개요 §\n\ntcpdump 를 사용할 때, 포트를 지정하지 않으면 모든 포트에 대한 패킷을 캡쳐한다.\n근데 문제는 이 양이 너무 많아서 보기 힘들다는 것.\n그래서 이렇게 하면 포트 번호로 필터링이 가능하다:\n\nTL;DR! §\ntcpdump port ${PORT_NUM}\n\n뭐 예를 들어 DNS 쿼리를 캡쳐하고 싶다면,\n\ntcpdump port 53\n\n이렇게 하면 되것지?\n"},"botanicals/shellscript/tr/tr---문자-대체하기":{"title":"tr - 문자 대체하기","links":[],"tags":["쉘스크립트"],"content":"개요 §\n\n문자열에서 특정 문자 대체하기\n\nTL;DR! §\necho good | tr &#039;o&#039; &#039;O&#039; # STDOUT: &#039;gOOd&#039;"},"botanicals/shellscript/tr/tr---문자-지우기":{"title":"tr - 문자 지우기","links":[],"tags":["쉘스크립트"],"content":"개요 §\n\n문자열에서 지정한 모든 문자 지우기\n\nTL;DR! §\n\n-d 옵션을 사용하면 된다\n\necho good | tr -d &#039;o&#039; # STDOUT: &#039;gd&#039;"},"botanicals/shellscript/watch/watch---김해람의-꿀조합":{"title":"watch - 김해람의 꿀조합","links":[],"tags":["쉘스크립트"],"content":"안궁금하겠지만 §\n\n그래도 이렇게 Bash alias 설정해 두면 편하다 (zshrc 나 bashrc 에 설정해 두자).\n\nalias watch=&quot;watch -d -n0.5&quot;\n1. -d 옵션 §\n\n이 옵션을 넣으면 뭔가 바뀔때마다 하이라이트를 해줘 어떤 것이 바뀌었는지 알기 편하다.\n\n막 번쩍번적댄다 신나부러\n\n\n\nwatch -d ${명령어}\n\n이렇게\n\n\n2. -n 옵션 §\n\nwatch 의 기본 시간 간격 옵션은 2초인데, 이거 기다리고 있으면 진짜 열불나고 극적인 효과도 없다.\n그래서 이 옵션으로 시간 간격을 확 줄여버리자.\n\n물론 근데 너무 줄이면 생각보다 메모리 많이 먹는다.\n주인장은 이번 생에 이 옵션은 외판 뼉다구 문제없는  0.5 초로 종결을 하였다.\n\n\n\nwatch -n 0.5 ${명령어}"},"botanicals/storage/(Botanical-Garden)-Storage,-SSD":{"title":"(Botanical Garden) Storage, SSD","links":["botanicals/os/(Botanical-Garden)-Operating-Systems,-Linux","botanicals/storage/terms/Conventional-Magnetic-Recording,-CMR-HDD-(Storage)","botanicals/storage/terms/Data-Chunk-(Storage)","botanicals/storage/terms/Flash-Memory,-SSD-(Storage)","botanicals/storage/terms/Flash-Translation-Layer,-FTL-(Storage)","botanicals/storage/terms/Flexible-Data-Placement,-FDP-(Storage)","botanicals/storage/terms/Garbage-Collection,-GC-(Storage)","botanicals/storage/terms/Hot-Cold-Separation-(Storage)","botanicals/storage/terms/Input-Output-per-second,-IOps-(storage)","botanicals/storage/terms/Latency-(Storage)","botanicals/storage/terms/Logical-Block-Addressing,-LBA-(Storage)","botanicals/storage/terms/Multi-Level-Cell,-MLC-(Storage)","botanicals/storage/terms/Multi-stream-SSD-(Storage)","botanicals/storage/terms/NOR-based-Flash-Memory-(Storage)","botanicals/storage/terms/NVMe-Namespace-(Storage)","botanicals/storage/terms/Open-Channel-SSD,-OCSSD-(Storage)","botanicals/storage/terms/Over-Provisioning,-OP-(Storage)","botanicals/storage/terms/PE-Cyclen-Limit,-Wearing-off-(Storage)","botanicals/storage/terms/Physical-Block-Address,-PBA-(Storage)","botanicals/storage/terms/Pre-conditioning-(Storage)","botanicals/storage/terms/Read-Disturb-(Storage)","botanicals/storage/terms/Shingled-Magnetic-Recording-HDD,-SMR-HDD-(Storage)","botanicals/storage/terms/Superblock-(Storage)","botanicals/storage/terms/Throughput-(Storage)","botanicals/storage/terms/TRIM,-Deallocation-(Storage)","botanicals/storage/terms/Wear-Leveling-(Storage)","botanicals/storage/terms/Write-Amplification,-WA-and-Write-Amplication-Factor,-WAF-(Storage)","botanicals/storage/terms/Zoned-Storage-Model-(Storage)"],"tags":[],"content":"개요 §\n\nOS 보다 한단계 더 아래.. 스토리지도 심어보자\n\n작물들 §\n\nConventional Magnetic Recording HDD, CMR HDD\nData Chunk\nFlash Memory, SSD\nFlash Translation Layer, FTL\nFlexible Data Placement, FDP\nGarbage Collection, GC\nHot Cold Separation\nIOps\nLatency\nLogical Block Addressing, LBA\nMulti Level Cell, MLC\nMulti-stream SSD\nNAND Flash Memory\nNOR Flash Memory\nNVMe Namespace\nOpen Channel SSD, OCSSD\nOver Provisioning, OP\nPE Cycle Limit, Wearing-off\nPhysical Block Address, PBA\nPre-conditioning\nRead Disturb\nShingled Magnetic Recording HDD, SMR HDD\nSuperblock\nThroughput\nTRIM, Deallocation\nWear Leveling\nWrite Amplification, Write Amplication Factor (WA, WAF)\nZoned Storage Model\n"},"botanicals/storage/draft/Cylinder-Head-Section,-CHS-(Storage)":{"title":"Cylinder Head Section, CHS (Storage)","links":[],"tags":["용어집","storage"],"content":"\n\n                  \n                  참고한 것 \n                  \n                \n\n고급운영체제 (김진수 교수님 ‘24H1, SNU CSE)\n\n\n\n\n                  \n                  본 글은 #draft 상태입니다. \n                  \n                  \n                \n                \n\n 내용 정리\n\n"},"botanicals/storage/draft/Deep-Dive-SSD---Storing-and-Detecting-Electrons-(Storage)":{"title":"Deep Dive SSD - Storing and Detecting Electrons (Storage)","links":[],"tags":["스토리","storage"],"content":"\n\n                  \n                  본 글은 #draft 상태입니다. \n                  \n                  \n                \n                \n\n SSD 의 작동 원리 총정리\n\n"},"botanicals/storage/draft/Flash-Friendly-File-System,-F2FS-(Storage)":{"title":"Flash Friendly File System, F2FS (Storage)","links":[],"tags":["용어집","storage"],"content":"\n\n                  \n                  본 글은 #draft 상태입니다. \n                  \n                  \n                \n                \n\n 내용 정리\n\n"},"botanicals/storage/draft/Non-Volatile-Memory-Express,-NVMe-(Storage)":{"title":"Non-Volatile Memory Express, NVMe (Storage)","links":[],"tags":["용어집","storage"],"content":"\n\n                  \n                  본 글은 #draft 상태입니다. \n                  \n                  \n                \n                \n\n 내용 정리\n\n"},"botanicals/storage/draft/One-shot-Programming-(Storage)":{"title":"One-shot Programming (Storage)","links":[],"tags":["용어집","storage"],"content":"\n\n                  \n                  본 글은 #draft 상태입니다. \n                  \n                  \n                \n                \n\n 내용 정리\n\n"},"botanicals/storage/draft/Parallel-ATA,-AT-Attachment,-Integrated-Drive-Electronics,-PATA,-ATA,-IDE-(Storage)":{"title":"Parallel ATA, AT Attachment, Integrated Drive Electronics, PATA, ATA, IDE (Storage)","links":[],"tags":["용어집","storage"],"content":"\n\n                  \n                  본 글은 #draft 상태입니다. \n                  \n                  \n                \n                \n\n 내용 정리\n\n"},"botanicals/storage/draft/Small-Computer-Systems-Interface,-SCSI-(Storage)":{"title":"Small Computer Systems Interface, SCSI (Storage)","links":[],"tags":["용어집","storage"],"content":"\n\n                  \n                  본 글은 #draft 상태입니다. \n                  \n                  \n                \n                \n\n 내용 정리\n\n"},"botanicals/storage/draft/Total-Cost-Ownership,-TCO-(Storage)":{"title":"Total Cost Ownership, TCO (Storage)","links":[],"tags":["용어집","storage"],"content":"\n\n                  \n                  본 글은 #draft 상태입니다. \n                  \n                  \n                \n                \n\n 내용 정리\n\n"},"botanicals/storage/draft/Zoned-Block-Commands,-ZBC-(Storage)":{"title":"Zoned Block Commands, ZBC (Storage)","links":[],"tags":["용어집","storage"],"content":"\n\n                  \n                  본 글은 #draft 상태입니다. \n                  \n                  \n                \n                \n\n 내용 정리\n\n"},"botanicals/storage/draft/Zoned-Device-ATA-Command-Set,-ZAC-(Storage)":{"title":"Zoned Device ATA Command Set, ZAC (Storage)","links":[],"tags":["용어집","storage"],"content":"\n\n                  \n                  본 글은 #draft 상태입니다. \n                  \n                  \n                \n                \n\n 내용 정리\n\n"},"botanicals/storage/draft/Zoned-Namespaces,-ZNS-(Storage)":{"title":"Zoned Namespaces, ZNS (Storage)","links":["botanicals/storage/terms/Zoned-Storage-Model-(Storage)","botanicals/storage/draft/Non-Volatile-Memory-Express,-NVMe-(Storage)"],"tags":["용어집","storage"],"content":"\n\n                  \n                  참고한 자료 \n                  \n                \n\nZNS: Avoiding the Block Interface Tax for Flash-based SSDs (USENIX ATC ‘21)\nWD 블로그\n\n\n\n\n                  \n                  본 글은 #draft 상태입니다. \n                  \n                  \n                \n                \n\n 내용 정리\n\n\n이게 뭐임 §\n\nZoned Storage Model 에 대한 NVMe 의 구현체이다.\n"},"botanicals/storage/draft/논문---ZNS,-Avoiding-the-Block-Interface-Tax-for-Flash-based-SSDs":{"title":"논문 - ZNS, Avoiding the Block Interface Tax for Flash-based SSDs","links":["botanicals/storage/terms/Logical-Block-Addressing,-LBA-(Storage)","botanicals/storage/terms/Flash-Memory,-SSD-(Storage)","botanicals/storage/terms/Flash-Translation-Layer,-FTL-(Storage)","botanicals/storage/terms/Garbage-Collection,-GC-(Storage)","botanicals/storage/terms/Over-Provisioning,-OP-(Storage)","botanicals/storage/terms/Multi-stream-SSD-(Storage)","botanicals/storage/terms/Open-Channel-SSD,-OCSSD-(Storage)","botanicals/storage/terms/Zoned-Storage-Model-(Storage)","botanicals/storage/terms/Write-Amplification,-WA-and-Write-Amplication-Factor,-WAF-(Storage)","botanicals/database/rocksdb/LSM-Tree-(RocksDB)","botanicals/storage/draft/Flash-Friendly-File-System,-F2FS-(Storage)","botanicals/storage/terms/Shingled-Magnetic-Recording-HDD,-SMR-HDD-(Storage)","botanicals/os/fs/Slack-Space-Recycling,-SSR-(File-System)","botanicals/database/rocksdb/Memtable-(RocksDB)","botanicals/database/rocksdb/Static-Sorted-Table,-SST-(RocksDB)","botanicals/database/rocksdb/Leveled-Compaction-(RocksDB)","botanicals/storage/terms/Throughput-(Storage)","botanicals/storage/terms/Latency-(Storage)","botanicals/storage/draft/One-shot-Programming-(Storage)"],"tags":["논문","storage"],"content":"\n\n                  \n                  이 글은 USENIX ATC &#039;21 에 소개된 ZNS: Avoiding the Block Interface Tax for Flash-based SSDs 논문을 읽고 정리한 것입니다.\n                  \n                \n\n\n\n                  \n                  본 글은 #draft 상태입니다. \n                  \n                  \n                \n                \n\n 내용 정리\n\n\n1. Introduction §\n\n본 논문에서는 아래의 다섯가지 contribution 을 소개한다:\n\n기존의 Block SSD 와 ZNS SSD 간의 성능 비교\nZNS 에 대한 전반적인 리뷰\nHost software layer 에 ZNS SSD 적용하는 과정에서 배운 점들\nZNS 를 사용하기 위해 Storage stack 전반을 수정한 내용\n\n여기에는 Linux 커널, F2FS 파일시스템, NVMe 드라이버, Zoned Block Device 서브시스템, fio 벤치마크 툴이 포함된다.\n\n\nRocksDB 에서 ZNS SSD 를 사용하기 위한 새로운 스토리지 백엔드로 ZenFS 구현\n\n\n\n2. The Zoned Storage Model §\n2.1. The Block Interface Tax: 기존 방식의 문제점 §\n\nBlock Interface 는 이전의 HDD 를 위해 고안된 것으로, 고정된 크기의 block 들을 1차원 배열로 묶어 사용/관리하는 방식이다.\nSSD 가 등장했을 때에는 이러한 Block interface 와의 backward-compatibility 를 위해 FTL 과 같은 레이어가 추가되었다.\n하지만 SSD 와 HDD 는 작동 방식이 다르기에 FTL 은 여러 부작용 을 낳았다.\n\nGC 오버헤드\nGC 에서 데이터를 이동할 때 사용할 임시 저장 공간을 위한 OP\nFTL 을 위한 DRAM\nGC 오버헤드를 줄이기 위한 Application level 의 최적화 - 에 따라 증가하는 복잡도\n성능을 예측하기 힘듦 (performance unpredictability)\n\n\n위의 자원들 중 OP 와 DRAM 은 모두 현재의 SSD 가 감수해야 하는 아주 비싼 자원들이다.\nBlock interface 를 위해 고안된 FTL 은 Host 가 LBA 에만 접근할 수 있도록 하여 Host 의 물리적인 데이터 저장 위치를 관리 권한이 박탈되었다.\n\n2.2. Existing Tax-Reduction Strategies: 문제점을 해결하기 위해 이전에 시도된 것들 §\n\nMulti-stream SSD: GC 를 줄이는데 도움은 되나, 여전히 OP 공간과 FTL 을 위한 DRAM 을 필요로 한다.\nOCSSD: GC 도 줄이고 OP 공간과 DRAM 의 필요성을 줄여주었지만, 모든 SSD 에 대응할 수 있는 인터페이스가 OS 에 구현되어야 하기 때문에 한계점이 있다.\n\n2.3. Tax-free Storage with Zones: 문제를 해결하기 위한 접근 §\n\n“Backward-compatibility 는 포기하더라도, SSD 를 위한 새로운 방식의 Interface 를 만들자” 라는 생각으로 Block Interface Tax 문제에 접근한 것이 Zoned Storage Model 이다.\n해당 Model 에 대한 NVMe 의 구현체인 ZNS 는 이러한 기능을 제공해 준다:\n\nZoned Storage Model 와 완벽하게 호환됨\nSSD 의 특징을 최대한으로 이끌어내 성능을 높임\n(OCSSD와는 다르게) 각 디바이스의 특성과는 무관함\n\n\n\n3. Evolving towards ZNS: ZNS를 도입해 보자 §\n\nZNS 는 data placement 및 gc 과정을 host 에게 위임함으로써 device level 의 WAF 를 없앴고, 따라서 OP 도 적게 사용하며 성능과 ssd 의 수명도 늘렸다\n\n3.1. Hardware Impact §\nZone Sizing §\n\nZone 은 여러 die 의 block 들 (이것을 stripe 라고도 한다) 로 구성된다.\nZone size 가 커지는 것은 더욱 많은 die 의 block 들을 응집할 수 있으므로, (1) die-level fault 에서 데이터를 보호하기 쉽고 (2) 병렬 처리율이 높아진다는 장점이 있다.\n\n반대의 극단을 생각해보면 이해가 빠르다: zone 의 block 이 한 die 에 속하게 된다면,\n(1) 해당 die 에 문제가 생기면 zone 전체가 날라가게 되고 1\n(2) 해당 die 에만 command 를 실행할 수 있으므로 병렬처리율도 낮아져 성능도 낮아진다.\n\n\n반대로 커지는 것에 대한 단점은 zone 의 갯수가 작아지기 때문에 data placement 선택권이 낮아져 ZNS 의 이점을 살리지 못한다.\n\n만일 storage 전체를 커버하는 zone 하나만이 존재한다고 생각해 보자.\n그럼 모든 종류의 lifecycle 을 가지는 data 들이 하나의 zone 에 포함되게 되고, 결국에는 gc 를 해야 하거나 reset 시 valid data 가 날라가게 된다.\n\n\n따라서 data placement 선택권을 최대한 주기 위해 zone size 를 최대한 줄이되, die-level fault 에 영향과 병렬 처리율 감소를 감당할 수준이 될 정도까지만 줄였다고 한다.\n만일 reliability 를 포기한다면 zone(stripe)-wide parity 를 없애서 zone size 를 더욱 더 줄일 수 있으나 host level 에서 이런 parity 를 구현하거나 작아진 zone size 를 위해 IO queue depth 를 늘리는 것과 같은 희생을 감내해야만 한다.\n\nMapping Table §\n\n기존의 Block interface SSD 에서는 Fully-associative mapping table (Page level mapping) 을 사용했는데, 이것은 당연히 엄청난 양의 DRAM 공간을 필요로 한다.\n하지만 ZNS 의 Sequential write constraint 는 이것을 erase block level 혹은 hybrid fashion 으로 바꿀 수 있게 해서 DRAM 공간을 줄이거나 필요성을 아예 없앨 수도 있다고 한다.\n어떻게 ZNS 가 이런 것을 가능하게 하는지는 설명 안한다.\n\nDevice Resources §\n\n이것은 Open Zone Limit 과 연관된 내용이다.\nActive zone 의 data 와 parity 를 위해서는 XOR 엔진이나 SRAM, DRAM 같은 자원과 parity 보존을 위한 power capacitor 가 필요하다.\n하지만 zone 의 data 와 parity 의 사이즈는 아주 크고 2 자원의 양은 한정되어 있기 때문에 8개에서 32개의 active zone 만을 유지할 수 있고 이것이 Open Zone Limit 으로 제한걸려있는 것.\n이 active zone 개수를 늘리기 위해서는 다음과 같은 전략을 취할 수 있다고 한다 3 :\n\n더 많은 자원을 구비하거나 (adding extra power capacitors)\n최적화를 통해 자원 사용량을 줄이거나 (utilizing DRAM for data movements)\nParity 를 조금 포기하는 방법\n\n\n\n3.2. Host Software Adoption §\n\n이 섹션에서는 ZNS 를 도입하기 위한 host software 변경 세 가지를 소개한다:\n\nHost-side FTL (HFTL)\nFile System\nEnd-to-End Data Placement\n\n\nZNS 는 sequential write 가 기본 원리에 깔려있기 때문에, sequential write 를 자주 사용하는 application 에 적합하다.\n\n가령 LSM Tree 와 같은 것들\n당연히 in-place update 가 잦은 시스템은 ZNS 도입이 어렵다.\n\n\n\nHost-side FTL (HFTL) §\n\n이놈은 ZNS 의 sequential write 와 application 의 random write (+ in-place update) 간의 다리 역할을 해준다.\n기존의 FTL (SSD FTL) 과의 차이점은\n\n이름이 HFTL 인 만큼 SSD 에 포함되는 것이 아닌 Host OS 에 포함되는 계층이라는 것\nSSD FTL 의 역할 중 (1) address translation mapping 과 (2) GC 만 담당하는것 이다.\n\n\n이놈이 host 에서 작동한다는 것은, 다음과 같은 장단점을 가질 수 있다:\n\n일단 장점으로는 host 의 정보를 활용하여 data placement 와 gc 를 수행할 수 있도록 해준다\n단점 (주의할 점?) 으로는 host 와 cpu 및 mem 을 공유하기에 너무 많은 cpu 와 mem 을 먹지 않도록 해야 한다고 한다.\n\n\n이것의 구현체는 다음과 같은 것들이 있다고 한다:\n\ndm-zoned\ndm-zap - 논문 작성 시점에는 이놈만 ZNS 를 지원했다고 한다\npblk\nSPDK FTL\n\n\n\nFile System §\n\nFile system 은 application 들이 “file” 형식으로 storage 에 접근할 수 있도록 해준다.\nFile system 을 zone 과 통합함으로써 4, 여러 overhead 들 (data placement overhead 혹은 indirect overhead 5 와 같은 FTL 과 HFTL 이 발생시키는 overhead) 을 없앨 수 있다고 한다.\n또한 file 의 데이터 특성 정보들을 data placement 에 활용할 수 있다.\n\n적어도 이러한 정보들이 file system 에서 인지할 수 있도록 해준다.\n\n\n대부분의 file system 들은 in-place write 를 사용하기 때문에 zone 을 사용하기 힘들다.\n하지만 f2fs, btrfs, zfs 는 sequential write 자주 사용하고, 따러서 zone 또한 지원하도록 업데이트 되었다고 한다.\n\n물론 모든 write 가 sequential 한 것은 아니다; superblock 이나 metadata 같은 경우에는  in-place write 를 사용한다.\n하지만 이러한 non-sequential write 의 경우에는 strict log-structured write, floating superblock 과 같은 방법을 이용해 해결할 수 있다고 한다.\n\n\n이러한 file system 에는 HFTL 의 로직들이 많이 포함된다고 한다.\n\nMetadata 를 통해 on-disk 로 관리되는 LBA mapping table 이랄지\nGC 기능이랄지\n\n\n하지만 논문 작성 당시 위 file system 들은 ZAC/ZBC 만을 지원했고, 따라서 본 논문에서는 f2fs 에서 ZNS 를 지원하도록 개발했다고 한다.\n\nEnd-to-End Data Placement §\n\nEnd-to-End Data Placement 는 application 이 중간 fs 와 같은 layer 를 거치지 않고 직접 device 에 data placement 를 실시하게 하는 것이다.\n\n이렇게 함으로써 application 에는 data placement 에 대한 최대의 자율성을 제공해 줄 수 있고\n동시에 indirection overhead 5 도 줄일 수 있다.\n또한 application 자체에서 raw block device 에 접근하는 것이기에 성능이 향상되고 WAF 도 줄어든다.\n\n\nFile system 을 포기하는 것은 당연히 쉬운 일은 아니다; file 형식을 사용할 수 없기 때문에, application 에 직접 zone support 를 추가해야 되고, data inspection, error checking, backup/restore operation 을 위한 tool 또한 제공되어야 한다.\n이 방법을 사용하기에 용이한 application 은 당연히 sequential write 를 활용하고 있는 것들이고, 여기에는 대표적으로\n\nLSM 을 활용하는 RocksDB\n캐싱 스토어인 CacheLib\n오브젝트 스토어인 Ceph SeaStore\n\n\n본 논문에서는 RocksDB 에 ZNS E2E Data Placement 를 지원하기 위한 ZenFS 를 개발하였고, 이것을 f2fs 를 사용했을 때 등과 비교했다고 한다.\n\n4. Implementation §\n\n본 논문에서는 ZNS support 를 위해 다음의 4가지 기여를 했다고 한다.\n\nLinux kernel 수정\nF2fs 수정\nFio 수정\nZenFS (ZNS 용 RocksDB backend store) 개발\n\n\n\n4.1. General Linux Support §\n\nLinux kernel 의 Zoned Block Device (ZBD) subsystem 은 zoned storage model 을 따르는 device 들에 대한 API 를 제공해 준다.\n\n이 API 들에는 list devices, report of zones, zone management (open, reset 등) 이 포함된다.\nKernel-level 및 user-level (ioctl) API 모두 제공한다더라.\n\n\n이런 API 들을 활용해 fio 와 같은 툴들이 device-speecific 하지 않은 zoned storage model operation 을 이용하게 된다.\n본 논문에서는,\n\nZBD subsystem 에서 ZNS SSD 를 등록하거나 나열할 수 있게 하기 위해 NVMe 드라이버를 수정했고\nZNS 를 테스트할 때 활용하기 위해 ZBD subsystem 에 zone capacity attribute 와 active zones limit 을 추가했다고 한다.\n\n\n\nZone Capacity §\n\nLinux kernel 은 모든 zone 에 대한 zone descriptor data structure 6 들을 host memory 상에 저장해 두고 사용하고, 문제가 생겼을 경우에는 특정 디스크로부터 다시 가져와서 사용한다.\n논문의 저자들은 Zone descriptor data structure 에 zone capacity 라는 attribute 를 추가했다고 한다.\n그리고 fio 와 f2fs 에서 해당 attribute 를 사용하기 위한 수정을 했다.\nfio 의 경우에는 그냥 zone capacity 내에서만 IO 를 수행하도록 수정하면 되었지만,\nf2fs 의 경우에는 수정할 것이 많았다고 한다.\n\n\n\n기존의 f2fs 는 다음과 같은 특징을 가졌다고 한다.\n\nf2fs capacity (zone capacity 랑 다른거임) 는 segment (2MiB) 단위로 관리되고, 이 segment 들이 모인 것을 section 라고 하며, 이놈의 크기가 zone size 이다\nf2fs 는 section 의 segment 들에 sequential write 를 수행하고,\n일부만 write 할 수 있는 segment 따위는 없었다.\n\n\n여기에 zone capacity 를 f2fs 에서 지원하기 위해 다음과 같은 변경이 이루어졌다\n\n기존의 세 segment type (free, open, full) 이외에 두개의 segment type (unusable, partial) 이 추가되었다고 한다.\n\nunusable 은 zone 의 unwritable part (아마 zone size 에서 zone capacity 를 제하고 남은 공간) 을 나타내는 segment\npartial 은 unwritable 과 writable 이 섞여있는 segment (zone capacity 가 끝나고 unwritable 이 시작되는 부근의 segment)\n즉, zone capacity 크기가 segment 크기의 배수가 아닌 경우에 partial 이 생김\n\n\n\n\nSMR HDD 에는 zone capacity 를 지원하지 않기 때문에, zone capacity 는 zone size 와 동일하게 초기값이 설정된다.\n\nLimiting Active Zones §\n\nActive Zone Limit 은 Zoned Block Device subsystem 에서 device listing 을 할 때 인식되어 kernel/user-space API 로 노출된다.\n이것은 ZNS SSD 만의 특징이기에 SMR HDD 에는 필요하지 않는 값이고, 따라서 0으로 초기화된다.\nFio 의 경우에는 이것을 위한 수정사항은 없다고 한다; 그냥 사용할 때 알아서 이 limit 을 지켜야 하고, 만일 그렇지 않는다면 IO error 가 발생한다.\nF2fs 의 경우에는 이 limit 이 f2fs 의 open segment limit 7 과 결부된다. f2fs 에서는 open segment limit 을 6으로 제한해 놓았고, 만일 device 가 active zone limit 을 6까지 지원하지 않는 다면, 그에 맞게 조정할 수 있다.\n\n\n\n                  \n                  주인장의 한마디 \n                  \n                \n\nZone 은 여러 segment 들로 구성되는 것을 고려해 보면, open segment limit 이 너무 적은 것 아니냐 싶을 수 있다.\n근데 아마 zone 당 open segment 를 1개씩만 유지하는 것이 아닐까 싶다.\nZone 은 어차피 writing pointer 가 있는 segment 에만 write 할 것이기 때문에, 해당 segment 만 open 하면 되지 않을까.\n따라서 f2fs 의 open segment limit 이 6이기 때문에, f2fs 를 사용할 때에는 active zone limit 도 6을 넘지 못할 것 같다.\n\n\n\nF2fs 는 메타데이터를 Conventional Zone 에 저장하는 것을 필요로 한다.\n\nZoned Storage Model 에도 있는 만큼 ZNS SSD 에서 이것을 지원하는 것이 기본이고, 따라서 본 논문의 저자도 이것과 관련해서는 딱히 수정을 하지 않았다고 한다.\n하지만 어떤 ZNS SSD 의 경우에는 이것을 지원하지 않는 경우도 있을 것이고, 이때에는 btrfs 나 dm-zap 에서 처럼 Sequential write required zone 에서 일반적인 block interface 를 제공하도록 기능을 추가할 수도 있을 것이다.\n\n\nF2fs 에서는 Zoned device 들에서 SSR 기능을 사용하지 못하도록 되어 있다.\n\n이것은 어느 정도 성능 저하를 유발할 수 있는데, 그럼에도 불구하고 ZNS SSD 의 전반적인 빠른 성능때문에, 일반 SSD 에서 f2fs-SSR 기능을 사용했을 때보다 더 성능이 좋았다고 한다.\n\n\n\n4.2. RocksDB Zone Support §\n\n이 섹션에서는 RocksDB 에서 Zoned device 를 사용하기 위해 ZenFS 라는 backend store 를 구현한 것에 대해 설명한다.\n\nZenFS 는 RocksDB 의 LSM 과 seqential-only compaction 를 ZNS SSD 에서 효율적으로 수행할 수 있게 도와준다.\n\n\n\nRocksDB 기본 설명 §\nLog Structured Merge Tree §\n\nRocksDB 에서의 LSM tree 는 인메모리 Memtable 와 저장장치에의 여러 level 들 (L0 ~ LMAX) 로 구성되는데\n우선 memtable 에 데이터가 저장되고, 이후 주기적 혹은 memtable 의 공간이 부족해지면 L0 로 flush 된다.\n\nMemtable 의 내용은 WAL 이 작성되어 crash recovery 를 지원한다.\nMemtable 에서 L0 으로 flush 될 때는 key 를 기준으로 중복 제거 및 정렬되어 SST 로 저장된다.\n이 SST 들은 변경이 불가능하고 sequential write 되며 SST 단위로 생성과 삭제된다.\n\n\nLevel 은 사이즈가 exponential 하게 증가하고, 각 level 에는 여러 SST 파일들이 key 범위가 겹치지 않게 저장된다.\n하위 level 로 내리는 작업은 Compaction 를 통해 수행된다.\n\nCompaction 에서는 현재 level 의 SST 와 다음 level 의 SST 가 병합되어 다름 level 의 새로운 SST 로 생성되게 된다.\n낮은 level 로 갈수록 오래된 key-value 가 저장되기에 자연스럽게 hot-cold separation 이 달성된다.\n\n\n\nBackend Storage API §\n\nRocksDB 는 File System Wrapper API 를 통해 다양한 backend storage 를 단일 인터페이스를 통해 사용할 수 있도록 설계되어 있다.\nWrapper API 는 데이터의 단위 (SST 파일 혹은 WAL 등) 을 고유한 식별자 (파일 이름 등) 으로 식별한다.\n이 식별자들은 파일과 같은 하나의 연속된 주소 공간 (byte-addressable linear address space) 상에 저장된다.\n이 식별자들에 대해서는 add, remove, current size, utilization, random access, sequential r/w 의 연산이 가능하다.\n따라서 이런 연산들은 file interface 과 유사하기에, RocksDB 도 file 을 주된 backend store 로 사용한다.\n즉, 데이터 접근이나 버퍼링, free space management 등을 fs 의 도움을 받아서 사용하는 것이 흔하나\nFile system 을 거치지 않고 zone 에 직접 data 를 넣는 e2e 방식을 사용하면 더욱 성능이 좋아질 것이기에 ZenFS 를 개발하게 된 것.\n\n4.2.1. ZenFS Architecture §\n\n정리하자면 ZenFS 는 ZNS SSD 의 특성을 최대한 살려 RocksDB 에서 사용할 수 있도록 FS 의 필수적인 것만 구현한 것이다.\n\nJournaling and Data §\n\nZenFS 는 두가지 종류의 zone 이 존재한다:\n\nJournaling Zone: 이것은 다음과 같은 용도로 사용된다:\n\nFS 의 crash recovery\nSuperblock 구조 유지\nWAL 과 data file 을 zone 에 매핑\n\n\nData Zone: 일반적인 data file 을 저장\n\n\n\nExtents §\n\nData file 들은 Extent 라는 단위로 저장되고, 또 이들은 하나의 data zone 에 sequential write 된다.\n\nExtent 는 (1) 가변 크기 (2) 블럭 단위 (3) 연속된 공간 이라는 특징을 가진다.\n특정한 ID 와 연관된 데이터들이 들어있다\n하나의 zone 에는 여러 extent 가 들어가지만 extent 가 zone 을 넘칠 수는 없다.\n\n\nExtent 에 대한 metadata 8 는 인메모리에 자료구조에 기록된다.\n\nExtent metadata 에는 를 할당하고 반환하는 것, extent 가 어느 zone 에 매핑되었는지 추적하는 등이 포함된다.\n이것은 Extent 의 file 이 close 되거나 rocksdb 가 명시적으로 flush 하면 journal zone 에 기록된다.\nZone 의 모든 extent 에 할당된 파일들이 모두 삭제되면 zone 은 reset 될 수 있다.\n\n\n\nSuperblock §\n\nSuperblock 은 ZenFS 를 초기화하거나 복구할 때 첫 진입점이 된다.\n현재의 상태에 대한 ID 값, magic value 9, user option 등이 저장된다.\n“현재의 상태에 대한 ID 값” 은 system 에서의 device 순서가 바뀌어도 (가령 재부팅 이후 /dev/nvme0 에서 /dev/nvme1 로 바뀌는 등) filesystem 을 식별할 수 있게 해준다.\n\nJournal §\n\nZenFS 가 journaling 을 하는 것은 아래의 두가지 목적을 위해서 이다:\n\nSuperblock 저장\nWAL 과 data file 이 어떤 extent 를 통해 어떤 zone 에 매핑되었는지를 추적\n\n\n당연히 journal state 는 journal zone 에 저장되는데, 이것은 OFFLINE 상태가 아닌 첫 두 zone 으로 지정된다.\n\n두 zone 은 번갈아 사용되며 journal state update 가 logging 된다.\n(F2FS 에서처럼 이전 버전의 journal zone 을 보존해놓는 용도 아닐까)\n\n\nJournal zone 에는 제일 먼저 header 가 저장된다.\n\nHeader 에는 (1) sequence number (새로운 journal zone 이 초기화될 때마다 증가하는 값) (2) superblock 자료 구조 (3) 현재의 journal state 에 대한 스냅샷 (journal snapshot) 이 들어간다.\nheader 가 저장된 이후에는 journal update 들이 쭉 logging 된다.\n\n\nJournal zone 를 이용해 ZenFS 를 초기화하는 것은 다음과 같은 세 단계로 진행된다.\n\n두 journal zone 의 첫 LBA 를 읽은 후, 여기의 header 에서 sequence number 를 읽어와 어떤 journal zone 이 더 최신인지 (어떤 zone 이 active zone 인지, 더 sequence number 가 높은지) 확인한다.\nActive zone 의 header 전체를 읽어들여 superblock 과 journal state 를 초기화한다.\njournal update 를 쭉 따라가며 journal snapshot 에 반영한다.\n\n\nJournal update 를 어디까지 따라가며 journal snapshot 에 반영할지는 zone 의 상태와 write pointer 에 따라 결정된다.\n\n만일 zone 이 OPEN 혹은 CLOSED 상태라면 현재 write pointer 가 있는 위치까지의 journal update 가 반영된다.\n만일 zone 이 FULL 상태라면 header 뒤의 모든 journal update 가 반영된다.\n\n만일 zone 이 FULL 상태라면 recovery 이후 나머지 한 journal zone 이 active 가 되며 초기화 후 journal update 를 logging 하게 된다.\n\n\n\n\nFresh journal state 를 생성하는 것은 타 file system 의 초기화 툴과 비슷한 방식으로 진행된다.\n\nZenFS 의 fresh journal state 초기화 툴은 journal zone 에 sequence number 초기값, superblock, 빈 journal snapshot 로 이루어진 header 를 저장한다.\n\n\n만일 RocksDB 에 의해 ZenFS 가 초기화되면 상기한 모든 recovery process 가 실행되고, RocksDB 로 부터 데이터를 받아들일 준비가 된다.\n\nWritable capacity in Data Zones §\n\n\n\nData Zone Selection §\nActive Zone Limits §\nDirect I/O and Buffered Writes §\nEvaluation §\n5.1. Raw I/O Characteristics §\n5.2. RocksDB §\n5.3. Streams §\n6. Related Work §\n7. Conclusion §\n\n\n\nZNS 특징 §\n\nZNS 는 flash erase boundary 와 write ordering rule 들을 Host 에 노출시켜서 이러한 세금을 해결한다고 한다.\nNVMe Zoned Namespace Command Set Specification\n기존의 Block interface 는 Block 을 1차원 배열로 취급해 관리했지만, ZNS 는 logical block 들을 zone 으로 묶는다\nzone 의 블럭들은 random read 는 가능하지만 무조건 sequential write 되어야 한다.\n또한 zone 은 매 rewrite 작업때마다 erase 되어야 한다.\nZNS SSD 는 zone 과  physical media boundary 를 정렬해서 데이터 관리를 Host 가 직접 하도록 한다?\nZNS 는 디바이스들마다 다른 reliability 특성들과 media 관리 복잡성은 Host 로부터 감춘다?\nZNS 는 효율적으로 erase block 을 하기 위한 책임을 Host 로 이전한다.\nLBA-PBA 매핑과 데이터 저장 위치 선정을 통합하는 것보다는 이러한 FTL 의 책임 중 일부를 Host 에 이관하는 것은 덜 효과적이다?\n\nZNS 성능 측정 §\n\nConcurrent write 수행시 ZNS SSD 가 Block SSD 보다 2.7배 Throughput 이 좋았다.\nRandom read 수행시 ZNS SSD 가 Block SSD 보다 64% 낮은 Latency 를 보여줬다.\nRocksDB 를 f2fs + ZNS SSD 와 POSIX fs + Block SSD 에서 사용했을 때, ZNS 를 사용할 때가 2-4 배 낮은 random read latency 를 보여줬다.\n또한 RocksDB 를 ZenFS + ZNS 에서 사용했을 때, POSIX + Block SSD 를 사용했을때 보다 2배 높은 throughput 을 보여줬다.\n\n\n\n출처\n\n\n위 그림은 ZNS SSD 와 OP 가 다르게 설정된 Block SSD 두개 총 세개의 SSD 의 write throughput 을 실험한 것이다.\n실험은 SSD 의 물리 사이즈인 2TB 데이터를 총 4번 concurrent 하게 write 하는 방식으로 진행했다. (02: 첫번째 write, 24: 두번째 write, 이런식으로 아마?)\n첫 write 에서는 SSD 가 fresh 한 상태였기에 세 SSD 간의 성능 차이가 없었지만, 두번째 write 부터는 기존 데이터가 overwrite 되며 Block SSD 들에서 성능 저하가 나타났다.\n또한 Block SSD 끼리 비교했을 때에는, OP 를 더 많이 설정한 SSD 가 그나마 성능 저하가 덜 나타나는 것으로 확인됐다.\n다만 28% OP 를 먹인 SSD 의 경우에는 공간이 부족하기 때문에 write 가 6TB 을 넘어가자 더이상 기록되지 않는 것을 볼 수 있다.\n\n\nFootnotes §\n\n\n다만, (1) 의 경우에는 본문에서는 좀 다른 뉘앙스로 말한다. 여러개의 die 에 분산되어 있으면 parity 를 구성하기 용이하기에 여러 die 에 분산시키는 것이 protection 에 유리하다고 한다. - “There is a direct correlation between a zone’s write capacity and the size of the erase block implemented by the SSD. In a block-interface SSD, the erase block size is selected such that data is striped across multiple flash dies, both to gain higher read/write performance, but also to protect against die-level and other media failures through per-stripe parity.” ↩\n\n\n본문에서는 zone 사이즈가 큰 이유로 Two-step programming 을 언급하지만, 어떤 연관이 있는지 모르겠다. ↩\n\n\n본문에서는 SLC 에서의 Write-back cache 를 사용하는 방법도 소개한다. 이게 뭔지는 모르겡누 ↩\n\n\n본문에서는 통합의 예시로 “ensuring a primarily sequential workload” 를 제시하는데 감이 안온다. ↩\n\n\n본문에서 말하는 “Indirection overhead” 는 Don’t stack your Log on my Log, INFLOW ‘14 논문에서 제기된 문제를 말하는 것이다. 해당 논문에서는 sequential write 를 활용하기 위한 방법 중 하나인 log-structured 를 중복해서 사용하는 것 (가령, log-structured fs 위에서 log-structured application 을 사용하는 등) 이 오히려 성능 저하를 유발한다고 한다. ↩ ↩2\n\n\n“Zone Descriptor Data Structure” 는 본문에 별도의 설명이 되어 있지는 않지만, 일단 zone 의 메타데이터로 생각하고 넘어가자. 아마 “Zone Descriptor” 는 zone 의 attribute 들에 대한 key-value 쌍이 아닐까. ↩\n\n\n본문에는 “Open Segment Limit” 과 같은 용어는 나오지 않는다. 대신 “The number of segments that can be open simultaneously” 라는 표현이 나오며, 주인장이 이것을 단어화 한 것. ↩\n\n\n“Extent metadata” 라는 용어는 없다. 이해를 위해 주인장이 임의로 쓴 용어이다. ↩\n\n\n이게 무엇인지는 자세한 설명이 안나온다. ↩\n\n\n"},"botanicals/storage/terms/Conventional-Magnetic-Recording,-CMR-HDD-(Storage)":{"title":"Conventional Magnetic Recording, CMR HDD (Storage)","links":["botanicals/storage/terms/Shingled-Magnetic-Recording-HDD,-SMR-HDD-(Storage)"],"tags":["용어집","storage"],"content":"\n\n                  \n                  참고한 것들 \n                  \n                \n\n서울대 김진수 교수님 고급운영체제 강의(Spring 2024)\n\n\n이게 뭐고 §\n\n\nSMR HDD 와 대조적으로, write 에 필요한 공간을 기준으로 track 너비를 산정하는 방법이다.\n\nSMR HDD 와 대조되는 개념이기에 해당 문서를 같이 참조하면 이해하기 쉬울듯.\n\n\nRead 에 필요한 공간은 write 에 필요한 공간보다 너비가 작기 때문에, write 너비로 track 너비를 정하면 데이터를 부분적으로 수정하는 것에 (in-place update) 아무 문제가 없다는 장점이 있다.\n\n즉, 데이터 수정이 빠르다는 장점이 있는 것.\n\n\n하지만 그만큼 track 의 너비가 넓어져 데이터를 저장할 공간은 부족해 진다.\n\n다시말해, 디스크의 용량이 작다는 단점이 있다.\n\n\n"},"botanicals/storage/terms/Data-Chunk-(Storage)":{"title":"Data Chunk (Storage)","links":[],"tags":["storage","용어집"],"content":"데이터 청크, Data Chunk §\n\n이놈도 분야별로 의미가 살짝은 다르긴 한데\nStorage 분야에서는 “한번에 (atomic 하게) 처리되는 데이터” 정도로 생각할 수 있을 것 같다.\n\n즉, “Input (write) 혹은 output (read) 작업 1회 수행시 처리하는 데이터” 정도로 이해하자.\n\n\n따라서 Data Chunk Length 는 “한번에 처리되는 데이터의 양” 로 이해할 수 있다.\n"},"botanicals/storage/terms/Flash-Memory,-SSD-(Storage)":{"title":"Flash Memory, SSD (Storage)","links":["botanicals/storage/terms/Write-Amplification,-WA-and-Write-Amplication-Factor,-WAF-(Storage)","botanicals/storage/terms/Garbage-Collection,-GC-(Storage)","botanicals/storage/draft/Deep-Dive-SSD---Storing-and-Detecting-Electrons-(Storage)","botanicals/storage/terms/PE-Cyclen-Limit,-Wearing-off-(Storage)","botanicals/storage/terms/Multi-Level-Cell,-MLC-(Storage)","botanicals/storage/terms/Pre-conditioning-(Storage)","botanicals/storage/terms/Data-Chunk-(Storage)","botanicals/storage/terms/Throughput-(Storage)","botanicals/storage/terms/Input-Output-per-second,-IOps-(storage)","botanicals/storage/terms/Latency-(Storage)"],"tags":["storage","용어집"],"content":"\n\n                  \n                  참고한 자료 \n                  \n                  \n                \n                \n\n블로그 글\n어떤 회사 블로그 글\n어떤 글\n카카오 테크 블로그\n\n\n이게 무언가? §\n\n반도체 소자를 이용해 전기적으로 읽고 (read) 쓸 (write, program) 수 있는 저장장치를 말한다.\n하나의 비트는 Floating-gate 트랜지스터로 구성된 셀에 저장되며 여기에 전압을 가해 bit 를 읽거나 쓰게 된다.\n\n구조 §\n\n\n출처\n\nHost Interface §\n\nHost Interface 로 부터 호스트 (가령 OS) 의 요청이 들어오게 된다. 조립컴 살때 종종 보이는 SATA 나 PCIe 가 여기에 속한다.\n\nSATA 3.0 는 대략 550Mb/s, PCIe 3.0 는 1 lane 당 1Gb/s 의 속도를 낸다. (보통은 4, 8 lane 으로 구성된다)\n대부분의 SSD 는 처리 속도가 550Mb/s 보다는 크기에, SATA 3.0 을 사용하는 것은 Host Interface 에의 병목이 생기게 된다.\n\n\n\nFlash memory package §\n\nFlash memory package 가 실제 정보 저장을 위한 반도체 소자이다.\n요놈의 구조를 하나씩 살펴보자.\n\n\n\nBit 를 저장하는 최소단위인 cell 이 있고\nCell 이 모여 page 가 되고\n\nPage 는 Read/Write operation 의 데이터 크기 단위이다. (Read/Write by Page)\n\n\nPage 가 모여 block 이 되고\n\nBlock 은 Erase operation 의 데이터 크기 단위이다. (Erase by Block)\n\n\nBlock 이 모이면 plane 이 되고\n\nPlane 은 Read/Write operation 의 단위이다.\nPlane 별로 register 가 존재하고, read 한 데이터는 이 register 에 채워진 후 SSD controller 에 보내지며 write data 또한 이 register 에 채워진 후 page 에 저장된다.\n\n\nPlane 이 모이면 die 가 되고\n이 die 들이 하나의 chip 을 구성하게 된다\n\nSSD Controller, RAM, Channel §\n\nSSD 의 컨트롤러에도 나름의 Processor 와 RAM 이 있다.\n\nProcessor 는 명령어를 받아서 Flash Controller 로 보내고\nRAM 은 매핑 정보를 저장하거나 캐시로 쓰인다.\n\n\nFlash Controller 는 실제 반도체 소자인 Flash Memory Package 와 Channel 로 연결되어 제어하게 된다.\n\nOperation 상의 특징들 §\nRead/Write by Page §\n\nRead, Write (혹은 program 이라는 용어도 쓴다) 작업은 page 단위로 이루어 진다.\n사용자 입장에서 하나의 byte 만 읽고 쓰는건 가능하다. 하지만 이 요청이 SSD 레벨로 가게 되면 동일하게 page 전체를 r/w 하고 나머지는 버리게 된다.\n\nPage 에 부분적으로 write 할 수는 없다. 즉, write 하려는 데이터가 page 사이즈보다 작을 경우 나머지 공간은 그냥 빈공간으로 남고 그 공간에 이어서 write 할 수는 없다. (이러한 경우도 WA 에 속한다.)\n\n\n\nErase by Block §\n\nErase 작업은 page 들을 그룹한 단위인 block 단위로 이루어 진다.\n\n이때 block 에 있던 기존에 write 된 page 들은 다른 곳으로 옮겨 가게 되는데, 이 작업을 GC 라 한다.\n\n\nErase 작업을 하게 되면 해당 block 의 모든 page 가 free 상태가 된다.\nErase 를 page 단위가 아닌 더 큰 block 단위로 하는 이유는 비용때문에 설계를 그렇게 했기 때문이다.\n\n간단히 말하자면, erase 를 위한 회로를 page 마다 넣는 것이 비용상 비효율적이기 때문.\n자세한 설명은 여기 에서 해준다.\n\n\n\nFree Page Write, Non-overwritable §\n\nWrite 는 free page 에서만 가능하다.\n따라서, page overwrite (in-place update) 가 불가능하다: 이전에 write 된 적이 있는 page 는 free page 가 아니기 때문에 write 가 불가능한 것.\n\nRead-modify-write §\n\n\nPage 를 수정하고 이후 erase (gc) 하는 과정 정리 이미지 (출처)\n\n\nPage 는 in-place update 가 안되기에, 내용을 변경하고자 할 때에는 다음과 같은 방법을 사용한다.\n\n기존의 페이지는 stale 혹은 invalid 상태로 바꾸고,\n해당 페이지를 레지스터 (아마 SSD Processor 안에 있는?) 로 옮겨서 수정을 한 뒤에,\n새로운 free page 에 write 하게 된다.\n이 과정은 Read-Modify-Write 라고 부르기도 한다.\n\n\n이후 이 stale 페이지는 GC 과정에서 정리된다.\n\nP/E Cycle Limit (문서 분리: PE Cyclen Limit) §\n\nSSD 는 전기 소자의 특성때문에 r/w 횟수에 제한이 있다.\n\n종류 (문서 분리: Multi Level Cell) §\n\nSSD 는 Cell 하나가 몇개의 bit 를 표현할 수 있냐에 따라 SLC (Single), MLC (Multiple), TLC (Triple), QLC (Quadra) 등으로 나눌 수 있다.\n\n\u001dSLC 로 갈수록 용량은 줄어들지만 성능과 수명은 좋아진다.\n\n\n\n벤치마킹 §\n\nSSD 의 경우 최악의 성능을 테스트하기 위해 부하를 미리 걸어 놓는 Pre-conditioning 을 사용하기도 한다.\n\n하지만 이것이 반드시 서비스 환경에서의 성능을 반영한다고 말할 수는 없다. 랜덤 읽기 쓰기 이기 때문에 실 서비스 환경과는 당연히 차이가 있기 때문.\n실 서비스의 데이터 특성을 고려한 자체개발 (in-house) 테스트 툴을 사용하는 것이 (물론 뭐 여유가 된다면) 좋다고 하더라.\n\n\n벤치마킹을 수행할 때에는 여러 파라미터 (설정값 정도로 생각하자) 들을 주입하는데, 대표적으로는:\n\n워크로드 타입\n\n“주입되는 데이터의 특성” 정도로 생각하면 된다. 데이터가 application 에서 생성하는 특정 패턴 (뭐 json log 등의) 을 따르는지, 아니면 sequential, random r/w 인지 등\n\n\n읽기/쓰기 비율\n\n이건 뭐 말 그대로… 읽기와 쓰기를 어떤 비율로 해서 벤치마킹을 하는지\n\n\n큐 길이\n\n동시성과 관련된 것이다. 동시에 몇개의 프로세스 혹은 스레드가 부하를 거는지\n\n\n데이터 청크 길이\n\nInput 혹은 output 작업 1회 수행시 처리되는 양\n\n\n\n\n또한 이런 벤치마킹 결과는 다음과 같은 메트릭 (뭐 단위 정도로 생각하자) 으로 정량적인 결과를 산출한다:\n\n스루풋 (Throughput)\nIOps\n레이턴시 (Latency)\n\n\n벤치마킹의 결과를 해석할 때는, (각 메트릭들은 SSD 의 성능을 각기 다른 시선에서 수치화하기 때문에) 이러한 메트릭을 정확하게 이해하고 분석하는게 좋다고 한다.\n"},"botanicals/storage/terms/Flash-Translation-Layer,-FTL-(Storage)":{"title":"Flash Translation Layer, FTL (Storage)","links":["botanicals/storage/terms/Logical-Block-Addressing,-LBA-(Storage)","botanicals/storage/terms/Over-Provisioning,-OP-(Storage)","botanicals/storage/terms/Garbage-Collection,-GC-(Storage)","botanicals/storage/terms/Write-Amplification,-WA-and-Write-Amplication-Factor,-WAF-(Storage)"],"tags":["용어집","storage"],"content":"\n\n                  \n                  참고한 자료 \n                  \n                \n\n카카오 테크 블로그\n서울대 OCW 강의 자료\n\n\n이게 뭐지 §\n\nHost 에서 사용하는 주소인 Logical Block Address (LBA) 를 실제 데이터가 저장된 주소인 Physical Block Address (PBA) 로 바꿔주는 작업이 필요한데\n\n아마 이러한 LBA 가 존재하는 이유는 데이터의 실제 주소가 바뀌어도 Host 에서는 변경된 주소가 아닌 기존의 주소를 그대로 사용하게 해주기 위함이리라.\n\n\nHDD 는 overwrite 가 가능하기 때문에 LBA 어레이를 사용하는 것이 효율적이었지만 SSD 에서는 (overwrite 가 불가능하기 때문에) 다소 문제가 있다.\n\n고 하더라. 어떤게 문제가 되는지는 깊게 들어가 보지 않았다.\n\n\n따라서 SSD 에서도 HDD 의 LBA 시스템을 동일하게 지원해주기 위해 도입된 것이 Flash Translation Layer (FTL) 이다.\n이놈은 별도의 HW 가 아닌 SW layer 로, SSD Controller 펌웨어에 포함된다.\n\n주소 변환 과정 (Logical block mapping) §\n\n당연히 LBA 와 PBA 의 매핑을 테이블 형식으로 저장하게 된다.\n\n이 테이블은 SSD 내의 RAM 에 저장되고, 전원 차단시에도 이 내용을 유지하기 위해 저장공간 (플래시 메모리) 에도 저장한다.\n아마 오버프로비저닝 된 공간에 저장되겠지\n이 테이블은 L2P Table 이라고도 불린다.\n\n\nMapping table 을 구현하는 방식은 여러 가지가 있을 수 있다:\n\nPage level mapping §\n\n단순하게 생각하면 page 별 LBA-PBA 관계를 저장할 수 있을 것이다.\n구체적인 write operation 작동 방식은 다음과 같다:\n\n작동 방식 §\n\n\n출처\n\n\n(주의 - 위 예시에서 테이블에 적힌 2 와 3은 무시하자.)\n일단 LBA 의 앞부분 일부를 읽어 테이블 index 를 알아낸다. (이 index 값을 Logical page number 라고도 부른다.)\n\n위의 예시에서는 이 값이 f 이다.\n\n\n그 다음, 이 index 의 테이블 데이터 ([Physical block num, Page offset num]) 값을 읽어 온다.\n\n위의 예시에서는 [1, 3] 이다.\n\n\n해당 Physical block num 의 block 으로 가서 Page offset 에 해당하는 페이지를 찾는다.\n\n위 예시에서는 1번 block 에서 3번 page 를 찾는다.\n\n\n해당 페이지는 invalid 처리한 후에, 새로운 free page 를 찾아 write 를 하고, 테이블 entry 를 수정한다.\n\n위의 예시에서는 테이블 entry 값이 [1, 3] 에서 [2, 3] 으로 변경된다.\n\n\n그럼 write 작업은 완료되고, 이 과정에서 생성된 invalid page 는 추후에 GC 로 사라지게 될 것이다.\n\n문제점 §\n\n제일 큰 문제는 SSD 에는 수많은 page 가 있기 때문에 테이블의 크기가 너무 커지게 된다는 것이다.\n\n테이블의 크기가 커진다는 것은 다르게 말해 RAM 의 용량을 많이 차지하게 된다는 소리와 같다.\n뭐 커져봤자 얼마나 커지겠어… 라고 하지만 만일 32TB SSD 에 페이지 크기가 8KB 이고 테이블 entry 사이즈가 4byte 라면 테이블의 크기는 16GB 가 된다. (직접 계산해 보시라.)\n\n\n\nBlock level mapping §\n\n반대로 block 별 LBA-PBA 관계를 저장하면 어떻게 될까.\n당연히 page 별로 entry 가 필요한 것이 아니고 block 별로 entry 가 필요할 테니 경장히 많은 공간은 절약될 것이다.\n\n작동 방식 §\n\n\n출처\n\n\n이번에는 LBA 의 앞부분 일부를 읽어 테이블 index 를 알아내고, (이 index 값은 Logical block number 라고도 부른다.) 나머지 뒷부분 일부를 읽어 page offset 을 알아낸다. (즉, [Logical block number, Page offset num] 을 알아낸다.)\n\n위 예시에서는 [d, 3] 이다.\n\n\n그리고 이 index 의 테이블 entry ([Physical block num]) 값을 읽어 온다.\n\n위 예시에서는 1 이다.\n\n\n새로운 free block 를 찾아 동일한 offset 의 page 에 write 를 하고, 테이블 entry 를 수정한다.\n\n위의 예시에서는 테이블 entry 값이 [1] 에서 [3] 으로 변경된다.\n\n\n또한 기존에 page 가 위치하던 block 에서 변경된 page 이외의 page 전부를 새로운 block 으로 전부 복사한다.\n\n위의 예시에서는 block 1 의 page offset 0, 1, 2 데이터들을 block 3 의 page offset 0, 1, 2 로 복사한다.\n\n\n기존에 page 가 위치하던 block 의 모든 page 를 invalid 처리한다.\n\nFAQ… §\n\n여기까지 오면 머릿속에 물음표 부하가 걸릴 것이다.\n\n일단 왜 free page 가 아니라 free block 을 찾지? 하는 의문과\n왜 변경되지 않은 page 까지 전부 복사하지? 하는 의문\n\n\n이건 변경되지 않은 page 에 대한 접근을 생각해 보면 답이 나온다.\n\n위의 예시에서 LBA [d, 3] 을 변경하는 작업을 한 뒤에 변경되지 않은 page 를 복사해오지 않았다고 해보자.\n그리고 LBA [d, 2] 값을 read 하는 작업을 한다고 해보자.\n그럼 마찬가지의 과정으로 테이블에 접근해 테이블 index d 의 entry 인 Physical block number 를 알아내게 된다.\n근데 문제는 이 값이 기존의 1 이 아닌 3 으로 변경되었다는 것이다.\n그래서 Physical block number 3 으로 가서 LBA 로  page offset 인 2 로 page 를 찾아 봤자 (page 들을 복사해오지 않았기 때문에) 원하는 놈은 거기에 없다.\n\n\n즉, 테이블의 Physical block num 을 변경하는 것은 해당 block 의 모든 page 들의 LBA-PBA 관계에 영향을 미치기 때문에 변경하지 않은 page 들도 전부 복사해 오는 것.\n\n문제점 §\n\n위 과정은 딱 봐도 너무나 비효율적인 것처럼 보인다.\n\nPage 들을 복사하는 것 자체부터 수많은 WA 를 유발하고\nPage 들을 복사하는 과정에서 Invalid page 가 수도 없이 생기기 때문에 당연히 GC 도 자주 발생하게 될 것이기 때문.\n\n\n\nHybrid log-block FTL §\n\nPage 별 테이블을 구성하는 것과 block 별 테이블을 구성하는 것에는 trade-off 가 있고, 이들 간의 타협점을 찾는 것이 중요하다.\n따라서 이 둘을 잘 조합하는 Hybrid 방식이 고안되었는데, 그 중 많이 알려진 방법이 이 Hybrid log-block FTL 방식이다.\n\n\n\n                  \n                  이 부분은 추후에 추가될 예정입니다. \n                  \n                \n\n다만.. §\n\nFTL 의 알고리즘은 성능 향상에 큰 영향을 미치므로, 각 회사별 영업 비밀과 같다.\n\n즉, 각 회사별로 알고리즘이 상이하며, 구체적으로 어떻게 작동하는 지는 잘 공개하지 않는다고 한다.\n\n\n"},"botanicals/storage/terms/Flexible-Data-Placement,-FDP-(Storage)":{"title":"Flexible Data Placement, FDP (Storage)","links":["botanicals/storage/terms/Logical-Block-Addressing,-LBA-(Storage)","botanicals/storage/terms/Garbage-Collection,-GC-(Storage)","botanicals/storage/terms/Write-Amplification,-WA-and-Write-Amplication-Factor,-WAF-(Storage)","botanicals/storage/terms/Pre-conditioning-(Storage)","botanicals/storage/terms/PE-Cyclen-Limit,-Wearing-off-(Storage)","botanicals/storage/terms/Over-Provisioning,-OP-(Storage)","botanicals/storage/terms/Superblock-(Storage)","botanicals/storage/terms/TRIM,-Deallocation-(Storage)","botanicals/storage/terms/Multi-stream-SSD-(Storage)","botanicals/storage/draft/Zoned-Namespaces,-ZNS-(Storage)","botanicals/storage/terms/NVMe-Namespace-(Storage)"],"tags":["용어집","storage"],"content":"\n\n                  \n                  참고한 자료 \n                  \n                \n\nOCP 발표 영상\nNVMe 발표 자료 1\nNVMe 발표 자료 2\n어떤 회사 자료\n\n\n\n\n                  \n                  본 문서의 이미지는 별도의 참조가 걸려있지 않는 한 이 영상 에서 가져왔습니다.\n                  \n                \n\n\n\n                  \n                  주인장의 기술 이해도가 낮아, 신뢰성이 낮은 문서입니다. \n                  \n                \n\n이건 뭐람 §\n\n결론부터 간단히 말하면, Host 에서 data 를 어디에 저장할지 (어느 LBA 공간을 어느 위치에 저장할지) 지정하는 방식 을 통해 GC 로 인한 WAF 증가 등의 문제점을 해결한 방식이다.\n2022-12-12 에, NVMe TP (Technical Proposal) 4146 으로 제안된 제안서가 승낙 받았다.\n\n정식 표준으로 도입되었는 지는 모르겠다.\n\n\n이제 이거에 대해 차근차근 알아보자구\n\nBackground §\n기존 방식의 문제점 - WAF 증가 §\n\n기존의 GC 방식은 데이터 이동이 불가피 하였고, 따라서  WAF 가 증가하게 되는 문제점이 있었다.\n\n이것은 추가적인 R/W 가 수반되기 때문에 대역폭 차지, 컴퓨팅 자원 소모 등의 오버헤드가 있어 성능 및 QoS (Quality of Service) 저하를 일으켰다.\n\n성능 저하의 일환으로, Host operation 과 GC 의 경합에 의해 시간이 지남에 따라 성능이 더욱 저하되는 문제 (Pre-conditioning 참고) 가 있다.\n\n\n추가적인 R/W 는 PE Cycle Limit 에 더 일찍 도달하게 하여 디바이스 수명을 단축하는 문제가 있었고\n마찬가지로 추가적인 R/W 는 전력을 더 많이 소모하게 해 환경적/비용적으로도 좋지 않았다.\n또한 성능을 개선하고자 도입된 OP 는 디바이스의 가용 저장 공간을 제한하는 부작용도 낳았다.\n\n\n\nWAF 를 줄이기 위한 FDP 의 접근 §\n\nFDP 의 핵심 아이디어는 간단하게 두 가지로 정리해 볼 수 있다:\n\n\nApplication 별 데이터들이 섞여 있어서 GC 오버헤드가 크다. -&gt; “Application 별로 독립된 Superblock 에 저장해 GC 오버헤드를 줄이자.”\n\n단순한 예시를 들면, application 이 data 를 전부 deallocate 했을 때 해당 superblock 을 전부 erase 하면 되기 때문에 GC 에서의 page 이동 오버헤드가 없어지게 된다.\n\n\nSSD 레벨에서는 데이터 특성을 알기 어렵기 때문에 특성이 비슷한 데이터들을 모아놓기 힘들다. -&gt; “SSD 에서 Host 에게 superblock 사이즈와 같은 일부 정보를 공유해 주고, Host 에서 직접 데이터를 어디에 저장할 지 결정하게 하여 특성이 비슷한 데이터들끼리 모아 GC 오버헤드를 줄이자.”\n\n가령 사용하지 않는 데이터는 Controller 가 GC 에 들어가기 전에 Host 가 미리 모아놓는 등의 준비를 해 놓을 수 있다.\n\n\n\n기존 방식의 문제점을 해결하기 위해 이전에 시도된 것들 (History) §\n\n제일 처음으로 도입된 것은 OP 이다.\n\n이것은 WAF 를 줄이지는 못했지만 수명 단축 문제와 Random write 부하 상황에서 GC 성능을 개선했다.\n\n\n그 다음으로 도입된 것은 TRIM 이다.\n\nHost 가 사용하지 않는 LBA 공간에 대한 정보를 제공해 줌으로서 GC 시 이동시켜야 하는 page 의 양을 줄이도록 하였다.\n\n\n이후에는 Multi-stream 방식, ZNS 와 FDP 가 제안되었다.\n\n이것은 Life cycle 이 유사한 데이터들을 함께 배치함으로써, 데이터 이동 없이 GC 가 수행될 수 있도록 해 WAF 를 획기적으로 감소시키고자 하는 접근이다.\n\n\n\nMulti-stream, ZNS 와의 차이점 §\n\n\n                  \n                  이 부분은 추후에 추가될 예정입니다. \n                  \n                \n\nFDP 가 등장하게 된 경위 §\n\n구글과 메타는 각각 독립적으로 WAF 를 줄이고자 하는 연구를 진행했는데, 결론은 “데이터를 디바이스의 어디에 저장할 것이냐” 가 WAF 를 줄이는 핵심 포인트였다고 한다.\n따라서 구글과 메타는 각각 “SMART FTL” 과 “Direct Placement Mode” 라는 방식을 제안하게 되는데,\nFDP 는 이 두 제안에서 좋은점들만 쏙쏙 뽑아 합친 것이라 한다.\n\nFDP 작동 과정 §\nArchitecture §\n\nReclaim Unit (RU) §\n\n한개 이상의 Block 으로 이루어져서, 다른 RU 들에 영향을 주지 않고 erase, reused, repurposed (다른 목적으로 사용될 수 있는? 모르겠음) 될 수 있는 SSD 의 일부분\n\n즉, 실질적으로 데이터를 저장하는 부분이다.\n정해진 사이즈는 없다: RU 를 몇개의 block 으로 구성할 것인지, 그리고 각 block 은 몇 byte 인지는 제조사가 알아서\n대신 이 사이즈는 host 에 전달되어서 host 에서도 RU 의 사이즈를 알고 있게 된다.\n이것은 이전까지는 Superblock 이라고도 불렸다. 즉, RU 를 구성하는 block 들은 물리적으로 인접해 있지 않고 다른 die 에 배치된다.\n이 FDP 에서는 RU 를 Host 에서 직접 조작하는 방법에 대해서는 언급하지 않는다; 다만, SSD 가 어떻게 이 RU 를 Host 에 노출시키는 것인 지에 대한 것이다.\n\n\n\nReclaim Group (RG) §\n\n한개 이상의 RU 로 구성돼서, Host 가 데이터를 어디에 저장할지 정할 수 있는 단위가 된다.\n\n즉, Host 에서 RU 를 직접 선택하는 것이 아니라, Host 는 RG 를 선택하고 그럼 Controller 에서 해당 RG 안의 RU 를 선택해 데이터를 저장하게 된다. (더 구체적인 작동 과정은 아래 나온다.)\n\n\n\nReclaim Unit Handle (RUH) §\n\n모든 RG 안의 RU 하나씩을 관리하는 핸들러.\n\nRUH 는 모든 RG 에 대해 그 안의 RU 하나씩을 반드시 참조하고 있다.\n따라서 (위 그림 기준) RG 가 RU 에 대한 세로방향 그루핑이라면, RUH 는 RU 에 대한 가로방향의, 모든 RG 에 걸친 그루핑이라고 생각할 수 있다.\n결과적으로, RG 번호와 RUH 번호가 정해지면 단 하나의 RU 가 특정되고 이 두 번호의 조합으로 Host 는 SSD 에게 데이터를 어디에 저장할 지 알려주게 되는 것이다. (더 구체적인 작동 과정은 아래에서 설명한다.)\n\n\n\nEndurance Group §\n\nEndurance group 은 RG 들과 RUH 를 묶은 단위로, 하나의 FDP Configuration 를 가진다.\n\n어떤 FDP Configuration 들이 있는지는 잘 모르겠으나, Endurance group 은 여러 Configuration 을 지원하고 그 중에 하나로 설정할 수 있다.\nSSD 는 한개 이상의 Endurance Group 을 가질 수 있다. 가령 media type 이 상이한 여러개의 소자로 SSD 를 구성할 경우 각각의 media type 에 대해 endurance group 을 묶어 서로 다른 configuration 을 적용할 수 있다.\nFDP 는 기본적으로 비활성화 되어 있는데, 특정 Endurance group 에 대해 활성화 하고 어떤 Configuration 을 가질 것인지 설정할 수 있는 인터페이스가 있다고 한다.\n\n\n\nNVMe Namespace support §\n\n\nNVMe Namespace 에서도 FDP 기능을 사용할 수 있도록 호환성을 가지고 있다.\nHost 가 Namespace 를 생성할 때 해당 Namespace 에서 접근할 수 있는 RUH 들을 지정할 수 있다.\n\n즉, 해당 NS 에서는 지정된 RUH 밖에 접근할 수 없게 되는 것.\n\n\n그렇다고 해서 한 RUH 가 한 NS 에 종속되는 것은 아니다; 한 RUH 는 여러 NS 에서 접근할 수 있도록 설정할 수도 있다.\n\n다만, 이렇게 되면 하나의 RU에 여러 NS 의 데이터가 섞여서 저장될 수 있다. 따라서 RUH 레벨에서 데이터 저장 위치를 분리하고자 한다면, 하나의 RUH 는 하나의 NS 에 종속되게 설정하는 것이 좋을 것이다.\n\n\n기존의 NS create command 에는 이러한 매핑 기능이 없었기 때문에, backward-compatibility 를 위해 defaulting 기능을 제공한다.\n\n즉, 만일 NS create command 에 mapping 에 대한 정보가 없다면, Controller 가 자동으로 mapping table 하나를 생성하고 RUH 도 하나 선택해서 연관지어준다.\n따라서 Host 의 시선에서는 기존에 사용하던 방식 그대로 mapping 정보 없이 NS 를 생성할 수 있는 것이고, Controller 의 시선에서는 (어차피 default mapping table 이 생성될 것이므로) mapping table 이 무조건 존재하기에 이걸 통해 RUH 에 접근하게 되는 것.\n\n\n\nWrite 과정 예시 §\n\n\n위 그림은 예시를 위한 간단한 SSD 이다.\nRG 0 한개와 RUH 는 0~3 4개가 있고, Host 는 RUH 0, 2, 3 세개를 사용하는 NS ‘A’ 를 만들어 놓은 상황.\n\n다만, 위의 예시에서 RU 번호는 편의를 위한 것 뿐이고 실제로 RU 에 번호가 메겨져 있지도 않고, 외부에서 특정 RU 가 어디에 있는지 확인할 수도 없다.\n\n\n이때 write command 의 작동 과정을 보면 다음과 같다.\n\n\nHost 에서 index 와 RG 를 명시해 write command 를 날린다. (index: 1, RG: 0)\n\n\n\nWrite command 가 controller 에 도착하면 controller 는 NS ‘A’ 의 mapping table 을 보고 index 를 RUH 로 변환한다 (RUH: 2, RG: 0)\n\n\n\n해당 RUH 가 참조하고 있는 RG 내의 RU 에 데이터가 저장된다.\n\nRUH: 2 는 RG: 0 내의 RU: 3 을 참조하고 있으므로 해당 RU 에 데이터가 저장된다.\n\n\n\n\n특이 케이스 1) RU 가 전부 찬 경우 처리 §\n\n\nRU 가 전부 차서 더이상 공간이 없을 때에는, Controller 에 의해 RUH 가 참조하고 있는 RU 가 누구에게도 참조되고 있지 않은 RU 로 자동으로 바뀐다.\n\n위의 예시에서는 RU: 4 가 전부 차서 RU: 2 로 참조가 변경된 것을 보여주고 있다.\n\n\n\n특이 케이스 2) Backward compatibility: index, RG 를 명시하지 않은 경우 §\n\n\nFDP 를 지원하지 않는 시스템에서 FDP SSD 를 사용하고자 하는 경우에는 이러한 index, RG 값을 write command 에 포함하지 않을 것이다.\n이때 또한 backward-compatibility 를 위해 defaulting 이 들어간다:\n\nindex 는 무조건 0 으로 설정된다.\n그리고 RG 는 Controller 가 알아서 선택한다.\n\n\n이렇게 하면 [index, RG] 튜플이 없어도 정상적으로 작동하게 된다.\n\n(주인장 견해 - 뭐 똑똑이들이 이 경우에도 어떻게 처리되도록 해놨겠지) 다만 이 경우에는 index: 0 의 RUH 만 사용될 것이기 때문에 모든 요청이 튜플이 없는 이전 버전의 요청이라면, 사용되지 않는 RUH 가 참조하고 있는 RU 들이 낭비될 것 같다. (NS 에서 RUH 할당 관계를 빼면 되지 않냐 라고 할 수 있는데 그렇다고 해서 RUH 가 사라지는 것이 아니기 때문에? RUH 갯수도 조정이 가능한지 확인해볼 필요가 있다.)\n\n\n\nFTP 가 제공해주는 부가 기능들 §\n\nFDP 에서는 Endurance group 별로 WAF 통계를 보여주는 기능도 있고 (아마?)\nHost 가 직접 새로운 RU 를 달라고 요청할 수도 있다고 한다.\n또한 Host 가 WAF 를 줄이기 위해 직접 개입할 경우에는 몇가지의 정책(rule) 을 지켜야 한다.\n\n만일 이러한 정책을 지키지 않았을 때에는 경고 로그를 작성하게끔 하는 기능도 있다고 한다.\n\n\n(비록 위에서 제시한 개념으로는 잘 이해가 안되지만) 특정 ns 의 데이터들을 전부 하나의 RG 에 넣는 것도 가능하다고 한다.\n\n여기서 중요한 것은 Controller 는 그냥 placement 정보를 보고 그것에 따라서 넣을 뿐이고, 어디에 넣을지 정하는 것은 전적으로 Host 에 달려있다는 것이다.\n\n\n"},"botanicals/storage/terms/Garbage-Collection,-GC-(Storage)":{"title":"Garbage Collection, GC (Storage)","links":["botanicals/storage/terms/Flash-Memory,-SSD-(Storage)","botanicals/storage/terms/Flash-Translation-Layer,-FTL-(Storage)","botanicals/storage/terms/Write-Amplification,-WA-and-Write-Amplication-Factor,-WAF-(Storage)"],"tags":["용어집","storage"],"content":"\n\n                  \n                  참고한 자료 \n                  \n                \n\n어떤 회사 글\n어떤 블로그 글\n카카오 테크 블로그\n윅히피디아\n\n\nSSD 에서의 Garbage Collection (GC) §\n\n\n이미지 출처\n\n\n여기서 언급한 것 처럼, 플래시 메모리에서는 GC (Garbage Collection) 을 필요로 한다.\n\n즉, read/write size (page) 와 erase size (block) 이 다르기 때문\nwrite page 를 하려면 erase 를 먼저 해야 하는데 이것이 page 단위가 아닌 block 단위로만 가능하기 때문에 block 내부에 있던 기존의 valid page 들을 딴 곳으로 옮겨야 한다.\n\n\n구체적으로 이것이 어떻게 수행되는 지는 아래에서 설명해준다.\n\nGC 의 과정 §\n\nSSD 의 컨트롤러는 FTL 의 LBA mapping table 를 보고 block 내의 valid page 들을 확인한다.\n그리고 이들을 다른 block 으로 옮긴 후, LBA 에 기존의 page 는 invalid 로 표시한 뒤 새로운 page address 를 매핑해 놓는다.\n\nSSD 를 사용하는 호스트 (예: OS) 는 GC 가 수행되었는지 아닌지 모르기 때문. 즉, GC 여부와 관계 없이 호스트는 자신이 알고 있던 주소로 접근한다.\n\n\n이후 해당 block 을 erase 한다.\n\nGC 의 문제점 및 개선 방법들 §\n\nGC 를 한다는 것은 page 를 옮기는 작업이 수반되므로, 추가적인 write 가 발생해 WA 를 늘리는 원인이 된다.\n또한 write 보다 erase 의 작업 시간이 더 길다. (250 ~ 1500 마이크로 초 vs 1500 ~ 3500 마이크로 초) 따라서 GC 를 하는 것은 비용이 꽤나 큰 작업이다.\n\nGC 종류들 §\nBackground GC (BGC), Idle Collection, Idle-time Garbage Collection (ITGC) §\n\nBackground GC 는 SSD 가 한가할 때 주기적으로 블럭들에 대해 GC 를 수행하는 방식이다.\n\n이 방식을 이용하면 free page 를 사전에 확보해 놓는 셈이 되어 실제 write operation 이 들어왔을 때 free page 가 부족해질 가능성이 적어진다.\n\n\n보통 “Background operation” 이라 하면 이러한 BGC 를 말하고, 반대로 “Foreground operation” 은 host 로부터 전달되는 r/w 등의 작업을 일컫는다.\n\nParallel Garbage Collection (PGC) §\n\n이 방식은 BGC 와 두가지 차이점이 있다:\n\n주기적으로 GC 를 하는 것이 아닌, write operation 시에 수행한다.\nBCG 는 최대한 많은 free block 을 확보하는 반면, PGC 는 (Foreground operation 과의 경합을 최소화하기 위해) 최소한의 free block 을 확보한다.\n\n\n이 방식은 write 부하가 아주 많이 걸리는 환경에서 이점이 있다.\n\nBGC 에서는 “한가” 할 때 “주기적” 으로 GC 가 실행되기 때문에, write 부하가 많을 경우에는 write operation 시에 free page 가 부족해질 수 있기 때문이다.\n그럼 PGC 와 동일하게 write operation 이 들어왔을 때 GC 가 수행되는데, BGC 는 free block 을 최대한 많이 생성하려 하기 때문에 PGC 의 GC 보다는 느리고, 따라서 PGC 보다도 더 write operation 에 딜레이가 걸리게 된다. (아마?)\n\n\n"},"botanicals/storage/terms/Hot-Cold-Separation-(Storage)":{"title":"Hot Cold Separation (Storage)","links":["botanicals/storage/terms/Write-Amplification,-WA-and-Write-Amplication-Factor,-WAF-(Storage)","botanicals/storage/terms/Garbage-Collection,-GC-(Storage)","botanicals/storage/terms/Wear-Leveling-(Storage)","botanicals/storage/terms/Flash-Translation-Layer,-FTL-(Storage)"],"tags":["용어집","storage"],"content":"뭘까 §\n\n일단 데이터는 수정 빈도에 따라 종류를 두가지 정도로 나눌 수 있다.\n\n자주 바뀌지 않는 cold data (static data)\n자주 변경되는 hot data (dynamic data)\n\n\n이러한 구분에 따라 WAF 를 줄이기 위해 다음과 같은 전략을 짤 수 있다.\n\nHot data 와 cold data 가 같은 page 에 있을 경우 hot data 가 rewite 될 때 cold data 까지 옮겨지게 된다.\n만일 cold data 를 별도의 page 에 모아두면 이 page 들은 rewrite 되지 않으므로 invalid page 가 비교적 적어지게 된다.\n\n이렇게 생각하면 쉽다: hot data 가 많은 page 에 분산되어 있는가 아니면 적은 page 에 밀집되어 있는가 - 당연히 밀집되어 있을 때 rewrite 시 적은 page 가 invalid 처리된다.\n\n\nPage 단위가 아닌, block 단위에서도 동일하게 적용할 수 있다.\n\n즉, block 에 hot page 와 cold page 가 섞여있을 때 보다 이들이 별도의 block 에 분리되어 있게 되면 hot block 에 있는 valid (즉, cold) page 가 적어지기에 옮겨야 할 page 가 줄어들어  GC 시에 이점을 보게 된다.\n\n\n즉, GC 를 비교적 적게 실행할 수 있게 하고, 따라서 WA 도 개선된다.\n\n\n물론 이렇게 하면 cold data page 와 hot data page 간에 wear level 에 다소 차이가 생긴다는 문제점이 있긴 하다.\n\n이를 위해 cold data page 와 hot data page 들을 주기적으로 swap 해주기도 한다. (물론 이것 또한 WA 를 증가시킨다.)\n\n\n다만 FTL 입장에서는 어떤 데이터가 cold 인지 hot 인지 구분하기 힘들기 때문에, host level 에서 제어를 해야 된다.\n"},"botanicals/storage/terms/Input-Output-per-second,-IOps-(storage)":{"title":"Input Output per second, IOps (storage)","links":["botanicals/storage/terms/Throughput-(Storage)"],"tags":["용어집","storage"],"content":"\n\n                  \n                  참고한 자료 \n                  \n                \n\n카카오 테크 블로그\n\n\nIOps §\n\n초당 r/w 횟수를 의미한다.\n\n이렇게 말하면 좀 모호하다고 생각할 수 있는데, 여기 에서 헷갈릴 수 있는 개념인 “Throughput” 과의 차이점을 적어놨으니 참고해 보시라.\n\n\n랜덤 r/w 벤치마크에서 주로 쓰인다고 한다.\n"},"botanicals/storage/terms/Latency-(Storage)":{"title":"Latency (Storage)","links":[],"tags":["용어집","storage"],"content":"\n\n                  \n                  참고한 자료 \n                  \n                \n\n카카오 테크 블로그\n\n\n응답시간, Latency §\n\n“입출력 명령이 전달된 후 응답을 받기까지의 시간” 을 의미한다.\nμs(마이크로 초) 또는 ms(밀리 초) 의 단위를 사용한다고 한다.\n"},"botanicals/storage/terms/Logical-Block-Addressing,-LBA-(Storage)":{"title":"Logical Block Addressing, LBA (Storage)","links":["botanicals/storage/terms/Physical-Block-Address,-PBA-(Storage)","botanicals/storage/draft/Cylinder-Head-Section,-CHS-(Storage)","botanicals/storage/terms/Flash-Memory,-SSD-(Storage)","botanicals/storage/terms/Flash-Translation-Layer,-FTL-(Storage)"],"tags":["용어집","storage"],"content":"\n\n                  \n                  참고한 자료 \n                  \n                \n\n카카오 테크 블로그\n고급운영체제 (김진수 교수님 ‘24H1, SNU CSE)\n\n\n이게 뭐임 §\n\nStorage 를 고정크기인 Block 들의 1차원 배열로 나타내는 논리적인 주소 공간.\n\nVirtual memory 공간의 storage 버전인 셈.\n반대 개념으로는 PBA 가 있다.\n\n\n이 공간은 논리적인 공간인 만큼, block 들에는 아무런 제약도 걸려있지 않다고 보면 된다:\n\nLBA 주소를 통해 Random access 가능\nRead, write, overwrite 가능\n\n\n\n등장 배경 §\n\n원래 HDD 는 block 을 3차원 주소로 나타내는 CHS 라는 주소체계를 사용했는데,\n이 방식은 track 의 길이에 무관하게 track 당 일정한 개수의 block 을 가지는 문제점이 있어서\n길이가 긴 track 에는 더 많은 block 을 담도록 하고 주소도 1차원 주소 공간으로 바꾸면서 나온 것이 이 LBA 이다.\n\b따라서 논리적인 공간인 LBA 의 주소를 물리적인 실제 주소 (PBA) 로 바꿔주는 로직이 각 storage device 의 펌웨어에 포함된다\n\nSSD 의 경우에는 FTL 이 그 역할을 한다.\n\n\n"},"botanicals/storage/terms/Multi-Level-Cell,-MLC-(Storage)":{"title":"Multi Level Cell, MLC (Storage)","links":["botanicals/storage/terms/Flash-Memory,-SSD-(Storage)","botanicals/storage/draft/Deep-Dive-SSD---Storing-and-Detecting-Electrons-(Storage)"],"tags":["용어집","storage"],"content":"\n\n                  \n                  참고한 자료 \n                  \n                \n\n카카오 테크 블로그\n고급운영체제 (김진수 교수님 ‘24H1, SNU CSE)\n\n\n란? §\n\nSSD 는 셀 하나로 여러 비트를 표현하는 것이 가능하다. (어떻게?)\n\n많이 표현하면 당연히 더 좋은게 아니겠는가 생각할 수 있지만, 기숙사랑 비슷한 느낌으로 생각하면 된다. 1인실이 제일 좋고 다인실 일수록 별로지만 가격은 싸다.\n마찬가지로, 셀이 비트를 적게 표현할수록 성능은 좋지만 가격은 비싸지게 된다.\n이는 전략적으로 사용하면 R/W 가 많은, 성능이 중요한 hot storage 에는 1인실 (SLC), R/W 는 비교적 적은 용량이 중요한 cold storage 에 는 다인실 (TLC) 로 구성할 수 있을 것이다.\n\n\n표현 비트 갯수에 따라 (Single, Multiple, Triple, Quadra) Level Cell (SLC, MLC, TLC, QLC) 로 구분할 수 있다.\n각각의 성능 비교는 카카오 테크 블로그 글에서 가져와 봤다:\n\n\n\n출처\n"},"botanicals/storage/terms/Multi-stream-SSD-(Storage)":{"title":"Multi-stream SSD (Storage)","links":["botanicals/storage/terms/Garbage-Collection,-GC-(Storage)"],"tags":["용어집","storage"],"content":"\n\n                  \n                  참고한 자료 \n                  \n                \n\n누군가의 블로그\nZNS 논문의 background 파트 (ATC ‘21)\n\n\n이건 또 뭐야 §\n\n결국에는 이것도 GC 오버헤드를 줄이기 위해 도입된 것이다.\n\n만일 invalid page 들이 한 block 에 모여있으면 GC 오버헤드가 없을 텐데\nLifecycle 이 유사한 page 들이 한 block 에 모여 있으면 다같이 write 된 이후에 다같이 invalid 가 되고 다같이 GC 가 이루어 질 수 있으므로 참 좋다잉 그쵸?\n\n\nMulti-stream SSD 는 이렇게 lifecycle 이 비슷한 page 를 한 block 에 모아놓기 위한 방법으로 여러개의 Stream 을 제공하는 것을 택한 방식이다.\n\n즉, 각 Stream 은 독립된 block 들에 저장되고 하나의 stream 에다는 비슷한 lifecycle 을 가지는 데이터들을 전달해서 저장하게 된다.\n이렇게 되면 하나의 block 내에는 하나의 stream 에서 들어온 데이터들만이 있을 것이고,\n따라서 block 내에는 유사한 lifecycle 을 가지는 데이터들만이 있을 것이므로\n유사한 시점에 invalid 가 될 가능성이 높아지기에 GC 오버헤드가 줄어들게 되는 것\n\n\nWrite command 에 stream hint (뭐 stream ID 정도로 생각해도 될 것 같다) 까지 같이 전달하면 SSD Controller 에서 알아서 처리하는 식으로 구현된다고 한다.\n\n그럼 Stream 은 어떻게 할당하지? §\n\nLifecycle 이 다른 데이터들이 stream 으로 들어오게 되면 그냥 SSD 와 별반 다를게 없기에, 데이터의 lifecycle 을 명확히 판단해서 그에 맞는 stream 으로 넣어 주는 것이 중요하다.\nApplication 이 데이터의 lifecycle 을 제일 잘 알고 있을테니 이 수준에서 stream 을 할당하면 아주 좋지만, 그럼 application 코드를 변경해야 하기에 한계점이 있다.\n따라서 커널레벨의 파일시스템 및 블럭 레이어 수준에서 stream 을 할당하는 연구가 진행되어 왔고,\n최근에는 program context 에 따라서 stream 을 할당하는 연구도 진행된다고 한다.\n"},"botanicals/storage/terms/NAND-based-Flash-Memory-(Storage)":{"title":"NAND-based Flash Memory (Storage)","links":["botanicals/storage/terms/Flash-Memory,-SSD-(Storage)","botanicals/storage/terms/NOR-based-Flash-Memory-(Storage)"],"tags":["storage","용어집"],"content":"\n\n                  \n                  참고한 자료 \n                  \n                \n\n블로그 글\n\n\n이게 무언가? §\n\n플래시 메모리 의 일종으로 반도체들을 직렬 연결해 만든 저장장치라고 한다.\n이놈은 같은 플래시 메모리의 일종인 NOR-based Flash Memory (Storage) 에 비해 용량을 늘리기 쉽고 쓰기 속도가 빠르며 가격이 저렴하다는 장점이 있다.\n사용되는 대부분의 SSD 가 이 방식으로 제조되기에, SSD 와 혼용하여 용어를 사용하기도 한다.\n"},"botanicals/storage/terms/NOR-based-Flash-Memory-(Storage)":{"title":"NOR-based Flash Memory (Storage)","links":["botanicals/storage/terms/Flash-Memory,-SSD-(Storage)","botanicals/storage/terms/NAND-based-Flash-Memory-(Storage)"],"tags":["용어집","storage"],"content":"\n\n                  \n                  참고한 자료 \n                  \n                \n\n블로그 글\n\n\n이게 무언가? §\n\n플래시 메모리 의 일종으로 반도체들을 병렬 연결해 만든 저장장치라고 한다.\n이놈은 같은 플래시 메모리의 일종인 NAND Flash 에 비해 읽기 속도가 아주 빠르다고 한당.\n"},"botanicals/storage/terms/NVMe-Namespace-(Storage)":{"title":"NVMe Namespace (Storage)","links":[],"tags":["용어집","storage"],"content":"\n\n                  \n                  참고한 자료 \n                  \n                \n\nNVMe document\n\n\n이건 뭐지 §\n\nNVMe 스펙에 명시된 LBA 공간의 논리적인 하위 공간이다.\n\n즉, 전체 LBA 공간을 논리적으로 분리하여 사용할 수 있도록 한 것.\n뭐 “논리적 분리” 이기 때문에 물리적인 분리보다는 분리 정도가 약하긴 하다.\n\n\n이렇게 분리하는 이유는 여러가지가 있을 수 있다:\n\n뭐 보안 측면 때문이라던지\n아니면 multi-tenancy 를 위해서라던지 등등\n\n\n각 Namespace 는 ID 가 부여되며 (NSID) 이것은 Host 가 SSD Controller 를 거쳐 특정 NS 에 접근할 수 있도록 해준다.\n"},"botanicals/storage/terms/Open-Channel-SSD,-OCSSD-(Storage)":{"title":"Open Channel SSD, OCSSD (Storage)","links":["botanicals/storage/terms/Flash-Translation-Layer,-FTL-(Storage)","botanicals/storage/terms/Flash-Memory,-SSD-(Storage)","botanicals/storage/terms/Over-Provisioning,-OP-(Storage)","botanicals/storage/terms/Garbage-Collection,-GC-(Storage)","botanicals/storage/draft/Zoned-Namespaces,-ZNS-(Storage)","botanicals/storage/terms/Flexible-Data-Placement,-FDP-(Storage)","botanicals/storage/terms/Multi-stream-SSD-(Storage)"],"tags":["용어집","storage"],"content":"\n\n                  \n                  참고한 자료 \n                  \n                \n\n위키피디아\n\n\n이건 또 뭐야 §\n\n간단하게 말하면 FTL 을 SSD 내에 구현하지 않고 Host 에게로 넘겨버린 것이다.\n\n기존에는 SSD 안에 Processor 와 DRAM 존재하고, 여기에 FTL 가 구현된 SSD 펌웨어가 설치되었다면 OCSSD 에서는 FTL 을 통째로 Host 에 이관시키고 Host 의 CPU 와 RAM 을 이용하게 된다.\n\n\n따라서 FTL 이 담당하고 있던 데이터 저장 위치 선정, OP, GC 등의 작업을 전부 Host 가 담당하게 된다.\n\nOS 가 OCSSD 에 접근할 수 있게 해주는 인터페이스로 LightNVM 이 구현되어 있다.\n\n\n다만, OCSSD 는 ZNS 의 등장에 따라 현재에는 거의 사용되지 않는다고 한다.\n\n좋은 점 §\n\n이렇게 하면 좋은점은 (지겹게 등장하긴 하지만) GC 오버헤드 등의 한계를 완화할 수 있다는 것이다.\n\n데이터를 어디에 저장하냐가 GC 오버헤드에 영향을 주고\n데이터의 저장 위치를 정하는 것에는 Host 가 알고 있는 정보들을 활용하는 것이 도움이 된다고 한다.\n\n이에 대해서는 FDP 문서 나 ZNS 문서, Multi-stream SSD 에서도 여러번 언급했으니 모르겠으면 가서 보도록 하자.\n\n\n따라서 OCSSD 에서는 FTL 자체를 Host 로 넘겨 Host 가 알고 있는 정보를 활용하자는 아이디어이다.\n\n\n\n나쁜 점 §\n\n생각보다 RAM 을 많이 먹는다 - 4KB 의 write 작업이 지속적으로 들어오는 환경에서 SSD 용량이 1TB 라면 3GB 의 RAM 을 먹는다고 한다.\n또한 OS 에서 모든 종류의 SSD 에 대응하는 인터페이스를 구현해야 되고, 이것이 핵심적인 문제가 되어 지금은 ZNS 로 대체되었다.\n"},"botanicals/storage/terms/Over-Provisioning,-OP-(Storage)":{"title":"Over Provisioning, OP (Storage)","links":["botanicals/storage/terms/Logical-Block-Addressing,-LBA-(Storage)","botanicals/storage/terms/PE-Cyclen-Limit,-Wearing-off-(Storage)","botanicals/storage/terms/Garbage-Collection,-GC-(Storage)","botanicals/storage/terms/TRIM,-Deallocation-(Storage)","botanicals/storage/terms/Write-Amplification,-WA-and-Write-Amplication-Factor,-WAF-(Storage)"],"tags":["storage","용어집"],"content":"\n\n                  \n                  참고한 자료 \n                  \n                \n\n카카오 테크 블로그\n\n\n초과해서 (Over) 공급하다 (Provisioning) §\n\n간단하게 말하면 Host 에서 사용할 수 있는 공간의 크기보다 더 큰 공간을 물리적으로 구성해 놓는 것이다.\n\n즉, LBA 공간보다 더 큰 공간을 PBA 공간으로 잡아 놓는 것.\n\n\n여러 이유에서 이러한 짓을 한다.\n\n이유 §\n1. 단위의 차이 §\n\n일반 사용자들은 1000 단위 (KB, MB, GB 등) 에 더 익숙하지 1024 단위 (KiB, MiB, GiB 등) 에는 별로 익숙하지 않다.\nSSD 는 1024 단위로 제작되기에, 이것을 1000 단위로 변경하면 그만큼 공간이 남게 된다.\n\n128GB 에 비해 128GiB 는 용량이 7.37% 정도 더 크다. (직접 계산해 보시라)\n\n\n\n2. 여러가지 효율성 §\n\nPBA 를 더 크게 잡아 놓는 것은 이제부터 설명할 여러 점에서 성능 향상에 도움이 된다.\n\n제조사들은 이러한 이점때문에 실제로는 128GiB 를 만들어 놓고 100GB 라고 하거나 아니면 (삼성처럼) OP 공간을 직접 늘릴 수 있도록 제조하기도 한다.\nSSD 에서 자체 지원하지 않더라도 사용자가 필요에 따라 이 공간을 늘릴 수 있다: 디스크 파티셔닝할 때 적은 공간을 파티션하면 남는 공간은 자동으로 OP 공간으로 사용된다.\n\n\n이렇게 남는 공간은 Host 에서는 보이지 않지만 SSD Controller 에서는 보이고, 따라서 SSD Controller 에 의해 이 공간을 성능 향상을 위해 활용하게 된다.\n\n3. 수명 연장 §\n\n이 공간은 PE Cycle Limit 을 극복하는데 사용될 수 있다.\n즉, LBA 에 연결된 PBA 공간의 일부 block 이 수명이 다 했을 경우, SSD Controller 는 OP 공간에 있는 block 으로 PBA 공간을 매핑해 수명이 다한 block 을 대체하게 된다.\n\n4. Write Throughput 향상 §\n\nRandom write 부하가 걸리는 상황에서는 free page 소진 속도가 GC 로 생성해 내는 free page 생성 속도보다 빠르기 때문에 성능 저하가 나타나게 된다.\n이때 OP 공간의 free page 를 버퍼처럼 사용해 GC 가 free page 를 생성하는 시간을 벌어 성능 저하를 감소할 수 있게 된다.\n또한 이 친구 는 비록 추측이긴 하지만 이 OP 가 TRIM 처럼 작용해 성능이 향상될 수 있다고 한다.\n\nRandom write 부하가 걸려 OP 공간까지 활용해 ssd 가 100% 사용되더라도 다시 부하가 낮아져 OP 공간을 사용할 필요성이 없어지면 OP 공간은 LBA 와 매핑되지 않은 공간이기 때문에 TRIM 으로 invalid 공간을 inform 받지 않고서도 invalid 하다고 판단할 수 있을 것이고, 따라서 GC 효율성과 WA 감소에 도움이 될 것이라는 것.\n\n\n"},"botanicals/storage/terms/PE-Cyclen-Limit,-Wearing-off-(Storage)":{"title":"PE Cyclen Limit, Wearing-off (Storage)","links":[],"tags":["용어집","storage"],"content":"\n\n                  \n                  참고한 자료 \n                  \n                \n\n블로그 글\n어떤 회사 블로그 글\n어떤 글\n카카오 테크 블로그\n\n\nP/E Cycle Limit, Wearing-off §\n\nWrite, erase 를 위해 셀에 전압을 가했을 때 일부 전자가 셀에 잔존하며 점점 쌓이게 되는 문제가 발생한다고 한다.\n그렇게 쌓이다가 일정 수준을 넘어가면 수명을 다하게 되고, 이것을 Wearing-off 라고 한다.\n따라서 SSD 에는 Write, Erase 작업 수행 횟수 제한이 있고 이걸 P/E (Program/Erase) Cycle LImit 이라고 한다.\n열을 가하면 전자가 튀어 나가 다시 사용 가능해질 수도 있다는 말이 있다 (진짜?)\n"},"botanicals/storage/terms/Physical-Block-Address,-PBA-(Storage)":{"title":"Physical Block Address, PBA (Storage)","links":["botanicals/storage/terms/Logical-Block-Addressing,-LBA-(Storage)","botanicals/storage/draft/Cylinder-Head-Section,-CHS-(Storage)"],"tags":["용어집","storage"],"content":"물리 주소 공간 §\n\n이것은 LBA 와 반대되는 개념으로, Storage device 에서의 block 의 물리적인 주소를 말한다.\n\n어찌 보면 이전 HDD 의 CHS 도 이 PBA 의 일종이라고 볼 수 있다.\n\n\n"},"botanicals/storage/terms/Pre-conditioning-(Storage)":{"title":"Pre-conditioning (Storage)","links":["botanicals/storage/terms/Flash-Memory,-SSD-(Storage)","botanicals/storage/terms/Garbage-Collection,-GC-(Storage)"],"tags":["용어집","storage"],"content":"\n\n                  \n                  참고한 자료 \n                  \n                \n\n카카오 테크 블로그\n\n\n이게 무언가? §\n\nSSD 의 성능을 벤치마크하고자 할 때, 30분 이상의 지속적인 랜덤 쓰기 부하를 건 뒤에 측정을 하는 것.\nSSD 는 30 여분정도의 부하가 걸린 이후에 실질적인 성능 저하가 발생하는 경향이 있기 때문에 (아래 그림 보면 진자루 그렇타) 이러한 방법을 통해 최악의 성능을 확인해 보는 것.\n\n\n\n출처\n\n\n\n출처\n\n왜 그런가? §\n\n과한 랜덤 쓰기가 가해질 경우, GC 과도하게 발생하기 때문.\n\n저기 에서는 “Sustaining mode” 에 들어간다고 했는데, 공식 용어가 아닌건지, 검색해도 잘 안나온다.\n\n\n"},"botanicals/storage/terms/Read-Disturb-(Storage)":{"title":"Read Disturb (Storage)","links":[],"tags":["용어집","storage"],"content":"\n\n                  \n                  참고한 자료 \n                  \n                \n\n카카오 테크 블로그\n\n\n이게 뭐람 §\n\n데이터를 읽는 것은 주변 cell 들의 상태를 변경할 수도 있어서 결과적으로는 주변 cell 의 데이터를 잘못 읽어오는 현상이 발생할 수도 있다고 한다.\n이를 위해 주기적으로 block 들을 이동시키기도 한다.\n"},"botanicals/storage/terms/Shingled-Magnetic-Recording-HDD,-SMR-HDD-(Storage)":{"title":"Shingled Magnetic Recording HDD, SMR HDD (Storage)","links":["botanicals/storage/terms/Conventional-Magnetic-Recording,-CMR-HDD-(Storage)","botanicals/storage/terms/Flash-Memory,-SSD-(Storage)"],"tags":["storage","용어집"],"content":"\n\n                  \n                  참고한 것들 \n                  \n                \n\n고급운영체제 (김진수 교수님 ‘24H1, SNU CSE)\n\n\n이게 뭐고 §\n\nHDD 는 write 작업에 필요되는 너비와 read 작업에 필요되는 너비가 다르다고 한다.\n\nWrite 이 read 보다 더 넓은 너비를 차지하게 된다.\n\n\n따라서 이전의 CMR HDD 에서는 in-place update 를 가능하게 해 빠른 데이터 수정을 지원하기 위해 write 너비를 기준으로 track 의 너비를 산정했다:\n\n\n\n하지만 이 방식은 디스크의 용량이 작아지게 된다는 단점이 있었기에, SMR HDD 에서는 다음과 같은 방식으로 데이터를 저장한다:\n\n\n\n즉, write 너비 중 read 에 사용되지 않는 공간을 다음 track 에서 write 시에 overwrite 해버리는 것.\n이렇게 중첨해서 write 하는 것이 집의 지붕을 만들 때 널빤지를 중첩해서 붙이는 것 (Roof shingle - 아래 그림 참고) 과 비슷하다고 하여 Shingled Magnetic Recording 이란 이름이 붙게 되었다.\n\n\n\n사진 출처: 위키피디아\n\n\n이렇게 하면 다음과 같은 장단점이 있다.\n\n좋은점 §\n\nTrack 의 너비가 read 너비와 같아지기에, CMR 방식보다 track 의 너비가 좁아져 디스크의 용량이 늘어나게 된다.\n\n나쁜점 §\n\nIn-place update 가 불가능하다.\n\n따지고 보면 당연한 일이다. 데이터의 특정 부분을 수정하기 위해 해당 부분을 write 해버리면 다음 track 의 read 공간이 훼손되기에 해당 데이터를 전부 read 한 다음 다른 곳에 새로 write 하는 수밖에 없다. (Read-modify-update)\n즉, 특성이 SSD 와 비슷해져 버리게 되는 것.\n\n\n"},"botanicals/storage/terms/Superblock-(Storage)":{"title":"Superblock (Storage)","links":[],"tags":["용어집","storage"],"content":"이게 뭐지 §\n\nSuperblock 은 여러 die 에 있는 block 들을 모아 하나의 block 처럼 다루는 단위이다.\n즉, block 과 동일한 기능을 제공하지만 (r/w page, erase block) 여러 die 에 걸쳐 있다고 이해하면 된다.\n"},"botanicals/storage/terms/TRIM,-Deallocation-(Storage)":{"title":"TRIM, Deallocation (Storage)","links":["botanicals/storage/terms/Logical-Block-Addressing,-LBA-(Storage)","botanicals/storage/terms/Garbage-Collection,-GC-(Storage)","botanicals/storage/terms/Write-Amplification,-WA-and-Write-Amplication-Factor,-WAF-(Storage)"],"tags":["용어집","storage"],"content":"\n\n                  \n                  참고한 자료 \n                  \n                \n\n카카오 테크 블로그\n\n\n이게 뭐람 §\n\nTRIM (Deallocation) 기능은 Host 가 SSD Controller 에게 사용하지 않는 LBA 를 알려주는 기능이다.\n이것은 Host 와 SSD 간의 인터페이스 차이에 의해 발생하는 문제점을 해결하기 위해 등장했다.\nHost 에서는 “Delete” 라는 것이 있지만 SSD 는 이러한 기능이 없다고 할 수 있다.\n\nSSD 에서는 “Erase” 가 있지만 이것은 free block 을 생성하기 위한 것이다.\n즉, Host 에서 데이터를 지웠을때 해당 데이터를 “Erase” 하라고 SSD 에 전달하지는 않는다는 것이다.\n\n\n그럼 Host 에서 데이터를 “Delete” 하면 이것은 어떻게 처리되는가:\n\n일단 Host 에서는 LBA 공간에서 해당 부분을 할당 해제할 것이다.\n이후 새로운 데이터가 생성되면 (데이터가 지워졌다는 것을 Host 는 알고 있기 때문에) 해당 데이터를 지워진 LBA 공간에 할당한다.\n이것은 SSD 의 관점에서 보자면 “Rewrite” 의 작업이고, 이를 수행하게 된다.\n\n기존의 데이터가 새로운 데이터로 변경된 것이기 때문\n\n\n\n\n이것은 그럼 어떤 문제를 초래할까.\n\nSSD 관점에서는 해당 데이터가 지워졌다는 사실 (invalid 하다는 것) 을 “Rewrite” 시에 인지하게 된다.\n\nInvalid 함을 일찍 알았으면 BGC 를 수행해서 free block 을 미리 확보해 놓을 수 있었을 텐데, 이것을 너무 늦게 알았기 때문에 write 요청이 들어왔을 떄 free page 가 부족한 상황이라면 그때서야 GC 를 수행하게 되고, 이는 성능 저하를 유발한다.\n또한 그 전까지는 valid 하다고 생각할 것이므로, BGC 에 해당 page 들을 이리저리 옮기며 추가적인 WA 를 유발하게 된다.\n\n\n\n\n따라서 이 TRIM 기능을 이용하면 Host 가 알고 있던 지워진 데이터들 (더 이상 사용하지 않는 LBA 공간들) 을 SSD 에 전달하게 되고, 그럼 SSD 는 해당 LBA 공간에 할당되어 있던 PBA 들을 더욱 일찍 invalid 처리할 수 있게 된다.\n"},"botanicals/storage/terms/Throughput-(Storage)":{"title":"Throughput (Storage)","links":["botanicals/storage/terms/Input-Output-per-second,-IOps-(storage)","botanicals/storage/terms/Data-Chunk-(Storage)"],"tags":["용어집","storage"],"content":"\n\n                  \n                  참고한 자료 \n                  \n                \n카카오 테크 블로그\n\n스루풋, Throughput §\n\n범용적으로 말하면 단위 시간당 처리량 이지만\nStorage 관련해서 좀 더 구체적으로 말하면, 전송속도를 나타낸다.\nKB/s, MB/s 등의 단위를 사용하고\nSequential r/w 벤치마크에 주로 사용된다고 한다.\n\nIOps 와의 차이? §\n\nIOps 도 결국에는 단위 시간당 어쩌고 이기 때문에 throughput 과 뭔차인가 싶을 수 있는데\nStorage 에서 throughput 은 IOps 뿐 아니라 데이터 청크의 길이에도 영향을 받는다.\n\n가령 데이터 청크 길이가 4Kb 이고 1k IOps 를 가지고 있다면 이놈의 throughput 은 4Mb/s 로 말할 수 있는 것.\n\n\n또한 데이터 r/w 에 대해서도 sequential 하게 처리는지 아니면 random 하게 처리하는 지에 따라서도 IOps 와 throughput 은 차이를 보일 수 있다.\n\n즉, IOps 와 데이터 청크의 길이가 같아도 sequential 인지, random 인지에 따라서 throughput 은 달라질 수 있다.\n이 친구의 경험 에 따르면, sequential 일 때 throughput 이 10배 가량 더 좋았다고 한다.\n\n\n"},"botanicals/storage/terms/Wear-Leveling-(Storage)":{"title":"Wear Leveling (Storage)","links":["botanicals/storage/terms/PE-Cyclen-Limit,-Wearing-off-(Storage)"],"tags":["용어집","storage"],"content":"\n\n                  \n                  참고한 자료 \n                  \n                \n\n어떤 회사 글\n위키피디아\n\n\n닳는 것 (wear) 을 \b고르게 (leveling) 하는 것 §\n\n\n이미지 출처\n\n\nPE Cycle Limit 때문에, 플래시 메모리는 write, erase 작업을 한 부분에 집중적으로 수행할 경우 그 부분만 수명이 짧아지게 되는 문제가 있다.\n따라서 실제로 write 할 때에는, 한 block 에 page 들을 몰빵하지 않고 여러 block 에 고르게 펼쳐서 작업을 해 모든 block 에 고르게 저장될 수 있게 한다.\n"},"botanicals/storage/terms/Write-Amplification,-WA-and-Write-Amplication-Factor,-WAF-(Storage)":{"title":"Write Amplification, WA and Write Amplication Factor, WAF (Storage)","links":["botanicals/storage/terms/Flash-Memory,-SSD-(Storage)","botanicals/storage/terms/PE-Cyclen-Limit,-Wearing-off-(Storage)","botanicals/storage/terms/Garbage-Collection,-GC-(Storage)","botanicals/storage/terms/Over-Provisioning,-OP-(Storage)","botanicals/storage/terms/TRIM,-Deallocation-(Storage)","botanicals/storage/draft/Zoned-Namespaces,-ZNS-(Storage)","botanicals/storage/terms/Flexible-Data-Placement,-FDP-(Storage)","botanicals/storage/terms/Wear-Leveling-(Storage)","botanicals/storage/terms/Hot-Cold-Separation-(Storage)","botanicals/storage/terms/Read-Disturb-(Storage)"],"tags":["용어집","storage"],"content":"\n\n                  \n                  참고한 자료 \n                  \n                \n\n어느 회사 사이트\n위키피디아\n\n\n쓰기 작업 (write) 이 증폭 (amplification) 되는 것 §\n\n뭐 비유를 해보자면 난 100만원을 입금했는데 실제로는 150만원이 입금되는 거다.\n\n이렇게 비유하면 개꿀이네 싶지만 스토리지 입장에서는 원하지 않은 작업이 이루어지는 것이기 때문에 당연히 손해다.\n\n\n지금의 SSD 에는 이것이 성능 저하의 중요한 원인으로 손꼽히고 있다고 한다.\n\n옛날 HDD 시절에도 Write Amplification 문제가 있었지만, 별로 중요한 문제는 아니었다.\n\n\n\nWA 로 인해 발생하는 문제 §\n\nWA 로 인해 추가적인 쓰기 작업이 발생한다는 것은 두 문제점을 초래한다:\n\n수명 단축: NAND 플래시 메모리는 PE Cycle Limit 이 있기 때문에 당연히 수명이 짧아질 수 밖에 없다.\n성능 저하: 그만큼 대역폭을 소모하는 등의 퍼포먼스 저하가 발생하게 된다.\n\n\n\nWA 가 발생하는 이유들 §\nFile system operations §\n\n보통 파일시스템은 파일의 데이터 뿐 아니라 메타데이터 (이름, 권한, 생성/변경 시간 등) 도 같이 저장한다.\n그럼 당연히 이 메타데이터를 어딘가에 저장해야 될 것이기에 WA 가 발생하게 된다.\n다만 이건 OS 의 영역에서 핸들링하는 부분이기에 넓게 보면 WA 가 맞지만 Storage 관점에서 보면 내 알바 아니다.\n\nGarbage collection §\n\nNAND 플래시에서는 write 하기 위해 GC 가 수행되기도 하는데\n이때 invalid block 들을 옮기는 작업 때문에 추가적인 write 가 발생하게 되고, 따라서 WA 가 발생하게 된다.\n이를 해결하기 위해 다음과 같은 기술들이 도입되었다고 한다… (출처)\n\n~1991 년: Over Provisioning\n~2007-2008 년: TRIM, Deallocation\n2022 년: ZNS, FDP\n\n\n\nWear leveling §\n\nWear Leveling 도 WA 를 증가시킬 수 있다고 한다.\n\n데이터가 여러 block 에 분산되어 저장된다는 것은 그만큼 데이터 rewrite 시에 invalid 로 마킹되는 page 들이 여러 block 들에 분산된다는 것이고, 따라서 GC 를 수행할 때 더 많은 page 들을 이동시켜야 하기 때문.\n\n좀만 생각해보면 당연하다: GC 는 어찌보면 invalid page 들을 모아서 지우는 것이기 때문에 invalid page 들이 한 블럭에 이미 모여있으면 옮겨야 할 page 가 더 적어지기 때문이다.\n\n\n또한 Wear Leveling 방식에 따라 위와는 다른 이유로 데이터를 옮겨야 할 수도 있다.\n\n\n즉 Wear Leveling 과 WA 사이에는 어느정도의 trade-off 가 있는 것.\n따라서 조금이라도 WA 를 줄이기 위해 Hot cold separation 와 같은 방법을 사용할 수 있다.\n\nRead/Write Page, Erase Block §\n\nSSD 의 Read, Write 와 Erase 의 단위가 다른 특징 도 WA 를 유발한다.\n즉, write 작업은 page 단위로 이루어 지기 때문에, 데이터의 크기가 page 사이즈에 딱 맞지 않으면 비는 만큼 불필요한 write 가 발생하는 것.\n\n이러한 것을 방지하기 위해 page 크기에 맞게 데이터의 크기를 맞추거나 (Align writes), 아니면 여러 데이터를 합쳐서 쓰는 방법 (Buffer small writes) 을 사용하기도 한다고 한다.\n\n\n\nRead Disturb §\n\nRead Disturb 현상도 WA 를 증가시킨다.\n\nRead disturb 를 막기 위해 block 을 종종 옮겨줘야 하고, 이것은 마찬가지로 추가적인 GC 를 유발하기 때문\n\n\n\nWrite Amplification Factor (WAF) §\n\nWA 의 정도를 나타내는 수치로 WAF (Write Amplification Factor) 를 사용한다.\n이것은 “배수” 로 생각하면 된다. 즉, WAF 가 2라면 실 데이터의 2배 양의 write 가 발생한다는 것.\n\n따라서 1보다 작아질 수는 없다. (더 적은 양의 write 가 발생할 수는 없으므로)\n\n\n일반적인 SSD 에서는 이 수치가 4를 넘어가기도 하며, 이 문제를 해결하기 위해 등장한 ZNS 가 이론적으로는 WAF 가 1이라고 한다.\n"},"botanicals/storage/terms/Zoned-Storage-Model-(Storage)":{"title":"Zoned Storage Model (Storage)","links":["botanicals/storage/terms/Multi-stream-SSD-(Storage)","botanicals/storage/terms/Shingled-Magnetic-Recording-HDD,-SMR-HDD-(Storage)","botanicals/storage/terms/Conventional-Magnetic-Recording,-CMR-HDD-(Storage)","botanicals/storage/terms/Write-Amplification,-WA-and-Write-Amplication-Factor,-WAF-(Storage)","botanicals/storage/draft/Parallel-ATA,-AT-Attachment,-Integrated-Drive-Electronics,-PATA,-ATA,-IDE-(Storage)","botanicals/storage/draft/Zoned-Device-ATA-Command-Set,-ZAC-(Storage)","botanicals/storage/draft/Small-Computer-Systems-Interface,-SCSI-(Storage)","botanicals/storage/draft/Zoned-Block-Commands,-ZBC-(Storage)","botanicals/storage/draft/Non-Volatile-Memory-Express,-NVMe-(Storage)","botanicals/storage/draft/Zoned-Namespaces,-ZNS-(Storage)","botanicals/storage/terms/Logical-Block-Addressing,-LBA-(Storage)","botanicals/storage/terms/Flash-Memory,-SSD-(Storage)"],"tags":["용어집","storage"],"content":"\n\n                  \n                  참고 한 것들 \n                  \n                \n\nZNS: Avoiding the Block Interface Tax for Flash-based SSDs (ATC ‘21) 섹션 2.3 내용\nZoned Storage Initiative 문서\n\n\n이건 뭔가 §\n\n이것은 다음과 같은 특성을 가지는 디바이스 (대표적으로 SSD 와 SMR HDD 가 있다.) 를 위한 표준이다.\n\nRandom read 가능\nIn-place update 불가능; Read-modify-write 방식으로 데이터 수정\n\n\n이러한 디바이스들은 기존의 HDD 와는 근본적인 작동 방식이 다르기 때문에, backward-compatibility 를 어느정도 포기하고 대신 다음과 같은 이점을 가져왔다고 한다:\n\nWAF 감소\n예측가능한 성능\n\n\n얘는 인터페이스별로 다음과 같이 구현되었다:\n\nSATA 를 위한 ZAC\nSAS 위한 ZBC\nNVMe 를 위한 ZNS\n\n\n\n구조, 작동 원리 §\nZone, Sequential Write Constraint §\n\n이 모델에서는 LBA 공간을 동일한 크기의 Zone 이라는 것으로 나눈다.\nZone 은 다음과 같은 특성을 가진다. - 이것을 Sequential Write Contstraint 라고 한다.\n\nRandom read 가능\nSequential write 만 가능\n용량이 다 차서 새로 write 하기 위해서는, zone 전체에 대해 명시적으로 reset 을 수행\n\n\nZone 의 이러한 특성은 State machine 과 Write pointer 로 작동 방식이 구현된다.\n\nState Machine §\n\nZone 의 State machine 은 다음과 같이 상태가 전이된다:\n\n\n\n출처: 주인장 그림솜씨\n\n\n처음에는 EMPTY 상태이고, zone 에 write 하거나 명시적으로  OPEN ZONE 명령어를 사용하면 OPEN 상태가 되며 zone 이 다 차거나 명시적으로 FINISH ZONE 명령어를 사용하면 FULL 상태가 된다.\nDevice 는 OPEN 상태의 zone 개수에 제한을 걸어둘 수 있다. (Zone Limits 섹션 참고)\n\n만약 이 개수 제한에 미치지 않았을 때에는, 추가적인 zone 을 맘대로 OPEN 상태로 바꿀 수 있다.\n하지만 이 개수 제한에 걸리게 되면, 어떤 OPEN zone 은 CLOSE 상태로 바꿔야만 다른 zone 을 OPEN 할 수 있다.\n\n이것은 CLOSE ZONE 명령어를 사용하면 된다.\nzone 을 CLOSE 하게 되면, write buffer 와 같은 자원들을 정리하게 되고 다시 OPEN 되기 전까지는 write 할 수 없다.\n\n\n\n\nOPEN, CLOSE, FULL 상태에서는 reset (RESET ZONE WRITE POINTER 명령어) 을 통해 다시 EMPTY 로 바꿀 수 있다.\n즉, 상태들은 다음과 같이 표로 정리해볼 수 있다:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSTATEDESCRIPTIONEMPTY초기 상태OPEN데이터를 write 할 수 있는 상태 (자원 할당)CLOSE데이터를 write 할 수는 없지만, OPEN 상태로 바꾸면 write 할 수 있는 상태 (자원 반환)FULLZone 의 용량이 다 차서 더 이상 write 하지 못하는 상태\n\n또한 \bCommand 들을 표로 정리하면 다음과 같다:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOPERATIONDESCRIPTIONOPEN ZONEZone 을 OPEN 상태로 바꾸고 자원을 할당함CLOSE ZONEZone 을 CLOSE 상태로 바꾸고 자원을 해제함FINISH ZONEZone 을 FULL 상태로 바꿈RESET ZONE WRITE POINTERZone 을 EMPRY 상태로 바꾸고 zone 의 데이터를 erase 함\n\n다만 Official doc 의 State machine 은 위에 설명한 것과 (뼈대는 비슷하지만) 디테일한 부분에서 약간 차이가 있다.\n\nwrite 에 의한 OPEN zone 과 open 에 의한 OPEN zone 을 구분짓는다 (IMPLICIT OPEN, EXPLICIT OPEN)\nDevice 에서 event 를 보내 특정 zone 을 특수한 상태로 바꿀 수 있다:\n\nREAD ONLY: 말그대로 zone 이 읽기만 가능한 상태\n\n그냥 맘대로 바꿀 수 있는 것은 아니고, 보통 문제상황 - SMR HDD 의 write head 가 망가지는 등 - 에서만 이 상태로 바뀐다고 한다.\n\n\nOFFLINE: zone 이 망가져서 작동하지 않는 상태\n\n\n왜인지는 모르겠지만 공식문서에서는 CLOSE 상태에서 write 를 통해 FULL 로 바뀔 수 있다고 되어 있다.\n\n\n\nWrite pointer §\n\nWrite pointer 는 처음에는 zone LBA 공간의 시작점에서 시작해서\nWrite 작업이 이루어짐에 따라 점점 뒤로 밀리다가\nRESET ZONE WRITE POINTER 명령어를 사용하면 write pointer 를 zone 의 처음으로 (zone 의 첫 LBA 로) 쭉 땡기고 zone 전체를 erase 한다.\n만일 write pointer 가 가리키는 위치에 write 를 하지 않거나 FULL 상태인 zone 에 write 를 하려할 경우에는 실패한다.\n\nZone Size, Zone Capacity §\n\n\n출처: 공식문서\n\n\nZone Size 는 말 그대로 Zone 의 크기이다: 전체 LBA 공간을 동일한 개수의 block 으로 나누는 것.\n\nZone Size 는 SSD/HDD 제조과정에서 픽스되어서 나오고, 사용자가 임의로 바꿀 수 없다.\n\n\nZone Capacity 는 Zone 내에서 실제로 사용할 수 있는 공간이다.\n\n따라서 당연히 Zone Size 보다는 작다.\n\n\nZone Size 와 Zone Capacity 의 사이즈를 다르게 하는것은 Device 에서 바라보는 zone 의 크기는 모든 zone 에 걸쳐 동일하게 유지하되, Host 에서 바라보는 zone 의 크기는 media 의 특성에 맞게 최적화할 수 있게 하기 위함이라 한다…\n\nFlash device 의 경우에는 이를 통해 erase block 의 사이즈에 맞게 Zone Capacity 를 조정할 수 있게 해준다\n고 하는데 잘 모르겠다 - 어차피 Zone 이 block 의 집합이면 이런 것이 왜 필요한지\n\n\n\nZone Limits §\n\nWrite buffer 와 같은 내부 자원들이 한정되어 있어서, 그리고 기타 여러 Device media 들의 특징에 따라 zone 의 개수를 한정해야 할 수도 있다.\n\n이것은 Zone 을 OPEN/CLOSE 하는 것이 Host 에 의해서 이루어 지기 때문에 더욱이 필요하다.\nHost 는 위와 같은 Device 측면에서의 제약사항을 알지 못하기 때문에, 무분별하게 zone 을 OPEN 할 경우 성능 저하가 발생할 수도 있기 때문.\n\n\n하지만 이 제한은 Read 에는 아무 영향도 주지 않는다. Data read 는 항상 모든 zone 에 대해 가능하다. (뭐 물론 OFFLINE 이 아니고 data 가 존재한다는 전제 하에.)\n\nOpen Zone Limit §\n\n여기 에서 잠깐 언급한 내용이다: Write buffer 가 모자라거나 Device 의 parallel 능력이 부족한 경우를 위해 Writable zone (= Open zone) 의 개수를 제한하는 것이다.\n\n즉, EXPLITIT OPEN zone 개수 + IMPLICIT OPEN zone 개수\n\n\n이 한계치에 다다르게 되면 새로운 zone 에 write 하거나 OPEN ZONE 명령어를 실행하기 위해서는 어떤 OPEN zone 은 그 전에 CLOSE 상태가 되어야 하고, 그렇지 않다면 에러가 난다.\n\nActive Zones Limit §\n\nHost 가 data 를 write 하려고 할 때, 선택할 수 있는 zone 의 개수를 제한하는 기능이다.\nOPEN zone 과 CLOSE zone 을 합친 개수를 제한하는 것이다.\n\n뭐 더 정확하게 말하자면 EXPLICIT OPEN + IMPLICIT OPEN + CLOSE zone 개수이다.\n근데 EMPTY 에도 write 할 수 있는데 (물론 이후에 OPEN 으로 변경되지만) EMPTY zone 의 개수는 왜 빠지는지 모르겠다.\n\n\n이 한계치에 다다르게 되면 어떤 zone 은 FINISH ZONE 으로 FULL 상태로 만들거나 RESET ZONE WRITE POINTER 로 EMPTY 상태로 만들어야 한다.\n솔직히 용례가 없어서 이것이 왜 필요한지 감이 안오긴 한다.\n\nBackward-compatibility §\n\n여기까지 보면 Zoned Storage Model 은 Regular Block Model 을 따르는 기존의 디바이스들과 호환되지 않는 것처럼 보이고, 실제로 호환되지 않는다\n따라서 이러한 호환성을 위해 몇개의 방안들이 준비되어 있는데, 정리해 보면 아래와 같다.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMODELDESCRIPTIONUSED ZONE TYPEBACKWARD-COMPATIBILITY[[#host-managed-modelHost-Managed Model]]Sequential Write Constraint 가 강제됨[[#sequential-write-required-zone[[#host-aware-modelHost-Aware Model]]Sequential Write Constraint 를 선택적으로 이용할 수 있음[[#sequential-write-prefered-zone\nZone Models §\n\nZoned Storage Model 을 사용하는 방법을 Model 이라고 하는데, 두 가지로 나눌 수 있다.\n\nHost-Managed Model §\n\n이것은 Zoned Storage Model 을 Host 에 강제하는 방법이다.\n따라서 Sequential Write Constraint 에 따라 write 작업을 수행하도록 Host level 의 변경이 필요하다.\n\nHost-Aware Model §\n\n이것은 Backward-compatibility 를 위한 방법으로, 약간 하이브리드라고 생각하면 된다.\n즉, Random write 등의 Regular Block Model 의 기능을 사용할 수 있고\nSequential Write Constraint 를 위한 Zoned Storage Model Command 들을 사용할 수도 있다.\n\nZone Types §\n\nZone 들은 아래와 같은 타입을 가질 수 있다고 한다.\n\nConventional Zone §\n\n여기는 기존의 Reguar Block Model 처럼 사용할 수 있는 Zone이다.\n\n즉, Sequential Write Constraint 없이, Random Write 밖에 지원되지 않는다는 것.\n\n\n일반적인 용도 (데이터 저장) 보다는 Metadata 저장 등의 용도로 사용한다고 하며, 전체 Device 내에서 아주 작은 부분을 차지한다고 한다.\n\nSequential-write-required Zone §\n\n여기는 Host-Managed Model 을 위한 곳으로, Sequential Write Constriaint 가 빡세게 적용된다.\n\nSequential-write-preferred Zone §\n\n여기는 Host-Aware Model 을 위한 곳이라고 생각하면 된다.\n즉, Random write 도 되고, Zoned Storage Model command 들도 사용할 수 있는 공간이다.\n\nZone Append §\n필요성 §\n\n일반적으로는, host 가 보낸 write command 의 순서와 device 에 도착해서 처리되는 순서는 동일해야 하고, 변경되어서는 안된다.\n\n만일 그렇지 않다면, 데이터가 sequential 하게 저장된 것이 아니기에 sequential write constraint 에 위반되어 에러가 발생한다.\n\n\n하지만 실제로는 이것을 지키는 것이 쉬운 일은 아니다.\n\nHost 의 IO stack 이 복잡하기도 하고\nStorage adapter 혹은 command transport 가 순서를 보장해주지 않을 수도 있기 때문.\n\n\n따라서 이 문제를 해결하기 위해 host 에서 zone 당 한번에 1개의 command 만 실행되게 제한을 걸 수도 있지만, 이렇게 하면 병렬처리가 안되기 때문에 성능이 저하될 수 있다.\n정리해 보면, 다음과 같은 필요성에 의해 Zone Append 가 나오게 되었다.\n\nWrite command 순서가 예기치 않게 꼬여도 문제가 생기지 않게 하기 위해\nWrite command 들을 동시에 사용하기 위해\n\n\n\nZone Append 명령어 §\n\nZone Append 명령어는 한마디로 정리하면 “host 가 write 명령을 순서에 대한 고려 없이 동시에 device 에게 보낼 수 있게 하는 것” 이다.\n구체적인 작동 과정은 다음과 같다:\n\n이 명령어는 기본적으로는 write 명령어와 동일한데, 다만 저장 위치를 write pointer 의 위치가 아닌 zone 의 첫 LBA 에 write 하라고 지시한다.\nDevice 에서 이 명령어들을 처리할 때에는, 데이터를 효과적으로 저장할 수 있는 순서로 재배치 하여 write pointer 의 위치부터 데이터를 저장하게 된다.\n처리가 완료된 뒤에는 device 가 host 에게 데이터들이 어떤 순서로 어디에 저장되었는지 host 에게 알려주게 된다.\n\n\n아래의 예시를 참고하면 감이 올 것이니라\n\n작동 예시 §\n\n세 데이터를 write 하려 한다고 해보자:\n\nW0: A (4K 데이터) write\nW1: B (8K 데이터) write\nW2: C (16K 데이터) write\n\n\n그럼 일반적인 write (regular write) 의 경우에는 다음처럼 처리된다.\n\n\n\nW0 가 처리되며 A 를 write 하고, WP(Write Pointer) 가 WP0 위치로 움직인다.\n이후 W1 가 처리되며 WP0 위치에 B 를 write 하고, WP 가 WP1로 움직인다.\n마찬가지로 W2 가 처리되며 WP1 위치에 C 를 write 하고, WP 는 최종적으로 WP2 로 움직인다.\n\n\n하지만 Zone Append 명령어를 사용할 경우, 다음처럼 처리된다.\n\n\n\nW0, W1, W2 모두 저장 위치를 zone 시작점으로 하여 명령어가 수신된다.\nDevice 는 나름의 알고리즘에 따라 A -&gt; C -&gt; B 순서로 data 를 write 하기로 결정하고, 해당 순서대로 sequential write 를 수행한다.\n작업 수행 뒤 Host 에게 A, B, C 가 어디에 저장되었는지 알리게 된다.\n\n\n위의 두 과정 모두 WP 는 동일한 위치로 옮겨진다 - A, B, C 데이터 크기 총합은 결국에는 동일하기 때문에\n하지만 regular write 에서는 A, B, C 가 순서대로, 앞선 write 가 종료되어야 다음 write 가 시작되기 때문에 다소 느리지만\nZone append 에서는 A, B, C 가 동시에 처리되기 때문에 더 빠르게 처리된다.\n"},"botanicals/보따니깔-갈든---Botanical-Garden":{"title":"보따니깔 갈든 - Botanical Garden","links":["botanicals/algorithm/(Botanical-Garden)-Algorithm,-Data-Structure","botanicals/cybersecurity/(Botanical-Garden)-Cybersecurity","botanicals/database/(Botanical-Garden)-Database","botanicals/elasticsearch/(Botanical-Garden)-ElasticSearch","botanicals/kubernetes/(Botanical-Garden)-Kubernetes","botanicals/os/(Botanical-Garden)-Operating-Systems,-Linux","botanicals/shellscript/(Botanical-Garden)-Shell-Script","botanicals/storage/(Botanical-Garden)-Storage,-SSD"],"tags":[],"content":"\n\n                  \n                  &quot;보따니깔 갈든&quot; 은 작물들을 연결하며 재배하는 구역입니다. \n                  \n                \n\n\n\n                  \n                  현재 기존의 Notion 및 Bear 에 기록된 문서들의 Migration 작업이 진행중입니다. \n                  \n                \n\n재배 작물들 §\n\n알고리즘, 자료구조\n사이버보안\n데이터베이스\n엘라스틱서치\n쿠버네티스\n운영체제\n쉘스크립트\n스토리지\n"},"index":{"title":"매디쏜 디지딸 갈든","links":["","botanicals/보따니깔-갈든---Botanical-Garden","originals/오리지날-갈든---Original-Garden","archives/아까이브-갈든---Archive-Garden"],"tags":[],"content":"\n    \n        \n    \n\n김해람과 디지털 귀농 §\n뉴욕에 있는 Madison Square Garden 을 따서 Madison Digital Garden 라고 이름은 지었지만 아직 디지털 가드닝 이 뭔지 잘 모르겠습니다. 이곳은 예쁘고 아기자기하게 꾸민 정원 (Garden) 보다는 먹고살기 위한 농사 (Farming) 가 좀더 어울리지 않나 싶어요. 그래서 여기는 디지털 가드닝의 공간이라기 보다는, 도시사람의 먹고살기위한 농사, 즉 디지털 귀농 의 공간입니다.\n이런식으로 구역을 나눠봤습니다.\n\n보따니깔 갈든 : 연결된 작물들 (Networked-thought)\n오리지날 갈든 : Networked-thought 에 포함되지 않는, 강의 필기록과 같은 Sequential 한 작물들\n아까이브 갈든 : 정리는 안돼있지만 버리기에는 “아까” 운 작물들 - 그냥 창고\n\n그리고 저는 정원일 혹은 농사일 둘 다와 무관한 이런걸로 먹고사는 사람입니다.\n하여간 만나서 반갑네요. 만약 여기 심어진 작물들이 좀 상태가 안좋아보인다면, 이메일 이나 링크드인 DM 혹은 깃허브 이슈 를 남겨주셔도 됩니다."},"originals/comnet.fall.2021.cse.cnu.ac.kr/(충남대)-컴퓨터-네트워크-강의록":{"title":"(충남대) 컴퓨터 네트워크 강의록","links":["originals/comnet.fall.2021.cse.cnu.ac.kr/01.-데이터통신-회고","originals/comnet.fall.2021.cse.cnu.ac.kr/02.-Network-Layer","originals/comnet.fall.2021.cse.cnu.ac.kr/03.-Packet-switching-example","originals/comnet.fall.2021.cse.cnu.ac.kr/04.-Routing-복습","originals/comnet.fall.2021.cse.cnu.ac.kr/05.-Routing-예시","originals/comnet.fall.2021.cse.cnu.ac.kr/06.-IPv4,-IPv6","originals/comnet.fall.2021.cse.cnu.ac.kr/07.-Address-mapping,-Multicasting,-Error-rep","originals/comnet.fall.2021.cse.cnu.ac.kr/08.-Transport-Layer-&-UDP","originals/comnet.fall.2021.cse.cnu.ac.kr/09.-TCP","originals/comnet.fall.2021.cse.cnu.ac.kr/10.-Congestion-control,-SCTP","originals/comnet.fall.2021.cse.cnu.ac.kr/11.-Application-Layer,-DNS","originals/comnet.fall.2021.cse.cnu.ac.kr/12.-TELNET,-Email,-File-Transfer","originals/comnet.fall.2021.cse.cnu.ac.kr/13.-WWW,--HTTP","originals/comnet.fall.2021.cse.cnu.ac.kr/14.-SNMP","originals/comnet.fall.2021.cse.cnu.ac.kr/부록---실습자료-1)-Network-layer-&-ARP","originals/comnet.fall.2021.cse.cnu.ac.kr/부록---실습자료-2)-Proxy-ARP","originals/comnet.fall.2021.cse.cnu.ac.kr/부록---실습자료-3)-GARP","originals/comnet.fall.2021.cse.cnu.ac.kr/부록---실습자료-4)-Static-Router","originals/comnet.fall.2021.cse.cnu.ac.kr/부록---시험대비)-싱하형배-컴퓨터-네트워크-모의고사","originals/comnet.fall.2021.cse.cnu.ac.kr/부록---시험대비)-싱하형배-컴퓨터-네트워크-모의고사-정답"],"tags":[],"content":"개요 §\n강의 정보 §\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n강의 구분소속교수시기학부 수업충남대학교 공과대학 컴퓨터공학과김상하 교수님2021년 가을학기\n실습 자료 §\n\nARP 프로토콜 구현: github://haeramkeem/Fall2021-CNU-Comnet-ARP\nStatic router 구현: github://haeramkeem/Fall2021-CNU-Comnet-Router\n\n목차 §\n\n01. 데이터통신 회고\n02. Network Layer\n03. Packet switching example\n04. Routing 복습\n05. Routing 예시\n06. IPv4, IPv6\n07. Address mapping, Multicasting, Error rep\n08. Transport Layer &amp; UDP\n09. TCP\n10. Congestion control, SCTP\n11. Application Layer, DNS\n12. TELNET, Email, File Transfer\n13. WWW,  HTTP\n14. SNMP\n부록 - 실습자료 1) Network layer &amp; ARP\n부록 - 실습자료 2) Proxy ARP\n부록 - 실습자료 3) GARP\n부록 - 실습자료 4) Static Router\n부록 - 시험대비) 싱하형배 컴퓨터 네트워크 모의고사\n부록 - 시험대비) 싱하형배 컴퓨터 네트워크 모의고사 정답\n"},"originals/comnet.fall.2021.cse.cnu.ac.kr/01.-데이터통신-회고":{"title":"01. 데이터통신 회고","links":[],"tags":[],"content":"\n\n                  \n                  충남대학교 컴퓨터공학과 김상하 교수님의 &quot;컴퓨터 네트워크&quot; 강의를 필기한 내용입니다. \n                  \n                \n\n\n\n                  \n                  다소 잘못된 내용과 구어적 표현 이 포함되어 있을 수 있습니다. \n                  \n                \n\n지난학기 복습 §\n\nPhysical Layer : Bit transmission - 0과 1을 전송하는 데 전압의 높음과 낮음으로만 0과 1을 표현하는 것에 많은 단점이 있어 Encoding과 Modulation의 방법으로 bit을 전환해 전송하는 것\nData link Layer : Frame transmission - 노드 - 노드 간 통신에서 에러가 전혀 없는 통신을 하기 위한 절차와 에러를 잡아낼 수 있는 별도의 비트를 묶어 데이터를 프레임화 시키는 것을 담당함\n\n또한 MAC주소로 알려진 고유한 물리주소를 사용해 송신지와 수신지의 주소를 표시함. 프레임을 받은 노드는 자신의 물리주소와 일치한다면 위의 계층으로 올려보내고 일치하지 않는다면 discard하는 방식으로 작동\n\n\nNetwork Layer : Packet transmission - 여러번의 노드 - 노드간 통신을 거쳐 목적지까지 제대로 도달하게 하는 것을 담당함(Tele Communication)\n\n목적지까지 제대로 가기 위한 송신지와 목적지의 주소로 IP주소를 사용\n경로(route)를 찾기 위한 것(router)으로 IP주소를 통해 다음 노드의 MAC주소를 찾고 전송하는 과정을 여러번 반복해 목적지까지 도달\n상대의 MAC주소를 알아내는 것은 broadcast 물리주소를 이용해 ARP request를 보내는 방법으로 해결\n\n\nTransport Layer : Segment transmission - 이번학기부터 배울 내용 - 컴퓨터 내에서 어떤 프로세스로 전달되어야 할 지를 결정\n\nSegment 내의 Port number 를 통해 프로세스를 찾아내게 된다\n\n\nApplication Layer : 이번학기에 배운댄다\nNetwork Architecture : OSI 7계층 - 통신 과정을 7개의 계층으로 나누고 각각의 계층들을 캡슐화해 하나의 계층에 대해 연구할때는 다른계층들의 작동원리를 정확하게 알고 있지 않아도 되게 함 - Peer 2 Peer 통신 - 같은 계층끼리의 통신에만 집중하는 것\n"},"originals/comnet.fall.2021.cse.cnu.ac.kr/02.-Network-Layer":{"title":"02. Network Layer","links":[],"tags":[],"content":"\n\n                  \n                  충남대학교 컴퓨터공학과 김상하 교수님의 &quot;컴퓨터 네트워크&quot; 강의를 필기한 내용입니다. \n                  \n                \n\n\n\n                  \n                  다소 잘못된 내용과 구어적 표현 이 포함되어 있을 수 있습니다. \n                  \n                \n\nIP §\n\n일단 IP는 Network Layer의 한 종류인데\n이것 말고도 다른 것들도 있었지만 결과적으로 IP가 승리를 거두었고 앞으로도 계속 쓰이게 될 것이다\nNetwork Layer로 IP를 사용하는 통신망에 연결되어 있으면 인터넷에 연결되어 있다고 하더라\n그리고 컴퓨터같은 송수신지 말고 중간에 거쳐가는 Intermediate Node같은 경우에는 Network Layer까지만 있고 그 상위 프로토콜에 대한 기능은 가지고 있지 않더라 - 까지도 데통시간에 배웠쥬?\n\nPacket Switching §\n\n뭐 옛날에는 Circuit switching이라는 기술도 있었지만 지금은 거의 안쓴댄다\n\nPrinciples of Packet Switching §\n\n\n일단 송신하려고 하는 user data를 패킷단위로 쪼개고 각 패킷에 packet header라는 control information을 붙인다.\n\npacket header에는 송수신지의 Network address(IP address)와 다른 여러 정보들이 들어가게 된다\n\n\n그리고 Packet Switching이라는 것은 큐에 있는 패킷을 바꿔치기 하는 것을 의미한다\n\n이러한 작업을 하는 장비를 Router라고 하며 Packet Switch라는 말과 동일하게 쓰인다\n\n\n\n\n\n근데 갑자기 뭔 큐냐\n위 그림의 왼쪽은 전체 네트워크 구조의 예시이고 오른쪽은 저 네트워크 안에서 2번 라우터의 구조를 나타낸 것이다 - 보면 C, 3, 5, 1과 연결되어 있는 것을 알 수 있다\n그리고 각각의 노드마다 입출력 회선이 존재한다 - 그림에서는 선 하나로 표현됐지만 사실 두개인 것이다\n또한 각각의 회선의 끝에는 큐가 존재한다 - 입력 회선의 경우에는 Input queue가 존재해 들어오는 패킷들이 쌓이고, 출력 회선의 경우에는 output queue가 존재해 나가야 되는 패킷들이 쌓이게 된다\n오른쪽 그림을 통해 Packet switching의 과정을 보면\n\n1번 노드와 연결된 회선으로 송신지 B, 수신지 D인 패킷이 들어온다\n그럼 그 패킷이 그 회선의 input queue에 쌓인다\nqueue에서 나오면, 2번 노드가 보고 수신지가 D인 것을 확인한 후 3번 노드로 나가는 output queue에 넣어주게 된다\nOutput queue에서 기다리다 3번 노드로 나가게 된다\n\n\n\nTwo types of packet switching §\n\nDatagram방식 : Connectionless한 방식\nVirtual-circuit방식 : Connect-oriented방식 - Orderly Delivery(connection / disconnection 프로세스를 필요로함)\n뭔 개소린지 이제 배운다\n\nDatagram §\n\nDatagram방식은 패킷화하여 분리된 패킷들이 같은 경로로 가든 다른 경로로 가든 상관 없는 방식이다\n\n\n\n위의 예시를 보면\n일단 datagram방식이나 virtual circuit이나 패킷으로 나누는건 동일하다\n그리고 나눈 패킷 중\n첫번째 패킷은 B → 1 → 4 → 5 → 3 → D의 경로로 갔고\n두번째 패킷은 B → 1 → 2 → 5 → 3 → D의 경로로 가고\n세번째 패킷은 B → 1 → 2 → 3 → D의 경로로 갔다고 해보자\n이 경로를 설정하는 것은 각각 노드 맘대로 하는거다 - 한쪽이 트래픽이 몰려서 다른길로 보낼 수도 있고 뭐 지꼴리는대로 판단해서 보내는 것\nDatagram방식은 이처럼 가는 경로가 일정하지 않고, 따라서 D에 도착하는 순서도 출발한 순서가 아닐 수도 있다 - 따라서 Orderly delivery를 지원하지 않게 되는 것\n현재 IP망만 Datagram방식을 사용해 통신하고 있고, 전화망같은 다른 망의 경우에는 뒤이어 설명하는 Virtual Circuit방식을 사용한다 - 생각해보면 당연한일 - 전화의 경우 순서가 중요한데 순서가 바뀔 수 있는 Datagram으로 보내는 것은 이상하제\n\nVirtual Circuit §\n\nVirtual Circuit의 경우에는 패킷화해서 분리된 패킷들이 항상 같은 경로를 따라 가게 되는 방식이다\n그리고 이를 위해 Connect / Disconnect과정이 들어간다\nVirtual circuit의 작동방식은 다음과 같다\n\n1. Connect Phase §\n\n\n일단 위와 같은 망에서 B → D로 보낸다고 하자\n그럼 패킷들을 보내기 앞서 다음과 같은 구조의 컨트롤 패킷을 B가 먼저 보낸다\n\n\n\n보면 일단 Connect packet인 것을 나타내기 위한 정보와 함께 Virtual circuit number, 송수신지 주소가 들어간다\nVirtual circuit number는 예시 보다 보면 왜필요한지 딱알게 된다 - 약간 통신 id같은 느낌임\n\n\n\nConnect phase가 끝나고 나면 다음과 같은 구조가 되는데 어떻게 이래되는지 보자\n일단 B가 1번으로 보내는게 좋겠다고 판단해 connect packet을 보내며 자신의 virtual circuit table에 행을 하나 추가한다 - virtual circuit number는 자기가 보낸 virtual circuit number인 0, 송신지는 자신이니까 적을 필요 없고 수신지는 1번 노드 - virtual circuit table은 현재 진행되고 있는 virtual circuit 정보를 저장하는 테이블\n그리고 1번 노드가 이걸 받고 2번으로 보내는게 좋겠다고 판단하면 2번으로 connect packet을 전달하며 자신의 virtual circuit table에도 행을 하나 추가한다 - virtual circuit number는 받은 connect packet에 담긴 번호인 0, 송신지는 B, 수신지는 2번\n마찬가지로 2번 노드도 connect packet을 전달받고 3번 노드로 보내는게 좋겠다고 판단한 경우 3번으로 전달하며 자신의 virtual circuit table에도 행을 하나 추가한다 - virtual circuit number는 받은 connect packet에 담긴 번호인 0, 송신지는 1, 수신지는 3\n3번 노드에서도 동일한 과정을 거치고 D가 받은 다음에도 동일하게 virtual circuit 0에 대한 정보를 자신의 virtual circuit table에 넣는다\n이렇게 각 노드마다 virtual circuit table에 행이 하나씩 들어가게 되면 Connect phase가 끝이난다\n\n2. Data Transfer Phase §\n\n\nConnect phase 가 끝나고 나서 이제 B가 위의 그림과 같은 패킷들을 전송한다 - 여기서 중요한 점은 패킷의 헤더에 송수신지 주소가 들어가는게 아니고 virtual circuit number랑 몇번째 패킷인지의 정보가 들어가게 된다는 것이다\n왜냐하면 virtual circuit number가 0인 통신에 대한 경로가 다 각각 노드의 virtual circuit table에 들어가 있기 때문에 virtual circuit number만 보내도 경로를 따라갈 수 있기 때문\nB가 virtual circuit table을 보고 1번으로 보내야겠다는것을 알아낸 뒤, 1번 노드로 패킷을 보낸다\n그럼 1번노드는 패킷을 받아들고 virtual circuit table에 가서 확인한다 - virtual circuit number가 0이고 송신지가 B이므로 2번으로 보내야 된다는 것을 알아내게 됨 - 따라서 1번 노드는 패킷을 2번노드로 보내게 된다\n2번 노드도 마찬가지로 패킷을 받은 뒤 virtual circuit table에 가서 어디로 보내야되는지 찾는다 - virtual circuit number가 0번이고 송신지가 1번이므로 3번으로 보내야 되는 것을 알아냄 - 따라서 2번 노드는 3번노드로 보내게 된다\n3번 노드도 동일한 과정을 거치게 되고 결과적으로 모든 패킷이 같은 경로를 따라 D번 노드에 도착하게 된다\n\n3. Disconnect Phase §\n\n통신이 끝난 뒤에 각각 노드의 virtual circuit table에 해당 행을 지워 저장공간을 확보해야 된다 - 하지만 각각 노드는 통신이 끝났는지 모르기 때문에 Disconnect Phase가 진행되게 되는 것\n\n\n\n통신이 끝난 뒤에 B는 위와 같은 Disconnect packet을 전송하게 된다 - virtual circuit table을 보고 1번으로 보내야 한다는 것을 알아낸 뒤 1번으로 보내고 자신의 virtual circuit table에서 해당 행을 지운다\nDisconnect packet을 받아든 1번 노드는 virtual circuit number가 0번이고 송신지가 B인 행을 찾은 뒤 2번으로 보내야 된다는 것을 알아낸다 - 이후 2번으로 보내고 자신의 virtual circuit table에서 해당 행을 지운다\n2번과 3번, D에서도 동일한 과정을 거치게 되고 결과적으로 모든 노드에서 이번 통신에 대한 virtual circuit 정보가 지워지게 된다\n\n\n\nVirtual Circuit방식은 패킷들이 항상 같은 경로를 따라가기 때문에 복잡하긴하지만 송신순서와 동일한 순서로 수신되게 된다 - Orderly Delivery를 지원한다\n옛날에는 순서대로 가는 것이 당연하다 생각했기 때문에 역사가 오래된 방식이며 IP를 제외한 대부분의 통신이 이 방식을 사용하게 된다\n\nExample code §\n\n\nPacket은 종착역에 도착할때까지 변하지 않지만 Frame의 물리주소는 계속 바뀌게 된다\n\n\n\n위와 같은 구조를 대강 코드로 짜보면 아래와 같다 - 다만 위의 그림에서는 Frame의 색깔이 전부 동일하게 표현되었지만 위에서 말한거처럼 Frame의 내용은 매번 달라진다 - Packet이 동일하게 유지되는거고 Frame은 물리주소가 계속 바뀌기 때문에 달라짐\n\n\n\n일단 이건 packet과 frame의 자료구조\n\n\n\n이건 Sender의 코드\n\n\n\n이건 1~4번 노드의 코드 - Intermediate node의 경우에는 Network layer까지밖에 없기 때문에 main()함수가 Network layer의 역할을 하고 있다\n\n\n\n이건 Receiver의 코드\n위의 코드들은 걍 한 읽어보면 뭐 어떻게 작동하는지 알 수 있을것이다\n여기서 중요한건 일단\nTransparency가 잘 지켜져야 된다는 것이다 - 보면 Network layer에서만 packet_type이 등장하고 다른 layer에서는 등장하지 않음 - 마찬가지로 Data link layer에서만 frame_type이 등장하고 다른 layer에서는 등장하지 않는다\n\nSender의 경우에 main()에서 Packet을 생성하여 send_data()를 호출할 수도 있지만 그렇게 하지 않고 주소와 데이터를 전달해 send_data()에서 packet을 생성하는 이유가 이러한 이유에서인 것\n이렇게 하는 이유는 만약에 Packet의 구조가 달라졌을 때 network계층만 손보면 되기 때문 - 그 상위계층에서 Packet을 만들어 전달하는 구조였다면 Packet의 구조가 바뀌게 되었을 때 상위계층의 구현도 바꿔줘야 하는 문제점이 발생하게 된다\n하지만 Transparency라는 것이 모든걸 다 숨긴다는 것이 아니다 - 각 계층의 자료구조를 숨긴다는 것이고 위의 예제에서 보는것처럼 각 계층에서 사용하는 주소의 경우에는 상위 계층에서도 사용할 수 있다\n\n\n또한 항상 상위계층에서 하위계층의 함수를 호출하는 방식으로 구현된다는 점이다\n\n일단 sender의 경우에는 상위 계층에서 하위계층으로 전달하는 방식이기 때문에 이와 같은 구조가 이상하지 않음\n하지만 receiver의 경우에는 하위계층에서 상위계층으로 전달하는 방식이지만 함수호출은 상위계층에서 하위계층으로 이루어지게 된다\n왜냐면 상위계층에서 하위계층의 함수를 호출하고, 하위계층에서는 패킷 / 프레임이 도착할때까지 기다렸다가 도착하면 처리한 다음에 return하거나 주소를 참조하는 방식으로 상위계층에 전달하는 구조이기 때문\nmain()함수에는 항상 최상위 계층의 코드가 들어가게 되는 것이 이러한 이유에서이다\n\n\n"},"originals/comnet.fall.2021.cse.cnu.ac.kr/03.-Packet-switching-example":{"title":"03. Packet switching example","links":[],"tags":[],"content":"\n\n                  \n                  충남대학교 컴퓨터공학과 김상하 교수님의 &quot;컴퓨터 네트워크&quot; 강의를 필기한 내용입니다. \n                  \n                \n\n\n\n                  \n                  다소 잘못된 내용과 구어적 표현 이 포함되어 있을 수 있습니다. \n                  \n                \n\n참고 §\n\nDatagram방식은 미 국방성에서 나온 아이디어이다\n전장의 특성상 네트워크가 끊어질 가능성이 높기 때문에, 네트워크가 끊어지더라고 우회해서 패킷을 보내기 위해 만들어진 기술인 것\nVirtual circuit의 경우에는 경로가 설정되고 나면 그 방향으로만 보낼 수 있기 때문에, 중간에 끊기면 패킷을 보낼 수가 없는 반면\nDatagram의 경우에는 다른 경로로 갈 수 있기 때문에 패킷이 도착할 수 있는 가능성이 더 높아지게 된다\n\nPacket switching example §\n\n간단한 코드를 통해 작동방법 이해하기\n\nDatagram §\n\n\n일단 기본 자료 구조는 위와 같더라\n위의 자료구조는 Datagram의 자료구조인데 Virtual circuit의 자료구조도 packet_type만 바뀌고 frame_type은 바뀌지 않는다\n\n즉, Network layer가 바뀌어도 다른 계층은 바꾸지 않아도 된다는 것을 이것을 통해서도 알 수 있다\n\n\n\n\n\n그리고 위의 코드도 Datagram과 Virtual circuit이 저 send_data()라는 함수만 변경되고 나머지는 다 똑같이 이루어지더라\n즉, Datagram을 위한 함수와 Virtual circuit을 위한 함수가 따로 제공되고 상위계층에서는 목적에 맞게 해당 함수를 불러다 쓰기만 하면 되고 내부 동작을 알 필요는 없으며 Data Link Layer의 send_data()함수는 변경하지 않아도 된다는 것\n\n\n\n또한 Sender나 reciever의 경우에는 main()함수에 Application layer와 Transport layer가 들어갔지만 위 그림처럼 Node의 경우에는 main()함수에 Network layer가 들어간다 - Node의 최상위 노드는 Network layer이기 때문\n\nVirtual circuit §\n\n\n구조를 보면 일단 위와 같다 - 이건 실제 패킷의 구조가 아닌 이해를 위해 간략하게 표시한 구조임\n위에서 보여준 Datagram의 패킷과는 다르게 Virtual circuit패킷에는 connection과 disconnection phase를 나타내기 위한 비트와 별도의 패킷 구조가 존재한다\nvc_num : Virtual circuit number. 지난시간에 배웠던것처럼 virtual cirtuit을 식별하기 위한 id같은거다\nc_or_d : 패킷의 종류를 나타내는 비트. 위 그림처럼 1이면 데이터이고 0이면 컨트롤 패킷이다.\n데이터 패킷일 때는 패킷의 순서를 알려주기 위한 seq와 데이터가 나머지 부분에 들어가게 되고\n그리고 컨트롤 패킷일 때 c_type의 값이 0이면 connection packet이고, 1이면 disconnection packet이 된다. 나머지에는 송수신 주소가 들어가게 된다\n\n\n\n따라서 패킷의 구조를 구조체로 정의하면 위와 같이 된다\nvirtual circuit number를 위한 vc_num가 존재하고,\n패킷의 종류를 위한 c_or_d가 존재하며\nc_or_d에 따라서 다른 구조를 가지게 하기 위해 나머지 부분들에 대해 union type으로 정의되어있는 것을 볼 수 있다\n\n\n\n위의 그림은 Sender에 대한 구현인데 Datagram에서는 그냥 send_data()만을 상위계층에서 호출하는 것과는 달리 Virtual circuit에서는 connect()을 호출한 이후에 send_data()를 호출하게 되고 그것이 끝나면 disconnect()라는 함수를 호출하고 있는 것을 볼 수 있다\n그리고 보면 main()에서는 network layer의 작동방식에 대한 것은 알 지 못한체 그냥 network layer의 함수들을 호출하고 있는 것을 알 수 있다 - 이러한 식으로 캡슐화가 이루어지는 것이다 이말이야\n\n\n\n여기서도 보면 data link layer의 send_packet()의 함수는 datagram과 virtual circuit이 동일한 것을 볼 수 있다\n\n\n\n노드의 구현에서는 main()이 network layer이기 때문에 여기서 get_packet을 하고, 패킷의 c_or_d비트에 따라서 각기 다른 함수를 호출해 주고 있는 것을 볼 수 있다\nhandle_data_packet에서는 vc_table에서 vc_num을 이용해 route를 알아내고, 해당 route로 패킷을 전송해주는 것을 알 수 있다\n\n\n\n그리고 handle_control_packet의 경우에는 c_type을 보고 0인지 1인지에 따라서 connect phase와 disconnect phase를 진행해주는 것을 알 수 있다\n보면 connect phase에서는 루트를 설정하고 vc_table에 넣어주는 반면 disconnect phase에서는 vc_table에서 route를 가져온 다음 그놈을 지우는 것을 알 수 있다\nnode의 datalink layer 함수들은 datagram과 동일하므로 생략\n\n\n\nReceiver의 경우에도 c_or_d를 보고 그에 맞는 함수를 호출해주는 것으로 network layer가 작동한다\n\n\n\n마찬가지로 handle_control_packet의 경우에도 c_type을 보고 그에 맞는 동작을 하게 된다\n\n그림으로 이해하기 §\n\n\n위의 그림은 Virtual Circuit Table의 모습이다.\n보면 Incoming의 경우에는 In Port와 In VC# 가 있다 - 해당 포트로 해당 Virtual Circuit Number를 가진 놈이 들어왔을때 매칭해라라는 뜻\n그리고 Outgoing의 경우에는 Out Port와 Out VC# 가 있다 - 해당 포트로 해당 Virtual Circuit Number를 가지고 나가라는 뜻인데 여기에도 VCNum이 있는 이유는 In VCNum와 Out VCNum을 다르게 해줌으로써 얻는 이점이 있기 때문이다 - 근데 그게 뭔지는 안배운댄다\n\n\n\n위와 같은 방식으로 통신이 진행된다고 하자\n\n\n\n그리고 Topology는 위의 그림과 같다고 해보자\n그럼 일단 VC1을 진행하기 위해 H1, A, B, D, H2의 순서로 connection control packet이 움직인다\n그러고 나면 아래와 같은 방식으로 각 노드와 스테이션에 VCTable이 저장된다\n\n\n\n보면 거쳐간 모든 노드에 0번 포트로 0번 VCNum이 들어왔고 1번 포트로 0번 VCNum을 가지고 나간 것을 볼 수 있다\nVC1인데 왜 0번이냐고 궁금할 수 있는데 VC1의 경우 위의 단계를 보면 VCNum이 0이기 때문에 0인 것이다. VCNum가 0이 되는 이유는 H1에서는 A로 VC를 보낸 적이 없기 때문에 VCNum0으로 패킷이 만들었기 때문이다\n그리고 지금 설정한 이 경로대로 데이터가 전송이 되는 것으로 (2)단계까지 완성을 시킨다\n\n\n\n그리고 위 그림은 (3)단계인데 VC2에 대해 H1, A, B, D, H3로 경로를 설정하면 위와 같은 그림이 된다\n여기서 중요한게 있는데 위 그림에서 보면 D노드 의 VCTable의 마지막 행에는 0121이 아니라 0120로 적혀있다\n\n이건 왜그러냐면 VCNum을 할당할때는 In VCNum과 무조건 같은 번호를 쓰는게 아니고 충돌이 나지 않는 번호를 고르기 때문이다\n즉, A와 B노드에서는 1번 포트로 나가는 0번 VC가 있기 때문에 0번을 사용하게 되면 충돌이 나게 된다. 하지만 D노드에서는 1번 포트가 아닌 2번 포트로 나가야 되고, 2번 포트로 나가는 0번 VC는 없기 때문에 VC를 0으로 설정해주는 것이다\n\n\n\n\n\n이제 위의 그림이 (4)단계인데 VC3(H2, D, B, E, H4)의 경로를 설정하면 위와 같은 그림이 된다\n위의 그림에서도 볼 수 있듯이 H2는 D로 VC를 보낸 적이 없으니까 VC0번으로 시작해서 D에서도 1번 포트로 VC0를 받고, 0번 포트로 VC0으로 내보내도 충돌나지 않기 때문에 그렇게 내보낸 것을 볼 수 있다\nB와 E노드에서도 동일하게 In &amp; Out port와 In &amp; Out VC를 설정해준 것을 볼 수 있다\nIn &amp; Out VC가 같다고 해서 In VC값을 Out VC에 그대로 쓴 게 아니라는 것 꼭 기억해라\n\n\n\n(5)단계 VC4(H5, E, C, A, H1)의 경로설정을 하고 나면 위처럼 된다\n마찬가지로 들어오고 나간 포트 번호와 해당 포트 번호에 대해 사용한 적이 없는 VC번호로 할당되어 있는 것을 볼 수 있다\n\n\n\n(6)단계에서는 VC2경로로 데이터를 보내게 되고\n(7)단계에서는 VC3경로를 지우게 된다\nDisconnect control packet을 보내고 난 뒤의 테이블 모습이 위의 그림이다\n\n보면 VC3에 해당하는 경로가 싹 지워진 것을 볼 수 있다\n\n\n(8)단계에서는 VC4경로로 데이터가 움직이게 된다\n시험공부할때 각 단계별로 connect, data, disconnect 패킷이 어떻게 움직이는지, 그리고 그때마다 VCTable들이 어떻게 갱신되는지 따라가봐라\n\nExternal &amp; internal operation §\n\n일단 Service Provider에 대해서 알아야 한다\n먼저 컴퓨터나 핸드폰, 라우터 등의 단말들을 만드는 Equipment Provider가 있고\n단말들을 연결할 회선들을 제공해주는 선로 제공자가 있다\n그리고 Service Provider는 이런 단말들과 선로들을 설계 및 시공하여 통신을 가능하게 해주는 것이라고 할 수 있다\n뭐 간단하게 생각해서 SKT 나 KT 생각하면 됨\n\n\n\n이때 위의 그림을 보면\n일단 사용자 단말과 네트워크 장비 간의 통신은 User Network Interface(UNI) 라고 하고\n네트워크 장비들간의 통신은 Network Node Interface(NNI) 라고 한다\n그리고 UNI에서는 Virtual Circuit을 사용하고, NNI에서는 Datagram을 사용하는 등 경우에 따라 다른 프로토콜을 사용하는 경우가 많더라\n이렇게 이원화하는 이유는 SP는 NNI에서 일어나는 일들이나 프로토콜 등을 보안상의 이유로 사용자에게 알리고싶어하지 않기 때문이다\n이때 UNI같은 겉으로 드러나는 통신을 External이라고도 하고 NNI처럼 내부적으로 일어나는 통신을 Internal이라고도 하는데\n크게는 (1) External=Virtual Circuit, Internal=Datagram을 이용하는 경우, (2) External=Virtual Circuit, Internal=또 다른 Virtual Circuit을 이용하는 경우, (3) External=Datagram, Internal=Virtual Circuit을 이용하는 경우로 나눠볼 수 있다\n"},"originals/comnet.fall.2021.cse.cnu.ac.kr/04.-Routing-복습":{"title":"04. Routing 복습","links":[],"tags":[],"content":"\n\n                  \n                  충남대학교 컴퓨터공학과 김상하 교수님의 &quot;컴퓨터 네트워크&quot; 강의를 필기한 내용입니다. \n                  \n                \n\n\n\n                  \n                  다소 잘못된 내용과 구어적 표현 이 포함되어 있을 수 있습니다. \n                  \n                \n\nTCP/IP §\n\n\nOSI 7계층과 대비되는 TCP/IP계층의 전체적인 구조는 다음과 같다\n네트워크 계층에서는 IP가 사용되고 나머지 ICMP, IGMP, RARP, ARP는 IP를 보조하는 역할을 하게 되며\nTransport에는 STCP, TCP, UDP가 있지만 TCP가 주로 쓰인다\nInternet Protocol의 약자가 IP이고 Transmission Control Protocol의 약자가 TCP이다\n\nInternet Routing §\n\n데통시간 배운 Routing에 대해서 복습하고 넘어가자고\n\n\n\n일단 Routing이라는 것은 수신지의 주소를 이용해 어디로 가야할 지 길을 설정해주는 것인것 기억나제\n그래서 길을 찾아주기 위해 주소를 key로 하고 나가야 될 port를 value로 하는 테이블을 가지고 있어야 되는데 이세상 모든 컴퓨터들의 주소와 그에 맞는 port를 매칭시켜 테이블을 만드는 것은 테이블의 사이즈도 커지고 찾는데도 오래걸릴것이여\n따라서 아래의 그림처럼 주소 전체를 key로 하지 않고 주소의 앞 일부분(netid)만 key로 하고 그에 맞는 port를 value로 하되 해당 port로 나가서 접근할 수 있는 컴퓨터는 전부 해당 netid에 속하게 구성하게 된다\n그렇게 하면 테이블의 사이즈도 작아지고 더 빨리 찾을 수 있기 때문\n위의 그림에서 보면 netid를 key로 하고 port를 value로 해서 테이블을 구성한 뒤, port로 나갔을때의 호스트 그룹은 전부 같은 netid를 갖고 있는 것을 볼 수 있다\n\n\n\n그래서 실제로의 IP주소를 보면 위처럼 A, B, C클래스로 나뉘어져 있다\n일단 어느 클래스에 속하는 주소인지는 맨 처음의 몇개의 비트를 이용해 식별하게 된다\n그리고 위 그림에 보면 netid랑 hostid가 있는데 netid는 위에서 설명한 것처럼 그루핑을 위한 것이고 이것은 인터넷을 관리하는 기관(Network Information Center)에서 특정 기관(뭐 예를들면 충남대)으로 발급해 주는 값이다\n그리고 hostid는 netid를 받급받은 기관이 자신이 관리하는 호스트들에다가 나눠주는 값이 되는 거임\n그래서 만약 큰 기관의 경우에는 NIC에서 A클래스 netid를 발급해주고, 작은 기관에는 C클래스 여러개를 발급해준다던지 그런식으로 사용하게 된다\n\nRouting의 과정 §\n\n일단 들어온 패킷의 Dst Addr를 봐야것제\n그리고 Router가 가지고 있는 Routing Table(Forwarding Table) 와 Dst Addr를 비교해서 나가야 될 port번호를 알아내게 되는 방식이다\n그리고 Routing Table은 다른 netid와 통신하는 외부망과의 연결을 위한 routing을 할때(그냥 일반적인 Router)는 netid를 가지고 port를 결정하도록 구성되어 있고\n동일한netid를 가지는 내부망으로 들어왔을 때에는 주소 전체를 가지고 port번호를 결정하도록 구성 - 얘는 Gateway Router라는 놈이 담당하게 됨\n\nSubnetting §\n\n\n봐봐라\n위처럼 198.66.168.xxx의 netid를 할당받은 기관에서 Gateway router를 이용해 내부망에 대한 라우팅을 할때\n256개의 호스트를 전부 하나의 랜선에 연결해 들어오면 알아서 모든 호스트를 방문해 찾아가도록 하거나\n그냥 전부 router에 다 연결해놓고 router가 256개의 주소에 대한 port번호를 가지게 할 수도 있지만\n위 그림처럼 64개의 호스트별로 묶어서 0, 1, 2, 3의 포트번호를 할당하고 hostid의 범위에 따라 다른 포트번호로 나가게 하는 것이 더 효율적이더라\n그리고 데통때 배운거처럼 이렇게 하는게 근접해있는 호스트끼리 묶어 소그룹(뭐 부서라던지)별 routing을 하는 것이 정리정돈 하는데에도 더 좋다더라\n\n\n\n따라서 위와 같은 경우라면 Gateway router는 위의 그림과 같은 routing table을 가질 수 있다\n뭐 subnetting하는 방법은 데통때 배워서 알겠지만\n위의 예제에서 /26가 (1)26개와 (0)6개의 비트를 의미하는 거고 이것이 곧 subnet mask가 되어 위의 테이블에 subnet mask가 255.255.255.192로 설정되어 있는 거고\n패킷의 Dst Addr와 subnet mask를 bitwise AND해서 나온 결과(Network Address라고 표현한다)가 테이블 첫번째 열의 Destination Address와 같으면 테이블의 세번째 열의 Port number로 routing하는 방식이라는 거 기억해내면 끝임\n만약에 매치되는게 없을때에는 해당 내부망으로 들어오지 말고 다시 왔던길로 나가라는 의미에서 subnet mask 0.0.0.0에 destination address 0.0.0.0로 설정해 위에서 매치되지 않은 모든 address를 잡아내도록 되어 있고 이때의 port number가 들어왔던 포트번호인 4번으로 되어 있는 것이다\n그래서\nRouting table의 한 행을 Destination address / Subnet Mask 로 표현하되 된다는 것 - 뭐 192,66,168.128/26처럼\n그리고 Subnet mask를 구성할때는 연속된 1이 나오다가 0이 나오면 그때부터는 전부 0이 등장하는 방식으로 Subnet mask가 생성돼야 한다는 점\n/26일 경우에는 32 - 26 = 6이기 때문에 하나의 포트에는 64개의 호스트가 연결되고 마지막 8비트 중 첫 2개의 비트가 1이기 때문에 4개의 포트가 존재한다는 점등을 알아낼 수 있어야 한다.\n\n\n\n\n위의 예제도 기본적으로는 똑같다\nSubnet mask가 /24이기 때문에 한 포트에는 기본적으로 255개가 붙고\n168.188.12.xxx의 경우에는 0번 포트\n168.188.15.xxx의 경우에는 1번 포트\n168.188.128.xxx의 경우에는 2번 포트로 묶은 대신\n나머지의 168.188.xxx.xxx의 경우에는 /16으로 subnet mask를 설정해 다른 서브넷으로 빠져나가 인접한 기관에서 사용하는 등 활용할 수 있게 하는 예제이다\n뭐 별로 어려운건 없쥬?\n\n\n\n\n그리고 위의 예제처럼 하나의 router에 1024개를 붙이기 위해 /22의 subnet mask를 설정해 network address가 특정 destination address가 될때만 들어오고 아니면 나가게 할 수도 있다\n대신 위의 예제들과의 차이점은 하나의 Router에 여러개의 포트를 두어 각각의 포트로 빠져나가게 하는 것이 아닌 여러개의 router를 두고 각각의 router에는 포트를 하나만 두어서 분기하는것도 가능하다 이거야\n"},"originals/comnet.fall.2021.cse.cnu.ac.kr/05.-Routing-예시":{"title":"05. Routing 예시","links":[],"tags":[],"content":"\n\n                  \n                  충남대학교 컴퓨터공학과 김상하 교수님의 &quot;컴퓨터 네트워크&quot; 강의를 필기한 내용입니다. \n                  \n                \n\n\n\n                  \n                  다소 잘못된 내용과 구어적 표현 이 포함되어 있을 수 있습니다. \n                  \n                \n\nRouting 의 과정 예시 §\n기본 구조와 설정 §\n\n\n일단 위와 같은 구조로 되어있고\n\n\n\n내 컴퓨터에는 이렇게 설정이 되어있다고 해보자\n\n\n\n그럼 위와 같은 테이블이 생성이 된다 - 위의 테이블은 내 컴퓨터의 routing table이다\n일단 내가 IP주소는 168.188.129.51을 입력했고 서브넷 마스크는 255.255.255.0을 입력했으므로 이 둘을 bitwise AND한 결과인 168.188.129.0와 서브넷 마스크가 내 컴퓨터의 첫번째 행에 들어가게 된다\nIP주소와 서브넷 마스크를 설정하면 자동으로 해당 행이 완성이 되는데, 이말은 해당 Destination과 매핑되는 모든 IP는 내 컴퓨터와 직접적으로 연결되어 있다는 것을 뜻한다\n따라서 Gateway 열에 connected라고 표시 되는 것\n그리고 맨 아래줄인 Default은 내 컴퓨터와 직접적으로 연결되어 있지 않으니 라우터로 보내라는 의미가 된다\n\n즉, 입력한 기본 게이트웨이 값이 나랑 연결된 호스트가 아닐 경우에 패킷을 보내야 되는 IP주소가 되는 것\n기본 게이트웨이의 경우에는 G의 값을 가지는 flag가 붙게 된다\n\n\n따라서 나랑 연결된 놈이 아니라면 router로 보내야 하고, 위의 예제에서는 router의 IP주소가 168.188.129.1이므로 이 값을 기본 게이트웨이에 적어주게 되는 것이다.\n\n\n\n그리고 위의 예제에서 R_CE 라우터의 라우팅 테이블은 위와 같이 구성이 된다\n마스킹 결과가 128.0이면 0번 포트로 , 129면 1번 포트로, 140이면 2번 포트로 하되 해당 라우터가 관할하는 IP주소가 아닌 경우에는 다른 라우터로 보내기 위해 이때 보내야 할 라우터의 주소가 default에 들어가게 되는 것\n위의 예제에서는 빨간색 라우터로 보내야 되므로 빨간색 라우터의 IP주소인 168.188.140.2가 들어가있게 되는 것이다\n\n\n\n그리고 다른 서브넷에 있는 CE3와 CE4의 라우팅 테이블은 위처럼 구성이 되어 있다고 해보자\n\nRouting 과정 §\n\n\n일단 첫번째로 CE1이 CE2에게 보내려고 한다면 먼저 자신의 라우팅 테이블을 확인한다\n이후 수신지의 IP와 서브넷 마스크를 &amp;해 Destination을 알아오고, 매치된 Gateway를 확인하게 된다\nCE1에서 CE2로 보낼때 자신의 라우팅 테이블로 확인을 해보니까 Gateway가 connected로 나오므로 라우터를 거치지 않고 바로 보낼 수 있다는 것을 확인할 수 있다\n즉, Gateway가 connected인 경우에는 바로 보낼 수 있으니까 IP주소를 수신지의 IP주소로 하여 ARP를 보내고, 물리주소를 알아내어 바로 패킷을 쏘게 되는 것\n\n\n\n하지만 다른 서브넷에 있는 CE3과 CE4에게 보내는 과정은 한번에 갈 수 없으므로 몇가지의 절차를 밟게 된다\n일단 CE1에서 CE3으로 보내고 싶다고 해보자\n그럼 먼저 자신의 라우팅 테이블을 확인해 next hop의 IP를 알아온다\n다른 서브넷에 있기 때문에 당연히 라우팅 테이블에서 확인하면 Gateway가 connected가 아니라 flag G의 라우터 IP가 나오게 된다\n\n즉, 위의 예제에서는 168.188.129.1이 나오게 되는 것\n\n\n그러면 일단 라우터에게 보내야 된다는 것을 확인하게 되었으므로 라우터 IP에게 ARP를 날려 라우터의 물리주소를 알아온 후 전송을 하게 된다\n\n위의 예제에서는 168.188.129.1로 ARP를 날려 여기에 해당하는 물리주소를 알아온 후 보내게 되는 것\n\n\n여기서 주의할점은 나의 최종 목적지는 라우터가 아닌 다른 서브넷에 있는 호스트이므로 라우터의 IP를 패킷에 적는게 아니고 다른 호스트의 IP를 패킷에 적되, 라우터의 물리주소를 프레임에 적어야 된다는 점이다\n\n위의 예제에서 편의상 물리주소랑 노드 이름이랑 일치시킨다면\n송신지 물리주소 : CE1\n수신지 물리주소 : R_CE\n송신지 IP : 168.188.129.51\n수신지 IP : 168.188.128.30 - 168.188.129.1이 아니라는 것!\n\n\n그럼 이제 라우터가 패킷을 받고 자신의 라우팅 테이블을 이용해 next hop의 IP주소를 확인하고, 그쪽으로 ARP를 날려 물리주소를 확인하고 패킷을 전달하는 과정을 반복한다\n\n위의 예제에서는 패킷이 라우터에 도착했으니까 자신의 라우팅 테이블을 돌렸더니 168.188.128.30은 connected에 interface 0 이라고 뜨게 된다\n따라서 0번 포트에 연결되어있다는 것을 확인하고 0번 포트로 168.188.128.30에 대한 ARP를 날리고 물리주소를 받으면 패킷을 쏘게 되는 것\n\n\n저번 시험에서도 실수했듯이 반드시 기억할것은 패킷의 IP주소는 처음부터 끝까지 항상 동일하고 프레임의 물리주소는 hop2hop으로 건너갈때마다 계속 바뀐다는 것 항상 조심혀라\n\nSubnet mask가 잘못 설정되어 있을때 §\n\n\n윈도우에서 IP주소를 입력하면 서브넷 마스트가 자동으로 채워진다\n자동으로 채워지는 서브넷 마스크는 IP주소의 Class에 기반해서 채워지는 것으로, 이것으로 서브넷 마스크를 설정하게 되면 오작동할 수 있으므로 제대로 설정해 주는 것이 필요하다\n이게 왜그런지를 위의 예제를 가지고 설명하면\n255.255.0.0으로 서브넷 마스크가 설정이 되어 있으면 자신의 라우팅 테이블의 Destination 에는 168.188.0.0으로 들어가게 될 것이다\n그럼 실제로도 나랑 연결되어 있는 168.188.129.52같은 경우에는 잘 패킷이 전달된다 - AND연산 결과 168.188.0.0이므로 connected로 뜰 것이고, 따라서 같은 망 내에서 전송하려고 할 것이기 때문\n하지만 나랑 다른 서브넷에 있는 168.188.128.30의 경우에는 라우터로 간 다음에 다른 서브넷으로 가야되는데 그렇지 않고 이 경우에도 AND의 결과가 168.188.0.0으로 connected로 나오기 때문에 같은 망에서 전송을 하려 할 것이다\n하지만 ARP를 요청해도 해당 호스트가 여기 없기 때문에 답장이 안오고, 통신에 실패하게 된다\n즉, 다른 서브넷에 있는데 같은 서브넷에 있는것으로 판단해 잘못 ARP를 날려 물리주소를 받아오지 못하는 상황이 발생하기 때문\n하지만 완전 다른 netid를 가진 놈한테 보내는 경우에는 AND를 해도 라우터로 가라고 나와 라우터까지 정상적으로 가기 때문에 통신이 가능한 이상한 상황이 벌어지게 된다\n\nPC Router - Proxy ARP §\n\n\n\nProxy ARP는 실습시간에 죽어라 하고 있으니 간단맨하게 짚고 넘어가자고\n일단 위의 예시에서 기본 세팅은 다음과 같음\n\nR_CE의 경우에 0번 포트는 168.188.2.0/ 23이고 1번 포트는 168.188.4.0/ 23 이기 때문에 168.188.2.xxx와 168.188.3.xxx은 0번 포트에 묶이고 168.188.4.xxx와 168.188.5.xxx은 1번 포트에 묶이게 된다\n그리고 168.188.4.72에 붙어있는 우리의 PC Router는 168.188.5.0부터 168.188.5.63까지 64개의 호스트를 관할에 두고 있다\n또한 우리의 PC Router는 자신이 관할하는 호스트를 /28의 서브넷 마스크를 가지는 4개의 서브넷으로 나누어 묶어놓았다\n\n즉, 32 - 28 = 4이므로 서브넷 하나당 16개의 호스트가 묶여있는 셈\n위 그림에서 PC라우터의 라우팅 테이블을 보면 각각 서브넷의 Destination과 Subnet mask가 적절히 설정되어 있는 것을 볼 수 있음\n\n\n\n\n이제 우리의 PC Router에 묶여있는 놈이 패킷을 보내는 과정을 보자\n\n이 과정은 지금까지 배운거랑 동일하다\n\n\n먼저 자신의 라우팅 테이블을 확인해 ARP를 날려야 할 IP를 알아내고\n같은 서브넷이면 걍 ARP를 보낼 것이고, 다른 서브넷이면 라우터에게 ARP를 보내 물리주소를 받고 패킷을 보낼거임\n라우터로 온 패킷은 자신의 라우팅 테이블을 돌려 어케할지 결정하고 ARP날리고 보내고 ㅇㅈㄹ할거임\n\n\n근데 패킷을 받아오는 과정은 좀 다르다\n\n왜냐하면 PC Router에 묶여있는 놈은 R_CE와 직접적으로 연결되어있는 게 아니기 때문에 R_CE에서 ARP를 보내봤자 받지 못하기 때문\n따라서 PC Router에서 자신 관할의 호스트에게 ARP가 오면 자기가 대신 받아주기 위해 자신의 물리주소를 답장으로 보낸다\n그러면 R_CE가 PC Router에게 패킷을 보내게 되고 그 다음부턴 PC Router의 라우팅 테이블을 돌려 알아서 보내게 될거임\n\n\n\n좀 더 넓은 관점에서의 예시 §\n\n\n뭐 이것도 저번 학기에 한 예시이긴 한데\n위 예시를 읽는 방법은 간단하다\n일단 검은색 굵은 선은 호스트들이라고 생각하면 됨 - 즉, 130.10.0.0이라고 이름붙여져있는 검은 선은 130.10.0.xxx의 IP를 가진 호스트들이 모여있다고 생각하셈\n\n다만 주의할 점은 여기서는 Subnet mask가 명시되어있지 않는데 걍 /24라고 생각하셈\n\n\n그리고 라우터의 각각 포트에 IP주소가 할당되어 있는 것을 볼 수 있고\n라우팅 테이블을 읽는 방법은 다음과 같다\n일단 첫번째 행인 Dest는 너가 아는 그 Dest가 맞다\n세번째 행은 지금까지 보던 Next와 동일하다 - 다음에 패킷을 보내야 되는 IP를 나타낸 것\n그리고 두번째 행인 Hop은 몇번만에 해당 지점으로 갈 수 있냐를 나타내는 숫자임 - 보면 Next가 Connected인 경우에는 바로 갈 수 있으므로 Hop이 1이 되어 있고, 라우터를 한번 거텨서 가야되는 경우에는 2, 두번 거쳐야 되면 3 이런식이다\n이걸 토대로 그림 보면 구구절절 맞는얘기임\n"},"originals/comnet.fall.2021.cse.cnu.ac.kr/06.-IPv4,-IPv6":{"title":"06. IPv4, IPv6","links":[],"tags":[],"content":"\n\n                  \n                  충남대학교 컴퓨터공학과 김상하 교수님의 &quot;컴퓨터 네트워크&quot; 강의를 필기한 내용입니다. \n                  \n                \n\n\n\n                  \n                  다소 잘못된 내용과 구어적 표현 이 포함되어 있을 수 있습니다. \n                  \n                \n\nIP의 버전들 §\n\nv4가 나온 이후 v5와 v6가 나왔지만\nv5의 경우에는 OSI 7 Layer를 도입한 실험적인 모델이었고\nv6의 경우에는 v4에 밀려 잘 사용되지 않는댄다\n\nNetwork layer 작동과정 다른 예시 §\n\n\n위의 예시에서 주의해야 할 점은 Processing다음에 이어지는 패킷 구조에서 분홍색 박스이다\n위의 그림은 조금 잘못되어있는데, Network layer에서는 IP header에 해당하는 앞부분의 회색 헤더만 붙이게 되고, Router table을 이용해 알아낸 어느 Interface (Network card)로 나가야되는지의 정보는 뒤에 footer로 붙이는 것이 아닌, datalink layer한테 함수의 argument로 전달해주게 된다\n\n\n\n위의 그림은 host가 아닌 router의 작동원리에 대해 나타내는 것인데\n일단 Router의 경우에는 main()함수가 Network layer이기 때문에 상위계층이 더 없다\n그리고 마찬가지로 interface에 해당하는 저 분홍색 부분은 packet에 붙어서 하위 계층으로 전달되는 것이 아닌 argument의 형태로 전달된다\n또한 하위계층에서 상위계층을 function call하는 것이 아닌 상위계층에서 하위계층을 function call하고, packet은 return statement를 통해 상위계층으로 전달된다는 것 주의하덤둥\n\nDatagram §\n\n이전에 배웠다시피 IP의 경우에는 Datagram방식으로 packet switching을 한다\n이건 왜냐하면 Internet의 경우에는 전 세계에 걸쳐 연결되어 있는데 packet이 지나가는 network의 환경이 일정하지 않을 수 있기 때문에(이것을 Heterogeneous network라고 한다) Connection을 만드는 것은 불가능하기 때문\n\nIPv4 §\n\nTCP / IP protocol suite 가 인터넷인 거고 이걸 위한 패킷 전송 메커니즘이 IPv4인 것\nIPv4의 대표적인 특징은 다음과 같음\n\nConnectionless datagram protocol : 뭐 datagram방식을 이용한다는 소리고\nUnreliable, best-effort delivery service : 얘는 송신과정에서 에러가 날 수 있으나 최선을 다해 목적지까지 보내겠다는 뜻이다\n즉, 에러의 여부는 중요하지 않고 목적지까지 도달하는게 목적인 셈\n에러가 났을 경우 처리는 TCP에서 한다\n\n\n\nIPv4 datagram format §\n\n\nVER은 말그대로 IP버전을 말하는 것 - IPv4의 경우에는 4가 들어간다\nHLEN은 header length로, 4byte단위로 표현한다 - 위의 그림에서 한줄이 4byte이므로 저 한 줄이 몇개나 들어가있냐를 말하는 셈\n\n보통 물리계층에서 4byte단위로 전송이 이루어지기 때문에 4byte단위로 표현함\n그리고 중요한 것은 HLEN의 값은 무조건 5보다 커야 한다 - 즉, 헤더 길이가 20byte보다는 무조건 커야된다는 소리 - 이것보다 작은 경우에는 잘못된 것으로 판단하고 discard한다\n이건 왜냐하면 위 그림에서 흰색으로 표현된 5개의 층은 무조건 있어야 되고 여기에 추가적으로 Option이 들어갈 수 있기 때문\n만일 여기의 값이 8이어서 총 헤더의 길이가 32바이트가 된다면, 20바이트는 헤더에 꼭 필요하므로 나머지 12바이트가 Option의 길이가 되는 것이다\n\n\nTotal Length는 헤더를 포함한 패킷 하나의 전체 길이를 나타냄\n\n여기에 들어가는 값은 당연히 1바이트 단위이다 - 40이면 40바이트가 총 패킷의 길이가 되는 셈\nHLEN이란 Total length로 패킷 구조 도출해내는거 문제 나올거같다\n\n\nProtocol은 아래의 그림에서의 프로토콜을 나타냄\n\n\n\n즉, 상위계층의 프로토콜 중에서 어떤 프로토콜로 전송되었나를 나타내는 필드인 것\n딴건몰라도 6이 TCP인것 정도는 알고있으라\nID, Flag, Fragmentation offset의 경우에는 fragmentation을 위한 필드인데\n\n이것의 원리에 대해서는 설명하지 않고 fragmentation이 필요한 이유에 대해서만 좀 알고있으라\nfragmentation이 필요한 이유는 Datalink에서 회선의 종류에 따라 한번에 보낼 수 있는 데이터의 양이 정해지기 때문\n만일 광섬유같은 신뢰성이 높은 회선이라면, 에러가 잘 나지 않기 때문에 많은 양의 데이터를 한번에 보낼 수 있지만, 신뢰성이 낮은 회선의 경우에는 적은 양의 데이터를 보내야 한다 - 왜냐하면 에러가 많이 나는 회선에서 많은 데이터를 보내게 되면 에러가 났을 경우 그 많은 데이터를 다시 보내야 하고, 결과적으로 많은 오버헤드가 발생하게 됨\n따라서 회선에 따라 한번에 보낼 수 있는 데이터의 양이 정해지고, 만일 한번에 보낼 수 있는 데이터보다 더 많은 데이터가 들어오면 이것을 특정 크기로 잘라 여러번 송신하게 되는 것\n실습시간에 MTU(Maximum Transfer Unit) 으로 1500을 설정한 것이 이러한 이유에서다 - Ethernet의 경우에는 1500byte가 MTU이고, 따라서 이것보다 더 큰 데이터가 들어오면 해당 크기로 잘라 여러번 보내게 되는 것\n그리고 라우터에서 단편화된 패킷을 받으면 이것들을 전부 합친 다음 송신 회선의 MTU에 따라 새롭게 단편해 전송하게 된다 - 패킷을 잘라 송신하였으므로 수신할때는 이걸 다 합쳐야지 완성된 패킷이 되므로\n위와 같은 Fragmentation을 해주기 위한 필드가 바로 ID, Flag, Fragmentation offset인 것\n\n\nHeader checksum은 만일 상위 계층에서 Header에 대한 신뢰성 정보를 얻고싶을 때 사용한다 - Datalink에서 Error Detection / Correction처럼 IP에서도 Header에 한정해서 에러가 났는지 아닌지 확인하기 위한 용도\n\n왜 Header에 대해서만 에러를 판정하냐면 Network 계층에서는 Error detection보다는 패킷 전달에 목적이 있는데 만일 송수신 주소에 에러가 있으면 잘못된 주소로 패킷이 전달되기 때문에 Header에 대해서면 체크를 하게 되는 것\n하지만 IPv4에서는 잘 사용하지 않는 필드랜다\n\n\nTime to Live : 얘는 패킷이 네트워크에서 loop에 빠져서 계속 돌아다니거나 너무 먼 길을 돌아서 나중에 도착하는 것을 막기 위해 수명을 정해놓은 것이다\n\n최대 255까지의 값을 설정하여 하나의 hop을 지날때마다 1씩 감소시키고, 이 값이 0이 되면 수명을 다한것으로 판단하여 폐기하게 되는 구조\n\n\n\nOptions §\n\n\nNo operation\n\n\n\nHLEN을 적을 때 4바이트 단위로 적고, 물리계층에서 데이터를 송수신할때도 4바이트씩 병렬적으로 송수신하기 때문에 옵션들도 4바이트의 배수가 되께 하기 위해 넣어주는 일종의 패딩\n위의 그림처럼 7바이트의 옵션이 있으면 NO-OP를 하나 채워 8바이트를 만들어준다\nEnd of operation\n\n\n\n얘도 비슷한 이유이다 - 어떠한 이유에서든 마지막에 1바이트가 빌때 Option의 길이를 4바이트의 배수가 되게 하기 위해 넣어주는 것\nRecord Route : 패킷이 거처간 라우터들을 전부 기록한 옵션 - 어디에서 트래픽이 몰리는지 등을 체크하는데 도움이 된다\nStrict Source Route : Virtual circuit마냥 지나가야되는 Router를 전부 명확하게 명시해 해당 루트로 전송되게 하는 옵션\nLoose Source Route : 지나가야되는 Router를 명시하되 얘네들만 지나가는게 아니고 다른 라우터를 거쳐서 이 라우터만은 반드시 거쳐가야된다는 것을 명시하는 옵션\nTimestamp : 각각의 라우터를 지나가는데 걸린 프로세싱 시간 - 뭐 네트워크 관리 등을 하는데 중요한 정보가 된댄다\n\nIPv6 §\n\nIPv6혹은 IPng이라는 것은 두가지의 장점이 있다\n\n\n더 많은 주소 수용 가능 - 주소체계를 16바이트로 늘려 훨씬 더 많은 주소를 표현했고 따라서 IPv4에서의 2계층 구조(netid와 hostid)말고 더 계층을 세분화했댄다\nOn-demand hop-to-hop routing option : 얘는 IPv4에서처럼 option이 있지만 패킷의 모든 옵션을 다 꺼내봐야하는 IPv4와는 달리, 내가 봐야 하는 패킷만 볼 수 있고 따라서 더욱 빠르게 라우팅이 일어나게 된다는 것이다\n\n\n\n따라서 위처럼 반드시 가지고 있어야 하는 40byte - Base header와 추가적인 옵션 - Extension header으로 구성됨\n\nIPv4와의 차이점 §\n\n\nIPv4에 비해 바뀐 것을 간략하게 보면\nHLEN필드는 사라졌다 - 헤더의 길이가 40바이트로 고정이므로\nService type필드는 → Priority and Flow label필드로 변경되었고\nTotal length필드는 → Payload length필드로 변경되었고\nTTL필드는 → Hop limit필드로 변경되고\nProtocol필드는 → Next header필드의 Next Header Code로 변경되어 하나의 패킷에 여러개의 protocol에 대한 data가 저장될 수 있게 했고\nHeader checksum은 어차피 TCP같은 계층에서 수행하기 때문에 사라졌고\nOption필드는 → Extension header로 변경되었다더라\n\nExtension header §\n\n\n위와 같은 옵션들이 있음\n뭐 Pad1, PadN은 IPv4에서의 NO-OP나 End of OP같은 alignment을 맞춰주기 위한 헤더이고 - Pad1은 1바이트짜리 패딩, PadN은 n바이트짜리 패딩\n이 중에서 Source routing만 간략하게 보면\n\n\n\n위의 그림에서 검은색 굵은선 박스가 Source routing의 내용인데\nHELen은 뭐 Header extension length일거고\n그 아래 Left는 앞으로 몇개의 라우터를 더 거쳐야 되는지를 의미한다\n그리고 그 아래로 차례대로 가장 먼저 방문하게 되는 순서로 라우터릐 이름이 들어가게 된다\n진행과정은 다음과 같다\n\n패킷이 라우터에 도착하면 dst를 보고 자신이 맞는지 확인한다\n자신이 아니라면 routing table을 이용해 다음 목적지를 설정하여 보내면 되고 - 즉, base header만 보고 안꺼내봐도 될거같은 헤더는 꺼내보지 않는다 이거야\n만약 자신이 맞다면 그제서야 Source routing 에 있는 내용을 확인하게 된다\n\n즉, Source routing에 있는 내용은 항상 꺼내볼 필요가 없고 dst가 자신이 맞을때만 꺼내보는 것\n\n\n꺼내본 다음에는 자신의 주소를 Source routing에 적고 그 다음에 있는 라우터를 dst로 설정하여 송신하게 됨\n\n위 그림에서 보면 I1에 도달할때까지는 Source routing의 내용을 참조하지 않다가 I1에 도달하면 그때 열어보게 된다\n이후에는 I1를 Source routing에 적고 해당 위치에 있던 라우터를 dst로 하여 보내게 되는 것\n그럼 그 다음 라우터에 도달할때까지는 Source routing을 열어보지 않는 것을 반복하게 되는 것\n\n\n\n\n\n\n\n따라서 IPv6의 경우에는 위와 같은 헤더 구조를 갖게 되고\nNext header의 경우에는 다음과 같은 값을 가진다\n\n\n\n일단 Next header는 Next header code를 통해 뒤이어 나오는 옵션이 어떤 옵션에 속하는지 알려준다\n\nNext header code는 그리고 IPv4에서의 Protocol field처럼 어떤 상위 프로토콜에서 전송되었나를 표현하는 수단이 되기도 한다\n\n\n또한 Next header에는 다음 옵션에 대한 포인터가 저장되어 있어서 해당 헤더를 안봐도 되는 경우에 다음 옵션으로 손쉽게 넘어갈 수 있게 한다\nNext header의 작동과정은\n\n\n일단 Destination address가 라우터 자신의 주소와 같으면 Next header들을 전부 꺼내본다\n그리고 자신의 주소와 같지 않으면 Next header를 전부 꺼내보지 않고 필요한 Next header들만 꺼내보되\n자신의 주소와 같지 않을 경우에 Hop-by-hop option이 설정되어있는 경우에는 Next header를 전부 꺼내보게 된다\n\n\nHop-by-hop option이 모든 Next header들을 다 꺼내보라는 신호라고 생각하면 됨\n"},"originals/comnet.fall.2021.cse.cnu.ac.kr/07.-Address-mapping,-Multicasting,-Error-rep":{"title":"07. Address mapping, Multicasting, Error rep","links":["originals/datacommunication.spring.2021.cse.cnu.ac.kr/12.-Network-Layer,-Routing","originals/datacommunication.spring.2021.cse.cnu.ac.kr/13.-Routing","originals/comnet.fall.2021.cse.cnu.ac.kr/부록---실습자료-1)-Network-layer-&-ARP","originals/comnet.fall.2021.cse.cnu.ac.kr/부록---실습자료-2)-Proxy-ARP"],"tags":[],"content":"\n\n                  \n                  충남대학교 컴퓨터공학과 김상하 교수님의 &quot;컴퓨터 네트워크&quot; 강의를 필기한 내용입니다. \n                  \n                \n\n\n\n                  \n                  다소 잘못된 내용과 구어적 표현 이 포함되어 있을 수 있습니다. \n                  \n                \n\n개요 §\n\n\nARP와 RARP는 Logical address와 Physical address를 매핑하는 Address mapping에 관련된 부분이고\n\nRARP는 Application layer에 있는 BOOTP라는 놈과 연관이 있댄다\n\n\nIGMP는 Multicasting에 관한 부분\nICMP는 Error Reposting에 관한 부분이다 - 네트워크상에서 Congestion(혼잡현상)이나 어떤 다른 에러가 일어나는지 알려줌\n\nAddress mapping - ARP, RARP (+ BOOTP, DHCP) §\nARP §\n\n이미 다 배운내용이니 기억 안나면 이거 확인해라\nTwo levels of addressing : 12. Network Layer, Routing\nAddress Resolution Protocol : 13. Routing\nARP cache &amp; format : 부록 - 실습자료 1) Network layer &amp; ARP\nProxy ARP : 부록 - 실습자료 2) Proxy ARP\n아래는 생각해봄직한 예시들임\n\n\n\n위 그림은 뭐 간단맨함 - 시험에 ARP과정 적으라는거 나올거같으니까 함 쭉 읽어보고 각각 케이스가 어떻게 진행되는지 생각해보라\n\n\n\n예시인데 이 과정도 직접 패킷 구조 그림 그려가며 연습해라\n\nRARP §\n\n얘는 Reverse ARP로 물리주소(MAC 주소)를 알고있을 때 논리주소(IP 주소)를 알아내는 과정이다\nRARP는 BOOTP와 DHCP로 진화해 현재는 DHCP를 주로 사용하고 RARP는 구식이 됐다\n물리주소를 가지고 논리주소를 알아내야 되는 상황은 대표적으로 다음과 같다\nDiskless station의 경우\n\n얘는 자신한테 하드디스크가 없고 서버에게 원격접속하여 컴퓨팅을 하는 분산시스템이다\n이때 서버의 물리주소만 알고 얘의 논리주소는 모르기 때문에 알아와야 할 필요가 있는 것\nRARP와 BOOTP가 이러한 상황에 대처하기 위해 만들어졌다\n\n\n또한 현재의 IP는 IP주소의 고갈을 막기 위해 컴퓨터가 켜지면 IP주소를 빌려오고 컴퓨터가 꺼지면 IP주소를 반납하는 이런 대여시스템으로 작동하는데 이때 IP가 매번 달라지기 때문에 자신이 할당받은 논리주소를 자신의 물리주소를 통해 알아오는 과정이 필요하게 된다\n\n얘는 DHCP의 등장 배경이 된댄다\n\n\n\n작동과정 §\n\n\n위의 예시에는 BOOTP라고 적혀있지만 이 예시가 RARP의 작동과정이랑 동일하댄다\n작동과정은\n일단 요청하는놈(Client)와 응답하는놈(Server)가 있다 - Client는 그냥 일반 호스트이고, Server는 해당 서브넷에 추가적으로 설치되어있는 서버임 - Server는 모든 Client의 논리주소와 물리주소 쌍을 알고 있다\n그래서 Client가 물리주소를 가지고 논리주소를 요청하면 Server가 그에 맞는 논리주소를 응답해주는 아주 단순한 구조이다\n하지만 이러한 구조를 가지면 모든 서브넷마다 Server를 하나씩 설치해야되므로 아주 비효율적 - 이것을 해결하기 위해 BOOTP가 나왔다\n\nBOOTP §\n\n뒤에 다시 배운다\nRARP와의 차이점은\n일단 Server와 Client가 있는 것은 RARP와 동일하다\n다만 RARP는 해당 서브넷에 Server가 있어야 했지만, BOOTP의 경우에는 다른 곳에 하나만 있어도 된다는 차이점이 있고\n일단 BOOTP가 위치하는 Layer가 Application layer라는 것과\nUTP를 사용한다는 정도의 차이점이 있다\n작동과정은\n\n\n같은 서브넷에 Server가 있을 경우에는 그냥 RARP와 동일하다\n만일 다른 경우에는\n\n\n\n위의 그림처럼 서브넷에 Server가 아닌 Relay agent가 하나씩 있게 된다 - 얘는 BOOTP Server의 위치를 알고있는 놈임\n따라서 Client가 BOOTP Request를 Broadcast로 보내면 Relay agent가 받아서 Unicast로 BOOTP Server에게 보내 응답을 받아와 Client에게 전달해주는 방식으로 진행된다\n\n즉, Relay agent는 request를 datagram으로 encapsulate하여 BOOTP Server에게 Unicast하게 요청을 보내게 되고\nBOOTP Server는 encapsulated datagram을 받으면 그것에 대한 응답을 생성해 다시 encapsulate 하여 datagram으로 BOOTP Reply를 보내게 된다\n마지막으로 Relay agent가 응답을 받으면 BOOTP Client에게 응답을 보내는 방식으로 이루어진다\n\n\n\nDHCP §\n\nRARP와 BOOTP의 경우에는 논리주소와 물리주소가 1:1로 매핑되어 있고 바뀌지 않는다는 가정 하에 가능한 프로토콜이다\n\n즉, Deterministic binding이 되어있는 것\nDynamic configuration protocol이 아니다라고도 표현함 - 동적으로 알아낼 수 있는게 아니다 이거야\n\n\n하지만 현재에 사용되고 있는 IP는 논리주소가 네트워크에 접속할때마다 변경되기 때문에 새로운 프로토콜이 필요하게 되는 것이다\nDynamic Host Configuration Protocol(DHCP) 는 Static Address Allocation과 Dynamic Address Allocation을 모두 지원하는 방법이다\n우선, Static Address Allocation의 경우에는 BOOTP와 동일하게 작동한다 - 요청을 받으면, DB에서 상응하는 논리주소를 꺼내와 응답하고\nDynamic Address Allocation의 경우에는 안쓰는 논리주소를 하나 할당해서 응답해주고 임시적으로 값이 저장되는 또 다른 DB에 저장하게 된다\n결과적으로 다음과 같은 과정이 이루어진다\n\nRequest가 들어오면 일단 Static DB부터 확인한다\n그리고 Static DB에 있으면 그에 맞는 논리즈소를 응답한다\n만약 Static DB에 없으면, Available pool(아무도 사용하지 않고 있는 논리주소들의 모음)에서 하나를 꺼내서 응답하고\nDynamic DB에 추가한다\n\n\nBOOTP의 경우에는 DB를 변경하려면 Manually하게(관리자가 직접)해야 하는 단점이 있었지만\nDHCP의 경우에는 Static DB는 여전히 Manually하게 변경해야하지만 Dynamic DB은 Automatic하게 변경되게 된다\n\nError reporting : ICMP §\n\n일단 IP에는 Error reporting이랑 Error-correcting에 대한 기능이 없다 - 그래서 ICMP 프로토콜이 추가적으로 필요하게 되는 것\nInternet Control Message Protocol(ICMP) 는 IP패킷들이 지나가는 과정에서 발생할 수 있는 에러에 대해 Error reporting과 Error correcting을 해주며 관리하는 프로토콜이다\n네트워크상의 자원들을 관리하는 프로토콜은 또 따로 있고 여기서는 IP패킷이 지나가는 과정에서 일어날 수 있는 에러에만 초점 을 맞춘다\n즉, Network layer에 한정해서 일어날 수 있는 문제들을 관리하는 것\n얘가 보내는 메세지에는\nError reporting message : 실제로 IP 패킷이 지나갈때 발생할 수 있는 에러들을 알려줌\nQuery message : 이건 자신 옆에 있는 호스트에게 보내는 메세지로 내 옆에 있는 놈이 누구인가? 등을 물어볼 수 있는 기능이랜다\n\n\n\n뭐 위에 메세지 포맷은 그냥 참고만 해라\n\n\n\n이것도 뭐 참고만 해라\n\nIP Multicast : IGMP §\n\n일단 Multicast라는 것은 특정 다수에게 패킷을 보내는 방법이다\n뭐 Unicast가 특정 한명이고 Broadcast가 불특정 다수니까\n이걸 위해서는\n\n\n\n첫번째로는 위 그림처럼 메세지를 여러번 보내는 방법이 있다 - Multiple unicast라고 함\n\n\n\n그리고 메세지를 Broadcast하게 보내고 각 라우터를 지날때는 모든 Interface에 복사를 해서 보내는 식으로 보든 호스트한테 다 보내되, 수신측에서 필터링하는 방법도 있다\n\n\n\n하지만 특별한 Multicast strategy를 이용하면 위처럼 원하는애들한테만 골라서 보낼 수 있게 된다\n이 방법을 고안해야 되는 이유는 다음과 같다\n\nMultiple unicast의 경우에는 수가 많은 경우 너무 많은 패킷을 보내야 돼 병목현상이 일어날 수 있고\nBroadcast의 경우에는 원치 않은 애한테도 도달은 하게 된다는 문제가 있기 때문이다\n\n\n일단 여기서 알아야 할 것은 Router 간 통신에는 Multicasting Protocol이라는 것을 사용하고\nRouter와 Host간 통신에는 **Internet Group Management Protocol(IGMP)**를 사용한다는 것을 알아한다 - 프로토콜이 구분되어 있다는 것\n\n이건 왜냐하면 첫번째로는 통신의 특성이 다르기 때문 - Router와 Host의 통신에는 한번 보내면 다 퍼지지만 Router와 Router의 통신은 여러 대상에게 보내기 위해서는 여러번 보내야 하기 때문\n두번째로는 Router와 Host와는 다르게 Router와 Router의 통신은 Network 사업자의 영역이기 때문에 다른 프로토콜을 사용하게 된다 - 뭐 datagram과 virtual circuit할때 사업자랑 고객이랑 다른 프로토콜을 사용했던 것과 같은 이유\n\n\nMulticasting Protocol은 나중에 배운댄다\n\n구조 §\n\n\n뭐 이것도 참고만 하면 된다\n다만 라우터가 주기적으로 Group에 참여하고 싶은 호스트들을 Query의 형태로 설문받는데\nMembership report는 Group에 참여하고 싶음을 알리는 메세지이고\nLeave report는 Group에서 빠지고 싶음을 알리는 메세지이다\n\n\n\n얘도 그냥 참고만\n\nIGMP Operation §\n\n먼저 Group과 Group ID의 개념을 좀 알 필요가 있음\n\n예를 들어서 설명하는게 젤 이해 잘되는듯 - Group은 무도를 보는 가구의 집합이고 Group ID는 무도의 채널번호라고 대략적으로 감 잡으면 된다\n따라서 어떤 가구(호스트)하나가 무도를 보고싶으면 (Group에 속하고 싶으면) 지역 기지국에서 (Router 에서) 보고싶은 채널 설문 조사를 했을 때(General query를 날렸을 때) 설문 응답에 무도를 적어 (Membership report를 하여) 무도를 우리 지역에도 틀어달라고 요청할 수 있다 (Group에 속할 수 있다)\n그룹에서 빠져나올때는 지역 기지국에(Router에) 연락해(Leave report를 하여) 무도를 그만 틀어달라고 요청할 수 있는 것(Group에서 나올 수 있는 것)\n\n그러면 기지국은(Router는) 제공 채널 목록에서 (Group id list에서) 바로 지우는 것이 아니라 다른 가구들의 의견을 물어보고 결정하게 된다(Group id를 포함하여 Special query를 날려 Membership report를 추가적으로 받는다 - 특정 기간동안 기다려도 아무도 Membership report를 하지 않으면 지우지만 누군가가 보내게 되면 지우지 않고 냅두게 되는 것)\n이 과정은 Monitoring membership이라고 한다\n\n\n그래서 Group ID는 Multicast Address라고도 하는데 이제 라우터한테 해당 **Group ID(Multicast Address)**로 패킷이 도착하면 라우터에 속한 호스트들에게 뿌려주게 되는 것\n위 과정을 유심히 보면 가구 하나가 무도를 신청했으면 다른 가구는 추가적으로 신청하지 않아도 무도를 틀어서 볼 수 있다 - 즉, 호스트 하나가 라우터에게 Membership report를 날렸으면 Multicast packet이 도착했을 때 라우터가 뿌려주게 될 것이므로 다른 호스트들은 Membership report를 날릴 필요가 없이 그냥 받아 보기만 하면 되는 것 - 추가적으로 Membership report를 할 필요가 없다\n\n\n그리고 Multicast router라는 놈에 대해서도 이해를 해야 한다\n얘의 역할은 Multicast packet을 뿌려주는 역할을 하는 라우터인데\n여기서 중요한 것은 Multicast router의 갯수는 네트워크당 여러개가 될 수 있지만 각각 Multicast router에 배정된 group id 리스트는 배타적이어야 된다는 것이다\n이건 왜냐하면 만일 호스트가 하나의 Multicast router에만 연결되어있으면 걔가 모든 Multicast packet을 처리하면 되지만, 여러개의 Multicast router에 연결되어 있을 때 Group id 리스트가 배타적이지 않다면, 교집합에 해당하는 그것에 대한 Multicast packet은 여러개의 Multicast router에서 호스트로 보내기 때문에 호스트가 여러번 받게 되는것 - 비효율적이더라\n\n\n\n그래서 위 그림이 예시임\nA, B, Z는 라우터 R, R1, R2에 연결되어있고 이중에 R이 Multicast router로 역할을 하고 있다\n그리고 R에는 저렇게 Group ID(Multicast Address) List가 있어서 해당 GID로 Multicast packet이 도착하면 R이 패킷을 뿌려주게 되는 것\n\nDelayed response strategy §\n\n\n위에서 한 얘기를 좀 더 구체적인 과정으로 보여준거긴 한데\nMembership report를 한번만 보낼 수 있도록 하는 알고리즘 인 셈\nR에서 General query를 날린 시점이 0초라고 하자\n그럼 각각의 호스트는 General query를 받은 시점으로부터 자기가 원하는 GID 각각에 대해 난수를 하나 뽑아서 타이머를 설정해 놓는다\n\n위의 그림에서 Timer에 해당하는 숫자가 바로 그것임\n\n\n그리고 타이머가 종료되면 해당 GID에 대해 Membership report를 보내게 되고\n해당 GID에 대해 Membership report를 보내려고 했던 다른 호스트는 자기보다 먼저 타이머가 종료되어 Membership report를 보낸 놈이 있다는 것을 알고 타이머가 종료되어도 안보내게 된다\n\n위의 그림에서는 228.42.0.0에 대한 Membership report는 A가 12초 뒤에 타이머가 끝나므로 보내게 된다\n그럼 B의 경우에는 48초이므로 아직 36초가 남은 상황이겠제\n근데 B는 A가 먼저 보낸 것을 알고 228.42.0.0에 대한 Membership report를 타이머가 종료되어도 보내지 않게 된다(보내야 하는 Membership report 목록에서 지우게 됨)\n마찬가지로 225.14.0.0의 경우에도 A가 먼저 끝나므로 C는 보내지 않고\n230.43.0.0의 경우에도 C가 먼저 끝나므로 A는 보내지 않는 식\nMembership report 보내지는 순서 뭐 이런거 시험에 나올 수 있을듯 - ppt 50페이지 근처 예제 풀어볼것\n\n\n그리고 Query router라는 놈도 있는데 이놈은 Query를 보내게 되면 다량의 Response를 받게 되므로 Query를 보내는 라우터를 따로 하나 지정하고, 나머지 라우터들은 Response를 처리하는 식으로 역할 분담을 해 병목형상을 막는다\n"},"originals/comnet.fall.2021.cse.cnu.ac.kr/08.-Transport-Layer-&-UDP":{"title":"08. Transport Layer & UDP","links":[],"tags":[],"content":"\n\n                  \n                  충남대학교 컴퓨터공학과 김상하 교수님의 &quot;컴퓨터 네트워크&quot; 강의를 필기한 내용입니다. \n                  \n                \n\n\n\n                  \n                  다소 잘못된 내용과 구어적 표현 이 포함되어 있을 수 있습니다. \n                  \n                \n\nTransport Layer §\n\n\n위 그림에서처럼\n호스트한테 도착한 이후, 호스트 내의 특정 프로세스로 데이터를 전달하기 위한 계층이 Transport layer이다\n\n\n\n이것을 위해선 Port address가 있어 특정 port address로 데이터를 전송해 올바른 프로세스로 찾아가게 한다\n즉, Process-to-Process Delivery를 위한 계층이 Transport layer인 셈\n종류로는 UDP, TCP, SCTP가 있고 이중에 TCP가 제일 유명하지만 UDP나 SCTP를 사용할 수도 있댄다\n\nProcess-to-Process Delivery §\n\n일단 용어정리를 좀 하면\nIP주소가 A인 Host의 port a가 IP주소가 P인 Host의 port j로 보내면\nLocal host는 A이고 Remote host는 P이다 - Local host와 Remote host에서 host는 IP를 뜻하는 말임\nLocal process는 a이고 Remote process는 j이다 - Local process와 Remote process에서 process는 port를 뜻하는 거더라\n\nClient-server model §\n\n데이터를 받는 상대방의 port는 어떻게 알아내냐는 궁금증에 생기게 되는데\n상대방의 port를 알아내는 방법으로 Client-server model을 사용하게 된다\n일단 Client는 통신을 시작하는 쪽, 먼저 요청하는 놈 - Initiator이라고 생각하면 된다\n\n일반적으로는 서비스를 요청하는놈이라고 생각해도 되지만 특별한 경우에는 서비스를 제공해주는 놈이 통신을 시작하기도 하더라\n\n\n그리고 Server는 Client의 통신 / 요청에 대해 응답하는놈 - Responser이 된다\n이때 Client-server model에서는 Server의 port를 이미 잘 알려진 값인 well-known port를 사용한다\n\n뭐 알다시피 http의 경우에는 80을 사용하쥬\n\n\n즉, Server가 well known port를 사용하기 때문에 통신을 시작하는 쪽인 Client는 Server의 port번호를 알 수 밖에 없다\n따라서 Client가 well known port로 보내게 되면 Server는 그것을 받고 Client의 port번호를 알아낼 수 있기 때문에 정상적인 응답을 보내줄 수 있는 것\n\n\n\n위에가 예신데\n보다시피 Daytime 이라는 프로토콜에서는 Server가 13이라는 Well-known port를 이용하고\n클라이언트는 이걸 알기 때문에 자신의 임시 port인 52000을 실어 보내면 Server가 알게 되는 것\n클라이언트의 port는 임시적인거고 프로세스가 죽으면 다른 프로세스에게로 할당될 수 있다 - Ephemeral local port number라고 하더라\n그리고 MAC, IP주소와 마찬가지로 port번호도 다른 계층에서 알 수 없는 것은 아니다 - port번호가 패킷에 담기는 자료구조를 모르는 것\n\n일례로 IP주소가 Transport계층을 넘어 Application까지 넘어가는 경우가 있고 port라는 것도 Transport의 상위계층에서 넘겨주는 값이다\n\n\n\nAddress System §\nPort Number §\n\n\nIANA라는 기관에서 port번호를 정하는 규칙을 만들어놨댄다\n보면 0~1024까지는 well-known\n1024~49151까지는 Registered라고 해서 나중에 쓸 목적으로 비워둔 곳\n49152~65535는 프로세스가 임시로 할당받게 되는 값이다\n\nSocket Address §\n\n\nIP와 Port를 합친 주소를 Socket Address라고 한다\n얘는 Application Layer에서 사용하는 주소 중 하나로 다른 계층의 주소를 사용할 수 있다는 것을 보여주는 또 다른 사례인 것\n\nMultiplexer, Demultiplexer §\n\n\nProcess들에게서 전달받은 데이터를 취합하여 IP로 보내는 Multiplexer와\n받은 데이터를 다시 나눠 각각의 Process들에게 뿌려주는 Demultiplexer가 있댄다\n\nConnection, Reliable §\nConnectionless vs Connection-oriented §\n\n일단 앞에서 배운것처럼 Connection이라는 것은 데이터가 보내진 순서대로 도착하느냐 아니냐에 따라 나눠진다\nConnectionless는 순서가 바뀌든 중간에 유실되든 상관 없이 전송되는 것을 의미 - UDP가 여기에 해당한다\n그리고 Connection-Oriented는 순서가 바뀌면 안되고 보낸 순서대로 도착해야되는 것 - TCP과 SCTP가 여기에 해당한다\nConnection-Oriented는 다음과 같이 작동함\n\n일단 한놈이 Connection-Oriented하게 통신하자고 메세지를 보냄\n그럼 그걸 받은놈은 버퍼를 준비하고 준비됐다고 답장을 보냄\n통신시작하는쪽은 버퍼를 준비하며 알았다고 메세지를 보낸 뒤 데이터들을 보낼 순서대로 Numbering을 한다 - 순번을 다 적어놓는 셈\n그리고 이걸 보내게 되면\n받는쪽은 그걸 받아서 바로 Application Layer로 올리는게 아니고 일단 버퍼에 저장해둔다\n그리고 데이터가 다 도착하면 그제서야 버퍼에 있는 데이터들의 순번을 보고 순서대로 Application Layer로 올려보내게 됨\n\n\n그렇다고 Connectionless라고 해서 순서를 아예 무시하는건 아닐 수도 있다 - Transport계층에게 그걸 맡기지 않는다는 거지 Application Layer에서 자체적으로 하는 경우도 있다더라\n\nReliable vs Unreliable §\n\n일단 Reliable은 다음과 같은 에러가 없을때를 지칭하는 말이다\n\nFlow Control Error : 수신속도보다 송신속도가 더 빨라 Overwrite되는 경우\nPhysical Error : 노이즈가 끼는 경우\nTCP, SCTP가 여기 해당함\n\n\n당연히 Unreliable은 이러한 에러가 있을 수도 있을 때를 말하는 거겠지\n\nUDP가 여기 해당함\n\n\n이것도 마찬가지로 Unreliable하다고 에러를 무시할 수도 있지만 그렇지 않을 수도 있다 - Application Layer에서 자체적으로 하는 경우도 있다 이거야\n근데 Data link layer에서 이런 것들을 해주는데 왜 Transport 계층에서도 하는지 의문이 들 수 있는데\n그건 아래 예시 보면 알 수 있음\n\n\n\n보면 일단 분홍색 선으로 표시된 부분에는 Data link layer의 활약으로 에러가 없음\n근데 위 그림에서 검은색 선으로 표시된 부분에서 에러가 날 수 있다\n이건 왜냐하면 Router에서는 Incoming queue에서 Outgoing queue로 패킷을 옮겨야 하는데 이 queue의 크기가 무한한게 아니기 때문에 패킷이 많이 쌓여 공간이 부족하게 되어 에러가 남\n이런걸 Queue overflow by congestion, False Flow Control이라고 하더라\n\nUDP §\n\nUser Datagram Protocol(UDP) 는\nIP에 Port를 추가해 Process-to-Process 기능만 덧붙이고 나머지는 아무것도 하지 않는 프로토콜이다\n당연히 Process로 연결해주는것 외에는 아무것도 하지 않기 때문에 Connectionless, Unreliable하다\n\n\n\nUDP에서 사용하는 Well-known port 들임 - 참고만 혀\n\n\n\n헤더의 구조는 위와 같다 - 단순\n근데 Total length는 굳이 필요 없다 - IP헤더의 total length부분에서 hlen을 빼면 구할 수 있기 때문에\n하지만 Transport 계층의 정보를 얻기 위해 IP계층에 물어보는 것은 약간 자존심상해서 만들어놨댄다\n\n구조 §\n\n\n위 그림처럼 port 하나가 열리면 UDP에서는 Application과 데이터를 주고받을 Incoming queue와 Outgoing queue가 열린다\n근데 이때 서버에서는 여러 Client로부터 데이터를 받기 때문에 Incoming queue를 하나만 사용하면 데이터가 어디에서 온 건지 알수 없게 되는데\n\n왜 알수 없냐면 Application layer로 올라갈때는 Header가 제거되기 때문\n\n\n그래서 UDP에서 Application으로 올릴때 Header를 뗀 Data뿐 아니라 Socket Address도 같이 주어 이놈이 어디에서 와서 어디로 가야되는지 Application layer로 보내준다\n"},"originals/comnet.fall.2021.cse.cnu.ac.kr/09.-TCP":{"title":"09. TCP","links":["originals/datacommunication.spring.2021.cse.cnu.ac.kr/06.-ARQ-Protocol,-HDLC"],"tags":[],"content":"\n\n                  \n                  충남대학교 컴퓨터공학과 김상하 교수님의 &quot;컴퓨터 네트워크&quot; 강의를 필기한 내용입니다. \n                  \n                \n\n\n\n                  \n                  다소 잘못된 내용과 구어적 표현 이 포함되어 있을 수 있습니다. \n                  \n                \n\nTCP Services §\nProcess-to-Process Communication §\n\n일단 뭐 Process-to-Process Deilivery를 지원하기 위한 port number를 사용하니까 Client-Server Model을 사용한다\n\nTCP에서 사용하는 well know port는 80은 http, 53은 DNS라는것 정도는 알고 있어라\n\n\n\nStream Delivery Service §\n\n\n그리고 TCP에서는 Stream Delivery Service라는 것을 사용하는데 이게 뭐냐면\nUDP같은 경우에는 Application Layer로부터 내려온 데이터를 하나의 데이터그램으로 만들어서 보낸다\n\n이걸 내용적으로 의미있는 단위로 데이터그램을 전송한다하고 표현함\n\n\n하지만 TCP는 이렇게 하지 않고\nApplication Layer로부터 내려온 데이터들을 버퍼에 모았다가 버퍼가 일정 수준 쌓이면 그때 보내게 된다\n\n즉, UDP처럼 내용으로 구분해서 전송하는게 아니고\n버퍼에 쌓인 데이터의 크기로 구분해서 보내게 되는 것\n따라서 여러개의 데이터가 하나의 단위로 묶여서 보내질 수도 있고 Application Layer에서 내려온 데이터가 많은 경우에는 얘네들을 잘라서 보내기도 하고 이런식이더라\n뭐 예를들어서 Application Layer에서 두 프로세스가 각각 5byte, 1500byte의 데이터를 줬다면\nUCP의 경우에는 5byte, 1500byte로 전송을 하겠지만\nTCP의 경우에는 1000byte, 505byte로 전송을 한다 이말임\n\n\n이렇게 하는 것의 장점은 항상 비슷한 크기의 많은 데이터를 송수신하게 된다는 것이다\n\n이게 왜 장점이 되냐면\n데이터를 보낼때는 그것만 보내는게 아니고 여러 계층의 헤더를 붙여서 보내기 때문에 한번 보낼때 최대한 많은 데이터를 보내는게 효율적이기 때문\n만일 Header를 다 합쳤을때 100바이트라면 UDP같은 경우에는 메시지가 5byte와 800byte두개가 들어오면 105byte, 900 byte 두번이 전송되지만\nTCP같은 경우에는 얘네들을 합쳐서 보내기 때문에 905byte 한번만 전송하게 된다\n\n\n그리고 알아두어야할 게 Port별로 버퍼가 생성된다 - 어차피 Port들을 Multiplexing과 Demultiplexing을 다 하기 때문에 Port가 합쳐지는 것에 대한 생각은 하지 말고 Process-to-Process의 관점에서만 생각하면 된다\n\n\n\n그리고 TCP는 Reliable한 전송을 보장하기 때문에 송수신 속도 차이에 따른 Flow error를 방지하고자 송수신측 모두 버퍼를 둔다\n그래서 위 그림처럼 송수신측 모두 넉넉하게 버퍼를 준비해놓고 Sending process가 송신 버퍼에 쓰면 그걸 순차적으로 보내게 되고 받는쪽에서도 데이터를 받아 수신 버퍼에 쓰면 그걸 Receiving process가 가져가게 되는 구조\n버퍼가 없다면 아직 보내지도 않았는데 Sending process가 데이터를 줘 Overwrite된다거나 수신측에서도 Receiving Process가 가져가지도 않았는데 데이터가 수신되어 Overwrite되는 일이 벌어지게 되는 것\n\n\n\n위 내용을 종합해보면 위와 같은 그림으로 표현할 수 있다\n송수신 속도 차이에 따른 Flow error를 막기 위해 송수신 버퍼가 존재하고\nMessage별로 데이터를 보내는게 아닌 일정 수준 크기로 데이터들을 뭉쳐 Segment라는 단위로 보내게 된다\n\nFull-duplex Communication §\n\nFull-duplex communication은 TCP가 양방향 통신을 지원한다는 의미이다\n\nConnection Oriented Service §\n\n이전에 배운거처럼 TCP는 orderly delivery를 지원한다\n그래서 일단 Connect Phase를 거치고 - 전송을 이제 시작할 것이니 송수신측 모두 버퍼를 준비해라 + 송신할 데이터에 numbering을 하여 순서대로 도착하지 않아도 수신측에서 number를 보고 정렬하여 상위계층으로 보낼 수 있도록\n그리고 데이터를 송수신한 후 Disconnect Phase를 거쳐 준비한 버퍼를 삭제해 다른 통신에서도 사용할 수 있도록 함\n\nReliable Service §\n\nTCP는 Reliable Communication을 지원한다 - Flow &amp; Error Control을 하여 이러한 문제가 생기지 않도록 함\n\nNumbering System of TCP §\n\n일단 TCP에서 Numbering 하는 데에 중요한 것은 번호가 Segment별로 붙는게 아니라는 점이다\n\n이게 무슨말이냐면 위에서 TCP에서의 전송 단위가 Segment라고 했는데 첫번째 보내는 Segment는 0번, 두번째 보내는 Segment는 1번 이런식으로 숫자를 붙이지 않는다는 것 이다\n그럼 뭐 어떻게 하느냐\nByte 별로 번호를 붙이는 시스템을 이용한다\n이걸 위해 두개의 필드가 헤더에 들어감 - Sequence Number하고 Acknowledge Number\n얘네들은 Data link layer에서의 SEQ랑 ACK 번호랑 동일한 기능을 하는데 대신 번호를 매기는 단위가 Frame(Segment)가 아닌 바이트인 차이점이 있다\n따라서 Sequence Number는 데이터의 첫번째 바이트에 붙는 번호이다\n여기서 주의할 점은 Sequence Number는 0번부터 시작하지 않을 수도 있다는 점 - 0 ~ 2^31 - 1의 숫자 중 하나를 랜덤으로 골라 번호를 붙이게 된다\n그리고 첫번째를 이렇게 붙이고 그 다음 바이트부터 1씩 증가하다가 2^31 - 1을 넘어가면 다시 0번으로 돌아와서 번호가 붙는 셈\n당연히 Numbering이 이런식으로 된다는 거지 실제 Segment에는 첫번째 바이트의 Number인 Sequence number밖에 저장되지 않는다\n그리고 Acknowledge Number는 Data link layer에서와 동일하게 이전까지는 잘 받았고 이제 이거를 보내달라는 의미가 된다\n뒤에서 실제 예시를 보면 으케되는지 더 잘 알 수 있을거임\n\n\n이런식으로 Byte-oriented Numbering System을 이용하기 때문에 Flow control과 Error control도 byte-oriented하게 이루어진다\n뒤에 가서 어떻게 하는지 알려준댄다\n\nSegment §\n\n\n이게 Segment의 Header구조이다\n위에서 언급 안한것만 살펴보면\nHLEN은 헤더의 크기이다 - 근데 이것도 IP헤더랑 비슷하게 4-byte단위로 표시함 - 즉, HLEN이 1이면 헤더가 4바이트라는 거고 HLEN의 최대 크기가 15이기 때문에 최대 헤더의 크기는 60byte인데 Option and Padding을 제외한 필수적인 부분이 20byte이기 때문에 Option and Padding부분은 40byte 이내로 상황에 맞게 들어가게 된다\nReserved는 나중을 위해 비워둔 부분이고\n주황색으로 표시된 Control이라고 불리는 Flag들은 Connection을 위해 있는 부분\nWindow Size는 Flow Control을 위해 존재하는 부분\nUrgent Pointer는 뒤에서 배운댄다\nChecksum은 Error control을 위해 존재하는 부분이랜다\n\nA TCP Connection §\n\nTraffic이 막힌다던지 아니면 에러가 있어서 재전송을 하게 되는 등 전송의 순서가 바뀌게 되는 경우는 많다\n그럼에도 불구하고 순서대로 데이터를 합치기 위해 Connection이 반드시 필요하게 됨\nConnect → Data Transfer → Disconnect 순서로 수행된다\n\nConnection Establishment Phase - Three way handshake §\n\n일단 Connection단계에서는 Three way handshake라는 방식으로 Connection Establish를 하게 된다\n이게뭐냐면\n일단 Client가 통신하자고 Server에게 보내면 Server는 ㅇㅋ라고 하고 마지막으로 Client가 한번 더 확인차 ㅇㅋ라고 보내는 것\n저렇게 세번 통신을 하여 Connection이 이루어지므로 Three way handshake인 것\n\n\n\n\n위 그림 두개를 같이 봐야 한다\nState Diagram을 볼 때는 점선 화살표가 Server, 실선 화살표가 Client인 것을 기억혀\n그리고 edge에 붙어있는 라벨을 읽을 때 A/B이면 내가 지금 A를 했거나 A를 받은거고 그 다음에 B를 했다는 식으로 이해하면 됨\n보면\n\n\nClient가 Active open을 하고 Server한테 첫번째 악수를 날린다\n\nActive open인 이유는 Client는 통신을 시작하는 주체이기 때문 - 적극적이다!\n첫번째 악수를 날릴 때는 Control Flag의 SYN부분을 1로 만들어서 보낸다\n그래서 저기 State Diagram에서 보면 Client는 Active open/SYN을 한 후에SYN-SENT상태에 진입하게 된다\n\n\n그러면 Server는 Passive open을 하고 기다리다가 SYN을 받으면 Client에게 두번째 악수를 날린다\n\nPassive open인 이유는 당연히 Server는 Client가 통신을 시작해야만 시작할 수 있으므로 수동적으로 통신을 열게 되는 것임\n그리고 두번째 악수를 날릴 때는 Control Flag의 SYN부분과 ACK부분을 1로 만들어서 보낸다\n그래서 State Diagram에서도 Server는 일단 **Passive open/-**이므로 수동적 통신 개시를 한 후에 LISTEN상태에서 기다리고 있다가\nSYN/SYN + ACK을 한 후에 SYN-RCVD상태에 들어가게 된다\n\n\n마지막으로 Client가 SYN + ACK를 받으면 세번째 악수를 날리며 Connection이 Establish된다\n\n세번째 악수에서는 Client가 ACK하나만 올려서 보낸다\n그럼 Server쪽에서는 ACK를 받았으므로 Connection establish를 하게 된다\n그래서 Client쪽의 State Diagram을 보면 SYN + ACK/ACK을 하고 ESTABLISH상태로 가고\nServer쪽의 State Diagram을 봐도 **ACK/-**를 하고 ESTABLISH상태로 가게 된다\n\n\n\n\n그리고 여기서 Sequence Number하고 Acknowledge Number를 좀 유심히 봐야 하는데\n\n첫번째 악수에서는 Client가 8000번이라는 난수를 보냄 - 처음으로 보낼때는 SEQ 에 그냥 난수를 하나 보내게 된다\n두번째 악수에서는 Server가 SEQ 15000에 ACK로 8001번을 보내는 것을 알 수 있다\n15000은 당연히 처음 보내는 것이기 때문에 난수이고\nACK가 8001이 되는 이유는 처음에 Client가 보낸 SEQ가 8000번이었으므로 이것을 잘 받았고 8001번을 나는 원한다는 뜻이 되는 거임\n즉, ACK로 n을 받았으면 n - 1까지는 잘 받았고 이제 n을 보내주세요 라는 의미로 이해하면 된다\n그리고 세번째 악수를 보면 Client가 여전히 8000을 보내고 ACK는 15001을 보낸다\n뭐 ACK가 15001인 이유는 Server가 SEQ15000를 보냈기 때문이고\nSEQ가 8000인 이유는 데이터를 보내기 위한 Segment가 아니기 때문이다\n즉, 상대방의 ACK에 부응하여 그에 맞는 데이터를 보낼때는 상대방이 준 ACK를 SEQ에 넣어 데이터도 그에 맞는 것을 주지만 상대방에게 데이터를 보내는게 아닐때에는 SEQ로 ACK - 1을 주게 되는거 같음\n그리고 ACK도 그냥 기계적으로 생각하면 편하다 - 상대방이 준 Segment를 잘 받았으면 그냥 그 다음거를 받기 원하는 거임\n\n\n그리고 Control Flag에 대해서도 좀 정리를 해보면 SYN은 Connection을 하자는 의미인 거고 ACK는 방금 보낸 것을 잘 받았다는 의미인거다\n\n따라서 첫번째 악수에는 Connection을 할건데 이전에 상대방이 보낸 것은 없으니까 SYN하나만 올라가있게 되는 것이고\n두번째 악수는 Connection을 할거고 이전에 보낸 것을 잘 받았으니까 SYN과 ACK다 올라가 있는 것이다\n그리고 세번째 악수는 Connection하자는 답변을 받았으므로 굳이 SYN을 올리지 않고 그냥 방금 니가 보낸거 잘 받았소 의 느낌으로 ACK하나만 올리게 되는 것\n\n\n\nData Transfer §\n\n\n위의 예시에서 먼저 SEQ와 ACK를 보면\n\n이제 데이터를 보낼꺼니까 상대방이 준 ACK를 반영해 SEQ에 8001을 넣어 데이터를 보내게 된다\n그리고 방금 상대방이 준 것을 잘 받았고 이제 이걸 원한다는 의미로 ACK를 15001로 설정하는 것\n여기서 데이터를 보내는데 ACK도 같이 보내는 이유는 TCP는 Full-duplex communication을 지원하므로 이런식으로 piggybacking을 할 수 있다는 것을 보여주기 위한 것 이다\n즉, 데이터를 보냄과 동시에 ACK도 같이 보내 상대방도 ACK에 맞는 데이터를 보낼 수 있고 이런식으로 양방향 통신이 이루어지는 셈 - 이게 piggybacking인데 기억나시쥬?\n위의 통신에서 두세번째를 보면 알 수 있다 - 두번째에서 방금 9000번까지 보냈으니까 이제 입벌려9001들어간다 느낌으로 SEQ 9001을 설정하고, 데이터와 함께 ACK 15001을 보내면\n세번째에서 상대방은 그에 맞게 SEQ를 15001로 하여 자신도 데이터를 보내고 두번째에서 줬던 데이터를 잘 받았고 이제 10001을 원한다는 의미로 ACK를 같이 보내게 되는 것\n마지막으로 네번째에서는 더 이상 보낼게 없으니까 SEQ는 그냥 마지막에 보낸 10000으로 하고 방금 보낸 데이터 잘 받았고 이제 17001을 원하고 있다는 것을 피력하기 위해 ACK를 17001로 설정해서 보내게 되는 것\n\n\n그리고 Control Flag부분을 보면\n\n상대방이 보낸 것에 대한 ACK가 Segment에 포함되어 있으므로 ACK FLAG를 올리게 된다\n그리고 중요한게 저 PSH FLAG인데 이건 뭐냐면\nTCP는 기본적으로 버퍼링을 해 버퍼에 일정수준의 바이트가 차기 전까지는 보내지 않고 받는쪽에서도 동일하게 어느정도 모이기 전까지는 Application layer로 올리지 않는다\n받는쪽에서도 이렇게 기다리는 이유는 일단 Segment를 다 받고 정렬을 해서 올리기 위해서이기도 하고, 만일 데이터를 받을 Application이 바빠 지금 당장은 받지 못하는 경우에도 이렇게 기다렸다가 올리기 위해서이다\n하지만 PSH FLAG가 올라가 있으면 기다리지 말고 바로 Application 으로 올리라는 의미를 가진다\n보통 이것을 설정하는 것은 예를들어 채팅어플같은 실시간 통신이 중요할 때에는 기다리는 것이 곧 지연이기 때문에 이것을 막기 위해 바로 올려보내주세요 라고 하는 것이다\n따라서 위의 예시에서는 첫 두 Segment에 PSH가 설정되어있으므로 쟤네들은 바로 Application으로 올라가게 된다 - 만약 이게 설정되어있지 않았더라면 첫번째는 버퍼에서 기다리고 두번째가 도착했을때 수신자의 판단 하에 Application으로 올릴 수 있는 것이다\n\n\n위의 예시에서는 없지만 URG FLAG는 Urgent 즉, 긴급상황이 벌어진 것이다\n\n이건 어떤 경우에 설정되냐면\n예를들어서 큰 파일을 보내던 와중에 파일을 잘못보낸 것을 알고 이것을 취소하고자 할 때 사용한다\n이런 상황이 생기면 TCP에서는 Special TCP Segment를 만들어 URG FLAG를 올리고 URG POINTER를 설정하여 데이터와 함께 보내게 된다\nURG POINTER가 뭐냐면 위에 Segment Header구조 볼때 있던 필드인데 여기에 들어있는 값이 정상적인 데이터와 비정상적인 데이터를 구분하는 바이트 번호인 셈\n즉, URG POINTER가 400이라고 되어 있으면 Segment의 데이터에서 400번째 바이트까지는 폐기해야되는 비정상적인 데이터이고, 그 이후에 나오는 바이트들은 정상적으로 수신해야 되는 데이터인 것\n그래서 URG를 수신하게 되면 URG POINTER가 가르키는 곳까지 수신자는 폐기하게 된다\n이렇게 하는 이유는 한번에 최대한 많은 데이터를 보내기 위함이다 - 문제가 생겼다고 문제가 있음을 알리는 Segment를 별도로 보내는게 아니고 문제가 있음을 알리면서 동시에 정상적인 데이터들도 보내고 싶으신거지\n\n\n\nConnection Termination - Four-way Handshake(Half close) §\n\nConnection termination에서도 Establishment에서처럼 Three-way handshake로 할 수 있지만 요즘은 사용되지 않는댄다\n그래서 요즘 사용하고 있는 방법은 Four-way Handshake(Half close) 라는 방법이다\n그리고 위에서 언급한것처럼 Connection Termination단계에서 버퍼들을 반납하게 됨\n\n\n\n위 그림이 통신 전반에 걸친 State Diagram인데 Established까지는 전부 배웠고 이제 그 아랫부분을 보면 된다\n\n\n\n위와 같은 식으로 이루어짐\n\n\nClient가 Active close를 하고 FIN FLAG을 올려서 Segment를 보냄\n\nEstablish때와 마찬가지로 항상 Client가 먼저 제안을 한다\n뭐 FIN FLAG는 이름 그대로 이제 통신 그만하자 라는 뜻이다\nState Diagram에서 봐도 Close를 하고 FIN을 보낸 뒤 FIN-WAIT-1상태로 들어간 것을 볼 수 있다\n\n\nServer는 FIN을 받으면 알겠다고 ACK를 보내게 된다\n\nState Diagram에서 보면 FIN을 받고 ACK를 날린 뒤 CLOSE-WAIT상태로 들어가게 된다\n\n\nClient는 ACK를 받으면 아무것도 하지 않는다\n\nState Diagram에서 보면 ACK를 받고 FIN-WAIT-2상태로 진입한걸 볼 수 있는데\n이 단계가 뭐하는 거냐면 Client쪽은 데이터를 다 보냈어도 Server쪽은 Client가 요청한 데이터를 아직 덜 보냈을 수도 있기 때문에 Server가 마무리하는 단계가 되는 것이다\n따라서 Client가 FIN-WAIT-2상태일때 Server는 못보낸 것들을 다 보내고 Client는 ACK를 날려 잘 받았다고 알려줌\n\n\nServer는 마무리를 다 한 후에 FIN을 보낸다\n\nState Diagram에서 보면 Close/FIN이라고 되어 있는데 이게 Close하는 동안 나머지 데이터를 전부 보내고 그 이후에 FIN을 보낸다는 것\nFIN을 보내고 난 후에는 LAST-ACK상태로 들어가 ACK가 올때까지 기다린다\n\n\nClient는 FIN을 받으면 ACK를 날리고 잠시 대기한다\n\nState Diagram에서 보면 FIN/ACK후에 TIME-WAIT를 하는 것을 볼 수 있음\n\n\nServer는 ACK를 받고 바로 Close로 들어간다\n\n뭐 이제는 State diagram 설명안해도 되겠지\n\n\nClient는 일정시간 기다린 후에 Close로 들어간다\n\nServer는 바로 Close되는데 Client는 왜 일정시간 기다리는지 궁금하다면 대학원응안가\n\n\n\nFlow Control §\nWindow Size §\n\n일단 TCP의 Flow Control에서 중요한 점은 Receiver의 요청에 의해 Sender의 버퍼 크기를 늘렸다 줄였다 한다는 것이다\n이게 뭔소리냐면\n\n만일 Receiver의 버퍼 용량이 5000이고 1000이 아직 Application으로 올라가지 못했다고 해보면\nReceiver는 4000이상의 데이터를 받게 되면 버퍼가 터져나가게 된다\n따라서 Receiver가 Sender한테 말하는 거임 - 4000이상 보내지 마라고\n이때 Receiver가 사용할 수 있는 남은 버퍼의 크기를 rwnd라고 표현한다\n또한 이러한 이유 말고도 다음 강의때 배울 cwnd라는 것도 있는데\n이건 Congestion Window라고 네트워크의 혼잡도를 나타내는 것이다 - 네트워크가 혼잡하면 한번에 보내는 데이터의 양을 줄이라고 Sender에게 요청하는 것\n\n\n이러한 일을 Segment Header에 있던 Window Size필드를 이용해 수행한다\nWindow Size필드의 값은 rwnd와 cwnd중 작은 값 으로 설정하여 Receiver가 Sender에게 요청하게 되는 것 - 두 값보다도 적은 사이즈로 보내야 정상적으로 수신할 수 있으므로\n\n\n\n따라서 Sender의 버퍼를 보면 위와 같은 모양이 될 수 있다\n일단 Window Size는 Receiver의 요청에 의해 9로 설정된 상태고\n199까지는 전송했고 ACK까지 받은 애등\n200~202까지는 전송했지만 ACK는 받지 못한 애들\n그리고 203~208이 바로 전송할 수 있는 애들\n209이후로는 Application한테 받았지만 Window size 제한때문에 보낼 수 없는 애들인 것이다\n즉 위 그림에서 보이는것처럼 Window size가 정해져도 ACK를 받지 못한놈들 때문에 당장 보낼 수 있는 크기는 그것보다 작을 수도 있다는 것\n\nARQ §\n\nFlow Control이기 때문에 Data link layer에서의 Flow Control 방법을 사용하는데\nGo-back-N ARQ가 아니라 Selective ARQ를 사용한댄다\n기억안나면 06. ARQ Protocol, HDLC\n\nError Control §\n\nSegment Header의 Checksum 이라는 필드를 이용해 Error detection을 함\n그리고 수신측에서는 정상적으로 도착하면 ACK를 보내고 정상이 아니라면 아무것도 보내지 않는다 - 따라서 송신측에서는 ACK가 오지 않으면 Retransmission을 하게 됨\n\n여기에는 두 가지 용어가 등장한다\nRTO(Retransmission Time Out) 이라는 것은 말 그대로 일정 시간이 지나도 ACK가 오지 않는 것을 의미하고\nRTT(Round Trip Time) 이라는 것은 송신측이 시간을 잴 때 고정된 시간이 지나면 Retransmission을 하는 것이 아니고 Segment 왕복시간을 평균내서 해당 시간보다 늦어지면 Retransmission을 하게 되는 것을 말한다\n즉, 늦는다고 무조건 보내는게 아니고 Traffic에 의한 지연일 수도 있으니까 왕복시간을 고려해 타임아웃을 거는 구조다 이거지\n\n\n그리고 Three Duplicate ACK Segment가 와도 Retransmission을 하게 된다\n\n이게 뭔지는 뒤에 나올거임\n\n\n중요한 것은 Selective ARQ이기 때문에 순서에 맞지 않게 나중꺼가 먼저 도착해도 그걸 버리지 않는다 - out-of-order라는 플래그를 달아서 보류해뒀다가 빠진 Segment가 도착하면 그때 정렬을 해서 Application으로 올려보내는 구조\n\nNormal Operation §\n\n\n이건 뭐 정상적인 경우인데\n중요한점은 여러번의 수신을 하나의 ACK로 퉁칠수 있다는 것이다\n위의 예제에서 보면 50016001을 보내고 60017001을 보낸 후에 ACK로 7001을 보내게 되면 6001에 대한 ACK가 없으므로 이게 누락됐다고 생각하는게 아니고 7000까지는 잘 받았다고 생각하게 되는 것\n\nRTT Operation §\n\n\n여기서 보면\n701~800을 보내고 801~900을 보냈을 때 수신측은 701~800이 누락되었으므로 ACK 701를 한번 더 보내게 된다\n근데 여기서 중요한점은 위에서 말한것처럼 Out of Order를 버리지 않는다는 것이다\n\n위의 예제에서 보면 801~901까지는 정상적으로 왔는데 앞에꺼가 안왔다고 이것을 버리는게 아니라 Out of Order마킹해놓고 보류해놓은 뒤 701이 안왔다고 ACK 701을 보내게 되는 것\n\n\n송신측에서는 ACK 901을 기대하고있었는데 ACK 701이 오기도 했고\n보낸 701~800이 타임아웃이 났기 때문에 701~800을 다시 보내게 됨\n그럼 수신측에 도착하면 다 잘 받았다는 뜻으로 ACK 901을 주게 된다 - 701~800이 잘 도착했으므로 801~900을 Out of Order를 풀고 나머지를 이어 받거나 Application으로 올리던가 하게 됨\n\nThree Duplicate ACK - Fast Retransmission §\n\n\n말 그대로 동일한 ACK가 세번이나 들어왔을 때 재전송하는 것을 의미한다\nRTT가 끝나기 전에 ACK가 세번이 들어오면 걔도 뭔가 문제가 있다고 판단하고 재전송을 하게 됨\n위의 예제에서도 Out of Order를 버리지 않는다는 것이 나타난다 - 뒤에놈이 먼저 들어오면 Out of Order로 빼서 보류해두고 안들어온 301에 대해 ACK를 날리게 됨 - 이게 세번 중첩되면 재전송을 하고 재전송 성공하면 전부 다 들어왔음을 알리기 위해 ACK 701을 보내게 되는 것\n근데 IP에서의 Packet Switching은 Datagram을 사용하기 때문에 누락된게 아니라 경로를 잘못 들어 좀 오래 걸리는 것일 수도 있음\n\n근데도 동일한 ACK가 세번이나 들어오면 문제가 발생했다고 판단하긴 한다\n이러한 이유때문에 Three duplicate ACK를 Weak Error라고 부른댄다 - 확실하지는 않은 오류라 이거지\n반면에 RTT의 경우는 누락된 것이 확실하기 때문에 Strong Error라고 한댄다\n\n\n"},"originals/comnet.fall.2021.cse.cnu.ac.kr/10.-Congestion-control,-SCTP":{"title":"10. Congestion control, SCTP","links":[],"tags":[],"content":"\n\n                  \n                  충남대학교 컴퓨터공학과 김상하 교수님의 &quot;컴퓨터 네트워크&quot; 강의를 필기한 내용입니다. \n                  \n                \n\n\n\n                  \n                  다소 잘못된 내용과 구어적 표현 이 포함되어 있을 수 있습니다. \n                  \n                \n\nCongestion Control §\n\n일단 회선상의 문제는 Data Link Layer에서 다 잡기도 하고 요즘은 광케이블을 쓰기 때문에 거의 없다\n따라서 에러가 나면(ACK가 오지 않으면) 무조건 Queue Overflow에 의한 것이라고 생각\n이때 Receiver 쪽에서 나는 Queue Overflow는 Flow Control을 이용해 잡게 되고 중간 Router 쪽에서 나는 Queue Overflow는 Congestion Constol을 이용해 잡게 됨\n\nPhases of Congestion Control §\n\n각각의 단계를 알기 전에 일단 MSS(Maximum Segment Size) 를 알아야 한다\n\n걍 간단하게 말해서 한번에 보낼 수 있는 Segment의 최대 크기를 말하는거임\n뭐 MTU같은거지\n\n\n그리고 cwnd라는게 나오는데 그냥 Congestion Window의 약자이다 - Congestion이 일어나지 않고 한번에 받을 수 있을 것이라고 생각하는 버퍼의 크기\n\n\n1. Slow Start Phase §\n\n처음에는 cwnd를 1MSS로 해서 보내보고 송신에 성공하면 2배를 하여 cwnd를 2MSS로 하여 보내는 것을 반복하여 성공할때마다 cwnd의 크기를 2배씩 하여 보내게 된다\n\n물론 영원히 이렇게 보내는건 아니고 ssthresh(Slow Start Threshold) 라는 값에 도달할때까지 2배씩 증가함 - 보통 이 값은 65535byte로 지정되어 있다\n단위가 MSS랑 byte여서 헷갈리는데 그냥 뭐 저정도까지 올라가면 2배씩 무지성으로 올리지는 않는구나 라고 생각하면 됨\n뭐 이런식의 무지성 2배를 Exponential Increase라고 부른다 - 2배씩 지수적으로 늘어나기 때문\nssthresh에 도달하면 다음 단계인 Avoid Congestion Phase로 넘어감\n\n\n\n2. Congestion Avoidance Phase §\n\nSS에서 두배씩 무지성으로 올리다가 ssthresh에 도달하면 이때부터는 2배씩 올리는게 아니라 1MSS씩 증가하여 전송하게 된다 - 만일 64MSS를 보냈는데 성공하고 ssthresh에 도달했다면 그 다음에는 65MSS를 보내게 되는 것\n\n이번에는 1MSS씩 조심스럽게 cwnd를 늘리면서 보내보는 셈\ncwnd가 1씩 늘어나기 때문에 Additive Increase라고 부른다\n\n\n\n3. Congestion Detection Phase §\n\n\n혼잡이 일어난 경우에 어떻게 대처하는가\n\n혼잡이 일어난 경우에는 ssthresh의 크기를 cwnd 크기의 절반으로 줄이고 시작한다 - 이렇게 절반으로 만드는 것을 Multiplicative Decrease라고 부름\n이전의 ssthresh크기에서 절반하는거 아니다 - 마지막 cwnd의 크기를 절반해서 새로운 ssthresh의 값으로 설정하는 것\n그 다음에는 상황에 따라 대처방법이 다르다\n\n\n\n\n먼저 Time out, 즉, ACK가 오지 않은 경우 에는 무조건 혼잡한 경우이므로 cwnd를 1로 설정하고 2배씩 늘려나가는 Slow Start Phase로 되돌아가게 된다\n\n\n그리고 3-Duplicate ACKs 즉, 동일한 ACK가 3번 연달아 온 경우 에는 Weak Error라고 판단하기 때문에(전시간에 배웠쥬?) Slow Start로 돌아가는게 아닌 이전의 cwnd의 절반으로 줄어들은 ssthresh의 크기로 cwnd를 설정하고 Congestion Avoidance Phase로 돌아가게 된다\n\n여기서 뭐가 절반으로 줄어드는지 헷갈리지 마셈\nssthresh의 크기가 절반으로 줄어들고 cwnd의 크기는 1이 되거나 ssthresh와 같은 크기가 된다\n\n\n\n\n\n그래서 진행 과정 예시를 보면 위와 같다\n\nSS(Slow Start)로 시작을 해서\nssthresh에 도달하면 AI(Additive Increase)로 갔다가\n타임아웃이 나면 MD(Multiplicative Decrease)가 걸리고 다시 SS부터 시작을 했다가\n3ACK가 걸리면 또다시 MD가 걸리고 AI부터 다시 시작하는 형태\n\n\n\nSCTP(Stream Control Trasmission Protocol) §\n\n주요 특징들은 다음과 같음\n\n\nReliable : Error Detection및 Flow / Congestion Control을 지원한다\nConnection Oriented : SCTP에서는 Association이라는 용어를 사용하긴하는데 어쨋든 순서가 보장되는 통신을 지원한다\nMessage Oriented : TCP처럼 메세지들 한대 묶어서 전송하고 그러지 않고 Message의 Boundary를 잘 지켜서 보낸다\n\n뭐 너무 크면 Fragmentation 을 하긴 한다드라\n\n\n뭐 가장 최근에 소개됐댄다\n비디오나 오디오같은 멀티미디어를 전송하기에 TCP에서 부족한 부분을 보완한 프로토콜이고\nTCP와 UDP의 장점만 취한 프로토콜이랜다\n양방향 통신을 지원함 - Full Duplex Communication을 지원한다\n따라서 Piggybacking도 지원하더라\n\nProcess to Process Communication §\n\nUDP, TCP에서 사용하는 Well-known port number를 그대로 사용하고\n\n\n\n추가적으로 이런 Port number도 지원하는데 걍 참고만 하셈\n\nMulti-streaming, Multi-homing §\n\n\n일단 Multiple Streaming은\n\nTCP에서는 하나의 Stream만 사용해서 전송을 했는데\nSingle Stream으로는 보내다가 중간에 유실되면 나머지 데이터들까지 다 블락먹게 되는 문제점이 있다더라\n이게 텍스트파일 전송에는 문제가 없을지 몰라도 오디오나 비디오를 전송할때는 문제가 된댄다\n따라서 SCTP에서는 이러한 Stream을 여러개 지원하는 Multiple Streaming을 이용한댄다\n\n\n\n\n\n그리고 Multiple Homing은\n\nTCP의 경우에는 하나의 IP-IP쌍끼리 통신하는 경우였다면\nSCTP의 경우에는 여러개의 IP-IP이 통신하는 것을 지원한다\n이것도 약간 Multiple Streaming과 연관이 있는데\n우선 Primary IP-IP address 로 통신하다가 걔가 막혀버리면 송수신의 다른 Network Interface를 선택하여 통신을 이어가는 방식이다\n위 그림 보면 됨\n당연히 양쪽의 Host에 Network Interface가 여러개 설치되어있는 경우 가능함\n하지만 두개의 채널을 동시에 이용해 병렬로 보내는 것은 지원하지 않는다\n이렇게 말하면 이 두개가 뭔차이야 라고 생각할 수 있는데 아래 그림 보면 알 수 있다\n\n\n\n\n\n봐봐라\n일단 Application Layer에서 아래 내려보낼 수 있는 Stream이 여러개 있는 것이 Multiple Streaming이다\n\n따라서 각각의 Stream들은 한번에 하나만 이용할 수 있는게 아니라는 것도 Multiple Homing과의 차이점이라고 할 수 있겠네\n\n\n그리고 이 각각의 Stream들은 하나의 버퍼에 Multiplexing되고\n버퍼에 있는것들이 Primary Path를 타고 이동하다가 이게 막히면 차선책인 Retransmission Path를 타게 되고 이것을 Multiple Homing이라고 하는 것이다\n즉, 어디서 어디로 내려보내냐의 차이가 가장 크다고 할 수 있음\n\nTSN, SI, SSN §\n\n\n일단 SCTP에서도 당연히 Endpoint인 Port number는 송수신 양쪽에 한개씩이다\nTSN(Transmission Sequence Number) 는 Multiplex Buffer의 각각의 Chunk에 붙는 번호이다\n\nSCTP에서 하나의 Message를 Chunk라고 부른다고 생각하면 된다\n얘를 이용해서 ACK를 주고받고 정렬을 하는 등의 과정을 거친다\n\n\n그리고 수신측에서 Multiplex된 애들을 다시 Demultiplex해서 버퍼로 올려보내주기 위해서는 얘가 어느 버퍼에서 왔는지 기록해놔야 하는데 이게 SI(Stream Identifier) 이다\n또한 버퍼에 들어와서도 정렬을 해야 하기 때문에 이때 한 버퍼 내에서의 순서를 나타내는 숫자가 SSN(Stream Sequence Number) 이다\n\nPacket Structure §\n\nTCP에서는 전송단위가 Segment였던 반면 SCTP에서는 전송단위를 Packet이라고 부른다\n\n\n\nSCTP에서는 Header에는 반드시 모든 Packet에 있어야 하는것만 남기고 나머지 것들은 전부 Control Chunk로 뺐다\n\n즉, TCP에서의 Control Flag와 이와 관련된 것들은 필요할때 Control Chunk로 넣게 함으로 패킷 구조를 꺼내볼때 불필요한것까지 꺼내볼 필요가 없게 함\n따라서 SCTP의 Header는 12byte로 고정이고 따라서 hlen같은 필드도 필요없어졌더라\nACK나 rwnd, cwnd같은 것들 전부 다 Control Chunk에 들어가게 됨\nUrgent는 그냥 삭제되었댄다 - 이유는 안알려줌\n\n\n\n\n\n그리고 TCP에서는 byte단위로 송수신하기 때문에 Data Byte를 그냥 하나의 덩어리로 취급하지만 SCTP에서는 Message Chunk단위로 송수신하기 때문에 여러개의 Stream에서 내려온 여러개의 Chunk를 Packet의 Data Chunk에 넣어서 송수신하게 된다\n\n위 그림은 하나의 Packet에 Stream 0, 1에서 내려온 세개의 Chunk가 담기는 것을 보여주는 예시임\n\n\n그리고 Data Chunk들에게만 TSN이 존재한다는 것 꼭 알아둬야 한다\n\n따라서 TCP에서는 단순 Control을 위한 Segment에도 Sequence number가 할당되었지만\nSCTP에서는 Control Chunk에는 TSN이 붙지 않기 때문에 Sequence number를 소비하지 않게 된다\n또한 TCP에는 Segment당 하나의 Sequence Number가 붙었지만 SCTP에서는 Chunk별로 TSN, SI, SSN이 붙기 때문에 Packet내의 각 Data Chunk마다 Sequence number가 달리는거라고 볼 수 있다\nTSN이 Data Chunk에만 붙기 때문에 ACK는 Data Chunk에 대해서만 Acknowlegement를 하기 위한 것이 되고\nACK와 Error Control 등은 전부 Stream으로 올라가기 전 Buffer에서 이루어지므로 TSN만 사용하고 SI, SSN은 사용하지 않는다\n\n\nVerification tag는 SCTP로 통신할때 맺은 Association들을 구분하기 위한 필드라는것 정도만 알고 있으면 될듯\n\n\n\n하나의 Chunk는 위처럼 구성된다\nType에 Data Chunk인지, 아니면 어떤 Control Chunk인지의 정보가 들어감\n뭐 나머지는 별로 중요하지 않다\n\nAssociation §\n\n\nTCP와는 다르게 SCTP에서는 4-way handshake를 이용해서 Association을 맺는다\n여기서 알아야 할 것은 Cookie단계에서도 Data chunk를 같이 실어 보낼 수 있다는 것과\n\n\n\n위처럼 Piggybacking을 지원한다는 것\n그리고 ACK는 Selective ACK(SACK) 를 보내게 되는데 이때는 전과는 다르게 자신이 받고싶은 것이 아니라 마지막으로 받은 TSN을 써서 보내게 된다는 것 기억해라\n마지막으로 Terminating Association을 할때는 Half-close가 안된다 - 한쪽이 끝내고 나머지 한쪽이 다 정리될때까지 기다리는 방식이 아닌 끝나면 그냥 둘 다 끝나버림\n\nFlow, Error, Congestion Contol §\n\n용어정리가 좀 필요하다\n송신측\n\n\n\ncurTSN : 다음으로 보낼 Chunk의 TSN\nrwnd : 수신자가 보내준 수신버퍼 가용크기\ninTransit : 송신자가 보냈지만 아직 ACK를 받지 못한 데이터의 양\n송신측에서는 rwnd - inTransit의 값이 curTSN의 Chunk size보다 클때 해당 Chunk를 보내게 된다\n\n이 값이 curTSN의 Chunk size보다 작다면 수신자에게 공간이 없다는 것을 나타내기 때문\nrwnd가 아닌 여기에서 inTransit을 뺀 값이 기준이 되는 이유는 아직 수신자가 rwnd값을 알려주지 않았어도 내가 보낸것을 기준으로 추정할 수 있기 때문이다\n\n\n수신측\n\n\n\ncumTSN : 마지막으로 정상적으로 받은 Chunk의 TSN\n\n만일 정상적이지 않은 - 순서가 제대로 지켜지지 않은 - Chunk가 들어오면 걔는 cumTSN에 반영되지 않고 앞순번의 Chunk가 다 들어오면 그때서야 반영된다\n\n\nwinSize : 가용 수신버퍼 크기\n\nwinSize는 다음과 같이 계산된다 - 처음 크기는 뭐 알아서 설정될거고 만약 Chunk가 들어오면 그 크기만큼 winSize가 줄어들고 위 버퍼 혹은 프로세스에서 가져가면 그만큼 커지는 것\n이때는 정상적이지 않은 Chunk - 즉, 순서가 제대로 지켜지지 않은 Chunk의 크기까지 뺌 - 순서가 지켜지지 않아도 버퍼에 넣어놓고 앞순번의 Chunk가 올때까지 기다린다\n\n\nlastACK : 마지막으로 보낸 ACK\n\n뭐 당연한 얘기긴 한데 lactACK의 값이 cumTSN과 같으면 ACK보낼게 없다는 얘기니까 안보내고 작을 경우에만 cumTSN값을 SACK로 보내게 된다\n\n\n따라서 Flow Control 예시를 따라가보면\n\n\n\n우선 rwnd - inTransit값이 2000이고 curTSN의 Chunk size가 1000이므로 TSN 1을 보냄\n보내고 난 뒤에는 curTSN이 2가 되고 inTransit은 TSN 1에 대한 ACK를 받지 못했으므로 1000이 된다\n수신자는 TSN 1을 받아들고 cumTSN은 1, winSize는 1000을 줄여 1000으로 설정해놓는다\n그리고 여전히 rwnd - inTransit의 값이 1000이고 curTSN의 Chunk size가 1000이므로 TSN 2를 보내게 된다\n마찬가지고 송신자는 curTSN이 3이 되고 inTransit은 2000이 되며 수신자는 cumTSN이 2, winSize는 0이 된다\n이때 송신자는 rwnd - inTransit의 값이 0이므로 더이상 보내지 못하고 기다리는 상태가 되고\n수신자는 TSN 2까지 잘 받았다는 것을 ACK로 알려주고 rwnd가 0이라는 것도 송신자에게 알려준다\n그럼 송신자는 ACK를 받았으므로 inTransit을 0으로 해주고 rwnd도 0으로 해준다\n마지막으로 프로세스가 Chunk를 가져가면 그때 ACK2와 함께 rwnd 2000을 보내서 수신버퍼가 비었음을 알려준다\n\n\n그 다음에는 Error Control 예시를 하나 보면\n\n\n\n수신측인데\n순서가 맞지 않는 애들을 버리지 않고 구멍난 상태로 버퍼에 넣어놓되 OutOfOrder에 기록해둔다\n뭐 중복해서 들어온애들은 Duplicate 에 적어놓고\n위에서도 말했지만 Winsize는 정상적인애들 뿐만 아니라 순서가 맞지 않는 애들까지 고려해서 남은 자리가 되고\ncumTSN은 마지막으로 정상적인애를 가리키게 된당\n\n\n\n이건 송신측인데\n그냥 Timeout이 난 애들을 Retransmission Queue에 넣어서 보내게 된다는 점정도 기억해라\nCongestion Control은 TCP에서와 동일하다네\n"},"originals/comnet.fall.2021.cse.cnu.ac.kr/11.-Application-Layer,-DNS":{"title":"11. Application Layer, DNS","links":[],"tags":[],"content":"\n\n                  \n                  충남대학교 컴퓨터공학과 김상하 교수님의 &quot;컴퓨터 네트워크&quot; 강의를 필기한 내용입니다. \n                  \n                \n\n\n\n                  \n                  다소 잘못된 내용과 구어적 표현 이 포함되어 있을 수 있습니다. \n                  \n                \n\nApplication Layer §\n\n뭐 알고있어야 하는건 우리가 만드는 Application도 Application Layer에 포함되는거고 Application Layer에서 지원하는 여러 프로토콜들을 이용하게 된댄다\n\nDNS §\n\n알다시피 문자열을 IP주소로 바꿔주는 프로토콜이다\n뭐 옛날에는 hostfile이라는 것을 자기 컴퓨터에 저장해서 각자가 문자열과 IP를 매핑했었는데 이게 너무 개소리다 보니까 이러한 시스템을 만들게 된 것\nTransport Layer나 IP Layer랑 통신하기 위해서는 Socket Address를 알아야 되는데 Port number는 Well known이기 때문에 IP만 알아와야할 필요가 있는 것\n\n\n\n이런식으로 구동된다\n이건 이메일을 보내는 예시인데 여기서 핵심은 Client쪽에 DNS Client Process가 있고 DNS Server로 요청을 보내서 IP를 알아오는 구조라는 것이다\n\nName Space §\n\n뭐 약간 추상적으로 말해서 각 Name(문자열 주소)들이 존재하는 공간이라는 건데\n여기서 중요한 것은 Namespace 내에서 각각의 Name들은 겹치면 안된다는 것이다\n\n약간 당연한거임 - Name - IP쌍이 유일하게 존재해야지 Name을 가지고 IP를 찾아내거나 IP를 가지고 Name을 찾아낼 수 있기 때문\n\n\n이 Namespace에는 Flat Namespace와 Hierarchical Namespace가 있다\nFlat Namespace : Namespace전부를 하나의 기관에서 관리하는 것(Centrally Control)\n\n당연히 이렇게 하면 하나의 DNS Server가 모든 것을 다 처리해야 되기 때문에 좋지 않다\n\n\nHierarchical Namespace : 각각의 작명소에서 이름을 붙이고 마지막에 그 작명소의 이름을 추가해 이름이 같더라도 작명소가 다르면 다른 Name이 나오게 하는 것\n\n뭐 요즘 DNS에서 사용하고 있는 방식이기 때문에 익숙할거다\nchallenger라는 같은 이름을 붙일때 fhda.edu와 berkeley.edu에서 붙이게 되면 challenger.fhda.edu하고 challenger.berkeley.edu 가 되므로 다른 Name이 나오게 되는 것\n이렇게 하면 작명소들로 일을 나눌 수 있기 때문에 Decentralized된다\n\n\n\nDomain Name Space §\n\n현재의 DNS에서 사용하고 있는 Namespace를 말하는거임\nHierarchical Namespace를 사용하고 Inverted Tree - 흔히 아는 그 트리 - 구조를 가지게 된다\n\n트리의 최대 깊이는 128이 된다고 함\n\n\n\n\n\n여기서 용어정리를 좀 해야 되는데\n\nRoot는 트리의 최상단을 말하며 이놈의 Label은 null string이다\nLabel은 각각의 Node에 붙는 이름이고\nDomain은 각각의 Node를 루트로 하는 Subtree를 일컫는다\nDomain Name은 Root부터 자신까지의 Label을 (.)로 이은 것을 의미함\n\n그리고 Domain Name은 글자 그대로 Domain을 대표하는 이름이다 - Domain이 Subtree이므로 그 Subtree의 이름이 Domain Name이 되는거고 Root부터 해당 Subtree의 Root까지의 Label을 전부 (.)으로 이으면 되는 것\n\n\n\n\n\n\n\n그리고 위 그림에서 왼쪽처럼 모든 Domain name을 생략없이 다 적은 것을 FQDN(Fully Qualified Domain Name) 이라고 함\n\nRoot의 Label은 null string이므로 Domain name의 마지막이 (.)으로 끝나면 FQDN이 되는 것\n\n\n오른쪽처럼 Domain name일부를 생략하는 것을 PQDN(Partially Qualified Domain Name) 이라고 한다\n\n따라서 PQDN의 경우에는 마지막이 (.)으로 끝나지 않는다\n\n\n\nDistribution of Namespace §\n\n일단 Name - IP쌍을 저장하는 서버를 Name Server라고 한다\n그래서 Namespace에 있는 모든 Name - IP쌍을 어떻게 저장할거냐\nName Server에 나눠서 저장하게 되는데 이렇게 하면 약간 문제점이 있다\n\n일단 Tree에서 한 Node에 대응하는 Name Server가 자신의 Domain에 있는 모든 Name - IP를 저장하면 그의 Child는 아무것도 저장할게 없고\n그렇다고 Child각각이 자신의 Domain을 저장하자니 그럼 Parent가 저장할게 없어진다\n\n\n그래서 어떡할거냐\n\n\n\n일단 Zone이라는 용어를 알아야 됨 - Zone은 어떤 Name Server가 책임을 지고(Authority가 있다고 표현함)있는 Name - IP의 범위를 일컫는다\n보면 Domain이랑 비슷하지만 Domain이랑의 차이점은 만약 그 서버가 자신의 Domain에 있는 모든 Name - IP를 책임진다면 Domain이랑 Zone의 범위가 같아지지만 만일 그 서버가 자신의 자식에게 그놈의 Sub-domain에 대한 Authority를 넘겼다면 Domain이랑 Zone의 범위가 달라지게 되는 셈\nAuthority를 넘기는건 자신은 그 범위의 Name - IP를 저장하지 않고 다른 Name Server에게 넘기되, 넘긴 Name Server의 Reference(IP)를 갖고 있는 것을 의미한다\n그래서 위 그림처럼 되는거임\n\n.com의 Domain은 노란색이 되지만\n.mhhe한테 그놈의 Sub-domain의 Authority를 넘기면 이제 저 회색이 .mhhe의 domain이자 zone이 되는거고\n.com의 경우에는 그걸 제외한 갈색부분이 Zone이 되는 것\n\n\n\nRoot, Primary, Secondary Server §\n\nRoot Server는 말 그대로 Namespace에서의 최상위 Server이다\n\n얘는 Child Name Server에게 모든걸 위임하고 자기는 하나도 Name - IP쌍을 하나도 갖고있지 않는다\n대신 Child Name Server의 Reference만을 갖고있음\n\n\nPrimary Server는 자신의 Zone에대해 Name - IP를 생성, 수정, 삭제 등을 전부 할 수 있는 Server를 말한다\nSecondary Server는 Primary Server의 백업용 Server라고 보면 된다\n\n따라서, Primary Server의 데이터 복사본을 갖고 있되 얘네들을 직접 수정, 삭제, 추가하는것은 안됨\n\n\n여기서 주의할건 Primary와 Secondary 모두 Authority는 갖고 있다는 것\n하나의 Server가 Primary와 Secondary의 역할을 모두 하는 것도 가능하다 - 따라서 자시가 어느 Zone에 대해 Primary이고 어느 Zone에 대해 Secondary인지 등을 잘 기록해놔야 함\n또한 Namespace Tree에서의 논리적 위치와 실제 서버의 물리적 위치는 같을 필요가 없다\n\n예를 들어 어느 기관의 Domain을 관리하는 Name Server가 반드시 그 기관 내에 위치할 필요는 없다는 것\nNamespace Tree내에서의 위치와 Domain, Zone등은 논리적인 관계를 나타내는거지 그들의 물리적 위치는 관계없다\n\n\n뭐 Primary에서 Secondary로 정보를 복사하는 것을 Zone Transfer라고 한댄다\n\nDomains §\n\n\n실제 DNS 시스템에서의 Namespace는 Inverse Domain, Generic Domain, Country Domain으로 구성된다\n\n\n\nGeneric Domain : 지역과는 관계없는 도메인\n\n위 그림 보면 알 수 있듯이 우리가 흔히 보던 .com, .net, .org등등임\n근데 보통 미국을 중심으로 관리가 된댄다\n\n\n\n\n\nCountry Domain : 지역과 관련있는 도메인\n\n이것도 뭐 흔히 접했을만한것들임 - .kr .uk등등의 지역을 나타내는 도메인\n\n\n\n\n\nInverse Domain : 이건 별로 접해보지 못했을 텐데 IP를 Name으로 바꿔주는 도메인이다\n그래서 보면 노란색 처럼 질의를 하면 트리를 쭉 쫒아가며 그에 맞는 Name을 찾게 됨\n\nResolusion §\n\n그럼 어떻게 DNS는 요청에 대한 응답을 하는가\n일단 요청하는놈(DNS Client)을 Resolver라고 하는데\n요청을 하면 다음과 같은 순서대로 찾는다\n\n\n\nResolver는 자신과 가장 가까운 DNS Server에게 물어본다\n\n\n만일 가장 가까운 DNS Server한테 정보가 있으면 그걸 바로 알려주고\n\n\n없을 경우에는 Iterative, Recursive 두가지 방법중 하나의 방법으로 찾게 된다\n\n\n\nIterative resolution은 자신한테 정보가 없다면 자신의 부모나 자식 중 정보를 가지고 있을만한 놈의 IP를 넘겨주고 Resolver가 그 IP로 다시 물어보고 이러한 방식을 반복하는 방법이다\n\n위 그림처럼 된다는거임 - 자기가 모르면 그걸 알만한 전화번호를 주면서 이쪽으로 전화해보세여 하는셈\n\n\n\n\nRecursive resoluvion은 자신한테 정보가 없다면 자신의 부모나 자식 중 정보를 가지고 있을 만한 놈한테 자기가 직접 물어보는 것이다\n\n즉, 자기가 모르면 자기가 알아보고 다시 연락주겠다고 한 뒤에 딴사람한테 물어보고, 만약 그놈도 모르면 그놈도 직접 딴사람한테 물어보고 해서 알아내는 방식\n\n\n\n\n근데 위 그림처럼 DNS Server의 IP를 아는 경우에는 건너건너 알아내지 않고 직접 물어보는 것도 가능히다\n\n\n\n같은걸 여러번 물어볼때 물어볼때마다 이런식으로 진행되면 낭비가 심하다 - 따라서 DNS Server는 응답을 Caching해놓았다가 그에 대한 요청이 들어오면 Cache에서 꺼내서 돌려주기도 한다\n\n근데 이 경우에는 Unauthorize Mark를 해서 응답을 한다\n왜냐하면 Cache에 있는 Name - IP의 경우에는 자신한테 Authorize가 있는게 아니기 때문에 얘네가 변경되거나 삭제되어도 알수가 없음 - 따라서 신뢰성은 좀 떨어진다는 것을 Resolver에게 알려주는 것이다\n\n\n\nFormat §\n\n\n기능이 간단하기 때문에 Query와 Response두개의 메시지 포맷만 존재한다\nQuery의 경우에는 그냥 Header와 Question section(요청내용)만 있고\nResponse는 Header와 Question section외에도 Answer Section(요청에 대한 응답)과 Authoritative Section(응답자의 Zone에 요청에 대한 응답이 존재했는지 - 신뢰성), Additional Section(추가적인 정보 - DNS Server의 Domain Name, IP등을 같이 줘서 Resolution에 도움이 되도록 함)가 포함된다\n\n\n\n이건 Header의 정보인데 그냥 ID와 몇개의 Flag, 그리고 각 Section들의 Record 갯수가 몇개인지 정도가 들어간다고 알고있으면 된다\n\nRecords §\n\nRecord는 한번에 하나의 요청만 보내는게 아니고 마찬가지로 한번에 한개의 응답만 보내는게 아님 - 그 각각을 Record라고 부른다\nQuestion Section에 들어있는 Record들을 Question Record라고 부르고 여기에는 질문에 대한 Domain Name만 들어가게 된다\nAnswer, Authoritative, Additional Section에 들어가는 Record들을 Resource Record라고 하고 DNS Server가 가지고 있던 Domain Name, IP등의 정보가 들어가게 된다\n\nRegistrars §\n\nRegistrars는 돈을 받고 Name - IP를 Namespace에 추가해주는 업체라고 생각하면 됨\n\nDDNS §\n\nDDNS(Dynamic Domain Name System) 은 IP가 변경되는 경우를 추적하기 위한 시스템으로\nIP변경이 감지되면 보안성이 높은 방법으로 바뀐 IP를 Primary DNS Server에게 보내 정보를 업데이트하고 Secondary에게도 알린다\n\nEncapsulation §\n\nDNS Message가 하위 계층으로 어떻게 전달되냐\n일단 DNS의 Port number는 53번을 사용하고\nDNS Response Message의 크기가 512byte를 넘어갈거같으면 처음에 보낼때부터 TCP를 이용해서 보낸다\n근데 만약에 DNS Response Message의 크기가 얼마인지 알 수 없을 때에는 일단 UDP로 보내보고, 응답이 512byte를 넘으면 응답자가 **Truncate Bit(TC Bit)**를 먼저 보내 통신을 TCP로 바꾸고 그 다음에 요청에 대한 응답을 전달하게 된다\n이렇게 하는 이유는 TCP의 경우에는 3 Handshake를 하는 등의 과정이 있기 때문에 번거로움 - 가능하면 UDP를 사용하려 한다\n"},"originals/comnet.fall.2021.cse.cnu.ac.kr/12.-TELNET,-Email,-File-Transfer":{"title":"12. TELNET, Email, File Transfer","links":[],"tags":[],"content":"\n\n                  \n                  충남대학교 컴퓨터공학과 김상하 교수님의 &quot;컴퓨터 네트워크&quot; 강의를 필기한 내용입니다. \n                  \n                \n\n\n\n                  \n                  다소 잘못된 내용과 구어적 표현 이 포함되어 있을 수 있습니다. \n                  \n                \n\nTELNET §\n\nRemote Logging을 위한 프로토콜인데\n요즘의 클라우드 컴퓨팅마냥 옛날에도 조금 다른 형태의 클라우드 비스무리한게 서비스되었다\n\n강력한 CPU를 가진 중앙 컴퓨터가 있고, 거기에 간단한 CPU를 가진 컴퓨터들이 원격으로 접속해서 작업을 요청하고 그 결과를 받는 것 - Timesharing Environment라고 한다\nTerminal을 이용해 서버와 클라이언트가 소통하는데 이게 실제로는 사용자가 자기컴퓨터갖고 노는게 아니기 때문에 Virtual Terminal Service라는 말을 사용함\n서버에 여러 사용자가 각자의 공간과 접근권한, ID, PW등을 갖는 것을 Logging이라고 한다\n\n\n이때 Local 환경과 Remote환경의 차이를 줄이기 위한 프로토콜이 TELNET인 것이다\n\nASCII, Encoding Issue §\n\n일단 뭐 ASCII(American Standard Code for Information Interchange) 가 뭔지 이미 알고 있겠지만 화면에 표시될 수 있는 문자들 및 여러 컨트롤 명령들을 8비트로 매핑해놓은 것이다\n\n그래서 구성이 어케되냐면 8비트(1바이트)이기 때문에 0~255까지의 숫자로 매핑이 되는데\n1~31까지는 화면에 출력되지 않는(Non-Printable) 시스템 코드 이다\n\n뭐 종종 보이는 CR(커서 이동), LF(개행)등이 여기에 드감\n\n\n32~127까지는 화면에 출력되는(Printable) 코드 이다\n\n알파벳 대소문자와 &lt;, &gt; @ 등등의 여러 기호들이 여기에 드감\n\n\n그리고 128~255까지는 운영체제나 프로그램에서 자율적으로 매핑해서 사용할 수 있는 코드 이다\n\nctrl + D같은애들이 숫자로 변환되고 이게 각자의 운영체제나 프로그램에 맞게 해석되어 사용됨\n\n\n\n\n근데 여기서 문제가 뭐냐면 0~127까지는 표준으로 정해져있지만 128부터는 자율적으로 프로그래밍될 수 있게 함으로써 환경이 달라지면 다르게 해석된다는 것이다\n\n예를들어서 DOS에서는 EOF가 ctrl + Z이지만 UNIX에서는 ctrl + D로 매핑되어있는 것\n\n\n그리고 ASCII말고 다른 인코딩 포맷을 사용하는 운영체제나 프로그램도 존재한다\n\nDOS나 UNIX는 ASCII를 사용하지만\nWindows NT나 IBM S/390같은애들은 Unicode나 EBCDIC같은 인코딩 방식을 사용하는 등\n\n\n따라서 환경이 달라져도 원래 의도에 맞게 해석되도록 변환하는 놈이 필요함\n\nLocal Log in §\n\n\nTELNET의 작동원리를 정확하게 이해하기 위해서는 일단 Local환경에서 어떻게 Logging이 되는지 알아볼 필요가 있다\n우리가 Terminal 창을 켜서 키보드를 하나 누르면 다음과 같은 일이 일어난다\n\n키보드가 눌린 키보드에 대한 전기신호를 숫자의 형태로 Terminal Driver에게 보낸다\n\n여기서 알아야할게 키보드가 보내는 숫자 전기 신호는 뭐 ASCII같은 인코딩을 사용하는게 아니라 해당 키보드에서 사용하는 독자적인 수치를 이용한다는 것이다\n\n\n그럼 Terminal Driver는 그 전기 신호를 운영체제가 알아들을 수 있는(사용하고 있는) 인코딩 방식으로 변환해서 운영체제에게 전달한다\n\n즉, 키보드가 만들어낸 전기 신호를 운영체제가 알아들을 수 있는 ASCII 등의 포맷으로 인코딩하는 것이 Terminal Driver가 하는 일이다\n\n\n운영체제는 Terminal Driver가 준거를 보고 그에 맞는 Application Program에게 전달하게 된다\n\n\n예를들면 이렇게 된다는거임\n\nTerminal창을 열고 cd a를 칠라고 했는데 실수로 cd ab를 쳐서 백스페이스를 눌렀을때\n키보드가 생성해내는 Stream을 예를들어서 1 2 3 4 5 6이라고 해보자 - 걍 예시임 1이 c에 대한 신호고 2가 d에 대한 신호고 스페이스바가 3이고 뭐 이런식임\n그럼 Terminal Driver는 저거를 받아들고 (운영체제가 ASCII를 사용한다는 가정하에) 66 67 20 64 65 07로 번역해서 운영체제한테 전달한다\n그럼 운영체제가 뭐 zsh같은 쉘한테 “cd ab를 출력한 다음에 b를 화면에서 지워라” 같은 메세지를 전달하게 되는 것이다\n\n\n\nRemote Log in §\n\n\n근데 위에서 말한거같은 Timesharing Environment에서는 Local과 Remote의 운영체제나 프로그램등이 다를 가능성이 농후하다\n따라서 저런걸 이용하기 위해서는 Encoding 방식을 변환해야 될 필요가 있고 그걸 TELNET에서 지원하는거다\n이놈의 핵심 원리는 운영체제 등의 환경에 종속적인 인코딩을 환경에 종속적이지 않은 인코딩인 NVT(Network Virtual Terminal) 으로 변환해서 상대방에게 보내고, 상대방이 그걸 받으면 그걸 자신의 환경에 맞게 변환해서 사용하게 된다는 것이다\n\nNVT(Network Virtual Terminal) 에 대한 얘기를 좀 해보면\n위에서 0~127까지는 표준화가 되어있지만 128이후로는 각기 다르다고 했잖여\n따라서 NVT(Network Virtual Terminal) 에서도 127까지는 ASCII와 동일하지만 그 이후부터는 독자적인 포맷을 사용함\n그리고 이런 포맷으로 TELNET끼리 통신한 다음 각자의 Local에 맞게 인코딩방식을 바꾸는거다\n\n\n\n\n\n0~127까지는 최상위비트가 0이므로 0으로 시작할 경우에는 데이터 코드로 인식하고 이것에 대해서는 별도의 번역을 하지 않지만\n128~255까지는 최상위비트가 1이므로 1로 시작할 경우에는 컨트롤 코드로 인식하고 운영체제에 맞는 번역을 진행하게 된다\n이제 작동과정을 보면\n\nLocal에서 작동하는건 동일하게 이루어진다 - 키보드 신호가 Local의 운영체제에 맞는 포맷으로 인코딩되어 운영체제에 전달된다\n그럼 그 다음에는 운영체제가 Application인 TELNET Client에게 Local Env Encoding Stream을 전달한다\n\n키보드신호가 아니고 Local 운영체제가 사용하는 인코딩으로 도착한다는거 헷갈리지 말그라\n\n\nTELNET Client는 해당 Stream을 NVT(Network Virtual Terminal) 로 변환한 다음 TCP / IP를 이용해 Server에게 보낸다\n\n주목해야될거는 TELNET이 TCP / IP를 이용한다는 것과\n만국공통어 정도로 비유될 수 있는 NVT(Network Virtual Terminal) 로 번역된다는 거다\n\n\n그럼 그걸 Server에서는 TCP / IP를 통해 받아서 TELNET Server까지 올라가겠지\nTELNET Server는 NVT를 받은 뒤에 자신의 운영체제가 이해할수있는(Understandable)인코딩으로 변환해서 Pseudo-Terminal Driver에게 보낸다\n\n여기서 헷갈릴만한게 TELNET Server가 번역한 다음에 OS가 아닌 Pseudo-Terminal Driver에게 보낸다는 것 이다\n이렇게 하는 이유는 OS는 무조건 Terminal Driver한테서만 받도록 설계되어 있기 때문에 TELNET Server가 직접적으로 OS한테 보내지 못하고 저런 가짜 Terminal Driver 를 통해 보내게 되는 것\n\n\nPseudo-Terminal Driver는 그걸 OS에게 전달하고 OS가 그에 맞는 Application Program에게 Stream을 전달한다\n\n\n\n\n\n그래서 위의 그림처럼 표현할 수도 있더라\n\n\n\n예시임 - 이런식으로 진행된다\n\nElectronic Mail Service §\nArchitecture §\n\n여기서 System이라는 말이 종종 나오는데 이건 Mail Server 와 LAN으로 연결되어있는 범위정도로 이해하면 될거같다\n\nScenario 1 - Both Participant are Connected Direclty to the Same System §\n\n\n회사 사내 망에 송수신자 모두가 연결되어있는 경우 정도로 이해하면 된다\n여기서 User Agent는 메일을 작성하거나 출력하거나 목록을 보여주는 등의 사용자와 소통하는 작업과 (서버랑 같은 시스템에 있을 경우) 메일 서버의 메일 박스에 넣어놓거나 가져오는 정도의 메일 송수신이 가능한 프로세스라고 생각하면 된다\n따라서 모든 참여자가 같은 시스템에 연결되어있을때 에는 위 그림처럼 사용자 각각에 대한 메일박스들을 가지고 있는 메일서버와 UA(User Agent) 만 있으면 메일을 주고받을 수 있음\n송신자가 UA를 통해 메일을 작성하고 전송하기를 하면 UA는 그걸 Mail Server의 수신자 메일박스에 넣고, 수신자는 메일박스에 있는 메일을 받아보게 되는 과정으로 전송된다\n\nScenario 2 - Both Participants are Connected to Separate System §\n\n\n이건 내가 사내망에 접속되어있고 다른 사내망에 접속되어있는 사람한테 보내는 경우 정도로 생각하면 된다\n시스템에서 시스템으로 메일을 보내기 위해서는 MTA(Main Transfer Agent) 가 필요하다\n\nMTA에 대해 기억할것은 얘는 Client-Server모델을 이용하기 때문에 Client의 적극적인 송신에 Server는 수동적으로 수신할 수 밖에 없다는 것이다\n즉, Client가 메일을 보내고 Server가 받기 때문에 하나의 Client-Server Pair에 한해서, 그리고 실제 메시지에 한해서는 단방향 통신이라고 말할 수 있는거다\n이말을 오해하면 안되는게 그렇다고 Server가 Client에게 통신을 안한다는게 아니고 실제 메일이 전달되는거에 한해서만 단방향이라는 것 - 뭐 뒤에서도 배우겠지만 Connection과 Terminate등의 절차를 거치며 Control Message는 양방향으로 주고받게 된다\n\n\n어쨋든 모든 참여자가 시스템에 연결되어있지만 시스템이 다를 경우 에는 위 그림처럼 UA를 통해 시스템에게 메일을 보내면 그걸 MTA Cilent가 다른 시스템으로 보내고, 다른 시스템에 있는 MTA Server가 그걸 받아서 메일함에 넣어서 수신자가 가져가게 되는 과정이 이루어진다\n따라서 UA 두개와 한쌍의 MTA Client-Server가 필요함\n\nScenario 3 - Some Participant are not Connected to System §\n\n\n이건 내가 집에서 다른 사내망에 연결되어있는 사람에게 메일을 보내는 경우 정도로 생각하면 되는데\n\n\n송신자가 자신의 메일 서버 시스템에 연결되어있지 않기 때문에 송신자는 자신의 디바이스에 있는 MTA Client로 자신의 메일 서버 시스템의 MTA Server로 우선 메일을 보내는 작업을 한다\n그럼 그 다음부터는 Scenario 2와 동일함 - 수신자의 메일 서버 시스템의 MTA Server로 메일을 보내게 되고 그럼 MTA Server가 메일박스에 넣어놓음으로써 수신자가 받아가는 것\n\n\n따라서 이 경우에는 두개의 UA와 두개의 MTA Client-Server 쌍이 필요하게 됨\n\nScenario 4 - Both Participant are not Connected to System §\n\n이게 제일 일반적인 경우임 - 내가 집에서 다른 집에 있는 사람한테 메일을 보내는 경우\n\n\n\n여기서는 수신자가 메일을 가져가는 과정 외에는 전부 동일하다 - MTA Client로 자신의 Mail Server의 MTA Server 에게 보내고, 거기서는 또 Mail Server의 MTA Client로 상대방의 Mail Server의 MTA Server에게 보내면 메일함에 담기게 됨\n근데 이경우에는 그냥 수신자에게 메일함에 있는것을 줄 수 있는게 아니다 - Mail Server가 수신자에게 주려고 해도 저놈이 출무중이면(뭐 컴터가 꺼져있다거나) 메일을 받지 못하기 때문\n그리고 저넘이 언제 접속할지도 모름 - 따라서 Mail Server는 저놈이 달라고 할때까지 암것도 안하는 아몰랑 전략을 취한다\n\n즉, 수신자가 Mail Server에게 나에게 온 메일을 자기한테 달라고 요청 하게 되는 것\n이런걸 대행해주는 프로세스를 MAA(Mail Access Agent) 라고 하는데 수신자측이 메일을 받으니까 MAA Server일거라고 생각하면 경기도 오산시 오산낙지다\n메일을 달라고 요청 해야되니까 통신을 먼저 시작하게 되고, 따라서 수신자 측이 MAA Client 이고 Mail Server쪽이 MAA Server 가 되는 것\n\n\n그래서 전체적인 과정을 정리해보면 수신자의 MTA Client가 자신의 Mail Server’s MTA Server로 보내고, 그 Mail Server’s MTA Client가 상대방의 Mail Server’s MTA Server로 보내면 메일함에 넣어놓고 존버하다가 상대방 컴터의 MAA Client가 Mail Server’s MAA Server로 메일함에 있는거 싹다 주세요 하면 그때 메일함에 있는거 보내주는 것\n따라서 위 그림에서 보이는것처럼 두개의 UA, 두개의 MTA Client-Server 쌍, 한개의 MAA Client-Server쌍이 필요하다\n\nUA, MTA, MAA §\n\n뭐 위에서 다 말하긴 했지만 총정리하면\nUA(User Agent) 는 참여자와 소통하며 메일 작성하거나 도착한 메일을 출력하거나 하는 식의 UI에 해당하는 작업 및 같은 시스템에 있는 Mail Server의 메일함에 메일을 넣거나 가져오는 작업만 가능한 프로세스이고\n\n뭐 옛날 고조선사람들은 Terminal Command형태의 UA를 사용했다네\n\n\nMTA(Mail Transfer Agent) 는 다른 시스템에 있는 Mail Server한테 메일을 보내려고 할때 사용되는 프로세스로 메일을 보내는쪽이 Client, 받는쪽이 Server가 되는 것이다\n\nClient가 메일을 보내는 쪽이기 때문에 Push Functionality를 제공한다고들 함\n\n\nMAA(Mail Access Agent) 는 다른 시스템에 있는 Mail Server한테서 메일을 받아오려고 할 때 사용되는 프로세스로 메일을 받는쪽이 Client, 보내는쪽이 Server가 된다\n\n얘는 Client가 메일을 받아오는 쪽이기 때문에 Pull Functionality를 제공한다고 표현하드라\n\n\n\nMIME §\n\n\n얘는 UA와 MTA사이에서 메시지의 인코딩을 담당하는 놈인데\nMTA는 7-bit NVT ASCII만 보낼 수 있다 - 즉, Printable Character만 보낼 수 있고 최상위 비트는 무조건 0이어야 된다는 것\n근데 옛날에야 뭐 텍스트만 보내도 흡족했지만 지금은 파일도 보내고 동야도 보내고 해야되는데 7-bit NVT ASCII로는 저런 bit stream을 보낼 수가 없음\n그래서 bit stream을 7-bit NVT ASCII로 변환하고 그걸 다시 bit stream으로 변환하는 역할을 하는놈이 MIME(Multipurpose Internet Mail Extensions) 이다\n인코딩방식은 여러개 있는데 대표적으로 니가 아는 그 Base64로 인코딩한담에 나머지 2비트는 00으로 채워서 보내고 받을때도 00빼고 합치는 식으로 한다\n\nSMTP §\n\n\nSMTP(Simple Mail Transfer Protocol) MTA 프로토콜로 제일 유명하고 현재 거의 유일하게 사용되고 있는 프로토콜이다\n통신은 Connection Establishment, Mail Transfer, Connection Termination순서로 진행된다\n\n\n\n위 그림처럼 MTA Client는 COMMAND ARGUMENTS …의 포맷으로 Commands를 보내며\n그에 대한 응답으로 MTA Server는 STATUS_CODE STATUS_MSG의 형태로 Response를 보낸다\n\n예시 §\n\n예시를 보면서 통신 과정 알아보자구\n\n\n\n위처럼 telnet $MAIL_SERVER_DOMAIN 25 명령어로 시작하게 된다\n당연히 $MAIL_SERVER_DOMAIN은 메일 서버의 도메인이고\n25는 포트 번호이다 - SMTP는 25의 포트 번호를 사용하더라\n\n\n\n그럼 이래됨 - 예제에서 분홍색은 Response이고 검은색이 Command이다\n일단 220은 Service Ready → 메일 서버가 준비되었다는 뜻임\n그럼 그상태에서 HELO $MAIL_SERVER_DOMAIN을 보내면 Connection을 시도하게 됨 - HELO가 주어진 도메인이랑 Connection을 하겠다는 Command임\nConnection이 이루어졌으면 250 메시지가 오게 됨 - 요청이 완료되었다는 것으로 Connection이 정상적으로 됐다는 소리임\n\n\n\n솔직히 걍 읽어봐도 뭔말알이긴함\nMAIL FROM $SRC로 보내는 사람 메일 주소 명시 가 가능하고\nRCPT TO $DST로 받는 사람 메일 주소 명시 가 가능하며\nDATA 로 이제 메일을 보내겠다고 알려주게 되며\n354가 오면 메일 내용을 적으면 됨\n그리고 Response Message의 &lt;CRLF&gt;.&lt;CRLF&gt; 에서 알 수 있듯이 개행 + . + 개행으로 메일 본문이 끝났다는 것을 명시하게 된다\n\n\n\n그리고 QUIT으로 Termination을 하게 된다\n\nPOP3, IMAP4 §\n\n\nPOP3(Post Office Protocol v3) 이랑 IMAP4(Internet Mail Access Protocol) 은 MAA프로토콜이다\n여기서 알아둬야 할것은\nPOP3와 IMAP4모두 user-name과 password를 서버에게 보내 인증하는 과정을 거친 다음에 Pull을 진행한다는 절차적인 거하고\nPOP3는 오래됐고 IMAP4는 비교적 최신에 나온 보안성이 강화된 프로토콜이랜다\n\nWeb Based Mail §\n\n이건 간단한건데\n간단하게 생각하면 Outlook같은걸로 메일 송수신할 수도 있고 아니면 브라우저 드가서 메일 송수신할 수도 있자네\n이런식으로 End user가 메일링 프로그램을 이용해서 SMTP로 메일을 보내는 것도 가능하지만 브라우저를 이용해 HTTP로 Mail Server에게 push를 하는것도 가능하다\n하지만 Mail Server간에는 여전히 SMTP로 통신함\n\nMail Server §\n\n일단 이메일을 받을때는 무조건 내 메일함이 있는 Mail Server의 MAA Server에게 보내는게 맞는데\n이메일을 보낼때는 내 메일함이 있는 Mail Server의 MTA Server로 보낼 필요는 없다 - 가까이 있는 Mail Server로 보내도 됨\n이건 왜냐하면 나의 메일함이 있는 Mail Server가 아주 멀리 있는 상황에서 나랑 가까운 놈한테 메일을 보낼때 저짝으로 보내게 되면 멀리 돌아서 메일이 도착하게 되는데 이건 매우 비효율적이기 때문\n따라서 예전에는 주변에 있는 아무 Mail Server의 MTA Server로 보내는게 가능했다 - 근데 요즘은 내 메일이 정체를 알 수 없는 Mail Server에 도착한다는 것이 보안상 좋지 않기 때문에 대부분의 Mail Server들은 사용자 인증과정을 거쳐 신뢰할만한 놈인지 확인한 다음에야 Mail의 수신을 받아준다\n\nFTP §\n\nFTP(File Transfer Protocol) 은 말그대로 파일을 전송할때 사용하는 프로토콜이고\n\n\n\nFTP에서 핵심적인 내용은 FTP는 TCP를 사용하며 Connection을 두개 맺는다는 것이다\n\n하나는 전송과정에서 Command를 주고 받기 위한 Connection이고 이것은 File Transfer Session이 지속되는 동안 계속 연결되게 된다\n그리고 나머지 하나는 실제로 파일이 전송되는 Connection이고 얘는 파일 하나가 보내질때마다 연결을 하게 된다 - 파일 하나를 보내고 나서 또 다른 파일을 보낼때는 연결을 끊었다가 다시 연결하여 전송하게 됨\n\n\n\nControl Connection §\n\n\nControl Connnection은 위에서 말한것처럼 File Transfer Session이 지속되는 내내 연결되어 있고 파일전송간 Command를 주고받기 위해 사용하는데\nPort 21을 사용하고\n7-bit NVT ASCII를 사용한다 - 당연히 Command만을 주고받기 때문에 Printable한 bitstream만 주고받게 됨\n\n\n\n그리고 SMTP와 유사하게 Client가 Command 와 Argument로 이루어진 요청을 보내고 Server가 그에 대한 응답을 3-digit code로 보내는 식으로 진행된다\n위의 예시는 그냥 읽어보는 걸로도 충분함\n\nData Connection §\n\n\nFile Transfer에서 Data를 보낼때의 어려운 점은 Command를 보낼때와는 다르게 파일 타입, 인코딩 방식, 파일 디렉토리의 구조들, 파일 이름 등등이 표준화시킬 수 없기 때문에 이러한 다양성을 극복해야 했다는 것이다\n뭐 이런 어려운 점만 있었고 이걸 어떻게 극복했는지는 몰라도 된댄다\n"},"originals/comnet.fall.2021.cse.cnu.ac.kr/13.-WWW,--HTTP":{"title":"13. WWW,  HTTP","links":[],"tags":[],"content":"\n\n                  \n                  충남대학교 컴퓨터공학과 김상하 교수님의 &quot;컴퓨터 네트워크&quot; 강의를 필기한 내용입니다. \n                  \n                \n\n\n\n                  \n                  다소 잘못된 내용과 구어적 표현 이 포함되어 있을 수 있습니다. \n                  \n                \n\nWorld Wide Web §\n\nwww : 전 세계적으로 연결된 정보 저장소\n\nClient, Server §\n\n익숙한내용이니까 금방금방 넘어가자고\n\n\n\n이런식으로 Client와 Server로 구성되어 있고 Server가 Web Page를 가지고 있으며 Client가 그걸 요청하면 전달해주는 식으로 돌아간다\n\n\n\n그리고 이건 Client쪽 Browser의 구조를 나타낸건데\nWeb Document들을 HTTP, FTP 등의 Client Protocol을 이용해 가져오고\n그걸 HTML, JS 등을 해석하는 Interpreter을 통해 화면에 뿌리게 되는데\n이때 어떤 프로토콜을 이용할건지, 그리고 그걸 받아서 어떤 인터프리터를 사용할건지 연결해주는 것이 Controller가 하는 역할이다\n\nURL §\n\nURL(Uniform Resource Locator) 는 Client가 자기가 원하는 정보가 Server의 정확히 어디에 있는지, 그리고 어떻게 가져와야 하는지를 명시하는 방법이다\n\n\n\n지긋지긋하제?\n제일 먼저 Protocol을 명시한다 - HTTP인지, HTTPS인지 등\n그리고 Host는 숫자 혹은 DNS로 표현된 서버의 IP를 나타낸다\nPort는 말그대로 포트번호고\nPath는 서버 내에서의 디렉토리 구조상에서의 위치를 나타내는 것\n\nCookie §\n\n얘가 뭔지는 이미 알테니까 얘를 왜쓰는지를 중점적으로 보면\nHTTP는 Stateless - Client의 상태를 저장하지 않음. 즉, Client가 누구인지, 이전에는 어떤 요청을 해왔는지 등을 Server는 저장하지 않기 때문에 모른다 - 이기 때문에\n작은 데이터 조각인 Cookie를 Client가 Server에게 요청을 보낼때 같이 보내 자신의 State를 알려주게 되는 것\n따라서 다음과 같은 용도로 사용될 수 있음\n\nSession Management : Client와 Server가 교류하는 기간을 하나의 Session이라고 한다면 해당 Session을 컨트롤하는 용도나\nPersonalization : Server로 하여금 Client 각각을 식별하게 하는 용도니\nTracking : Client의 행동을 기록하고 분석하는 용도로 쓰이게 된다\n\n\n\nWeb Documents §\n\nWeb Document는 Web에서 다루는 문서들을 의미하는 건데 이것도 아는거니까 금방금방 지나가자고\n\nStatic Document §\n\nServer에서도 별다른 작업을 하지 않고 Client에서도 받은 다음에 화면에 뿌려주기만 하는 문서\n뭐 Raw HTML 파일 이 여기에 해당한다고 할 수 있다 - HTML파일을 요청하면 그냥 Server에서도 요청받은 HTML파일 주면 되고 Client에서도 그거 그냥 렌더링하면 되니까\n그래서 Client는 Static Document를 요청할때마다 같은 결과물을 받게 된다\n\nDynamic Document §\n\n클라이언트의 요청에 대해 Server가 동적으로 Document를 만들어서 제공해주는 문서\n뭐 php의 경우에도 그렇고 전에 DB 텀프할때도 nodejs로 html 생성해서 응답했자네 - 이런거 말하는거임\n따라서 Client는 Dynamic Document를 요청할때마다 그 결과물이 달라질 수 있다\n\nActive Document §\n\n이건 Client의 요청으로 Server가 보내준 파일이 Server에서 렌더링해서 준게 아니고 Client가 직접 렌더링해야되는 문서를 말한다\nJS 말하는거같은데 좀 다른거같다 - 수업때는 Java Applet이라는거 알려주던데\n\n\n\n위 그림처럼 요청에 대해 Applet을 응답하고 이것을 Client 쪽에서 실행시켜서 결과물을 얻는댄다\n\nHTTP §\n\nHTTP(HyperText Transfer Protocol) 은 Web Document를 통신하기에 최적화된 Application Layer Protocol이다\nHTTP는 FTP와 SMTP를 합쳐놓은 것과 비슷하게 작동하는데, 몇가지 차이점이 있다\n\n우선 파일 전송이 가능하다는 점에서는 HTTP와 FTP가 동일하지만, HTTP는 TCP Connection을 하나만 하는 반면에 FTP는 두개를 한다\n그리고 (파일을 전송하더라도 문서화하여 전송하기 때문에)문서의 형태로 통신한다는 점에서는 SMTP와 유사하지만 SMTP는 보통 Mail Server를 거쳐서 통신하는 경우가 많지만 HTTP는 목적지 서버로 바로 달린다는 점에서 차이점이 있다\n\n\n근데 강의시간에서는 PDF에서 소개된 SMTP와의 차이점은 부정확하댄다 - SMTP도 서버로 바로 보낼 수 있기 때문\n싱하형이 말한 FTP 혹은 SMTP와 HTTP의 가장 큰 차이점 은 FTP나 SMTP의 경우에는 Application Layer Level에서 Command를 사용해 Connection을 맺고 할일을 한 뒤에 또 Command를 이용해 Termination을 하게 되지만 HTTP에서는 그런거 없이 Command도 보내는 메시지에 포함시켜 한번의 통신으로 결과물을 받아낸다는 것이다\n그리고 이러한 성질이 HTTP에서의 Stateless와 연결되는데 FTP나 SMTP의 경우에는 Command가 오가며 연속적인 흐름이 존재하지만 HTTP는 한번 왔다갔다하면 끝이기 때문에 이러한 Stateless가 생기게 된다더라\n\n\n알고있었겟지만 HTTP는 TCP를 이용하고 Well known port로는 80번을 사용한다\n\nHTTP Transaction §\n\n\n반복학습이 짱이야 그지\n일단 웹프에서 배운 내용 다시 짚어보면 HTTP의 메시지 포맷은 요청의 경우 Request Line, 응답의 경우에는 Status Line이 드가고 그 다음부터는 둘 다 Header가 드간 뒤 한칸 공백을 두고 Body가 드가게 된다\n\n\n\n그리고 Request Line의 경우에는 METHOD URL HTTP_VER이런식으로HTTP 메소드와 URL, HTTP 버전이 공백을 두고 한줄에 위치하고\nStatus Line의 경우에는 HTTP_VER STATUS_CODE STATUS_MSG 이런식으로 HTTP버전과 상태코드, 상태메시지가 공박을 두고 한줄에 들어가게 된다\n이제 웹프에서와는 좀 다른 시각으로 이 메시지들을 보면\nSMTP와 좀 비교를 해보면 만일 HTTP 메시지를 SMTP로 바꿔보면 Request Line에 있던것들이 Command로 보내질 수 있고 Status Line에 있던애들이 Responce로 보내질 수 있으며 나머지 Header와 Body는 메일의 Content로 들어가는 식으로 연관지을 수 있다\n\nSMTP에서 무슨 요청을 보낼건지와 어디로 보낼건지 등을 Command로 보냈듯이 HTTP의 경우에는 그런것들이 다 첫번째 줄에 들어가게 되기 때문\n\n\n즉, 위에서 말한 HTTP는 SMTP와는 다르게 Command나 Response까지 전부 하나의 메시지에 합쳤다는게 바로 이소리임\nMethod와 Status Code에 대해서는 너가 아는 정도로도 충분하다 - 모르면 검색해\n\nHeader §\n\n\nHTTP에서 요청과 응답에 대한 다양한 정보들을 Header에 담게 되는데\n위처럼 HEADER_NAME: HEADER_VALUE의 포맷으로 명시된다\n헤더의 종류에는 4가지가 있다는것 정도와 각각의 대표적 예시 몇개 챙거가거라\nGeneral Header : 특정하게 분류하지 않은 공통적인 내용\n\nDate : 날짜\nMIME-version : HTTP 메시지의 경우 7-NVT ASCII만을 송수신 할 수 있기 때문에 SMTP에서처럼 Non-printable bitstream은 인코딩이 드간다 - 이때 사용되는 MIME의 버전을 나타내는 것\n\n\nRequest Header : Client가 보내는 요청에 대한 정보들\n\nAccept : Client가 원하는(받아들일 수 있는) 파일 형식\nAuthorization : 요청에 필요한 권한을 담는 부분\nHost : 요청을 받아줄 Server의 host와 port\n\n\nResponse Header : Server가 보내는 응답에 대한 정보들\n\nServer : 응답을 보내는 서버에 대한 정보\n\n\nEntity Header : 응답으로 보내는 Body에 대한 구체적인 정보들\n\nContent-length : 응답 Body의 길이\nContent-type : 응답 Body의 파일 파입 - 웹프에서 말한것처럼 파일을 처리하는 방법만 알려주면 모든 종류의 파일을 송수신하고 받아서 사용할 수 있게 할 수 있다는데 이부분이 그거임 - 파일의 타입을 명시해서 Client가 bitstream을 어떻게 처리해야될지 알려주게 됨\n\n\n\n\n\n예시 - 읽어보고 그렇구나만 해주면 됨\n\nPersistent VS Non-persistent §\n\n일단 Persistent Strategy는 한번의 Request - Response에서 한번의 TCP Connection을 맺었다가 끊는 것을 말하는데\n당연히 이건 비효율적 이다 - 왜냐하면 TCP는 기본적으로 Three Handshake를 해서 Connection을 한 다음에 데이터를 전송하고, 전송한 다음에는 Terminate를 하기 때문에 데이터 전송 앞뒤로 추가적인 과정이 붙어 전송세션을 오래 끄는게 이득이고\n앞에서 배운것처럼 TCP는 Slow Start를 하기 때문에 전송속도가 느리게 시작해서 점차 빨라지게 된다 - 따라서 전송을 짧게 여러번 하면 Slow Start를 여러번 하게 되므로 그만큼 평균속도는 느려지는 것\n그래서 Non Persistent Strategy는 TCP Connection을 한번 하고 나면 Request - Response를 여러번 하고, 만일 일정기간동안 Request - Response가 없으면 그때 Terminate되는 Time out 전략을 쓰는 것을 의미한다\n저번에 어떤새끼가 블로그에서 HTTP는 한번의 Request - Response에서 한번의 TCP Connection을 맺었다가 끊는다 라고 Persistent 전략을 사용하는 것으로 말해놨는데\n저것도 어느정도는 맞는말일수도 있지만 HTTP1.1부터는 Non Persistent를 Default로 하고 있다\n\nProxy Server §\n\nHTTP는 Proxy Server기능을 제공하는데 이건 원래 서버의 기능을 대리해주는 서버를 말한다\n이게 뭔말이냐면\nClient A가 B를 거쳐서 Server C에게 요청을 하고 받는 과정에서\nB는 C가 보내는 응답을 저장해놓고 있다가\n또 다른 Client D가 B를 거쳐서 C에게 요청을 하면\n그 요청이 C까지 안가고 B가 저장해놓은 응답을 보내주는 것을 말함\n즉, Proxy Server는 원래 Server의 응답을 저장해놨다가 누군가가 요청을 해오면 원래의 Server까지 안갔다와도 되게끔 Proxy Server가 대신 응답함으로써 응답을 좀 더 빨리 받을 수 있게 하는 것을 의미한다\n당연히 이 기능을 이용할때도 DNS의 Authorize기능처럼 해당 응답이 원래의 Server가 아니고 Proxy Server에서 왔음을 Client에게 알리게 된다\n\nHTTP/2 §\nProblems of HTTP 1.x §\n\nHTTP 1.x의 문제점은 한번에 하나의 Request - Response가 가능하다는 것이다\n뭐 HTTP 1.1부터는 Non Persistent가 됐다고 하더라도 이건 TCP를 연결하고 끊는 시간 낭비를 줄이는 정도이고\n하나의 Request를 보내고 나면 그것의 Response가 올때까지 Client는 추가적인 요청을 할 수가 없다\n따라서 하나의 웹페이지를 구성하기 위해서는 많은 Resource들이 필요한데 얘네들을 Parallel하게 보내지 못하고 Sequential하게 보내기 때문에 필요한 Resource들을 모두 요청하고 받는데까지 시간이 오래걸려 웹페이지 로딩이 오래걸리게 되는 것\nHTTP에서도 Parallel하게 요청을 보낼 수 있는 방법이 있긴 하다 - TCP Connection을 여러개 맺으면 Parallel하게 보낼 수는 있지만 TCP는 연결할때 Buffer도 준비해야 하고 Handshake도 해야 하는 등 사전준비가 많이 필요한 작업임 - 따라서 TCP Connection을 여러개 맺는 것으로도 속도 저하는 해결하지는 못한다\n이런 HTTP 1.x에서의 Parallel하게 요청을 보내고 받지 못하는 문제를 Head-of-Line Blocking이라고 한다\n\nHTTP/2 §\n\n위와 같은 배경에서 HTTP/2가 등장하게 되는데\nHTTP/2를 설계할때 가장 중점적이 되었던 것은 아래의 세 가지 이다\n\n기존의 HTTP Message Interface가 바뀌어서는 안된다는 것\n\n즉, HTTP 1.x에서의 HTTP Method, Status Code, URI, Header Field등이 이전과 동일해 HTTP Protocol을 이용하는 입장에서는 HTTP 1.x과 HTTP/2간의 호환성 문제가 생기면 안된다는 것\n\n\nParallel Request - Response가 가능해야 된다는 것\nTCP Connection은 기존과 동일하게 하나만 유지할 것\n\n\n\nRequest - Response Multiplexing §\n\n이제 위와 같은 문제점들을 어떻게 해결했는지 확인해보자고\n\n\n\nParallel과 Single TCP Connection을 모두 잡는 것의 핵심은 Multiplexing을 이용하는 것이다\n즉, Parallel하게 정보를 전송할 수 있도록 Bidirectional Stream을 여러개 제공하여 각 Stream에 병렬적으로 Message를 송수신 할 수 있게 하는 것\n그리고 Stream들을 하나로 모으는 Multiplexing을 한 다음 수신지에 도착해서는 그것을 다시 Demultiplexing하여 양 끝단에서는 마치 TCP Connection을 여러개 맺은 것 같은 착각에 빠지게 한다\n그래서 위 그림처럼 되는거임 - 여러개의 Stream에서 나온 Frame들이 일렬로 쭉 들어선 모양으로 Multiplexing되어 Single TCP Connection을 타고 가게 되고 도착해서는 다시 Demultiplexing되는 것\n\n저런식으로 여러개의 Stream에서 나온 Frame들이 일렬로 사이사이 끼어들어간 형태로 전송되는 것을 Interleaved Sequence of Frames라고 표현한다\n\n\n근데 위 그림에서 보이는 것처럼 Message단위로 전송되는게 아니라 이게 작게 Disintegrate되어서 Frame단위로 송신하고, 수신한 뒤에는 Frame들을 Reassemble하여 원래의 Message로 복원하는 작업을 하게 됨\n\n\n\n\n그럼 위에있는 그림도 어느정도 이해가 갈거임 - 한개의 Connection안에 여러개의 Stream이 있고 해당 Stream으로 양방향으로 Request와 Response가 오가는 형태\n따라서 Message들을 어떻게 Frame으로 잘라서 Multiplexing하냐가 관건인데 이를 담당하는 곳이 바로 Binary Framing Layer이다\n\n용어정리 §\n\nBinary Framing Layer를 설명하기에 앞서 용어정리를 딱 하고 넘어가면\n\nMessage는 HTTP API에서 사용하는 그 메세지(Line, Header, Body가 7-bit ASCII로 적혀있는)이고\n\n즉, 하나의 완성된 Request혹은 Response를 말하는거임\n\n\n그리고 Stream들에 의해 Message들이 Parallel하게 양방향으로 오가고\nFrame은 Multiplexing을 하기 위해 Message를 여러 조각으로 자른 것을 의미한다\n\n또한 Multiplexing과 Demultiplexing을 하기 위해서는 이 Frame이 어느 Stream에서 왔는지 알아야 하기 때문에 Stream Identifier가 Frame마다 붙게 된다\n이 Frame이 HTTP/2 Communication의 제일 작은 단위가 됨\n\n\n\n\n\nBinary Framing Layer §\n\n\n얘는 일단 뭐 이름부터가 Layer인 것 처럼 HTTP/2에서의 Sublayer라고 보면 된다 - HTTP 안에서 하부에 위치해있는 Layer\n\n따라서 HTTP 상단부를 HTTP API라고 부르고 Binary Framing Layer는 아래의 Socket Layer와 HTTP API사이에 끼어있는 계층이 되는 셈\n\n\n얘가 하는 일은 크게 세가지 인데\n\n\nMessage를 잘라서 Frame으로 Disintegrate하고\nFrame들을 Binary로 변환하는 일\n위에서 말한 Streaming과 Multiplexing\n\n\n우선 왜 Frame들을 Binary로 바꾸는 짓을 하나면\n\n기존의 Message는 Text-Driven 7-bit ASCII이고 CRLF같은 Delimiter로 한줄한줄이 구분되어 있는데\n이것을 컴퓨터가 알아듣기 위해서는 마치 Interprete하는 것 같은 과정이 필요하다 - 따라서 Binary로 표현하는 것이 컴퓨터 입장에서는 Compact 한 Representation인 것\n\n\n그리고 위에서 Multiplexing하기 위해 Message들을 Frame단위로 자른다고 했는데 이걸 으케하냐면\n\nHeader는 하나의 Frame안에 다 우겨넣고\nBody는 크기가 클 경우만 Frame들로 소분하게 된다\n\n\n그래서 종합해보면 Binary Framing Layer는 HTTP 메세지들이 어떻게 캡슐화되는지(Encapsulated), 그리고 전송되는지(Transfered)를 담당한다고 생각할 수 있다\nHTTP/2를 이렇게 설계함으로써 HTTP 1.x만을 지원하는 기기와는 통신이 불가능하다는 단점이 있지만\nHTTP API의 변화는 없기 때문에 HTTP를 사용하는 Application에의 변화는 불필요하다는 장점을 취하게 되는 것\n\nStream Prioritization §\n\n\n근데 이제 원래의 메세지를 Frame단위로 쪼개서 보내게 되면 순서가 중요한 경우에는 받는놈 입장에서 뭐가 앞에 있었고 뭐가 뒤에 있었는지 모른다\n그래서 위처럼 선후관계를 Edge로 하고, 각각의 Frame에 우선순위가 존재하는 Prioritization Tree를 각 Stream마다 두게 되고 그것을 이용해 Receive를 하게 된다\n뭐 어떻게 그리는지는 신경쓰지 마셈\n\nServer Push §\n\n\nHTTP는 Server Push라는 기능도 제공하는데 이게 뭐냐면\nClient가 요청을 했을 때 요청한 것 외에도 추가적으로 필요할거 같은 것을 Server가 추가적으로 보내주는 것\n수동적인 포지션에 있는 Server가 요청받지 않은 것을 자의적으로 파일을 보내주기 때문에 Server Push라는 이름이 붙은거라고 생각하면 됨\n다르게 말해보면 Request 하나에 대해 Response를 여러개 보내는 것이라고 말할 수도 있는 것\n서버가 클라이언트가 필요한것을 어케 아냐고 궁금증을 갖지 마셈 - 뭐 적당히 알아낸댄다\n이렇게 하는 것의 이점은 Client가 요청을 하지 않아도 Server가 연관된 Resource들을 같이 보내주기 때문에 그것들에 대한 요청을 Client가 하지 않아도 되고, 따라서 통신의 Latency가 더 줄어들게 된다\n\nHeader Compression §\n\n\n얘는 자주 쓰이는 Header Field와 Value 쌍들을 테이블에 저장해놓고 해당 Header 쌍에 대해서는 Header쌍 전체를 보내는 것이 아니라 그 인덱스만 보내서 Header의 크기를 획기적으로 줄이는 방법이다\n현재 통신과 상관없이 자주 사용되는 Header 쌍에 대해서는 Static Table에 저장이 되어 있고\n현재 통신에 한정에서 자주 사용되는 Header 쌍은 Dynamic Table에 동적으로 추가가 되는데\n위의 예제를 보면 method: GET같은 경우에는 경장히 자주 사용되는 Field - Value 이기 때문에 Static Table에 저장이 되어 있고\nhost: example.com은 다른 통신에서는 host값이 달라지기 때문에 흔하게 사용된다고 할 수는 없지만 적어도 현재의 통신에서는 여러 Request에 걸쳐 host가 바뀌지 않을 것이기 때문에 Dynamic Table에 드가게 되는 것\n따라서 이러한 테이블에 근거해서 왼쪽의 Request Header가 오른쪽처럼 축약되는 것이다\n근데 위의 예시를 보면 Table에 들어있지 않은 Header 쌍에 대해서는 Huffman Code라는 것을 이용해서 표현되게 되는데 이게 뭔지는 궁금하면 찾아보고 그냥 저걸 이용해서 Table에 있지 않은 Header쌍에 대해서도 크기를 줄일 수 있다는 것 정도만 알아두거라\n"},"originals/comnet.fall.2021.cse.cnu.ac.kr/14.-SNMP":{"title":"14. SNMP","links":[],"tags":[],"content":"\n\n                  \n                  충남대학교 컴퓨터공학과 김상하 교수님의 &quot;컴퓨터 네트워크&quot; 강의를 필기한 내용입니다. \n                  \n                \n\n\n\n                  \n                  다소 잘못된 내용과 구어적 표현 이 포함되어 있을 수 있습니다. \n                  \n                \n\nNetwork Management §\n\nNetwork Management는 네트워킹 전반에 걸쳐 초기 세팅을 한다거나 어딘가에서 문제가 생기거나 했을 때 대응을 하는 것을 의미한다고 할 수 있음\n이렇게 말하면 잘 이해가 안되는데\n이 5가지 기능 보면 좀 이해가 될거임\n\n\nConfiguration Management : 어떤 네트워크를 처음 구동시킬 때 네트워크 장비들을 초기화시키는 기능\nFault Management: 네트워크 장비가 고장나거나 이상행동을 할때 알려주는 기능\nPerformance Management: 네트워크의 성능에 대해 체크 - 뭐 전송하는데 얼마나 걸리는지, 어디에 트래픽이 몰리는 지 등 - 하는 기능\nSecurity Management: 네트워크의 보안성에 대해 체크하는 기능\nAccounting Management: 네트워크 사용량과 관련해서 과금 청구(돈내놔)와 관련된 일을 하는 기능\n\n\nFault, Configuration, Accounting, Performance, Security 앞글자를 따서 FCAPS라 부른다\n\nSNMP §\n\nSNMP(Simple Network Management Protocol) 은 위에서 소개한 Network Management를 하기 위한 프로토콜임\n여기에서는 Manager-Agent Model을 사용한다\n\n\n\n그래서 일반적으로 위처럼 구성됨\n보면 1개의 Manager가 Client 로 기능하고 다수의 Agent가 Server 로 기능하는데\n약간 지금까지 봐오던 구조와는 다르다 → 일반적으로는 하나의 Server와 Client가 존재하는 식 이었는데 SNMP에서는 1개의 Client가 있고 다수의 Server가 있음\n이것도 이전에 배운 Client Server의 개념을 되살리면 어떻게 구동되는지 알 수 있다 - SNMP에서는 1개의 Manager가 다수의 Agent들에게 요청을 하고 그 결과를 받아오는 셈\n여기서 Manager는 SNMP Client가 돌고 있는 컴퓨터를 의미하고 Agent는 라우터를 포함한 모든 네트워크 장비들을 말하게 된다\n즉, 라우터를 포함한 모든 네트워크 장비를 하나의 Manager 가 관리하고 모니터링하고 있는 셈\n그래서 Agent에는 몇가지의 변수가 있고 여기에 Management항목들에 대한 값들이 저장되어 있다\n\n뭐 위에서 말한 FCAPS와 관련된 변수들이 SNMP Server Process 에 변수로 저장되어 있는 것\n\n\n그리고 Manager는 Agent에게 요청을 보내 해당 변수의 값을 달라고 하거나 세팅하라고 요청한다\n\n\n\n따라서 위의 그림처럼 되는거임 - Manager는 각 Agent의 상태를 알기 위해 Agent들에게 GET으로 Agent Variable를 달라고 하거나 SET으로 어떤 값을 가지게 강제할 수 있다\n근데 저기 보면 Trap이라는게 있다 - Manager는 Client고 Agent가 Server라고 했는데 항상 이런 것은 아님 - 중대한 문제가 생겨 Manager에게 경고를 하는 것을 Trap이라고 하고 이때에는 Agent가 먼저 통신을 하기 때문에 Agent가 Server가 되고 Manager가 Client가 되는 것\nSNMP는 Network Management를 하기 위해 SMI와 MIB라는 두 프로토콜을 같이 이용함 - 얘네들은 약간 통신을 위한 규격(표준)을 정해놓은 것이다 - 즉, 다른 프로토콜처럼 통신이 어떤 방식으로 일어나는지에 초점을 맞춘 것이 아니고 정보의 Format을 정한 셈 - 그래서 어찌보면 프로토콜보다는 그냥 표준에 더 가까워보이기도 한다\n\nSMI §\n\nSMI(Structure of Management Information) 은 Agent Variable의 규격에 대한 프로토콜이다\n이게 뭔소린고 하니\nAgent Variable은 말 그대로 변수고 여기에 정보가 저장된다고 했자네\n그리고 Agent하나에는 이런 Agent Variable이 여러개가 있고\n이때 Agent Variable을 어떻게 이름붙일건지(Name)\n해당 Agent Variable은 어떤 자료형인지(Type)\n그리고 Agent Variable의 값을 네트워크를 통해 전송하려고 할 때 어떻게 인코딩할 것인지(Encoding)에 대한 규격을 정한 것이다\n\nName §\n\n일단 우선 알아야 될 것은 Agent Variable을 Object라고도 부르며 따라서 Object Identifier는 Agent Variable의 Name이라고 받아들이면 된다\nObject ID는 트리 형식으로 작명이 됨\n뭔소린고 하니\n\n\n\n약간 이렇게 생각하면 됨 - 카테고리가 있어서 어떤 변수를 특정하기 위해 카테고리를 내려오며 범위를 좁히면서 결국에는 하나를 결정하게 되는 것\n그래서 Root가 있고, Root에서부터 내려오면서 Label들을 (.)으로 연결하는 식으로 범위를 좁혀오다가 결국에는 Object하나가 특정되는 것\n그리고 각 Node에는 숫자가 부여되어 있어서 문자열 Label 말고 숫자들을 (.)으로 연결하면 이제 그게 Object ID가 되는 것이다\n약간 감이 올랑말랑 하제\n잘 모르겠으면 그냥 DNS마냥 Tree Namespace가 있고 이번에는 Root에서부터 내려오는 식으로 Object의 Name이 부여된다고 생각하면 된다\n그니까 DNS의 Name이랑 비슷하다고 생각해도 된다 - DNS에서는 Name을 주면 IP가 왔듯이 여기서는 Name을 주면 그에 대한 Object Value가 오게 되는 것\n\nType §\n\n이건 뭐 뻔한 얘기임\nObject의 값이 bit 로 표현되어 있는데 이때 이 데이터를 어떻게 해석할지에 관한 것\n그래서 뭐 언어마다 다양한 타입이 존재하는데 여기서는 ASN1 표준 타입 선언에 몇가지를 추가한 Type을 사용한댄다\n그래서 Simple Type은 그냥 정수나 문자, 같은 기본 자료형\nStructured Type은 배열이나 구조체인데\n\nSequence가 구조체고\nSequence of가 배열을 나타낸다\n헷갈리쥬\n\n\n\n\n\n그래서 뭐 이런 타입들이 있댄다\n\nEncoding §\n\nEncoding은 이제 Manager의 요청에 따라 Object의 값을 전달하거나 아니면 Object의 값을 설정하려고 할 때 그 ‘값’들이 네트워크를 따라 이동하게 될 텐데 이때 이것을 어떤 형식으로 주고받을 것이냐에 관한 것이다\n약간 이렇게 생각하면 됨 - DNS할때는 Name을 보내면 IP가 오니까 타입은 IP고 길이는 4이고 값도 뭐 4byte 값이니까 굳이 Encoding을 정하지 않아도 됐었지만\n이번에는 Name에 대한 값이 타입도 여러개고 길이도 가변적이기 때문에 타입과 길이, 그리고 실제 값도 묶어서 인코딩한 다음에 전송하게 되는 것이라 생각하면 된다\nSMI는 BEM(Basic Encoding Method) 라는 방법을 이용해 Encoding한다\n이전에 배운 DER인코딩같은거다 - DER인코딩은 ASN1 형식의 구조체를 Binary로 바꾸는 것 이었고 BEM은 SMI에서 사용하는 구조체(혹은 뭐 배열이나 그냥 값 등)을 Binary로 바꾸는 것이다\n그래서 BER에는 Tag, Length, Value세개가 들어감\nTag는 첫 1바이트에 들어가고 여기에는 Type에 대한 값이 들어간다\nLength는 그 다음 1바이트에 들어가고 여기에는 Value의 길이가 들어간다\n\n타입이 정해지면 Length가 정해지는 거 아닌가라고 생각할 수 있는데 그렇지 않은 듯\nType을 정해도 그것의 길이 또한 임의로 지정하는 것이 가능하다\n\n\nValue는 말 그대로 값임\n\n\n\n그래서 위 예시 보면 딱 감 올거임\n저런식으로 Tag-Length-Value순서대로 묶여서 BER인코딩되고 그것이 통신할때의 값에 대한 포맷이 되는 것\n뒤에서 실제 예시를 보면 알겠지만 Nested구조를 갖는 것도 가능하다\n즉, SEQUENCE 7 INTEGER 1 4 STRING 2 H I이런식으로 BER안에 또 다른 BER이 들어가는 식으로 Nested 된 구조를 표현할 수도 있다는 것 기억\n\nMIB §\n\nSMI에서는 그냥 트리 구조를 이용해 Naming을 하자 라고 규격을 정해 놓은 거고\nMIB(Management Information Base) 는 이제 실제로 어떻게 Naming이 되어 있냐 에 관한 것임\n약간 SMI와 MIB에서 등장하는 Tree구조 Naming방식 기억두면 좋다 - 암호키 Naming방식에서도 이런 Tree구조를 이용한 Naming방식으로 Object ID 규격을 정의하고 있음 - 표준 규격에서 많이 사용하는 방식이더라\n\n\n\n그래서 위처럼 되는거임\n일단 MIBv2는 트리상에서 1.3.6.1.2.1에 위치하고 있음 - Tree에 통신에 관한 부분(MIB)만 있는게 아니라 다른것도 다 있나봄\n그래서 그 중에서 또 udp에 관한 Object ID를 알아내고 싶으면 1.3.6.1.2.1.7 로 가게 되고\n거기에서 또 아래로 내려가면서 어떤 것에 대한 실제 Object ID가 정의되게 된다\n아 뭔가 감이 왔다갔다하는데\n러프하게 생각하면 Tree전체에 Computer Science에서 등장하는 개념들이 계층형태로 다 박혀있고 어떤 하나의 개념을 찾기 위해서는 Root부터 내려오면서 찾으면 되고 찾았으면 그것이 그 개념에 대한 Object ID가 되는 것이다\n그래서 Agent에 저장될때도 변수의 이름이 저 값을 사용해서 저장되는 셈인거지 - udpTable에 관한 것은 1.3.6.1.2.1.7.5의 이름으로 Agent에 저장되어 있고 Manager는 저걸로 GET이나 SET등을 하게 되는 것\n그니까 말그대로 이름에 대한 규격인 거다\n아몰라ㅅㅂ 대충 감은 오시쥬?\n\nSNMP §\n\n일단 SNMP에서 제일 중요한건 PDU이다\n\n\n\nPDU는 위 그림처럼 8종류가 있는데 HTTP Method같은거라고 생각하면 됨 - 따라서 PDU Type은 Method Type같은놈임\n\n\n\n그래서 위 그림처럼 하나의 PDU가 구성된다 처음에 PDU Type이 들어가고, 그 다음에 나오는 3개는 몰라도 되고, 마지막에 등장하는 Variable Bind List에는 요청으로 보내는 Variable(Object ID)이나 그것에 대해 응답으로 돌아오는 Variable Value등이 저장되는 것\n따라서 GET Request에 {Object ID} 이렇게 보냈다면 그것에 대한 요청으로는 {OID, Value}으로 오게 되는 것\n\n\n\n그래서 전체적인 구조를 보면 위와 같은 모습임\n일단 여기서 중요한거 첫번째는 PDU가 그거 하나만 달랑 가는게 아니고 Version, Header등을 다 포함한 완성된 메세지에 담겨서 간다는 것이랑\n구조체로 표현된 메세지가 Nested BER로 인코딩된다는 것이다\n그래서 위 그림에서 오른쪽 보면 일단 맨 위에 30 34 가 의미하는 바는 SEQUENCE 34, 즉, 전체가 구조체고 34바이트라는 의미인 것\n그 다음으로 나오는 02 01 03보면 INTEGER 1 3이고 이건 SNMP의 버전이 3임을 나타내는거임\n그 다음 30 0C는 SEQUENCE 12이고 이 뜻은 이 다음부터 또 Nested된 구조체가 등장한다는 거고 그것의 길이는 12바이트라는 것 - 왼쪽을 참고하면 여기에 이제 Header들이 담기게 된다\n뭐 이런식으로 저 구조체가 전부 BER로 바뀌어 통신되게 되는것\n\nSNMP Port §\n\n\n이건 뭐 간단하다\nSNMP Manager는 162 Well Known Port가 열리고 당연히 이건 SNMP Manager Server의 Port니까 Trap을 수신하는 용도겠지\nSNMP Agent는 161 Well Known Port가 열리고 이것도 SNMP Agent Server의 Port니까 GET이나 SET등을 수신하는 용도인거다\n그래서 위 그림 보면 이해됨\n"},"originals/comnet.fall.2021.cse.cnu.ac.kr/부록---시험대비)-싱하형배-컴퓨터-네트워크-모의고사-정답":{"title":"부록 - 시험대비) 싱하형배 컴퓨터 네트워크 모의고사 정답","links":[],"tags":[],"content":"\n\nFall 2021, CNU, Computer Networks by Prof. Sang-Ha Kim\n\nOverview §\n\nPhysical layer, Data link layer, Network layer, Transport layer, Application layer 각각에 대한 주된 역할(기능)을 적으라\n\nPhysical layer : bit를 전기 신호로 전송함에 있어서 통신 회선에서 발생할 수 있는 물리적인 오류를 최소화 하는 것을 목표로 하는 계층\nData link layer : Hop to Hop(Node to Node)통신의 무결성을 보장하기 위한 계층. Hop to Hop의 통신에 있어서 에러가 났을 경우 Error Detection과 Correction의 방법을 이용해 에러를 해결하고, 물리주소 체계를 이용해 목적지 Node를 정확히 찾아가게 하는 것을 담당한다.\nNetwork layer : Source to Destination 통신을 가능하게 해주는 계층. 논리 주소 체계를 이용해 여러번의 Hop to Hop 통신을 거치는 과정에서 원래의 목적지까지 도달할 수 있는 경로를 제공한다.\nTransport layer : Process to Process 통신의 무결성을 보장하기 위한 계층. Routing시에 발생할 수 있는 Queue Overflow 에러를 해결하고, Port번호를 통해 Destination host의 특정 Process에게 데이터가 전달될 수 있도록 한다.\nApplication layer : User application에서 네트워크 통신을 이용할 수 있도록 하는 것을 제공하는 계층\n\n\n각 Layer를 코드로 구현함에 있어서, Transparency의 의미와 숨겨여야 하는것, 그렇지 않은 것에 대해 설명하고(1) Send와 Receive 함수 Call의 방향성에 대해 설명하시오(2)\n\nLayer를 코드로 구현함에 있어서 Transparency는 각 계층을 Encapsulation하여 다른 계층의 작동 원리를 알지 못하게 하는 것이다. 따라서 어떤 계층에서의 작동 과정과 자료 구조는 다른계층에서 알 수 없도록 숨겨져야 한다. 하지만 다른 계층의 주소는 숨길 필요가 없다.\n네트워크 모델은 계층 구조로 설계되었기 때문에 항상 함수 Call은 상위계층에서 하위 계층으로 이루어져야 하고 하위 계층에서는 상위 계층의 함수를 호출할 수 없다. 따라서 Receive함수의 경우에도 상위계층에서 하위 계층의 Receive함수를 호출하고, 하위 계층에서 상위 계층으로의 데이터 이동은 해당 함수의 반환값으로써 상위계층으로 전달되게 된다.\n\n\n\nNetwork Layer §\nPacket Switching §\n\nPacket Switching을 제공하는 장비의 이름을 적고(1) Packet Switching의 개념을 해당 장비의 구조와 연관지어서 설명하시오(2)\n\nPacket Switching을 제공하는 장비의 이름은 Router이다\nRouter는 여러개의 Network Interface가 장착되어 있는데 각각의 Network Interface에는 송수신 통신 회선이 연결되어 있다. 또한 각각의 Network Interface은 수신된 패킷들이 저장되는 Input Queue와, 송신할 패킷들이 저장되는 Output Queue로 구성된다. Packet Switching이라는 것은 어떤 한 Network Interface의 Input Queue에 있는 패킷을 Routing 을 통해 어떤 Network Interface의 Output Queue로 옮겨야 되는지를 정하고, 해당 Output Queue로 Packet을 옮기는 것을 의미한다.\n\n\nDatagram과 Virtual Circuit에 대해 이들이 시작될때 공통적으로 행해지는 작업에 대해 적고(1) 이들의 핵심적인 차이점에 대해 Connection-oriented, Connectionless, Orderly Delivery의 개념을 포함하여 적어보거라(2). 그리고 각 Packet Switching방법을 사용하는 프로토콜(서비스) 에 대해 적어보고, 어느것이 먼저 세상에 나왔는지를 그 이유와 함께 적어보거라(3). 또한 각각의 방법이 가지는 강점에 대해 설명해보아라(4).\n\n우선 상위 계층에서 내려온 데이터를 Packet단위로 단편화하고, 각각 Packet들에 대해서 논리주소 등의 정보를 포함한 Packet Header를 붙이는 작업은 Datagram과 Virtual Circuit 모두 행해진다.\n이들의 핵심적인 차이점은 단편화한 Packet들이 어떻게 목적지까지 도달하게 되는지에 있다.\nDatagram은 단편화된 Packet들이 어떠한 경로를 통해 목적지까지 도달하는지에 대해 제약을 걸지 않는 반면, Virtual Circuit의 경우에는 단편화된 패킷이 모두 같은 경로를 통해 목적지까지 도달할 것을 요구한다.\n여러개의 패킷들이 같은 경로를 따라 목적지까지 가기 위해서는 패킷들이 전송되기 전 미리 경로를 설정하는 작업을 수행하게 되는데, 이것을 Connection이라고 한다. 따라서 Virtual Circuit의 경우에는 Connection을 수행해야 하므로 Connection-oriented Packet Switching인 것이고, Datagram의 경우에는 Connection이 필요가 없으므로 Connectionless Packet Switching이라고 말할 수 있다.\n항상 같은 경로를 따라가야 하는지의 여부는 패킷의 도착 순서에도 영향을 미치게 된다. 항상 같은 경로를 따라 가야 하는 Virtual Circuit의 경우에는 패킷이 전송 순서대로 경로를 지나가기 때문에 목적지까지 도달할때도 송신의 순서와 동일하게 수신된다. 하지만 Datagram의 경우에는 경로가 정해져있지 않기 때문에 먼저 송신된 패킷이라 할 지라도 돌아가는 경로가 선택된다면 나중에 송신된 패킷보다 더 늦게 수신될 수 있다. 따라서 결과적으로 Virtual Circuit의 경우에는 순서가 지켜지기 때문에 Orderly Delivery를 지원한다고 하고, Datagram은 순서를 보장할 수 없기 때문에 Orderly Delivery를 지원하지 않는다고 한다.\nIP의 경우에 Datagram 방식을 사용하고 IP를 제외한 거의 모든 프로토콜(대표적으로 유선전화)이 Virtual Circuit을 사용한다. 옛날 사람들은 송신한 순서와 동일하게 수신되는 것이 자연스럽다고 생각했기 때문에, Virtual Circuit이 먼저 발명되었고 이후에 Datagram방식이 등장하게 된다.\nVirtual Circuit의 경우에는 송수신 순서가 일치하기 때문에 순서가 중요한 통신에 강점이 있다. 하지만 송신 도중 Intermediate Node가 불능이 될 경우에는 대체 경로가 없기 때문에 나머지 패킷이 전부 소실되게 된다. 반면에 Datagram의 경우에는 위와 같은 경우 다른 경로를 선택하여 갈 수 있기 때문에 패킷이 도착할 확률이 더 높다는 강점이 잇다.\n\n\n아래와 같은 통신망이 있다고 해보자.\n\n\nB → D로 Virtual Circuit을 이용해 패킷을 전송하려고 할때, Connection Phase, Data Transfer Phase, Disconnection Phase에 대해 이동하는 패킷의 구조와 Virtual Circuit Table의 변화를 포함하여 설명하시오(단, 이동 경로와 Virtual Circuit Number는 임의로 정해도 된다)\n\n우선 이동 경로는 B → 1 → 2 → 3 → D이고, Virtual Circuit Number는 0이라고 가정한다.\nConnection Phase에서는 Packet Type이 Connect이고, Virtual Circuit Number를 0으로 하며, 송신지는 B, 수신지는 D로 하여 패킷을 송신하게 된다.\n이때 B에서의 다음 수신지는 1이기 때문에 B의 Virtual Circuit Table에는 Virtual Circuit Number 0에 대해, 1로 패킷을 보내라는 정보가 저장된다. 즉, Virtual Circuit Table에VC# INPUT OUTPUT의 형태로 저장된다는 전제 하에, VC0 - 1이 저장된다(B는 자신이 패킷을 보내는 경우이므로 Input에는 적을 것이 없다)\n1번에 도착한 Connect Packet은 이제 2번으로 전달된다. 따라서 1의 Virtual Circuit Table에는 VC0 B 2가 저장된다. 이것은 Virtual Circuit Number 0인 패킷이 B로 부터 전달된다면, 2로 전달하라는 의미로 해석할 수 있다.\n2번에 도착한 Connect Packet은 3번으로 전달된다. 마찬가지로 2번의 Virtual Circuit Table에는 VC0 1 3이 저장되고, 이것은 Virtual Circuit Number 0번인 패킷이 1번으로부터 전달된다면, 3번으로 전달하라는 뜻으로 해석할 수 있다.\n3번에 도착한 Connect Packet은 D로 전달된다. 3번에서도 마찬가지로 VC0 2 D가 Virtual Circuit Table에 저장된다.\nD에 도착한 Connect Packet에 의해 D의 Virtual Circuit Table에는 VC0 3 -이 저장되고 Connect Phase가 끝난다\nData Transfer Phase에서는 단편화된 패킷들이 송신된다. 하지만 이때 패킷의 헤더에는 송수신 논리주소 대신, Virtual Circuit Number와 단편화된 패킷 중 몇번째인지를 나타내는 Sequence Number가 들어간다. 송수신 논리주소 대신 Virtual Circuit Number로 경로를 찾아갈 수 있는 이유는, 경로상의 모든 노드의 Virtual Circuit Table에 해당 Virtual Circuit Number에 대한 다음 노드가 명시되어 있기 때문이다.\n단편화된 패킷 중 하나에 대해서만 예시를 들어보면, B에서 Virtual Circuit Table을 조회해본 결과 VC0의 다음 목적지는 1인 것을 알 수 있고, 1로 전달된다.\n패킷이 1에 도착한 이후에는 1의 Virtual Circuit Table에 VC0 B 2라고 명시되어 있고, 도착한 패킷이 VC0이며 바로 B로부터 전달되었기 때문에 2번으로 해당 패킷을 전달해야 된다는 것을 알게 된다. 따라서 패킷은 2로 전달된다.\n패킷이 2에 도착한 이후에도 동일한 작업이 이루어진다. 2의 Virtual Circuit Table에 VC0 1 3이라고 명시되어 있고, VC0인 패킷이 1로부터 전달되었으므로 3번으로 해당 패킷을 전달해야된다는 것을 알게 된다. 따라서 패킷은 3으로 전달된다.\n패킷이 3번으로 도착한 이후에도 Virtual Circuit Table의 VC0 2 D에 따라 VC0인 2로부터 전달된 패킷을 D로 전달한다.\n해당 패킷이 D까지 전달이 되었고 나머지 패킷들도 동일한 과정을 거치며 D까지 전달되게 된다.\n단편화된 패킷들이 전부 전달된 이후에는 Disconnect Phase에 진입한다. Disconnect Phase를 수행하는 이유는, 각각의 노드가 Data Transfer가 끝난지 모르기 때문에, 송신지에서 패킷을 전부 송신하고 난 뒤에는 Disconnect를 수행해 경로상의 노드의 Virtual Circuit Table에서 해당 Row를 지워 메모리를 절약하기 위해서이다.\n따라서 B는 Packet type을 Disconnect로 하고 Virtual Circuit Number를 0으로 명시하여 Disconnect Packet을 준비한 후에 Virtual Circuit Table을 조회하여 VC0에 대한 패킷이 1로 가야된다는 것을 알아낸다. 따라서 해당 패킷을 1로 전달한 후에, VC0에 대한 Row를 삭제한다.\nDisconnect Packet이 1에 도착한 이후에는 Virtual Circuit Table에 따라 2번으로 전달되어야 한다는 것을 알아낸다. 따라서 2번으로 Disconnect Packet을 전달하고 VC0에 대한 Row를 삭제한다.\nDisconnect Packet이 2와 3에 도착했을 때에도 마찬가지로 Virtual Citcuit Table에서 VC0에 대한 다음 행선지 정보를 얻어내고, Disconnect Packet을 전달한 뒤, Virtual Circuit Table에서 삭제하는 과정이 이루어진다.\n마지막으로 D에 도착했을 때에도 Disconnect Packet이 VC0이고 3번으로부터 전달되었다는 것을 확인한 후에 Virtual Circuit Table에서 매치되는 Row를 삭제한다. D가 최종 목적지이기 때문에 Disconnect Packet은 다른 곳으로 전달되지 않고 Disconnect Phase가 종료된다.\n따라서 Disconnect Phase가 진행되며 Disconnect Packet이 전달됨에 따라 경로상의 모든 Virtual Circuit Table에서 VC0가 삭제되게 되는 것이다.\nPacket은 송신 후 Packet Header는 Hop to Hop을 이동함에 에 따라 변경되고 Frame Header는 최종 수신지에 도착할때까지 변경되지 않는다(O / X)\n\nX → 반대이다 : Packet Header가 변경되지 않고 Frame Header는 Intermediate Node를 거치며 송수신 주소가 새로이 설정된다.\n\n\n아래왜 같은 통신망이 있다고 해보자\n\n\n이때,\n\nConnect: H1 → A → B → D → H2\nConnect: H2 → D → B → E → H4\nConnect: H5 → E → C → A → H1\nDisconnect: H2 → D → B → E → H4\nDisconnect: H1 → A → B → D → H2\nDisconnect: H5 → E → C → A → H1\n\n위와 같은 쿼리에 대해 Virtual Circuit Table의 변화를 보이시오(단, Table의 구조는 다음과 같음 : InPort | InVC# | OutPort | OutVC#)\n\n(1)\n\nA 0 0 1 0 ADD\nB 0 0 1 0 ADD\nD 0 0 1 0 ADD\n\n\n(2)\n\nA 0 0 1 0\nB 0 0 1 0\n1 0 2 0 ADD\nD 0 0 1 0\n1 0 0 0 ADD\nE 1 0 3 0 ADD\n\n\n(3)\n\nA 0 0 1 0\n2 0 0 0 ADD\nB 0 0 1 0\n1 0 2 0\nC 2 0 0 0 ADD\nD 0 0 1 0\n1 0 0 0\nE 1 0 3 0\n4 0 0 0 ADD\n\n\n(4)\n\nA 0 0 1 0\n2 0 0 0\n0 1 1 1 ADD\nB 0 0 1 0\n1 0 2 0\n0 1 1 1 ADD\nC 2 0 0 0\nD 0 0 1 0\n1 0 0 0\n0 1 2 0 ADD\nE 1 0 3 0\n4 0 0 0\n\n\n(5)\n\nA 0 0 1 0\n2 0 0 0\n0 1 1 1\nB 0 0 1 0\n1 0 2 0 DEL\n0 1 1 1\nC 2 0 0 0\nD 0 0 1 0\n1 0 0 0 DEL\n0 1 2 0\nE 1 0 3 0 DEL\n4 0 0 0\n\n\n(6)\n\nA 0 0 1 0 DEL\n2 0 0 0\n0 1 1 1\nB 0 0 1 0 DEL\n0 1 1 1\nC 2 0 0 0\nD 0 0 1 0 DEL\n0 1 2 0\nE 4 0 0 0\n\n\n(7)\n\nA 2 0 0 0 DEL\n0 1 1 1\nB 0 1 1 1\nC 2 0 0 0 DEL\nD 0 1 2 0\nE 4 0 0 0 DEL\n\n\n최종\n\nA 0 1 1 1\nB 0 1 1 1\nD 0 1 2 0\n\n\nService Provider, UNI, NNI, External Operation, Internal Operation의 용어에 대해 무엇의 약자인지, 그리고 개념은 무엇인지 적어보거라\n\nService Provider: 라우터 같은 네트워크 단말들과 통신 회선 구조를 설계하고 시공하여 사용자 혹은 네트워크 단말 간의 통신을 가능하게 해주는 업자\nUNI(User Network Interface): 사용자 단말과 네트워크 단말 간의 통신\n\n이러한 유형은 사용자와 밀접하게 접해있다는 점에서 겉으로 드러나기 때문에 External Operation이라고 한다\n\n\nNNI(Network Node Interface): 네트워크 단말 간의 통신\n\n이러한 유형은 사용자에게 직접적으로 보이지 않고 가려져 있기 때문에 Internal Operation이라고 한다\n\n\n\n\nExternal 과 Internal Operation에서의 Packet Switching을 이원화하는 이유와 이원화 경우의 수 대표적인 세가지를 적어보거라\n\nExternal과 Internal Operation에서의 Packet Switching을 이원화하는 것은 Service Provider가 NNI에서 일어나는 일을 보안상의 이유에 의해 숨기고 싶어하기 때문이다\n따라서 UNI를 Datagram을 사용하고 NNI는 Virtual Circuit을 사용하거나, UNI를 Virtual Circuit을 이용하고 NNI를 또 다른 Virtual Circuit을 이용하거나 UNI를 Virtual Circuit을 이용하고 NNI를 Datagram을 이용하는 식의 이원화 방법을 주로 사용하게 된다\n\n\n\nRouting §\n\n2 level Hierarchy Routing Table의 개념과 이것이 필요한 이유를 netid, hostid의 용어를 이용하여 설명하여라\n\nRouting Table은 기본적으로 입력으로 받은 IP주소를 가지고 어느 Port로 나가야 할지를 결정하는데 IP주소 전체를 매칭하여 Port를 결정하는 방식으로는 Routing Table의 Row가 너무 많아지게 된다는 문제점이 있다\n왜냐하면 이 세상에 존재하는 IP주소 전체에 대해 매칭되는 Port를 구성해야 하기 때문에 그만큼 저장해야 되는 Row도 많아지고 검색의 속도도 느려지게 된다\n따라서 IP주소의 앞 일정 부분을 netid로 하고 나머지 뒷부분을 hostid로 정한 다음 netid만을 이용해서 Port와 매칭하는 방식으로 Row의 수를 획기적으로 줄일 수 있다\n즉, 해당 Port와 연결된 Host들은 모두 같은 netid를 갖고 hostid만 달라지게 구성한다면 netid만을 가지고 Port를 결정해도 해당 Host에 도달할 수 있기 때문\n\n\nIP주소 체계의 A, B, C Class의 IP 주소 범위에 대해 적어보거라\n\nA 클래스는 비트가 0으로 시작하고 그 이후 7개의 비트가 netid이기 때문에 00000001 … ~ 01111111 …의 범위를 가지게 된다. 따라서 1.0.0.0부터 127.255.255.255까지의 IP주소가 A Class 에 포함되게 된다\nB클래스는 비트가 10으로 시작하고 그 이후 14개의 비트가 netid이기 때문에 10000000 00000000 … ~ 10111111 11111111 …의 범위를 가지게 된다. 따라서 128.0.0.0부터 191.255.255.255의 IP주소가 B클래스에 포함된다\nC클래스는 비트가 110으로 시작하고 그 이후 21개의 비트가 netid를 구성한다. 따라서 11000000 00000000 00000000 … ~ 11011111 11111111 11111111 …의 범위가 포함되고, 결과적으로 192.0.0.0부터 223.255.255.255까지의 IP주소가 C Class에 포함된다.\n\n\nnetid와 hostid가 발급되는 과정에 대해 간략하게 설명해보거라\n\nnetid는 Network Information Center에서 충남대 같은 특정 기관에 발급해준다. netid를 발급받은 기관은 자신의 산하에 있는 host들에게 hostid를 하나씩 발급해주게 된다\n\n\nGateway router와 Gateway가 아닌 Router의 Routing 방법의 차이에 대해 설명해보거라\n\nGateway Router는 host와 직접적으로 연결되어있는 Router를 뜻하는데 이때에는 논리주소 전체(netid + hostid)를 이용해 Port 를 결정한다. 반면, Gateway가 아닌 Router의 경우에는 논리주소 전체가 아닌 netid만을 이용해 Routing을 하게 된다.\n\n\n아래 그림의 Gateway Router의 Routing Table을 작성하시오(단, Table은 DestinationAddr | SubnetMast | PortNum으로 구성되어 있다고 가정한다). 또한, 각 Port에는 몇개의 Host가 연결될 수 있는지 적으시오\n\n\n\nRouting Table\n\nDestination SubnetMask PortNum\n198.66.168.0 255.255.255.192 0\n198.66.168.64 255.255.255.192 1\n198.66.168.128 255.255.255.192 2\n198.66.168.192 255.255.255.192 3\n0.0.0.0 0.0.0.0 4\n\n\n어떤 라우터가 Default Destination Port를 제외한 모든 Port의 Subnet Mask가 /27이었다면 해당 라우터는 Destination Port를 제외하고 몇개의 Port가 존재하는지(1), 그리고 하나의 Port에는 몇개의 Host가 연결되는지(2) 적으시오(단, 이 라우터에 연결되어 있는 Host의 총 갯수는 256개 이고 모두 같은 C Class netid를 가진다고 가정한다.)\n\nSubnet Mask가 11111111 11111111 11111111 11100000이기 때문에 Port의 총 갯수는 2^3  8개 이고, 하나의 Port에 연결되어 있는Host의 갯수는 2^5  32개 이다\n\n\n\n\nPort들이 모두 동일한 Subnet Mask를 가지고 해당 라우터가 하나의 C Class netid를 가지는 host전체를 커버한다면 Port의 총 갯수는 2^(Subnet Mask의 마지막 8비트 중 1의 갯수)와 같고 하나의 Port와 연결된 Host의 갯수는 2^(Subnet Mask의 마지막 8비트 중 0의 갯수)와 같다\n\n\n어떤 라우터의 Forward Table이 아래 그림과 같을 때, 168.188.15.5, 168.188.7.32, 168.192.32.0세 IP가 Routing되는 Port Number를 과정과 함께 적으시오\n\n\n\n168.188.15.5 :\n\n첫번째 Row의 Subnet Mask인 255.255.255.0과 Bitwise AND를 수행하면 그의 결과는 168.188.15.0이다. 따라서 Destination Address와 일치하지 않으므로 0번 포트로 Routing되지 않는다.\n두번째 Row의 Subnet Mask인 255.255.255.0과 Bitwise AND를 수행하면 그의 결과는 168.188.15.0이다. 따라서 Destination Address와 일치하므로 1번 포트로 Routing되게 된다.\n\n\n168.188.7.32 :\n\n첫번째 Row의 Subnet Mask인 255.255.255.0과 Bitwise AND를 수행하면 그의 결과는 168.188.7.0이다. 따라서 Destination Address와 일치하지 않으므로 0번 포트로 Routing되지 않는다.\n두번째 Row의 Subnet Mask인 255.255.255.0과 Bitwise AND를 수행하면 그의 결과는 168.188.7.0이다. 따라서 Destination Address와 일치하지 않으므로 1번 포트로 Routing되지 않는다.\n세번째 Row의 Subnet Mask인 255.255.255.0과 Bitwise AND를 수행하면 그의 결과는 168.188.7.0이다. 따라서 Destination Address와 일치하지 않으므로 2번 포트로 Routing되지 않는다.\n네번째 Row의 Subnet Mask인 255.255.0.0과 Bitwise AND를 수행하면 그의 결과는 168.188.0.0이다. 따라서 Destination Address와 일치하므로 3번 포트로 Routing된다.\n\n\n168.192.32.0 :\n\n첫번째 Row의 Subnet Mask인 255.255.255.0과 Bitwise AND를 수행하면 그의 결과는 168.192.32.0이다. 따라서 Destination Address와 일치하지 않으므로 0번 포트로 Routing되지 않는다.\n두번째 Row의 Subnet Mask인 255.255.255.0과 Bitwise AND를 수행하면 그의 결과는 168.192.32.0이다. 따라서 Destination Address와 일치하지 않으므로 1번 포트로 Routing되지 않는다.\n세번째 Row의 Subnet Mask인 255.255.255.0과 Bitwise AND를 수행하면 그의 결과는 168.192.32.0이다. 따라서 Destination Address와 일치하지 않으므로 2번 포트로 Routing되지 않는다.\n네번째 Row의 Subnet Mask인 255.255.0.0과 Bitwise AND를 수행하면 그의 결과는 168.192.0.0이다. 따라서 Destination Address와 일치하지 않으므로 3번 포트로 Routing되지 않는다.\n다섯번째 Row의 Subnet Mask인 0.0.0.0과 Bitwise AND를 수행하면 그의 결과는 0.0.0.0이다. 따라서 Destination Address와 일치하므로 4번 포트로 Routing된다.\n\n\n어떤 Host의 IP를 설정할 때 IP주소는 192.168.32.5, Subnet Mask는 255.255.255.0, Default Gateway는192.168.32.1로 설정했을 때 해당 Host한테 생성되는 Routing Table을 그리시오(단, Routing Table의 구조는 Destination | Subnet Mask | Gateway | Flag | Interface로 구성되어 있으며 Interface는 0번만이 장착되어있다고 가정한다)\n\nRouting Table\n\n\n\nDestination SubnetMask Gateway Flag Inf\n192.168.32.0 255.255.255.0 Connected 0\n0.0.0.0 0.0.0.0 192.168.32.1 G 0\n\n\n아래와 같은 그림에서 라우터 R_CE의 Routing Table을 그려라 (단, Routing Table의 구조는 Destination | Subnet Mask | Gateway | Flag | Interface로 구성되어 있다고 가정한다)\n\n\n\nRouting Table\n\nDestination SubnetMask Gateway Flag Inf\n168.188.128.0 255.255.255.0 Connected 0\n168.188.129.0 255.255.255.0 Connected 1\n168.188.140.0 255.255.255.0 Connected 2\n0.0.0.0 0.0.0.0 168.188.140.2 G 2\n\n\n아래와 같은 네트워크 구조에서 CE1에서 CE2로 패킷을 전송하는 과정과 CE1에서 CE3으로 패킷을 전송하는 과정에 대해 전송되는 패킷의 송수신 논리, 물리 주소를 포함하여 설명하시오(단, 물리주소는 Node / Host의 이름과 같다고 가정한다)\n\n\n\n\nCE1 → CE2 : CE2의 IP와 CE1의 Routing Table을 이용해 Routing을 하면 첫번째 Row의 Subnet Mask와 Masking을 한 결과가 168.188.129.0이기 때문에 첫번째 Row에 매칭된다. 이때 Gateway가 Connected이기 때문에 ARP를 통해 물리주소를 알아내고, 따라서 송신 물리주소는 CE1, 수신 물리주소는 CE2, 송신 IP는 168.188.129.51, 수신 IP는 168.188.129.52로 하여 패킷을 전송하는 것으로 최종 목적지에 도달한다.\nCE1 → CE3 : CE3의 IP와 CE1의 Routing Table을 이용해 Routing을 하면 첫번째 Row의 Subnet Mask와 Masking을 한 결과가 168.188.128.0이기 때문에 첫번째 Row와 매칭되지 않는다. 이후 두번째 Row의 Subnet Mask와 Masking을 하면 결과가 0.0.0.0이기 때문에 두번째 Row와 매칭되고, 이때의 Gateway가 168.188.129.1이기 때문에 해당 IP로 ARP를 보내 물리주소를 알아내고 패킷을 전송한다. 따라서 송신 물리주소는 CE1, 수신 물리주소는 R_CE, 송신 IP는 168.188.129.51, 수신 IP는 168.188.128.30으로 하여 패킷을 전송한다.\n따라서 패킷이 Router의 Interface 1에 전송되는데, 수신된 패킷의 수신 IP주소와 R_CE의 Routing Table의 첫번째 Row의 Subnet Mask를 Masking하면 168.188.128.0이기 때문에 첫번째 Row에 매칭된다. 이때의 Gateway가 Connected이기 때문에 Interface 0에 연결된 Subnet으로 ARP를 보내 수신 IP에 해당하는 물리주소를 알아낸 뒤 송신한다. 따라서 이때의 송신 물리주소는 R_CE, 수신 물리주소는 CE3, 송신 IP는 168.188.129.51, 수신 IP는 168.188.128.30으로 패킷을 전송해 최종 목적지에 도달한다.\n\n\n위의 문제에서는 물리주소를 Node / Host이름과 일치시켰기 때문에 Interface에 따라 물리주소가 달라지는 것이 보이지 않는다 - CE1에서 R_CE로 패킷을 전송할때는 R_CE의 Interface 1에 해당하는 물리주소가 수신 물리주소가 되고, R_CE에서 CE3으로 패킷을 전송할때는 Interface 0에 해당하는 물리주소가 송신 물리주소가 된다.\n\n\n장대동에 거주하는 강혜종이는 이번에 새로운 컴퓨터를 사서 IP를 설정하려고 한다. 그가 속한 Subnet은 192.168.2.0/24인데, 실수로 Subnet Mask를 255.255.0.0을 설정했다. 이때, 같은 Subnet에 속하는 Host와 통신이 이루어지는지의 여부와, 다른 Subnet에 속하는 Host와 통신이 이루어지는 경우와 이루어지지 않는 경우애 대해 설명하시오\n\n강혜종이의 IP주소가 192.168.2.3이라고 가정하면, 강혜종이의 Routing Table은 다음과 같이 설정된다\n\n\n\nDestination SubnetMask Gateway Flag Inf\n192.168.0.0 255.255.0.0 Connected 0\n0.0.0.0 0.0.0.0 192.168.2.1 G 0\n\n\n같은 Subnet에 수신지가 존재하는 경우에는 통신이 이루어진다. 왜냐하면 가령 192.168.2.5에게 패킷을 전송하려고 하는 경우, Masking의 결과가 192.168.0.0이고, 이것은 Routing Table의 첫번째 Destination Address와 매치되기 때문에 같은 Subnet안에서 ARP를 전송하고, 수신지가 같은 Subnet에 있기 때문에 수신 물리주소를 응답받을 수 있다.\n다른 Subnet에 수신지가 존재할때 통신이 안되는 경우는 예를 들면 192.168.3.0/24 Subnet으로 패킷을 전송하려고 하는 경우이다. 이때에는 다른 Subnet에 있기 때문에 Gateway로 패킷을 전송한 다음 Routing되어 다른 Subnet으로 빠져나가게 해야 하는데, 강혜종이의 Routing Table을 돌려봐도 Masking 결과가 192.168.0.0이 나와 첫번째 Row에 매치되어 Gateway가 Connected이므로 같은 Subnet안에서 ARP를 요청한다. 하지만 실제로는 다른 Subnet에 있기 때문에 요청한 물리주소를 응답받을 수 없고, 따라서 통신에 실패하게 된다\n하지만 다른 Subnet에 수신자가 존재할때 통신이 되는 경우는 예를 들면 192.188.4.0/24 Subnet으로 패킷을 전송하려고 할 때이다. 이때에는 강혜종이의 Routing Table로 Masking을 하면 192.188.0.0이므로 첫번째 Row에 매칭되지 않아 패킷이 Gateway로 전달되고, 그 이후로는 정상적인 과정을 거쳐 통신이 이루어지기 때문이다.\n아래와 같은 네트워크 구조에서 Proxy Router인 PC Router를 거쳐 CE3과 CE9가 양방향으로 통신하는 과정에 대해 전송되는 패킷의 송수신 IP주소와 물리주소를 포함하여 설명하시오\n\n\n\nCE9 → CE3 :\n\nCE9의 Routing Table을 확인한 결과 다른 Subnet에 존재하고 Gateway로 패킷을 전달해야 된다는 것을 확인함. 따라서 Gateway로 ARP를 날리고 송신하여 결과적으로 송신 물리주소는 CE9, 수신 물리주소는 PCRouter, 송신 IP는 168.188.5.51, 수신 IP는 168.188.2.30으로 하여 패킷을 전송한다.\nPC Router의 Routing Table을 확인한 결과 다른 Subnet에 존재하여 Gateway로 패킷을 전달해야 된다는 것을 확인함. 따라서 Gateway로 ARP를 날리고 송신하여 결과적으로 송신 물리주소는 PCRouter, 수신 물리주소는 R_CE, 송신 IP는 168.188.5.51, 수신 IP는 168.188.2.30으로 하여 패킷을 전송한다.\nR_CE의 Routing Table을 확인한 결과 Interface 0의 Subnet에 존재한다는 것을 확인함. 따라서 수신지 IP로 ARP를 날리고 송신하여 결과적으로는 송신 물리주소는 R_CE, 수신 물리주소는 CE3, 송신 IP는 168.188.5.51, 수신 IP는 168.188.2.30으로 하여 패킷을 전송하는 것으로 통신이 완료된다\n\n\nCE3 → CE9 :\n\nCE3의 Routing Table을 확인한 결과 다른 Subnet에 존재하고 Gateway로 패킷을 전달해야 된다는 것을 확인한다. 따라서 Gateway에 대해 ARP 요청을 해 물리주소를 받아오고 송신한다. 결과적으로 송신 물리주소는 CE3, 수신 물리주소는 R_CE, 송신 IP는 168.188.2.30, 수신 IP는 168.188.5.51로 패킷을 전송한다.\nR_CE의 Routing Table을 확인한 결과 Interface 1의 Subnet에 존재하는 것을 확인하고 Interface 1에 연결된 Subnet에 ARP요청을 한다. 이때, PC Router는 ARP요청이 자신한데 온 것은 아니지만, 자신한테 연결되어 있는 Host에 대한 ARP요청인 것을 확인하고 자신의 물리주소를 ARP 응답으로 전달한다. 따라서 R_CE는 송신 물리주소는 R_CE, 수신 물리주소는 PCRouter, 송신 IP는 168.188.2.30, 수신 IP는 168.188.5.51로 패킷을 전송하게 된다\nPCRouter의 Routing Table을 확인한 결과 Interface 4의 Subnet에 존재하는 것을 확인하고 Interface 4에 연결된 Subnet에 ARP요청을 하여 물리주소를 받아온다. 결과적으로 송신 물리주소는 PCRouter, 수신 물리주소는 CE9, 송신 IP는 168.188.2.30, 수신 IP는 168.188.5.51로 하여 패킷을 전송하고 통신이 완료된다\n\n\nRouting Table에서 Hop 혹은 Metric으로 표기되는 값에 대해 설명하시오\n\n현재의 Router에서 최종 목적지까지 도달하기까지 거쳐가야 되는 Router의 숫자를 뜻한다.\n\n\nRouting Table을 이용해 알아낸 Next-Hop의 IP주소는 패킷의 Tailer에 붙어 하위계층으로 전달된다(O / X)\n\nX → Routing Table을 통해 알아낸 Next-Hop의 IP주소는 하위계층에서 ARP를 진행하기 위해 하위계층으로 전달되는데, 기존의 Packet의 어딘가에 저장되는 것이 아니고 상위계층에서 하위계층의 Procedure를 호출할때 Argument로 전달하게 된다\n\n\n\nIPv4 §\n\nIP가 Datagram을 사용하는 이유를 Heterogeneous Network의 용어를 포함해서 설명하시오\n\nIP망은 전 세계에 퍼져 있는데, IP망이 Heterogeneous Network, 즉, 환경이 항상 일정한 네트워크가 아니기 때문에 Connection을 구축하고 송신하는 것은 불가능하기 때문이다.\n\n\nIPv4를 대표하는 두가지 중요한 특징에 대해 설명하시오\n\n첫번째는 Connectionless Datagram Protocol, 즉, Connection을 하지 않아 순서가 보장되지 않는 Datagram을 사용하는 프로토콜이라는 것이다\n두번째는 Unreliable, Best-effort Delivery Service이다. 이것은 에러에 대해 신경쓰지 않고 목적지까지 최선을 다해 전송하는 것에만 초점이 맞춰져있다는 뜻이다.\n\n\nIPv4의 Header의 필드인 HLEN, Total Length에 대해 설명하고 HLEN의 최솟값과 그 이유, HLEN이 8이고 Total Length가 112일 경우 패킷의 Header, Option, Data가 각각 몇 바이트인지 설명하시오\n\nHLEN은 헤더의 크기를 4로 나눈 값을 의미하며, 이것은 물리계층에서 주로 4바이트 단위로 패킷을 전송하기 때문에 Header나 Option의 크기가 4의 배수가 되도록 설계했기 때문이다.\nTotal Length는 패킷 하나의 전체 크기(byte단위)를 의미한다\nHLEN은 최솟값이 5인데, 왜냐하면 헤더에 반드시 포함되어야 하는 Mandatory Header의 크기가 20byte이기 때문이다.\nHLEN이 8라는 것은 32byte라는 소리이고, 그중 20byte가 Mandatory이기 때문에 나머지 12byte가 Option이다. 그리고 112byte에서 32bytee를 빼면 80byte가 되기 때문에 이것이 Data의 크기가 된다\n\n\nIPv4에서 Fragmentation이 필요한 이유와 1500byte로 Fragmentation하는 이유를 MTU의 용어를 사용하여 설명하덤둥. 또한, Router에서 단편화된 패킷을 받았을때 어떻게 행동하는지 서술하시오. 마지막으로 IPv4 패킷의 Header에서 Fragmentation과 관련된 필드 세가지를 적으시오\n\nData link layer에서는 회선의 종류에 따라 한번에 보낼 수 있는 데이터의 크기가 달라진다 - 신뢰도가 높은 회선의 경우에는 한번에 많은 데이터를 보내도 에러가 자주 발생하지 않지만, 신뢰도가 낮은 회선의 경우에는 한번에 많은 데이터를 보냈다가 에러가 나면 해당 데이터를 다시 보내야 하기 때문에 한번에 많은 데이터를 보내는 것은 부담되기 때문\n따라서 상위계층에서 내려온 데이터의 크기가 클 경우에는 Data link layer의 프로토콜에 따라 Fragmentation하여 하위계층으로 내려보낸다. 이때 Ethernet Protocol의 MTU(Maximum Transfer Unit)크기가 1500byte이기 때문에 1500byte로 Fragmentation하게 되는 것이다\nRouter에서 Fragmentation된 패킷을 받았을 때에는 합쳐서 원본의 데이터로 변환한 다음, 송신하고자 하는 회선의 Data link layer protocol에 따라 다시 Fragmentation하여 전송하게 된다. - 이것은 수신된 회선의 Protocol과 송신하려고 하는 회선의 Protocol이 일치하지 않을 수 있기 때문이다.\nIPv4의 Header에는 Identification, Flag, Fragmentation Offset 이렇게 세가지 필드에 Fragmentation과 관련된 정보들이 들어가게 된다.\n\n\nIPv4 Header의 Protocol, Header Checksum, Time to Live 필드에 대해 간략하게 설명하시오\n\nProtocol Field는 상위 계층(Transport layer)의 프로토콜을 나타낸다\nHeader Checksum은 IPv4가 목적지까지 도달하는 것에 초점이 맞춰져있는 프로토콜인데, Header가 망가져 있을 경우 송수신 주소를 제대로 알지 못하기 때문에 Header에 대해서만 Error Detection을 하는 용도이다.\nTime to Live는 어떤 패킷이 무한루프 경로에 빠지거나, 너무 먼 경로를 선택했을 경우에 해당 패킷을 죽여버리기 위한 일종의 목숨이다. 255부터 시작해 Hop을 하나 지날때마다 1씩 차감되는 방식으로 작동한다.\n\n\nIPv4의 Option인 No operation, End of option, Record route, Strict source route, Loose source route, Timestamp에 대해 간단하게 설명하시오\n\nNo operation: IPv4 패킷에서 Option부분의 크기는 4의 배수가 되어야 하는데, Option 각각에 대해서는 4의 배수가 아니기 때문에 Option뒤에다가 붙여 Option하나에 대해 크기가 4의 배수가 될 수 있도록 해주는 Padding\nEnd of option: 위와 같은 이유로, Option필드의 총 크기를 4의 배수로 맞춰주기 위해 사용하는 Padding\nRecord Route: IPv4 패킷이 이동하는 동안 거쳐간 Router를 기록해 어느 경로로 왔는지 알 수 있게 하는 옵션\nStrict Source Route: 해당 옵션에 지정되어있는 Router만 거쳐서 목적지에 도달해야 함을 강제하는 옵션. 해당 옵션에 지정되어있는 Router외에는 거쳐가면 안된다. 경로를 미리 지정하고 송신되는 경우.\nLoose Source Route: 해당 옵션에 지정되어 있는 Router를 반드시 거쳐서 목적지에 도달해야 함을 강제하는 옵션. 해당 옵션에 명시되어있는 Router는 반드시 거쳐가야 하고, 다른 Router는 거쳐가든 말든 상관없다\nTimestamp: 각각 Router를 거쳐가는데 소요된 시간을 기록하라는 옵션.\n\n\nIPv6의 가장 핵심적인 특징 두가지에 대해 적어보시오\n\nIPv6의 첫번째 특징은 주소 체계를 4byte에서 16byte로 늘리고 계층도 더 세분화해서 더 많은 IP주소를 수용할 수 있도록 한 것이다.\nIPv6의 두번째 특징은 On-demand hop to hop routing option으로, IPv4에서는 어떤 Router에서 Option의 정보가 필요하지 않음에도 그것들을 꺼내봐야 했었지만 IPv6에서는 필요할 때만 Option을 꺼내보도록 하여 Routing의 시간을 단축시켰다는 것이다.\n\n\nIPv4의 HLEN, Protocol, Header Checksum, Option 필드가 IPv6에서는 어떻게 바뀌었는지 서술하시오\n\nIPv6은 Header에 반드시 필요한 것들만 남겨 Base Header라는 이름으로 40byte의 고정크기로 만들고,\nIPv4에서의 Option의 경우에는 Extension Header라는 이름으로 바뀌되 여러개의 Next Header 필드를 통해 다음 Extension Header 필드의 위치를 가리키게 하여 필요한 경우에만 Extension Header에 참조할 수 있도록 했다.\n따라서 IPv4의 HLEN은 Base Header의 크기가 40byte로 고정이기 때문에 삭제되었고,\nIPv4의 Protocol은 Next Header 필드의 Next Header Code라는 것을 이용해 Transport 계층의 프로토콜을 명시하도록 변경되었으며\nHeader Checksum은 TCP같은 Transport 계층에서 Error Detection을 진행하기 때문에 필요가 없어져 삭제되었으며\nOption은 위에서 언급한 것처럼 Extension Header라는 이름으로 Base Header에서 참조를 통해 접근가능하도록 변경되었다.\n\n\nIPv6의 Next Header Field의 구조와 작동방식, Next Header가 참조되는 경우의 수에 대해 설명하시오\n\nNext Header는 다음에 나오는 Extension Header가 어떤 것인지를 알려주는 Next Header Code와 다음 Extension Header의 위치를 가리키는 참조값으로 구성되어 있고\n해당 Extension Header 정보가 필요한 경우에는 꺼내보지만 필요 없는 경우에는 다음 Extension Header로 스킵하는 방식으로 작동된다\nIPv6의 경우에는 Dst Addr에 최종 목적지가 아닌 특정 Router의 주소가 들어가는데, 해당 Dst Addr에 도달하거나 첫번째 Next Header의 Next Header Code가 Hop-to-Hop Option일 경우에만 모든 Extension Header를 꺼내어 확인하고 그렇지 않은 경우에는 꺼내보지 않고 Bypass하게 된다\n\n\n어떤 IPv6 패킷 헤더의 모습이 다음과 같다고 할때\n\n\n해당 패킷이 전송되는 과정과 Extension Header의 변화를 서술하거라(단, 위의 그림에 나와있는 Extension Header는 Source Routing이라고 가정한다)\n\nS에서 출발한 패킷은 I1에 도달하기 전까지는 거쳐간 어느 Router에서도 Extension Header를 확인하지 않고 Bypass한다\nI1에 도달하고 나서는 Extension Header를 꺼내보고 그 다음 Dst가 I2인 것을 깨닫고 Dst값을 I2로 바꾼 뒤 Extension Header의 I2가 있는 자리에는 자신인 I1을 적는다. 또한 Left를 1 줄여 2로 만든다\n그 다음에는 마찬가지로 I2에 도달할때까지 모든 Router가 Extension Header를 꺼내보지 않고 Bypass한다\nI2에 도달하고 나서는 Extension Header를 보고 다음 Dst가 I3인 것을 확인한다. 따라서 Dst를 I3로 바꾸고 I3자리에 I2를 채워넣는다. 마지막으로 Left를 1 줄여 1로 만든다\nI3에 도달하기 전에는 모든 Router에서 Bypass하다가 I3에 도달하고 나서는 Extension Header를 확인해 Dst를 D로 바꾸고, Extension Header의 D가 있던 자리에 I3을 넣은 뒤, Left를 1 줄여 0으로 만든다\nD에 도달하기 전까지는 모든 Router에서 Bypass하다가 D에 도달하고 나서는 Extension Header를 확인해 Left가 0인 것을 보고 자신이 최종 목적지임을 확인하고 상위계층으로 올려보내는 것으로 통신이 마무리된다.\n\nAddress Mapping §\n\nARP Cache에 대해 개념과 작동과정을 설명하고, 각 Entry의 지속시간에 대해 적어보아라\n\nARP Cache는 ARP의 결과로 얻어낸 IP - 물리주소 쌍을 저장해 중복된 요청을 방지하는 방법이다\n우선 ARP Request에는 ARP를 보내고 나서 해당 IP에 대한 물리주소는 아직은 알지 못하기 때문에 비워놓은 상태로 Cache Table에 추가한다. 물리주소가 비워져있기 때문에 Status는 Incomplete가 된다.\nARP Request를 수신한 Host는 그것이 자신한테 온 요청인지의 여부와 상관없이, ARP Request에 적힌 Sender IP - 물리주소 쌍을 자신의 ARP Cache Table에 추가한다. 이때, ARP Request의 Sender IP, 물리주소는 NULL이 아니고 완성된 쌍이기 때문에 Sender IP - 물리주소 쌍은 Complete Status 의 상태로 저장되게 된다\nARP Reply를 수신한 요청인은 응답으로 받은 IP-물리주소 쌍을 ARP Cache Table에 넣는다. 이로 인해 ARP Cache Table의 해당 부분이 Completed로 바뀌게 된다\nARP Cache Table의 Entry는 Complete의 경우에는 20분간 지속되고 삭제되지만, Incomplete의 경우에는 3분간 지속되고 삭제된다.\n\n\n자신을 위한 ARP Reply가 아닐지라도 ARP Reply에 적힌 IP - 물리주소를 이용해 자신의 ARP Cache Table을 업데이트한다(O / X)\n\nX → ARP Request는 Broadcast로 보내지기 때문에 해딩 ARP Request와 관련이 없다 하더라도 Discard하기 전에 Sender의 IP와 물리주소를 자신의 Cache Table에 추가하지만, ARP Reply의 경우에는 Broadcast가 아닌 ARP Request를 보낸 Host를 Destination으로 하여 발송되기 때문에, 자신한테 온 ARP Reply가 아닌 경우에는 Data link layer에서 Discard되게 된다.\n\n\nARP의 송수신 과정과, Proxy ARP의 작동과정을 패킷에 담기는 송수신 물리주소와 IP주소와 함께 설명해라. 또한, 각 과정에 대해 ARP Cache Table의 변화를 추적해라\n\nARP Cache Table에서 원하는 물리주소를 찾지 못해 ARP Request를 하게 되는 경우 Sender 의 IP, 물리주소는 자신의 것을 기입하고 Target의 IP는 상대방의 IP, Target 물리 주소는 알 수 없기 때문에 비워둔 상태로 전송하게 된다. 그리도 이때 ARP Cache Table에는 Incomplete Status 로 Target의 IP와 물리주소가 저장된다.\nARP Request를 받은 Host는 일단 Request의 Sender IP &amp; 물리주소를 자신의 ARP Cache Table에 Complete Status로 저장한다. 만일 자신한테 온 Request라면, Serder IP &amp; 물리주소를 자신의 것으로 바꾸고 기존의 Sender IP &amp; 물리주소는 Target IP &amp; 물리주소로 옮겨서 ARP Reply를 하게 된다\n만일 자신한테 온 ARP Request는 아니지만 자신이 Proxy Server로 기능하고 있고, 자신한테 연결된 Host한테 온 요청이라면 자신이 해당 Host를 대변하고 있기 때문에 자신의 물리주소를 응답한다. 즉, Request에 있던 Serder IP &amp; 물리주소는 Target IP &amp; 물리주소로 옮기고, Sender IP는 자신한테 연결된 Host 의 IP, Sender 물리주소는 자신의 물리주소를 응답한다. 이것은 연결된 Host에게 패킷을 보내기 위해서는 자신을 거쳐가야만 하기 때문에 자신한테 먼저 해당 패킷이 전달되게 하기 위함이다.\nARP Reply를 받은 요청자는 Reply에 들어있던 Sender IP &amp; 물리주소를 자신의 ARP Cache Table에 업데이트한다. 이때 미완성으로 남아있던 해당 ARP Cache Table Entry가 완성되기 때문에 Status가 Completed로 전환된다.\n\n\nARP Packet의 각 Field에 대해 들어가게 되는 값과 연관지어서 설명하시오.(단, Field는 Hardware Type, Protocol Type, Hardware Length, Protocol Length, Operation이 있다)\n\nHardware Type은 Data link layer의 protocol을 의미하는 것으로 Ethernet의 경우에는 0x0001이 들어간다.\nProtocol Type은 Netwoek layer의 protocol을 의미하는 것으로 IP의 경우에는 0x0800, ARP의 경우에는 0x0806이 들어간다.\nHardware Length의 경우에는 물리주소의 길이를 뜻하는 것으로 Ethernet 주소는 6바이트이기 때문에 0x06이 들어간다\nProtocol Length는 논리주소의 길이를 뜻하는 것으로 IP주소는 4바이트이기 때문에 0x04가 들어간다\nOperation은 해당 패킷의 용도를 뜻하는 것으로 ARP Request의 경우 1, Reply의 경우 2, RARP Request의 경우 3, RARP Reply의 경우 4가 들어간다.\n\n\nRARP에 대해 무엇의 약자인지, 이것의 개념은 무엇인지, 이런 것이 필요하게 된 배경은 무엇인지 적으라\n\nRARP는 Reverse Address Resolution Protocol로 물리주소를 이용해 논리주소를 알아내는 프로토콜이다.\n옛날의 Time sharing environment에서는 서버의 물리주소는 알지만 논리주소를 모르는 경우가 종종 있었기 때문에 필요성이 제기되었다\nRARP는 각 Subnet마다 RARP Server를 하나 두는 식으로 구현된다. 해당 Server는 Subnet의 모든 IP - 물리주소 쌍을 알고있기 때문에 Subnet의 한 Host가 물리주소를 가지고 IP주소를 요청하면 RARP Server가 응답해 주는 식으로 작동한다.\n따라서 모든 Subnet마다 RARP Server둬야 하는 비효율성이 한계점이다.\n\n\nBOOTP에 대해 (1)이것이 등장하게 된 배경, (2)RARP와의 공통점 및 차이점, (3)어느 Layer에 포함되며 어느 Transport Protocol을 사용하는지, (4)작동 과정에 대해 설명해보시오\n\nBOOTP는 RARP의 Subnet마다 RARP Server를 둬야 하는 한계점을 극복하기 위해 탄생했으며\nRARP와의 공통점은 해당 프로토콜도 Server를 하나 둬서 IP - 물리주소 쌍을 저장한다는 것이고 차이점은 해당 Server가 같은 Subnet에 있지 않아도 된다는 것이다\nBOOTP의 경우에는 Application Layer의 프로토콜이고, UDP를 사용한다.\n일단 BOOTP의 경우에도 BOOTP Server가 같은 Subnet에 있을 때에는 RARP와 동일하게 작동한다.\n하지만 BOOTP Server가 다른 Subnet에 있을 때에는 Relay Agent를 이용하게 되는데, 이것은 Subnet 마다 존재하는 BOOTP Server의 위치를 알고 있는 Host이다.\n따라서 Client가 IP주소를 알고 싶을때는 일단 Broadcast로 BOOTP Request를 보낸다. 그럼 Subnet에 있는 Relay Agent가 수신하여 Datagram으로 Encapsulate한 후, Unicast로 BOOTP Server에게 요청을 전달한다. BOOTP Server는 해당 요청을 받은 후 응답을 생성하여 다시 Datagram으로 Encapsulate해 Unicast로 해당 Relay Agent에게 보낸다. Relay Agent는 응답을 받은 후 Decapsulate한 다음 Client에게 전달하는 것으로 통신이 종료된다.\n\n\nDHCP에 대해 (1)이것이 무엇의 약자이고 이것이 필요한 이유를 BOOTP와 연관지어서 Deterministic Binding의 용어를 포함하여 설명하고 (2) Static Address Allocation일때와 Dynamic Address Allocation일때의 작동 방식을 설명하고 (3) 그 두가지를 종합한 작동방식을 Available Pool의 용어를 포함하여 설명하시오. 또한 (4) DB관점에서의 BOOTP와의 차이점 도 서술하시게\n\nDynamic Host Configuration Protocol은 동적 IP주소 쳬계에 기반을 두고 있다. 즉, BOOTP가 개발될 당시까지만 해도 IP주소가 Deterministic Binding되어 Host당 하나의 IP주소가 결정적으로 매핑되었지만, 현대에 이르러서는 IP주소의 고갈을 막기 위해 컴퓨터가 켜지면 IP주소를 할당받고 컴퓨터까 꺼지면 IP주소를 반환하는 시스템이 사용됨에 따라 Host가 가지게 되는 IP주소가 매번 달라지게 되었다. BOOTP는 이러한 점에 대응하지 못해, DHCP가 새롭게 등장하게 되었다\nDHCP도 Host가 고정 IP를 가지게 되는 경우인 Static Address Allocation에는 BOOTP와 동일하게 작동한다 - Relay Agent가 IP주소 요청을 Client를 대신해서 보내주고, DHCP Server에는 Static DB가 있어 여기에서 IP주소를 찾아 Relay Agent에게 보내주는 방식\n하지만 Host가 동적 IP를 할당받는 방식인 Dynamic Address Allocation 에서는 Relay Agent를 내세워 요청과 응답하는 것은 동일하지만, DHCP Server내에서 작동방식에 차이가 난다 - 아직 아무에게도 할당해주지 않은 IP를 찾은 다음 그걸 응답해주고, Dynamin DB에 Entry를 추가하는 방식이다.\n따라서 전체적인 작동방식은 다음과 같다 - 일단 DHCP Request가 오면 Static DB를 먼저 확인하여 Static DB에 있으면 그것을 보내주고 만일 없다면 아무에게도 할당해주지 않은 IP들이 모여있는 Available Pool에서 IP하나를 골라 응답한 뒤, Dynamic DB에 추가하는 방식이다.\nDB관점에서 BOOTP와 DHCP의 차이점을 보면 BOOTP의 경우에는 Static DB만을 가지고 있는 것이기 때문에 이것을 수정하기 위해서는 사람의 제어에 따라 Manual하게 하게 되는 반면, DHCP는 Static DB의 경우에는 동일하게 Manual하게 수정되지만, Dynamic DB의 경우에는 자동적으로 DB가 변경되게 된다.\n\n\n\nError Reporting §\n\nICMP가 (1) 무엇의 약자인지 (2) 이것이 왜 필요한지 (3) 이것이 어느 계층에서 일어날 수 있는 문제들을 초점으로 하고 있는지 어디한번 설명해보거라\n\nICMP는 Internet Control Message Protocol의 약자이다\n이것이 필요한 이유는 IP가 Unreliable한 통신이어서 Error Detection 및 Error Correction을 제공하지 않기 때문이다.\nICMP는 네트워크 전반이나 다른 계층에서의 문제나 자원관리가 아닌 Network Layer에서 일어날 수 있는 에러에 대한 프로토콜이다\n\n\nICMP의 Error Reporting Message와 Query Message, Ping &amp; Pong에 대해 간단하게 설명해보아라\n\nError Reporting Message: IP 패킷이 지나가며 일어날 수 있는 에러들을 알려주는 메시지\nQuery Message: 바로 옆에 있는 Host에게 질의를 하는 메세지\nPing &amp; Pong: 특정 IP주소를 가진 Host에게 Ping을 보내면 해당 Host가 Pong을 보내는 방식으로 두 Host간 연결성을 테스트하는 메시지\n\n\n\nMulticast §\n\n특정 다수에게 패킷을 송신하기 위해 Multiple Unicast와 Broadcast 방법이 갖는 단점에 대해 설명하시오\n\nMultiple Unicast는 송신자가 패킷을 N번 송신하는 것을 의미하는데, 이 경우 N이 아주 클 경우 송신자가 갖는 부담이 커지게 된다\n또한 Broadcast로 보낼 경우 불특정 다수에게 전부 패킷을 전달하는 것이기 때문에 원치 않는 Host에게도 패킷이 전달된다는 문제점이 있다\n\n\nMulticast를 함에 있어서 Intermediate Router 간의 통신과 Gateway - Host간의 통신 각각에 대한 프로토콜 이름을 적고, 이렇게 이원화한 이유를 적으시오\n\nIntermediate Router간 Multicast 패킷을 전달할때는 Multicast Protocol이라는 것을 사용하고\nGateway - Host간 Multicast 패킷을 전달할때는 IGMP(Internet Group Management Protocol)을 이용한다.\n이렇게 이원화하는 이유는 첫번째로는 통신의 특성이 다르기 때문이다. Gateway는 송신후에 해당 Subnet에 연결되어있는 모든 Host에게 도달하지만, Router 간의 통신에서는 여러 Interface로 패킷을 전송하기 위해서는 패킷을 복사하는 과정이 필요하기 때문이다.\n두번째는 내부 작동과정을 감추기 위해서이다. 사용자와 직접적으로 통신하는 경우와 사용자 입장에서는 보이지 않는 내부적으로 통신하는 경우의 프로토콜을 달리해 보안 등의 이점을 얻고자 하는 것이다.\n\n\nIGMP 의 전반적인 과정에 대해 설명하시오(단, Group ID, Multicast Router, Group ID List, General Query, Membership Report, Leave Report, Special Query의 개념을 포함하여 설명하고 General Query시에 진행되는 Delayed Response Strategy의 개념과 이것을 사용하는 이유를 포함하여라)\n\nGroup ID는 Multicast Packet를 식별하는 번호이고\nMulticast Router는 Router중 Multicast Pakcet을 관리하는 권한을 가진 Router로 Group ID List를 가지고 있어, 자신의 Group ID List에 포함된 Group ID를 갖는 Multicast Packet이 도착하면 자신과 연결된 Subnet에 해당 Packet을 송신해 Subnet에 속한 Host들이 받아볼 수 있게 해주는 Router이다\nMulticast Router가 Subnet에 Packet을 송신하면 Subnet에 속한 모든 Host들에게 전달이 되고, 그 다음에 Host각각이 해당 Packet을 Accept할지 Discard할지 결정하는 구조로 작동한다.\n따라서 Subnet에 속하는 Host들 중 하나라도 어떤 Group ID의 Multicast Packet을 수신받기를 원한다면, 해당 Group ID가 Multicast Router의 Group ID List에 추가되게 되고, Subnet에 속하는 모든 Host들이 어떤 Group ID의 Multicast Packet을 받기를 원하지 않을 경우에만 해당 Group ID가 Group ID List에서 삭제되게 된다.\n이러한 작동원리 하에 먼저 Multicast Router는 정기적으로 General Query를 Subnet에 송신해 추가적으로 수신하고 싶은 Group ID가 있는지 조사한다.\n이때, 어떤 Group ID를 Group ID List에 추가하기 위해서는 한 Host만 Membership report를 하면 되기 때문에, General Query가 Host에 도착함과 동시에 Delayed Response Strategy를 수행한다.\n이것은 Host 각각이 자신이 원하는 Group ID들 각각에 대해 General Query가 도착함과 동시에 랜덤한 시간을 대기하는 타이머를 걸어 놓고 타이머가 끝날때까지 기다렸다가 Membership Report를 보내는 방법이다.\n만일 한 Host의 어떤 Group ID 의 타이머가 끝나기 전에 다른 Host가 해당 Group ID에 대한 Membership Report를 송신했다면, Membership Report를 중복해서 보내지 않아도 해당 Group ID가 Group ID List에 포함될 것이므로 타이머가 종료되어도 Membership report를 보내지 않는다.\n이러한 전략을 통해 중복된 Membership Report 없이 Host들이 원하는 Group ID들을 Multicast Router의 Group ID List에 추가할 수 있게 된다\n만일 어떤 Host가 어떤 Group ID를 Group ID List에서 삭제하고 싶을때에는 해당 Group ID를 명시하여 Leave Report를 송신하게 된다.\nLeave Report를 받은 Multicast Router는 Subnet에 해당 Group ID를 가지는 Multicast Packet을 수신하고 싶어하는 Host가 더이상 없어야지만 삭제할 수 있기 때문에, Group ID를 명시하여 Special Query를 송신해 해당 Group ID를 희망하는 Host가 있는지 조사하게 된다\nSpecial Query를 수신받은 Host들을 만일 자신이 희망할 경우 Membership Report를 보내고 희망하지 않을 경우에는 보내지 않는다. Multicast Router는 일정 시간을 대기한 후에 아무도 Membership Report를 보내지 않았을 때에만 해당 Group ID를 Group ID List에서 삭제하게 된다.\n\n\nGeneral Query가 도착한 이후에 다음 그림처럼 난수 타이머가 설정되었다고 하자\n\n\n이때 어떤 Host가 어떤 Membership Report를 송신하게 되는지 순서와 이유를 저그시오\n\nA의 228.42.0.0이 제일 먼저 종료되므로 A가 해당 Group ID를 명시해 Membership Report를 한다.\nA의 225.14.0.0이 그 다음으로 종료되므로 A가 해당 Group ID를 명시해 Membership Report를 한다.\nB의 228.42.0.0이 종료되지만 해당 Group ID는 A가 이미 Membership Report를 했기 때문에 송신하지 않는다.\nB의 228.71.0.0이 그 다음으로 종료되므로 B가 해당 Group ID를 명시해 Membership Report를 한다.\nC의 225.14.0.0이 그 다음으로 종료되지만 해당 Group ID는 A가 이미 Membership Report를 했기 때문에 송신하지 않는다.\nC의 230.43.0.0이 그 다음으로 종료되므로 C가 해당 Group ID를 명시해 Membership Report를 송신한다.\nA의 230.43.0.0이 마지막으로 종료되지만 C가 해당 Group ID에 대한 Membership Report를 했기 때문에 송신하지 않는다.\nMulticast Address에 대해 설명하시오\n\nGroup ID와 동일한 개념으로 Multicast Packet을 식별하는 역할을 한다.\n\n\n한 Subnet에 여러개의 Multicast Router가 존재할 경우, 각각의 Group ID List는 상호배타적이어야 하는지의 여부와 그 이유를 적으시오\n\n한 Subnet에 여러개의 Multicast Router가 존재할 경우, 각각의 Group ID List는 상호배타적이어야 한다.\n만일 그렇지 않다면, 교집합에 해당하는 Group ID에 대한 Multicast Packet이 수신되었을 경우 여러개의 Router에서 송신하기 때문에 해당 Subnet에 중복하여 송신되게 된다.\n\n\nQuery Router에 대해 간단허게 적어보시오\n\nQuery Router는 Multicast Router가 Query를 송신할 경우 많은 Response를 받을 확률이 높기 때문에 Query를 송신하는 Router를 별개로 두어 병목현상을 막는 것을 말한다.\n\n\n\nTransport Layer §\n\nProcess to Process Delivery에 대해 간단하게 설명하고 이때 사용되는 주소 체계 이름을 적으시오라\n\nProcess to Process Delivery는 송신 Host의 특정 프로세스와 수신 Host의 특정 프로세스간 통신을 의미한다\n이때에는 Port라는 주소체계가 사용된다\n\n\nIP주소가 A인 Host의 Process a가 IP주소가 B인 Host의 Process b에게 송신하는 경우 local-host, remote-host, local-process, remote-process를 적으시오\n\nlocal-host는 A, remote-host는 B\nlocal-process는 a, remote-process는 b\n\n\nClient - Server모델을 Client, Server, Well-known Port, Ephimeral local port의 개념을 이용해 설명해보거라\n\nClient는 통신을 시작하는 Host를 말하고 Server는 Client의 통신에 응답하며 수동적으로 반응하는 Host를 말한다.\nClient-Server모델에서는 위와 같은 정의 아래, Server는 정해진, 잘 알려진 포트인 Well-known Port를 사용하게 하고 Client에 대해서만 임의의 Port인 Ephimeral local port를 사용하게 하여 통신하고자 하는 상대방의 Port를 알 수 있게 했다.\n즉, Server의 Port가 정해져있고 잘 알려져 있기 때문에 통신을 시작하는 쪽인 Client는 Server의 Port를 무조건 알 수 있게 되고, 그렇게 첫 통신을 개시할때 Client의 Ephimeral Local Port를 실어서 보냄으로써 Server도 Client의 Port를 알 수 있게 하는 것이다.\n\n\nPort번호는 065535까지의 범위를 가지게 되는데, IANA는 이 범위를 01023, 102449151, 4915265535 세개로 나눠 각각의 용도를 정의하고 있다. 이때 각 범위의 용도를 서술하시오\n\n0~1023의 범위는 Well-known port들이 존재하는 구역이고\n1024~49151은 Registered구역으로 Programmable한, 사용자가 임의로 정해서 사용할 수 있도록 비워둔 구역이고\n49152~65535는 Ephimeral local port들이 존재하는, 즉, Process들이 임의로 배점받는 Port들이 존재하는 구역이다.\n\n\nSocket Address에 대해 설명하시오\n\nSocket Address는 IP주소와 Port번호를 함께 적어 놓은 주소 체계를 말하고\nApplication Layer에서 주로 사용하게 된다\n\n\nTransport Layer에서 등장하는 Multiplexer와 Demultiplexer에 대해 설명하시오\n\nTransport Layer는 여러 Application Layer의 Process들로부터 Data를 받아 하나로 합쳐 IP Layer로 내려보내주는데\n이때 합치는 것을 담당하는 것이 Multiplexer이고\n합쳐진 것을 수신하여 다시 나누는 것이 Demultiplexer이다\n\n\nConnectionless와 Connection-oriented의 개념 및 차이점에 대해 간략히 설명하고 Connection-oriented 통신의 일반적인 작동과정을 간단흐이 설명하시오\n\nConnectionless는 송수신 순서나 유실 여부 등를 신경쓰지 않는 것을 의미하고 Connection-oriented는 송신순서와 수신순서가 같도록 하고 유실 여부도 체크하는 것을 의미한다.\nConnection-oriented 통신의 일반적인 절차는 Connection, Transfer, Disconnect로 나눌 수 있는데,\nConnection단계에서는 Connection-oriented하게 통신하자는 것을 상호간에 확인한 뒤 송수신쪽 모두 버퍼를 준비한다\nTransfer단계에서는 송신버퍼에 있는 것들을 Numbering해 송신하고, 수신측에서는 수신된 것들을 수신버퍼에 Numbering된대로 정렬한 뒤에 상위 Process가 가져가게 한다.\nDisconnect단계에서는 이제 Connection을 끊자고 상호협의한 뒤, 버퍼를 지우는 것으로 마무리된다.\n\n\nReliable과 Unreliable의 개념 및 차이점에 대해 Flow Control Error, Physical Error의 개념을 이용하여 설명하고 Data link layer에서의 Reliability와의 차이점에 대해 서술하시오\n\nReliable은 에러가 전혀 없는 통신을 의미하고 Unreliable은 에러에 대해 신경쓰지 않는 통신을 의미한다\n에러는 크게 통신 회선에서의 에러인 Physical Error와 전송 속도에 의해 생기는 에러인 Flow Control Error가 있고 이런 에러를 무시하느냐 아니냐에 따라 Reliable한가 아닌가로 나뉜다\nData link layer에서는 Physical Error에 대해 중점적으로 해결하는 반면, Transport layer에서는 Physical Error는 Data link layer에서 완벽하게 해결하기 때문에 라우터 장비와 수신 Host에서 발생하는 Flow Control Error를 해결하는 것에 중점을 둔다\n\n\n\nUDP §\n\nUDP가 (1)무엇의 약자인지, (2) 개념과 해당 개념으로 인해 생기는 두가지의 대표적인 특징에 대해 설명하시오\n\nUDP는 User Datagram Protocol의 약자로, Process to Process Delivery의 기능만 제공해준다.\n따라서 송수신 순서나 발생 가능한 에러에 대한 기능은 하나도 제공하지 않기 때문에, Connectionless이고 Unreliable한 통신이다.\n\n\nUDP에서 Client와 Server 각각에 대해 Port 가 열리면 상위 Application 계층과 통신하기 위해 어떤 자료구조 몇개가 어떤 용도로 생성되는지 적고, Server의 경우 Application Layer에서 Message를 식별하기 위해 추가적으로 진행되는 것과 그러한 것이 필요한 이유에 대해 적으시오\n\nClient와 Host모두 Port하나가 열리면 Incoming Queue와 Outgoing Queue가 하나씩 열리게 된다.\nIncoming Queue로는 Application Layer에서 내려오는 데이터들이 쌓이게 되고, Outgoing Queue는 IP Layer로 내려보낼 데이터들이 쌓이게 된다\nServer의 경우에는 다수의 Client를 하나의 Port로 처리하고 Application Layer가 가져갈때는 Header가 제거된 상태이기 때문에 어느 Client에서 온 요청인지 알 수 없다. 따라서 Header가 제거된 데이터와 함께 Socket Address를 같이 제공해줘 어느 Client에서 온 요청인지 알 수 있게 한다.\n\n\n\nTCP §\n\nTCP가 지원하는 다섯가지 핵심적인 서비스를 간략한 설명과 함께 적으시오\n\nProcess to Process Delivery : 두 호스트에서 실행되고 있는 Process간의 통신을 지원함\nStream Delivery Service : Flow Error를 막기 위한 송수신 버퍼를 준비하고 Data를 Message단위가 아닌 Byte단위로 송수신하는 것을 지원함\nFull Duplex Communication : piggybacking을 이용한 양방향 통신을 지원함\nConnection-oriented Communication : 송수신 순서를 일치시키고 누락된 데이터가 없도록 하는 통신을 지원함\nReliable Communication : 에러가 없는 완전무결한 통신을 지원함\n\n\nTCP가 지원하는 Stream Delivery Service의 개념에 대해 UDP와 비교하며 설명하고 이것의 장점에 대해 서술하시오. 또한 Stream Delivery Service에서 Flow Control Error를 막기 위해 행하는 작업과 전송 과정, 전송되는 하나의 단위를 일컫는 명칭에 대해 서술하시오\n\nTCP의 Stream Delivery Service는 송수신 버퍼를 준비하고 Data를 바이트 단위로 송수신하는 것을 말한다.\nUDP는 바이트 단위가 아니고 Message단위로 송수신하는데, Message단위 통신은 한번의 송신에 하나의 상위 계층으로부터 내려온 Message가 전송되지만 Byte단위 통신은 한번의 송신에 상위 계층으로 부터 내려온 여러개의 Message들, 혹은 하나의 Message 일부분 등이 전송될 수 있다는 차이가 있다\nTCP는 Flow Error를 막기 위해 송수신 버퍼를 마련하는 방법을 사용한다. 송수신 버퍼로 인해 이전의 데이터가 아직 송신되지 않은 상황에서도 상위 계층의 데이터를 받을 수 있고, 수신자의 입장에서도 상위 계층에서 데이터를 가져가기 전일지라도 버퍼의 공간이 남아있는 한 계속해서 데이터를 수신받을 수 있게 된다.\nTCP는 송신버퍼에 바이트를 모아 일정량이 되어야 송신하는 방법을 사용하고, 이때의 송신되는 바이트 덩어리를 Segment라고 한다. Message 단위로 송신하는 것과 비교해서 해당 방법이 갖는 이점은 데이터를 한번 보낼때는 Segment Header뿐 아니라 하위계층을 거치며 여러가지 Header가 붙게 되기 때문에, 작은 단위의 데이터를 여러번 보내는 것은 Header가 여러번 붙어야 돼서 비효율적이다. 따라서 바이트 단위로 일정량을 모아서 송신하는 방법으로 이러한 비효율성을 줄일 수 있다.\n\n\nTCP의 Numbering은 무엇을 단위로 하여 매겨지는지 적으시오\n\nTCP는 Segment가 아닌 Segment의 Data의 Byte단위로 Numbering이 이루어진다.\n\n\nTCP에서 ACK Number가 의미하는 바를 적으시오\n\nTCP에서 ACK Number가 의미하는 바는 ACK Number 바로 이전의 byte까지는 정상적으로 수신했고 ACK Number에 해당하는 byte를 보내달라는 의미이다\n\n\nSequence Number의 계산법에 대해 (1) 초기값 설정법, (2) 보낼 데이터가 있을때와 없을때 Sequence Number가 어떻게 설정되는지, (3) 2^31 - 1을 넘어갔을때 어떻게 되는지 적으시오\n\nSequence Number는 초기값으로 0~2^31-1범위 안의 난수를 갖는다\n데이터를 보내게 되면 Sequence Number는 상대방이 보낸 ACK값, 즉, 자신이 방금전에 보낸 마지막 Byte의 Numbering값 + 1으로 설정하여 Segment가 송신된다. 반면, 데이터를 보내지 않을때는 ACK - 1값이 Sequnce Number이다.\nSequence Number가 2^31-1을 초과하였을때는 다시 0부터 Numbering되는 과정을 가진다\n\n\nTCP Connection에서 3 Way Handshake의 과정을 서술하되 상태 변화가 어떻게 이루어지는지, 각각의 과정에서 어떤 동작을 하고 어떤 Flag가 올라간 Segment가 전송되는지(+해당 Flag가 어떤 의미를 가지는지), 각 Segment의 Sequence Number와 ACK Number의 변화를 포함하시오\n\n우선 Server는 자기가 직접 통신을 개시할 수 없기 때문에 Passive Open을 하고 Listen상태에 돌입하게 된다.\n이 상태에서 Client는 능동적으로 통신을 개시하기 때문에 Active Open을 하고 SYN Flag을 1로 하여 Segment를 송신한 뒤 SYN SENT상태가 된다. SYN은 SYNchronize로, 동기화(Connection)을 요청하는 Flag이다. 이때 Sequence Number는 난수로 설정되고 ACK Number는 상대방이 보낸 Segment가 없기 때문에 설정되지 않는다.\nServer는 SYN Flag가 1인 Segment를 받으면 SYN + ACK를 보내고 Listen상태에서 SYN RCVD상태가 된다. 이것은 방금 보낸 Segment를 잘 받았기 때문에 ACK Flag가 1로 되고 Connection을 하자는 의미에서 SYN Flag가 1도 되었다고 할 수 있다. 이때 Sequence Number는 처음 보내는 Segment이기 때문에 난수로 설정되고 ACK Number는 방금 Client가 보냈던 Sequence Number를 잘받았고 그 다음 것을 원한다는 의미에서 Client가 보낸 ACK Number + 1로 설정된다\nSYN SENT였던 Client는 SYN + ACK를 받은 뒤 ACK Flag만을 1로 하여 응답한 뒤 ESTABLISHED상태가 된다. 이때의 Sequence Number는 보낸 데이터가 없기 때문에 방금 Server가 보낸 ACK Number - 1로 설정된다. 또한 ACK는 방금 Server가 보낸 Sequnce Number + 1로 설정된다.\nSYN RCVD였던 Server는 ACK를 받은 뒤 ESTABLISHED상태가 되며 Connection과정이 완료된다.\n\n\nTCP Connection이 이루어진 뒤에 다음과 같이 Data Transfer가 이루어졌을 때\n\n\nSequence Number와 ACK Number가 왜 저렇게 설정되는지, 그림에 나온 Flag들은 어떤 의미를 가지는지, 과정에 따라 서술하시오. 또한 위의 예제에서 Piggybacking이 이루어지고 있는지 여부를 이유와 함께 서술하시오(단, Data Transfer 바로 직전에 Client로 수신된 ACK가 8001이었다고 가정하고 Sequence Number는 15000인 데이터가 없는 Segment가 수신되었다고 가정한다)\n\nClient로 수신된 ACK가 8001이기 때문에 Client는 Sequence Number를 8001로 하여 9000번까지의 데이터를 송신한다. 이때에는 방금 받은 Segment의 Sequence Number가 15000이고 데이터가 수신되지 않았기 때문에 다음 바이트인 15001을 ACK Number로 설정하여 요청한다. 이전에 받은 Segment에 대한 ACK Number가 설정되어있기 때문에 ACK Flag가 설정되어 있고, PSH Flag도 설정되어 있는데, 이는 해당 데이터를 버퍼에서 대기한 후 상위계층으로 올려보내지 말고 도착한 즉시 상위계층으로 올려보내라는 뜻이다. 이 Flag는 보통 실시간 통신을 하는 등 소요시간이 중요한 경우에 사용된다.\n그 다음 Client가 송신하는 Segment는 방금 송신한 Segment Data의 마지막 Byte가 9000번이었기 때문에 9001을 Sequence Number로 하여 10000번까지의 바이트를 보내게 된다. ACK Number는 Server가 새로운 Segment를 보내지 않았기 때문에 여전히 15001로 설정된다.\nServer는 10000번까지의 바이트를 잘 받았기 때문에 ACK Number를 10001번으로 하여 요청하게 된다. 또한 Client가 ACK Number를 15001을 보냈기 때문에 15001을 Sequence Number로 하여 17000까지를 보낸다.\n따라서 위 과정을 보면 Data와 ACK를 하나의 Segment에 같이 실어서 양방향 통신이 이루어지고 있는 것을 알 수 있다. 따라서 Piggybacking이 이루어지고 있다.\n마지막으로 Client는 데이터를 보내지 않았기 때문에 Sequence Number를 ACK - 1인 10000을 보낸다. 또한 Server가 보낸 17000번까지의 데이터를 잘 받았고 17001을 원한다는 의미로 ACK Number를 17001로 설정하여 보내게 된다. 또한, Server가 데이터를 보내고 나서 Receiver Window에 공간이 10000이 남았음을 알려줘 Flow Error가 나지 않도록 한다.\nTCP Data Transfer을 하던 도중 ctrl + c를 눌러 전송을 중단했을 경우 어떤 일이 일어나는지를 URG Flag, URG Pointer의 개념과 함께 서술하시오. 또한 이렇게 함으로써 얻는 이점에 대해서도 서술하시오\n\nCtrl + C를 누르는 등의 송신 강제 취소를 하게 되면 TCP에서는 보내려고 했던 Segment를 URG Flag를 설정하고 취소 시점까지의 바이트 위치를 URG Pointer Field에 담아 Special TCP Segment를 보내게 된다.\nURG Flag를 줌으로써 송신이 강제 취소됐고, URG Pointer가 설정되어있다는 것을 알려주는 것이다. URG Pointer는 취소된 바이트와 취소되지 않은 바이트를 구분하는 역할로, 해당 Pointer가 가리키는 바이트까지는 수신하고 나서 폐기하라는 의미를 가지게 된다. 이것은 방금 보낸 데이터가 비정상이라는 것을 알리는 동시에 정상적인 데이터 또한 전송하여 전송이 취소되었음을 알리는 추가적인 Segment를 만들지 않고 하나의 Segment로 해결할 수 있게 해준다.\n\n\nTCP Connection Termination에서 4 Way Handshake(Half Close)의 과정을 서술하되 상태 변화가 어떻게 이루어지는지, 각각의 과정에서 어떤 동작을 하고 어떤 Flag가 올라간 Segment가 전송되는지(+해당 Flag가 어떤 의미를 가지는지) 서술하시오\n\n우선 Client가 송신 버퍼를 Free하는 등의 Close 작업을 하고 FIN Flag를 설정하여 Segment를 송신한 후 FIN-WAIT 1상태가 된다.\nServer는 FIN Flag를 받으면 ACK를 보내 알겠다고 응답한 뒤 CLOSE-WAIT상태가 된다.\nClient는 Server가 보낸 ACK를 받으면 FIN-WAIT 2상태가 된다.\nServer는 CLOSE-WAIT상태에서 Close를 진행한다. 즉, 아직 보내지 않은 남은 바이트들을 전부 송신하고 송신버퍼를 반환하는 등의 작업을 수행한다.\nClient는 FIN-WAIT 2상태에서 Server가 보내는 잔여바이트를 수신하며 ACK를 보내 잔여바이트 통신을 한다.\nServer는 Close가 끝나면 FIN Flag를 설정해 Segment를 보내고, LAST-ACK 상태가 된다\nClient는 FIN을 받으면 ACK를 보내고 일정기간 기다린 뒤 Terminate된다\nServer는 ACK를 받은 뒤 바로 Terminate된다\n\n\nTCP 4 Way Handshake(Half Close)를 할때는 Server가 먼저 Termination을 제안한다(O/X)\n\nX → Connection을 할때나 Termination을 할 때나 항상 Client가 먼저 제안하게 된다.\n\n\n다음의 그림에서 회색 박스를 채우시오\n\n\n\n(0) Passive Open/-\n(1) Active Open/SYN\n(2) SYN/SYN + ACK\n(3) ACK/-\n(4) SYN + ACK/ACK\n(5) Close/FIN\n(6) FIN/ACK\n(7) ACK/-\n(8) Close/FIN\n(9) FIN/ACK\n(10) ACK/-\nTCP Flow Control을 할때는 Receiver의 요청에 따라 Sender의 버퍼 사이즈가 조정된다(O/X)\n\nO → TCP Flow Control은 Receiver가 보내는 Window Size Header의 값으로 Sender의 버퍼 사이즈가 결정된다\n\n\nrwnd가 무엇의 약자인지 적고 이것에 계산되는 과정을 적으시오\n\nrwnd는 Receiver Window의 약자로 현재 Receiver의 버퍼 크기에서 수신되엇지만 순서가 맞지 않아 Out of Order로 마킹되어 기다리고 있는 바이트나 Process에서 가져가지 않은 바이트의 크기를 뺀 값으로 설정된다\n\n\nSegment Header의 Window Size Field는 어떻게 결정되는지 그 이유와 함께 적으시오\n\nSegment Header의 Window Size Field는 Receiver Window인 rwnd와 Congestion Window인 cwnd 중 작은값으로 설정되어 Sender에게 전달된다\n\n\n특정 시점에 Sender의 버퍼 상태가 다음과 같았다고 할 때,\n\n\nSender로부터 전달된 Window Size와 Sequence Number 199, 200202, 203208, 209번의 현재 상태에 대해 적어보시오(단, Seqence Num가 작은것부터 전송된다고 가정한다)\n\n199번은 전송되었고 ACK도 받은 바이트이다\n200~202번은 전송되었지만 ACK를 받지 못한 바이트이다\n203~208번은 Window에 들어가 전송을 대기하고 있는 바이트이다\n209번은 Window에 들어간 뒤에 전송될 수 있는 바이트이다\nTCP가 사용하는 ARQ 종류에 대해 적고 간략하게 설명하시오\n\nTCP는 Selective ARQ를 사용하며 순서에 맞지 않는 데이터가 수신되어도 폐기하지 않고 가지고 있으며 중간의 빈부분을 ACK로 요청하게 되는 ARQ 방식이다\n\n\nTCP 통신에서 수신측은 Segment Header의 어떤 Field를 보고 Error Detection을 하게 되는지 적고 Error가 있을때, Error가 없을때 어떻게 행동하는지 설명하시오\n\nTCP Receiver는 Segment Header의 Checksum Field를 이용해 Error Detection을 하게 되고, Error가 없을 경우에는 ACK를 보내지만 Error가 있을 때에는 ACK를 보내지 않는다.\n\n\nTCP 통신에서 송신측은 어떤 경우에 Retransmission을 하게 되는지 RTO, RTT, Three Duplicate ACK Segment의 개념과 함께 설명하시오(단, RTO와 RTT가 무슨 말의 약자인지 적으시오)\n\nRTO는 Retransmission Time Out의 약자로, 보낸 데이터가 일정기간이 지나도 ACK가 오지 않을때 Retransmission하는 경우를 의미한다.\n이때 일정기간은 상수가 아닌 Segment 왕복시간의 평균을 사용하게 되는데, 이것이 RTT(Round Trip Time)이다. 즉, RTT를 넘어도 ACK가 수신되지 않는다면, RTO를 하게 되는 것이다\nThree Duplicate ACK Segment는 동일한 ACK 세개가 연달아 수신되었을 때를 의미한다. 동일한 ACK 세개가 수신되었다는 것은 중간에 누락된 바이트가 있음으로 받아들여 Retransmission을 하게 된다\n\n\nTCP 통신에서는 순서에 맞지 않는 Segment가 도착하면 해당 Segment를 어떻게 처리하고 어떤 ACK를 보내는지 out-of-order flag를 포함하여 서술하시오\n\n순서가 맞지 않는 Segment가 도착하면 폐기하지 않고 Out-of-Order flag를 줘서 버퍼 안에서 대기하도록 한다. 그리고 ACK는 해당 Segment를 포함하지 않고 정상적인 순서대로 도착한 마지막 바이트 + 1을 보내게 되며, 비어있던 부분의 Segment가 도착하면 그때 Out-of-Order Segment까지 포함한 ACK를 보내게 된다\n\n\nTCP 통신에서 Data Segment가 도착하고 어느정도 기간을 기다렸다가 ACK를 송신하는지 적고 해당 시간 내에 다른 Data Segment들이 추가적으로 수신되었을때 ACK를 어떻게 보내는지 설명하시오\n\nData Segment가 수신되고 500ms를 기다렸다가 ACK를 송신한다. 만일 해당 기간을 대기하던 중 다른 Data Segment가 도착하면, 그것까지 포함한 ACK를 송신하게 된다\n\n\nFast Retransmission에 대해 설명하고 그러한 경우는 Weak Error인지, Strong Error인지 판별하시오.\n\nFast Retransmission은 Three Duplicate ACK Segment를 의미한다. 즉, RTT가 만료되기 전에 세개의 동일한 ACK가 들어오면 그것도 에러라고 판단해 Retransmission을 하게 된다. 이때는 RTT가 만료되기 전에 Retransmission이 이루어지므로 RTO인 경우보다 빨리 Retransmission이 이루어지고 따라서 Fast Retransmission이라는 이름이 붙게된 것이다. 하지만 Datagram의 경우 경로가 정해져있지 않아 조금 느린 경로를 선택했을 가능성이 있기 때문에, RTO에 비해 확실한 에러는 아니고, 따라서 Weak Error라고 한다.\n\n\nFalse Flow Error, Queue Overflow by Congestion Error에 대해 Flow Error와 비교해서 간력하게 설명하시오\n\nFlow Control Error는 Receiver의 Incoming Queue가 Overflow하여 발생하는 에러이고 False Flow Error, 혹은 Queue Overflow by Congestion Error는 Receiver가 아닌 Intermediate Node에서 Incoming혹은 Outgoing Queue가 Overflow하여 발생하는 에러이다\n\n\nCongestion Control의 세 단계에 대해 아래의 그림을 이용해 설명하되 MSS, ssthresh가 무엇의 약자이고 개념은 무엇인지 포함하고 Exponential Increase, Additive Increase, Multiplicative Decrease의 개념 또한 포함해서 설명하시오\n\n\n\nMSS는 Maximum Segment Size로 한번에 보낼 수 있는 Segment 하나의 최대 크기를 나타내는 단위이다.\nTCP에서 Congestion Control를 할때 첫번째 단계는 Slow Start Phase이다. 이것은 Congestion Window(cwnd)를 1MSS로 설정한 다음, 통신에 성공할때마다 cwnd의 크기를 2배씩 증가시키는 단계에 해당한다. cwnd의 크기가 2배씩 증가하므로 Exponential Increase라고 하고, ssthresh(Slow Start Threshold)에 도달하기 전까지 Exponential Increase를 반복한다. ssthresh의 경우 초기값은 65535byte로 설정된다.\ncwnd의 바이트 크기가 ssthresh에 도달하게 되면 두번째 단계인 Congestion Avoidance Phase가 진행된다. 이것은, 통신에 성공할때마다 cwnd의 크기가 1MSS씩 증가하는 것을 의미힌다. 1MSS씩 선형적으로 증가하기 때문에, Additive Increase라고 하며, Congestion이 발생하기 전까지 Additive Increase를 반복한다.\n어떤 Phase이던 간에 상관없이, RTO가 발생하거나 3 Duplicate ACK가 발생했을 경우에 Congestion Detection Phase에 진입하게 된다. 이때에는 무조건 ssthresh의 크기가 현재 window size의 절반으로 줄어든다. 이것을 Multiplicative Decrease라고 한다. 이후, Error의 유형에 따라 다르게 동작하는데, RTO일 경우에는 Slow Start Phase부터 다시 시작하게 된다. 즉, cwnd를 1MSS로 초기화하고 통신을 성공하면 cwnd의 크기를 Exponent Increase하는 것을 ssthresh에 도달할때까지 반복하는 것이다. 다만, 이 경우에는 ssthresh이 이전보다 줄어들었기 때문에 더욱 일찍 Congestion Avoidance Phase로 진입하게 된다. 만일 3 Duplicate ACK가 발생한 경우에는 Congestion Avoidance Phase에서부터 시작하게 된다. 즉, cwnd의 크기를 줄어들은 ssthresh의 크기로 설정하고, 통신에 성공하면 cwnd의 크기를 Additive Increase하는 단계를 진행한다.\n따라서 위의 그림을 보면 SS가 시작되고 나서 16으로 설정된 ssthresh에 도달하자 AI에 진입하게 된 것을 볼 수 있다, 이후 8 round에서 RTO가 발생하게 되고, ssthresh는 현재의 cwnd크기인 20의 절반인 10으로 설정된다. 또한 RTO가 발생했기 때문에 다시 SS를 진행하는 것을 확인할 수 있다. 이후 SS가 진행되지만 ssthresh가 10으로 줄어들었기 때문에 더욱 일찍 AI에 진입하게 되고, round 14에 3 ACK가 발생한 것을 볼 수 있다. 이때의 cwnd가 12이므로 ssthresh는 6이 되고 3ACK이기 때문에 cwnd가 ssthresh와 같은 크기인 6으로 설정되고 AI가 진행되는 것을 볼 수 있다.\n\nSCTP §\n\nSCTP가 무엇의 약자이고 어떤 배경에서 소개되었는지, 그리고 이것의 특징 4가지에 대해 설명하시오\n\nSCTP는 Stream Control Transmission Protocol이고, TCP로 멀티미디어를 전송하는 것의 한계를 해결하기 위해 소개되었다.\nSCTP는 Process to Process Delivery를 제공하고\nByte-oriented가 아닌 Message-oriented 통신을 제공하며\nConnection-oriented 통신을 지원하고\nReliable한 통신도 지원하고\nFull Duplex Communication도 지원한다.\n\n\nSCTP의 Multi Streaming과 Multi Homing을 TCP와 비교하여 설명하고, Multi Streaming과 Multi Homing의 차이점과 종합적인 구조를 설명하시오.\n\nMulti Streaming은 TCP에서는 Port하나당 하나의 Stream을 제공했지만, SCTP에서는 하나의 Port당 여러개의 Stream을 제공하는 기능이다. TCP는 하나의 Stream만을 제공해 해당 Stream에서 문제가 생기면 나머지 데이터들이 전송되지 않는 문제점이 있었지만, SCTP에서는 하나의 Stream이 문제가 생기면 다른 Stream으로 전환할 수 있고 여러개의 Stream을 병렬적으로 운용할 수도 있다는 점에서 TCP에 비해 우위를 가진다.\nMulti Homing은 TCP에서는 하나의 송수신 IP쌍을 이용할 수 있었지만 SCTP에서는 하나의 송수신 IP쌍을 이용하되, 해당 IP 통신에서 문제가 생겼을 경우 다른 IP쌍을 선택할 수 있도록 하는 것이다. 즉, 여러 IP 쌍을 병렬적으로 운용하는 것은 TCP와 SCTP가 모두 불가능하지만, TCP와 다르게 SCTP는 대체 IP쌍이 있다는 차이가 있는 것이다\nMulti Streaming은 Process의 입장에서 하나의 Port 일지라도 아래로 내려보낼 수 있는 창구를 여러개 제공해주는 개념이고, Multi Homing은 Transport Layer에서 IP Layer로 내려보낼 때 대체제를 선택할 수 있게 해주는 개념이다.\n따라서, 하나의 Port해 대해 여러개의 Stream들이 존재하고 해당 Stream은 하나의 버퍼로 Multiplexing되며 Port들에 대해서도 Multiplexing하기 위해 해당 버퍼들의 내용이 하나로 Multiplexing되어 IP Layer로 내려가게 되는 것이다.\n\n\nTSN, SI, SSN에 대해 무엇의 약자인지를 포함해 개념을 적으시오. 또한 Chunk가 무엇인지도 같이 설명하시오\n\n일단 Chunk는 Process에서 전달하는 하나의 Message를 일컫는 말이다.\n여러개의 Stream에 뿌려진 Chunk들은 각각의 Stream내에서의 순서를 일컫는 SSN(Stream Sequence Number)와 Stream들을 구분하기 위한 번호인 SI(Stream Identifier)를 통해 식별되게 된다\n여러개의 Stream들이 하나의 버퍼로 Multiplexing될때, 해당 버퍼 내에서의 순서를 일컫는 번호가 TSN(Transmission Sequnece Number)이다.\n\n\nSCTP Packet의 구조에 대해 TCP와 비교하며 설명하시오.\n\nIPv4와 IPv6의 차이점과 유사하게, TCP와 다르게 SCTP에서는 Header에 꼭 필요한 것들만 넣어 고정크기로 설계해 HLEN의 필드를 제거하게 된다.\n그리고 ARP, rwnd, cwnd같은 여러 Control과 관련된 것들은 Control Chunk로써 Packet에 포함되고, Control Chunk들이 담긴 이후 버퍼에 있는 Chunk들이 TSN 순서대로 담기게 된다. 이들을 Data Chunk라고 한다.\n따라서 SCTP의 Packet은 Header와 Control Chunk, Data Chunk로 구성되게 된다\n\n\nControl Chunk에도 TSN이 할당된다(O/X)\n\nX → TSN은 Multiplex Buffer에서의 순서를 나타내기 위한 번호이므로, Data Chunk에만 할당되고 Control Chunk에는 할당되지 않는다.\n\n\nSCTP에서의 ACK, Error Control은 어떤 Chunk에 대해 이루어지며 어떤 Numbering을 시용하는지 설명하시오\n\nSCTP의 ACK, Error Control은 Data Chunk들에 대해 이루어진다.\nData Chunk의 순서를 바로잡거나 누락은 없는지 등을 확인하는 과정이 Multiplex Buffer에서 이루어지므로, TSN을 이용해 ACK를 보내거나 Error Control을 하게 된다\n\n\nSCTP에서의 Connection을 부르는 명칭과, 어떤 방법을 이용해 하게 되는지 간단하게 설명하시오\n\nSCTP에서의 Connection은 Association이라고 부르며, 4-Way Handshake의 방법을 이용한다.\n\n\nSCTP의 Association을 하는 과정에서 데이터도 같이 전송될 수 있다(O/X)\n\nO → Association의 과정에서는 Cookie가 전송될 수 있는데, 여기에 Data Chunk를 실어 보내는 것이 가능하다\n\n\n다음은 SCTP의 통신 모습을 나타낸 것이다\n\n\n위의 통신 과정애 대해 어떤 Chunk들이 송신되고 있는지와 그들의 의미에 대해 설명하고, piggybacking이 이루어지는지 여부와 이유를 설명하시오\n\nClient의 첫번째와 두번째 송신의 경우에는 Data Chunk를 각각 두개씩 보내고 있다.\nServer는 Client가 보낸 4개의 Data Chunk에 대한 Selective ACK Control Chunk와 한개의 Data Chunk를 송신한다. 이때의 ACK는 cumTSN로, 여기까지는 잘 받았다는 의미를 가진다. 따라서, cumTSN이 7108이므로 TSN 7108까지 정상적으로 수신했다는 뜻을 담고 있다.\n그 다음에는 Server가 Client에게 Data Chunk를 보내고, Client는 Server에게 SACK Chunk를 보내고 있다.\n그림에서 Server의 첫번째 송신을 보면 ACK와 Data를 같이 실어서 보내며 양방향 통신을 하고 있다. 따라서 Piggybacking이 이루어지고 있는 중이라고 할 수 있다.\nSCTP에서의 Association Termination을 할때는 Half Close를 지원하지 않는다(O/X)\n\nO → SCTP의 Association Termination에는 Half Close를 지원하지 않고 한번에 종료되게 된다.\n\n\n아래 그림은 SCTP의 Flow Control 과정을 나타낸 그림이다\n\n\n이때 그림에 등장하는 모든 용어에 대해 설명하고 SCTP의 Flow Conttrol 과정을 언제 송수신이 불가능해지는지의 조건을 포함하여 설명하시오.\n\nSender의 경우 curTSN은 다음에 보낼 Data Chunk의 TSN 을 나타내는 것이고\nrwnd는 Receiver가 알려주는 Receiver window의 크기,\ninTransit은 보냈지만 ACK를 받지 못한 Data Chunk의 크기를 바이트로 표시한 것이다\nReceiver의 경우 cumTSN은 마지막으로 수신된 Data Chunk의 TSN을 나타내는 것이고\nwinSize는 수신 가능한 버퍼의 크기\nlastACK는 마지막으로 보낸 ACK를 의미한다.\n첫번째 송신을 보면 sender의 curTSN이 1이고, rwnd가 2000이고 TSN1의 크기가 1000이며 inTransit은 0이기 때문에 송신을 하게 된다\n송신한 이후에는 curTSN이 2로 바뀌고, TSN 1에 대한 ACK를 받지 못했기 때문에 inTransit이 TSN1의 크기였던 1000으로 바뀐 것을 확인할 수 있다.\nReceiver측은 아무것도 수신된게 없으므로 cumTSN과 lastACK는 비어있고 winSize가 2000으로 설정되어 있었는데\nClient의 첫 송신에 따라 cumTSN은 1이 되고 winSize는 2000에서 1000을 뺀 1000이 된다. lastACK는 ACK를 보내지 않았기 때문에 빈칸으로 남는다.\n두번째 송신에서는 curTSN인 TSN 2를 보내려고 하는데, rwnd가 2000이고 inTransit과 TSN2의 크기가 모두 1000이므로 송신한다\n송신한 후에는 cutTSN이 3으로 변경되고, inTransit은 2000이 된다\nServer는 두번째 Data Chunk를 받은 뒤 cumTSN은 2가 되고 winSize는 1000바이트가 추가적으로 수신되었으므로 0이 된다\n따라서 winSize가 0이므로 Process가 Data Chunk를 가져가기 전까지는 더 이상 수신이 불가능하게 된다\nSender쪽에서도 curTSN을 보내려고 하지만, rwnd에서 inTransit을 뺀 값이 0이기 때문에 Receiver Window에 더이상 공간이 없다는 것을 알아 송신이 불가능하게 된다\n이후 Receiver는 lastACK가 0이고 cumTSN이 2이므로 ACK를 보낼게 있다는 것을 알고 SACK에 cumTSN을 적어 보내게 된다. 또한 rwnd가 0이어서 지금 당장은 더이상 수신받지 못한다는 것도 같이 보낸다.\n해당 ACK를 받은 Sender는 ACK를 수신했으므로 inTransit을 0으로 만들지만, ACK에 담겨있던 rwnd의 크기가 0이었기 때문에 여전히 rwnd - inTransit값이 0이어서 송신하지 못하게 된다\n마지막으로 Receiver에서 Proccess가 TSN 1, 2를 가져가면 winSize가 2000으로 늘어난다. 따라서 SACK를 cumTSN 2와 rwnd 2000으로 하여 전송하게 되고, 이후 Sender는 rwnd값이 다시 2000으로 늘어나 TSN 3의 크기가 2000보다 작을 경우에 송신할 수 있게 된다\nSCTP의 수신측에서 순서가 맞지 않는 Chunk들이 들어왔을때의 처리법과 이때의 cumTSN, winsize에 대해 설명하시오\n\n순서가 맞지 않는 Data Chunk가 들어왔을 때에는 버퍼에 그대로 냅두고 Out of Order에 순서가 맞지 않는 Chunk들의 TSN을 저장해 앞순번의 Data Chunk가 올때까지 기다린다.\n순서가 맞지 않는 Data Chunk는 curTSN에 반영되지 않는다 - 순서가 맞지 않는 Data Chunk가 오면 curTSN은 그대로 유지돠고 앞순번의 Data Chunk가 도착해야 해당 TSN으로 curTSN으로 업데이트된다\n하지만 그러한 Chunk들이 버퍼에 자리는 먹고 있으므로 winSize는 해당 Chunk의 크기만큼 줄어들게 된다\n\n\nSCTP의 송신측의 Retransmission Queue에 대해 간략하게 설명하시오\n\nRTO가 발생했더나 3ACK로 인해 재전송되어야 하는 Chunk들은 Retransmission Queue에 들어간 뒤에 전송된다.\n\n\n\nApplication Layer §\nDNS §\n\nDNS가 무엇의 약자인지 적고, 이것이 필요한 이유를 Socket Addres와 연관지어서 설명하시오\n\nDNS는 Domain Name Service로, 통신 대상을 알기 위해서는 Socket Address를 알아야 하는데, Port는 Well Known이기 때문에 IP주소만 알면 되고, 이때 문자열 주소를 이용해 IP주소를 알아오는 시스템\n\n\nDNS Client와 DNS Server의 개념에 대해 설명하시오\n\nDNS Client는 문자열을 이용해 IP주소를 얻어내는 요청을 하는 프로세스이고, DNS Server는 문자열 주소와 IP쌍에 대한 정보를 가지고 있어 해당 요청에 대해 응답해 주는 프로세스를 의미한다\n유저에 의해 문자열 주소가 주어지면, DNS Client가 그것을 DNS Server에게 보내 그것에 해당하는 IP주소를 알아오게 된다\n\n\nNamespace의 개념과 이것이 가지는 중요한 특징을 적으시오. 또한, Namespace의 종류 두가지에 대해 설명하고 각각의 장단점에 대해 설명하시오\n\nNamespace는 Name-IP의 쌍의 집합을 의미한다.\nNamespace에 저장되어 있는 Name-IP의 쌍들은 Name혹은 IP가 중복되어서는 안된다. 왜냐하면 Name이나 IP가 주어질때 나머지 하나가 유일하게 결정되어야 하기 때문이다\nFlat Namespace는 Namespace가 한 곳에 저장되어 있는 형태를 일컫는다. 장점은 저장공간을 구성하기 쉽다는 것이지만, 단점은 해당 저장소가 모든 Namespace 구성원을 관리하고 요청에 응답해야 하기 때문에 병목현상을 피할 수 없다는 것이다\nHierarchical Namespace는 Namespace를 여러 저장소에 분배하여 계층적으로 저장하는 것을 의미한다. 단점은 저장공간을 구성하는 것이 까다롭다는 것이지만, 장점으로는 Flat Namespace에서 발생할 수 있는 병목현상이나 관리의 어려움 등을 해결할 수 있다는 것이 있다. 계층적으로 Namespace를 저장하는 것은 다른 작명소에 영향을 받지 않고 내부적으로만 중복을 피하여 작명을 한 후, 작명소의 이름을 붙여 Name을 구성하면 다른 작명소에서 생성된 Name과도 필연적으로 중복이 생길 수 없다는 원리를 기반으로 한다.\n\n\nDomain Namespace의 개념에 대해 설명하고 해당 namespace가 사용하고 있는 namespace의 종류, 어떤 자료구조 형태를 갖게 되는지 적으시오\n\nDomain Namespace는 DNS에서 사용하는 Namespace를 일컫는다. 이것은 Hierarchical Namespace를 사용하고, Inverted Tree의 형태를 가지게 된다\n\n\nDomain Namespace에서 Root, Label, Domain, Domain Name의 개념에 대해 설명하시오. 또한 Root의 Label은 무엇인지, Domain Name은 어떻게 알아내는지 적으시오\n\nDomain Namespace는 inverted tree의 형태를 가지게 되는데 이때의 최상단 노드를 Root라고 한다.\ninverted tree에서 각각의 node의 값이 Label이다. Root Node의 경우에는 null string을 label로 갖는다\ninverted tree에서 각각 node를 root로 하는 subtree를 Domain이라고 한다\nDomain을 식별하는 이름을 Domain name이라고 하며, 이것은 Domain Namespace의 Root로부터 해당 Domain의 Root까지의 경로상에 있는 Node들의 Label을 (.)로 연결하는 방식으로 알아낼 수 있다\n\n\nFQDN, PQDN이 무엇의 약자인지 적고 각각의 개념에 대해 설명하시오. 또한 어떤 Domain Name이 FQDN인지 PQDN인지 알아내는 방법에 대해 서술하시오\n\nFQDN은 Full Qualified Domain Name을 의미하고 Domain Name을 Domain의 Root부터 Domain Namespace의 Root까지 생략 없이 표기한 것을 말한다.\nPQDN은 Partially Qualified Domain Name을 의미하고 FQDN에서 일부를 생략하여 표기한 것을 의미한다.\nDomain Namespace의 Root의 Label은 nullstring이기 때문에 FQDN은 반드시 (.)로 끝난다. 반면 FQDN의 일부를 생략한 PQDN은 (.)로 끝나지 않고 특정 Label로 끝난다.\n\n\nName Server와 Zone의 개념에 대해 Authority의 개념을 이용해 설명하시오\n\n어떤 Name Server가 Namespace의 부분집합에 대한 Name-IP쌍을 저장하고 해당 집합에 대해 정보의 신뢰성에 대한 책임이 있을 때 해당 부분에 대해 Authority가 있다고 하고 해당 부분집합의 범위를 Zone이라고 한다.\n\n\n어떤 Name Server의 Zone이 Domain과 같아지는 경우와 같지 않은 경우에 대해 Authority Delegation의 개념을 이용해 설명하시오\n\n만일 어떤 Name Server가 Domain Namespace상에서 자식의 관계에 있는 Name Server에게 Authority Delegation을 했다면, 자신의 Domain과 Zone은 달라진다. 즉, Authority Delegation을 하면 해당 부분집합에 대한 Authority는 Delegation을 받은 Name Server에게 속하게 되고, 자신의 Zone은 해당 부분만큼 제외되기 때문이다.\n하지만 하나도 위임하지 않았다면 자신의 Domain 전부에 대해 Authority를 갖게 되고 따라서 Domain과 Zone은 같아지게 된다\n어떤 부분에 대해 자식 Name Server에게 Authority Delegation을 하게 되면 부모 Name Server는 해당 부분에 대한 Name-IP 정보를 갖고 있지 않고 단지 위임받은 자식 Name Server의 참조만을 갖고 있게 된다\n\n\nRoot Server, Primary Server, Secondary Server의 개념과 특징에 대해 설명하고 Zone Transfer에 대해서도 설명하시오\n\nRoot Server는 Domain Namespace에서 Root에 해당하는 Name Server이다. Root Server는 자신의 모든 Domain을 자식들에게 위임해 자신은 어떠한 Name-IP도 저장하지 않고 단지 자식들의 참조만을 갖고 있게 된다\nPrimary Server는 자신의 Zone에 속하는 Name-IP를 저장하고, 수정하고, 생성하고, 삭제하는 것이 가능한 Name Server이다\nSecondary Server는 Primary Server의 백업 서버로 Primary Server가 저장하고 있는 데이터를 동일하게 갖고있지만, 수정하거나 생성하거나 삭제하는 등의 작업을 하지는 못한다.\nPrimary Server가 Secondary Server에게 정보를 복사해주는 것을 Zone Transfer이라고 한다\n\n\nSecondary Server는 해당 Namespace에 대해 Authority를 갖고있지 않다(O/X)\n\nX → Secondary Server도 해당 Namespace에 대해 Authority를 가지고 있다. 수정이나 삭제, 생성이 안될 뿐이다\n\n\n하나의 Name Server가 서로 다른 Zone에 대해 Primary Server와 Secondary Server의 역할을 겸할 수 있다(O/X)\n\nO → 하나의 Name Server가 여러개의 Zone에 대해 Primary Server나 Secondary Server의 역할을 겸임할 수 있다. 따라서 해당 서버가 어느 Zone에 대해 어떤 역할을 하는지의 정보를 저장해놓아야 한다.\n\n\nDomain Namespace에서의 논리적인 위치와 실제 Name Server에서의 물리적인 위치는 같아야 한다. 즉, 어떤 기관에서 사용하는 Domain Name을 관리하는 Name Server는 반드시 해당 기관 내에 있어야 한다(O/X)\n\nX → 트리에서의 논리적인 위치와 실제 서버의 물리적인 위치는 관련이 없어도 된다. 즉, 어떤 기관에서 사용하는 Domain Name에 대한 Name Server가 다른 위치에 있어도 된다.\n\n\nDNS에서의 Domain Namespace는 크게 세개의 Domain으로 구분된다. 각각에 대해 이름을 적고 설명을 하시오\n\nGeneral Domain: .com이나 .org처럼 특정 지역이랑은 무관한 Domain들을 의미한다\nCountry Domain: .kr이나 .uk등 특정 국가 / 지역이랑 연관된 Domain들을 의미한다\nInverted Domain: 이것은 IP주소를 이용해 Name을 알아내기 위한 Domain이다\n\n\nDNS Client가 DNS Server에게 요청을 보내 응답을 받는 방법 중 Recursive Resolution과 Iterative Resolution에 대해 설명하시오\n\nRecursive Resolution과 Iterative Resolution모두 DNS Client가 가까이 있는 DNS Server에게 요청하는 것으로 시작된다. 만일 해당 DNS Server가 요청받은 Name에 대한 Authority를 갖고 있으면 바로 응답을 해주지만, 그렇지 않을 경우에 Recursive와 Iterative의 동작이 나뉜다.\nRecursive의 경우는 DNS Server가 또 다시 응답을 해줄 수 있을 것 같은 부모나 자식 DNS Server에게 요청을 보내는 과정을 응답을 받을때까지 반복하는 반면\nIterative의 경우에는 DNS Client에게 응답을 해줄 수 있을 것 같은 부모나 자식 DNS Sever의 IP를 응답함으로써 DNS Client가 직접 응답으로 받은 DNS Server에게 요청을 보내는 것을 반복하는 방법이다\n\n\nDNS Server의 IP를 아는 경우에는 직접 요청을 보내고 받는 것도 가능하다(O/X)\n\nO → 해당 Name에 대한 Authority가 있는 DNS Server의 IP를 알고 있는 경우에 Recursive나 Iterative의 방법을 사용하지 않고 직접 요청을 보내는 것도 가능하다\n\n\nDNS Server의 Caching기능과 Unauthorized Mark가 필요한 이유에 대해 설명하시오\n\n어떤 DNS Server에게 Authority가 없는 Name에 대한 요청이 반복적으로 들어올 경우, 그에 대한 응답을 Cache에 넣어놓고 대신 응답하는 것을 의미한다.\n하지만 이때에는 Authority가 없는 DNS Server가 대신 응답해주는 것이므로, DNS Client에게 Unauthorized Mark를 하여 응답함으로써 신뢰도가 낮은 응답이라는 것을 알려주게 된다.\n\n\n다음의 그림은 DNS Message의 Query와 Response Message Format이다.\n\n\n각 필드에 대해 설명하고, 어떤 Record가 들어가는 지 설명하시오\n\nHeader: 헤더\nQuestion Section: 요청에 대한 정보가 담기는 공간. Query Record가 저장된다\nAnswer Section: 요청에 대한 응답이 담기는 공간.\nAuthoritative Section: 응답의 신뢰성에 대한 정보가 담기는 공간\nAdditional Section: DNS Client가 활용하면 Query를 하는데 도움이 될만한 여러가지 정보들이 저장되는 공간(응답을 제공해 준 DNS Server의 IP주소 등)\nAnswer, Authoritative, Additional Section에는 Reqource Record가 들어간다\nDDNS에 대해 무엇의 약자인지, 개념은 무엇인지, 작동원리는 무엇인지 간략하게 서술하시오\n\nDynamic Domain Name System은 동적 IP 환경에서 Name에 대한 IP가 변경되었을 때, 이를 감지하고 보안회선으로 Primary Server에게 정보를 보내 변경사실을 알려주는 방법이다. 이후 Primary Server는 Secondary Server에게 변경사실을 통지하게 된다\n\n\nDNS가 이용하는 Transport Layer의 Protocol 두가지를 말하고, 어느 경우에 해당 Protocol을 이용하는지 Truncate bit의 용어를 포함해 설명하시오\n\nDNS는 UDP와 TCP를 이용한다\n응답의 크기가 크면 에러가 날 확률이 높고, 따라서 UDP를 이용할 수 없게 된다. 따라서 응답이 512바이트를 넘어설것 같은 요청은 TCP로 송수신하게 된다\n하지만 응답의 크기를 모르는 경우에는 UDP로 송신한다. 만일 응답이 512바이트를 넘게 되면, DNS Server가 Client에게 Truncate bit(TC bit)를 1로 만들어 응답을 보내 우선 TCP로 통신을 전환하고, 그 다음에 응답을 하게 된다\n이렇게 하는 이유는 TCP는 Connection, Disconnection의 과정이 필요한 값이 비싼 프로토콜이기 때문에, 응답이 512 바이트를 넘지 않는 간단한 요청의 경우에는 UDP를 사용하고자 하는 것이다.\n\n\n\nTELNET §\n\nTELNET의 개념을 Time Sharing Environment, Remote Logging, Virtual Terminal 의 개념을 이용해 설명하시오\n\nTime Sharing Environment는 컴퓨팅 파워가 강력한 중앙 컴퓨터를 두고, 클라이언트 컴퓨터가 접속하여 명령을 내리는 환경을 말한다.\n이때 Terminal을 이용해 명령을 입력하게 되고, 클라이언트의 Terminal이 아니기 때문에 Virtual Terminal이라고 부른다\nTime Sharing Environment에서 Virtual Terminal을 이용해 명령을 내리고 결과를 받아보는 작업을 Remote Logging이라고 한다\n\n\nTELNET이 필요한 이유를 ASCII Code의 범위별 특징과 운영체제별 인코딩 특징을 이용해 설명하시오\n\nASCII는 0부터 31까지는 Non-Printable한 시스템 제어 명령을 가지는 코드이다\n32부터 127까지는 Printable Code이며\n128부터 255까지는 Programmable한 Code이다\n따라서 0부터 127까지는 표준이 정해져 있고 운영체제 간 차이가 없지만, 128부터는 운영체제간 사용되는 의미 차이가 존재한다.\n또한 특정 운영체제는 ASCII를 사용하지 않기도 하는데, 이때문에 Remote Logging을 함에 있어 명령을 전달하는데 차이가 있고, 따라서 TELNET이 필요해지는 것이다\n\n\nLocal Logging의 과정을 Terminal Driver가 하는일을 포함해 설명하시오\n\n우선 키보드를 누르면 그에 맞는 상수가 Terminal Driver로 전달된다\n그럼 Terminal Driver는 현재의 운영체제가 사용하는 Encoding방식으로 인코딩한 후 운영체제에게 Stream을 전달한다.\n그럼 해당 운영체제는 Stream을 적절한 Application으로 전달하며 키보드의 명령이 Application으로 전달된다\n\n\nNVT가 무엇의 약자인지 적고, 이것의 역할과 하는 일, 그리고 범위별 번역법에 대해 설명하시오\n\nNVT는 Network Virtual Terminal로, 네트웨크를 이용한 Virtual Terminal을 말하는데, NVT Character Set 혹은 7-bit NVT ASCII는 운영체제에 종속되지 않은 Encoding방식을 제공한다.\nASCII의 최상위 비트가 0인 경우에 대해서는 표준으로 자리하고 있기 때문에, 최상위 비트가 0인 경우에는 다른 Encoding방식과 차이가 없으나, 최상위 비트가 1인 ASCII에 대해서는 표준이 없기 때문에 NVT Character Set 독자적인 Encoding 방식을 이용하고, NVT Character Set으로 변환하려 할 경우 다른 인코딩은 이 경우에 대해서만 변환을 하게 된다.\n\n\nTELNET의 Remote Logging과정을 TELNET Client, TELNET Server를 이용해 설명하고 이것이 사용하는 Transport, Network에서의 프로토콜을 적으시오. 또한, 이때 Pseudo Terminal Driver의 개념과 이것이 필요한 이유도 포함하시오\n\n키보드 이벤트가 발생하면 우선 해당 신호가 Terminal Driver에게 전달되어 로컬 환경의 Encoding으로 운영체제에게 전달된다\n그러면 운영체제는 그것을 TELNET Client로 전달하고, TELNET Client는 그것을 7-bit ASCII NVT로 변환하여 TCP / IP를 이용해 TELNET Server로 전달한다\nTELNET Server는 수신 후에 자신의 로컬 인코딩으로 변환하고, 그것을 Pseudo Terminal Driver에게 전달한다\nPseudo Terminal Driver는 이것을 OS로 바로 전달하는데, 이런 과정을 거치는 이유는 OS는 Terminal Driver에게서만 입력을 받도록 설계되어있어 Pseudo Terminal Driver를 거치게 되는 것이다\nOS에 전달된 이후에는 적절한 Application으로 전달되는 것으로 통신이 마무리가 된다\n\n\n\nElectronic Mail §\n\n모든 참여자가 같은 시스템에 접속해 있을 때 Mailing과정을 UA의 약자와 개념을 포함해서 설명하시오. 또한, 이때 사용되는 프로세스의 종류의 갯수에 대해서도 적으시오\n\n모든 참여자가 같은 시스템에 접속해있을 때는 사용자가 메일의 작성과 관리 등을 도와주는 UA(User Agent)을 이용해 시스템의 메일함에 적고, 수신자가 해당 메일함에서 꺼내가는 구조로 작동한다.\n따라서 이때에는 두개의 UA가 필요하게 된다\n\n\n참여자가 시스템에 직접적으로 접속해 있되, 같은 시스템은 아닌 경우에 대해 Mailing과정을 MTA의 약자와 개념, 어느 쪽이 Clinet이고 어느 쪽이 Server인지를 포함하여 설명하시오. 또한 이때 사용되는 프로세스의 종류와 갯수에 대해서도 적으시오\n\n이때에는 송신자는 UA를 이용해 시스템에 입력을 하면, 시스템은 MTA(Mail Transfer Agent)를 이용해 상대방의 시스템에 전달한다.\n송신자의 시스템에 있는 MTA Client는 수신자의 시스템에 있는 MTA Server로 전달하게 되고, MTA Server는 메일함에 넣어 수신인이 UA를 통해 꺼내가게 되는 구조이다\n따라서, 두개의 UA 한쌍의 MTA Client - Server가 필요하다\n\n\n한 참여자는 시스템에 직접적으로 접속해있지만, 한 참여자는 접속해있지 않은 경우에 대해 Mailing과정을 설명하고 사용되는 프로세스의 종류와 갯수에 대해서도 적으시오\n\n이때에는 송신인이 UA를 통해 메일을 작성하고, 송신인의 디바이스에 있는 MTA Client로 송신인의 시스템의 MTA Server에게 전달한다. 송신인의 시스템의 MTA Cline는 그것을 수신인의 Mail Server의 MTA Server로 전달하고, 마지막으로 그것을 수신인의 메일함에 넣어서 수신인이 UA를 통해 가져가게 되는 구조이다\n따라서 이때에는 두개의 UA, 두쌍의 MTA가 필요하다\n\n\n모든 참여자가 서로다른 시스템에 접속해있지 않은 경우에 대해서 Mailing 과정을 MAA의 약자와 개념, 어느쪽이 Client이고 Server인지를 포함하여 설명하시오. 또한 이때 사용되는 프로세스의 종류와 갯수에 대해서도 적으시오\n\nMAA는 Mail Access Agent로 메일함에 있는 메일들을 가져오는 역할을 한다. 이것이 필요한 이유는 수신인이 언제 수신 가능한지 모르기 때문에 Mail Server가 함부로 메일을 전달할 수 없기 때문이다. 따라서 수신인이 요청할때 메일을 전달하기 위한 목적이다\n이때에는 송신인이 UA를 통해 메일을 작성하고, 송신인 디바이스의 MTA Client로 송신인 Mail Server의 MTA Server로 보낸다. 송신인 Mail Server의 MTA Client는 수신인 Mail Server의 MTA Server로 해당 메일을 보내고, 수신인 Mail Server는 그대로 메일함에 두게 된다.\n이후에 수신인이 MAA Client를 이용해 수신인 Mail Server의 MAA Server로 메일함에 있는 메일을 달라고 요청하게 되고, 이때 메일함에 있는 메일들이 수신인 디바이스로 전달되어 UA를 통해 열람할 수 있게 된다\n\n\nPush Functionality와 Pull Functionality에 대해 적으시오\n\nPush Funtionality는 메일을 전송하는 것으로, MTA가 제공하는 기능이다\nPull Functionality는 메일을 가져오는 것으로, MAA가 제공하는 기능이다\n\n\nMIME의 개념과 이것이 필요한 이유에 대해 적으시오\n\nMIME은 동영상이나 이미지, 음원등의 경우에는 Text형태로 표현되지 않고 byte stream으로 표현되기 때문에, 이것을 7-bit ASCII NVT만을 지원하는 프로토콜을 사용하여 송수신하기 위해 변환하는 프로세스를 가리킨다\n대표적으로 base64 encoding을 이용한다.\n\n\nSMTP의 약자와 어느 것에 대한 프로토콜인지, 통신의 순서와 Request, Response메세지의 포맷에 대해 적으시오\n\nSMTP는 Simple Mail Transfer Protocol로, MTA가 사용하는 프로토콜이다. Connection, Mail Transfer, Termination의 과정을 거치며,\nRequest는 COMMAND ARGUMENT…의 형태이고\nResponse는 STATUS_CODE STATUS_MSG로 전달된다\n\n\nPOP3와 IMAP4에 대해 어느 것의 프로토콜인지, 둘의 차이점은 무엇인지 적으시오\n\nPOP3와 IMAP4는 MAA에 대한 프로토콜로, POP3가 먼저 나왔고, IMAP4는 나중에 나와 좀 더 보안성이 강화된 Pull Funtionality를 제공한다\n\n\nWeb Based Mail에 대해서 설명하시오\n\nEnd User는 MTA Server로 SMTP가 아닌 HTTP로 Request를 전송하고, MAA Server로 HTTP로 요청을 전송하는 것이 Web Based Mail이다\n하지만 End User가 아닌 Mail Server간에는 여전히 SMTP가 사용된다\n\n\nPull Functionality를 할때는 나의 Mail Server로 요청을 보내야되지만, Push Functionality를 할때는 나의 Mail Server로 요청을 보낼 필요는 없다(O/X)\n\nO → 나의 메일함에 접근하기 위해서는 당연히 나의 Mail Server의 MAA Server로 요청을 해야 되지만, 메일을 보내는 입장에서는 나의 메일함이 있는 Mail Server를 이용할 필요가 없는데, 나와 Mail Serer의 거리가 아주 멀 확률이 높기 때문이다\n하지만 요즘은 다른 Mail Server을 이용하기 위해서는 인증과정이 필요하다\n\n\n\nFTP §\n\nFTP는 무엇을 위한 프로토콜인지 설명하고 어떤 Network Layer의 통신을 동시에 몇개 사용하며 각각 통신의 경우 연결이 얼마나 지속되는 지 적으시오\n\nFTP는 파일을 전송하기 위한 프로토콜이고 TCP Connection을 동시에 2개를 가질 수 있으며, Command를 보내기 위한 Control Connection은 FTP Session내내 연결되어 있지만 Data Connection은 파일 한개가 전송될때마다 연결을 끊고 맺어준다\n\n\nControl Connection때 사용하는 Encoding방식과 Port, Request / Response Format을 적으시오\n\nControl Connection에서는 7-bit ASCII를 이용하며, Port는 25번을 이용하고 Requst는 COMMAND ARGUMENTS…, Response는 STATUS_CODE STATUS_MSG로 전달된다\n\n\nFTP에서의 어려운 점에 대해 설명하시오\n\n파일은 정해진 표준도 없고 디렉토리 구조도 다른 등 데이터의 형식이 정해지지 않아 어려움이 있다\n\n\n\nHTTP §\n\n브라우저의 동작과정을 Client Protocol, Controller, Interpreter를 이용해 설명하시오\n\n브라우저는 여러 Web Document를 수신하기 위해 FTP, HTTP같은 Client Protocol을 이용한다.\n그리고 받은 Web Document들을 Controller를 이용해 그것을 해석할 Interpreter와 연결지어서 화면에 렌더링한다\n\n\nURL이 무엇의 약자인지 적으시오\n\nUniform Resource Locator\n\n\nCookie를 사용하는 이유에 대해 HTTP Stateless를 이용해 설명하고, 세가지 용도인 Session Management, Personalization, Tracking에 대해 설명하시오\n\nHTTP는 기본적으로 Client의 정보를 저장하지 않는 Stateless를 기반으로 하기 때문에 Client가 누구인지, 어떤 문맥에서 요청을 하는지 알 수 없다. 따라서 Cookie를 이용해 이러한 정보들을 Client에게 전송한다.\nSession Management는 Server와 Client가 상호작용하는 기간 동안의 작업을 관리하는 용도로 Cookie를 사용할 수 있음을 의미하고\nPersonalization의 경우에는 개인별 설정 등에 대한 정보를 제공해 주기 위함이고\nTracking은 Client의 행동을 추적해 기록하고 분석하는 용도이다\n\n\nWeb Document의 세 타입인 Static Document, Dynamic Document, Active Document에 대해 설명하시오\n\nStatic Document는 Server가 정적으로 전송한 데이터를 Client가 랜더링하기만 하면 되는 데이터를 말한다\nDynamic Document는 Server가 데이터를 동적으로 생성해 넘겨주고, 그것을 Client는 랜더링하는 데이터를 말한다\nActive Document는 Server가 정적으로 전송한 테이터를 Client가 동적으로 추가적인 부분을 생성하여 렌더링하는 것을 말한다\n\n\nHTTP가 무엇의 약자인지, 그리고 무엇을 위한 것인지 적고 SMTP나 FTP와 차별되는 특징에 대해 설명하시오\n\nHTTP는 Hyper Text Transmission Protocol로 여러 Web Document를 송수신하는 데에 최적화된 Protocol이다\nSMTP나 FTP는 Connection을 하며 여러번의 Command - Response를 하게 되지만 HTTP는 단 한번의 Request - Response로 원하는 데이터를 송수신한다는 점이 차별화되는 부분이다\n\n\nHTTP Request, Response의 포맷에 대해 적고, 이것을 SMTP로 보낸다면 어떻게 연관지을 수 있는지 적으시오\n\nMETHOD URL HTTP_VER\nHEADER_KEY: HEADER_CONTENT\n...\nBODY\nHTTP_VER STATUS_CODE STATUS_MSG\nHEADER_KEY: HEADER_CONTENT\n...\nBODY\n\n\n만일 SMTP로 보낸다면, Request Line을 Command로 보낸 후에 Header들과 Body를 Mail Body로 보낼 수 있을 것이다. 또한, Response Line을 Response로 받게 될 수 있다고 할 수 있을 것이다\nHTTP Header의 4가지 종류에 대해 적고, 각각을 설명하시오\n\nGeneral Header: 통신 전반에 걸친 기본적인 사항들이 들어감\nRequest Header: 보낸 요청와 관련된 사항들이 들어감\nResponce Header: 응답들과 관련된 사항들이 들어감\nEntry Header: 응답으로 받은 데이터와 관련된 사항들이 들어감\n\n\nHTTP의 Persistent와 Non Persistent에 대해 설명하고 HTTP 1.1이후로는 어떤 것을 Default로 하는지 적으시오\n\nPersistent는 TCP Connection을 한번의 Request Response한 뒤에 끊어 새로운 Request를 할때마다 TCP Connection을 하는 것을 말하고\nNon Persistent는 TCP Connection을 한 뒤에 이어지는 반복적인 통신에 대해서는 Connection을 끊지 않다가 어느정도의 Timeout을 걸고 통신이 이루어지지 않으면 그때 TCP Termination이 이루어지는 것을 말한다\nHTTP 1.1이후로는 Non Persistent가 Default이다\n\n\nProxy Server가 제공하는 기능과 Original Server가 제공해주는 Content와의 차이점에 대해 적으시오\n\nProxy Server를 설치하면 해당 서버를 거쳐서 Original Server에 요청을 할 때 반복적인 요청이 존재하면 해당 요청의 응답을 저장해두었다가 다음번의 요청때 대신 응답해주는 것을 의미한다\nProxy Server는 자신이 Original Server가 아니기 때문에 Original Server가 제공하는 응답과 차이가 발생할 수 있고, 이것을 Client에게 신뢰성이 낮음을 알린다\n\n\nHTTP 1.1의 문제점을 Head of Line Blocking의 용어를 이용해 설명하고 이것을 해결하기 위해 TCP Connection을 여러개 맺으면 안되는 이유에 대해 적으시오\n\nHead of Line Blocking은 HTTP1.x에서 나타나는 문제점으로 Request를 한 뒤 Response가 오기 전까지는 새로운 Request를 할 수 없다는 것이다\n하지만 이것을 위해서 TCP Connection을 여러개 맺으면 TCP는 버퍼와 Connection Establishment, Slow Start등의 비용이 큰 프로토콜이기 때문에 결과적으로는 느려질 수 있다\n\n\nHTTP/2를 설계함에 있어서 가장 중요한 특징 세가지에 대해 설명하시오\n\nHTTP/2를 설계함에 있어 중요한 점 첫번째는 HTTP1.x와 호환이 되어야 한다는 것이다. 즉, 기존의 Message Format, URL등을 동일하게 유지한다\n두번째는 HTTP1.x때와는 다르게 병렬적인 Request / Response가 가능하게 해야 한다는 것이다\n세번째는 TCP Connection은 여전히 한개로 한정되어야 한다는 것이다\n\n\nHTTP/2에서의 Request / Response Multiplexing &amp; Demultiplexing에 대해 Message, Frame, Bidirectional Stream, Stream Identifier, Interleaved Sequence의 개념을 이용해 설명하시오\n\nParallel Request / Response를 달성하기 위해 HTTP/2는 Multi Bidirectional Stream을 제공하고, 이것을 통해 Parallel Request / Response를 할 수 있으며 이것들은 Multiplexing되어 하나의 Stream이 되고 수신지에 도착해서는 다시 Demultiplexing되어 각각의 Stream들에 뿌려진다.\n따라서 Demultiplexing을 하기 위해 Stream Identifier가 존재한다.\n이때, HTTP Message는 Frame단위로 잘게 잘려 Binary로 변환된 이후에 사이사이에 다른 Stream의 Frame이 들어갈 수 있는 Interleaved Sequence의 형태로 Multiplexing된다\n\n\nBinary Framing Layer가 담당하는 일과 과정, 그리고 계층의 위치를 HTTP API와 Socket Layer를 이용해 설명하고 이걸을 수행했을 때의 이점에 대해 설명하시오\n\nBinary Framing Layer는 Message를 Binary Frame으로 바꾸어 HTTP Message가 어떻게 Encapsulation되어 Transfer되는지를 담당하는 계층이다.\n이것은 더 사용자와 밀접한 연관을 맺은 Application들에게 HTTP API를 제공해주는 부분과, TCP / IP로 대표되는 Socket Layer사이에 존재해 HTTP API로부터 들어온 Message를 Binary Frame으로 바꾸어 Socket Layer로 내려보내거나, 반대위 과정을 담당하게 된다\nFrame단위로 변환하는 것은 Multiplexing시에의 Interleaved Sequence를 만들기 위함이고, Message의 Header는 하나의 Frame으로 변환되고 Message Body는 그 크기에 따라 1 이상의 Frame들로 나뉘어진다\nFrame을 Binary로 변환하는 것은 개행으로 구분된 HTTP Message는 Interprete과정이 필요하기 때문에 이것이 필요 없는 Binary 로 변환하여 더욱 컴퓨터가 이해하기 쉽게 만들고, 따라서 송수신의 속도도 더 줄어들게 하기 위함이다\n\n\nHTTP/2에서의 Steam Prioritization에 대해 어떤 자료구조인지, 어떻게 그리는지, 어떻게 활용되는지 적으시오\n\nStream Prioritization은 Frame들로 변환된 이후에 Interleaved Sequence로 변환되는 형식으로 Multiplexing되기 때문에, 이것들의 순서가 바뀌게 될 가능성이 있다.\n따라서 Frame에 우선순위를 매기고, 선후관계에 따라 Edge로 연결한 트리구조를 만들어 Receive과정에서 활용되게 된다\n\n\nServer Push기능에 대해 설명하고 이것의 이점애 대해 설명하시오\n\nServer Push 기능은 Client가 Request를 보냈을 때, Server가 판단하여 추가적으로 필요할 것 같은 Resource들도 같이 Response로 보내는 것을 말한다.\n따라서, Client가 요청하지 않았건 것도 추가적으로 보내기 때문에 Request보다 많은 양의 Response가 가게 된다\n이렇게 함으로써 Client는 추가적인 Request를 하지 않아도 되고, 따라서 Latency가 줄어들어 더욱 더 빨라지게 된다\n\n\nHeader Compression에 대해 Static Table, Dynamic Table, Huffman Code를 이용하여 간략하게 설명하시오\n\nHeader Compression은 자주 사용되는 Header들은 Table로 분리하여 Full Header이 아닌 Table의 Index를 제공함으로 Header의 크기를 더욱 더 줄일 수 있는 기술을 의미한다\n따라서 특정 통신과 관련이 없는 자주 쓰이는 Header는 Static Table에 저장하고, 특정 통신과 관련이 있는 자주 쓰이는 Header는 Dynamic Table에 저장하여 index로 Header entry를 대체한다\n만일 Table에 없는 Header에 대해서도 Huffman Code를 통해 더욱 더 사이즈를 줄이게 된다\n\n\n"},"originals/comnet.fall.2021.cse.cnu.ac.kr/부록---시험대비)-싱하형배-컴퓨터-네트워크-모의고사":{"title":"부록 - 시험대비) 싱하형배 컴퓨터 네트워크 모의고사","links":[],"tags":[],"content":"\n\nFall 2021, CNU, Computer Networks by Prof. Sang-Ha Kim\n\nOverview §\n\nPhysical layer, Data link layer, Network layer, Transport layer, Application layer 각각에 대한 주된 역할(기능)을 적으라\n각 Layer를 코드로 구현함에 있어서, Transparency의 의미와 숨겨여야 하는것, 그렇지 않은 것에 대해 설명하고(1) Send와 Receive 함수 Call의 방향성에 대해 설명하시오(2)\n\nNetwork Layer §\nPacket Switching §\n\nPacket Switching을 제공하는 장비의 이름을 적고(1) Packet Switching의 개념을 해당 장비의 구조와 연관지어서 설명하시오(2)\nDatagram과 Virtual Circuit에 대해 이들이 시작될때 공통적으로 행해지는 작업에 대해 적고(1) 이들의 핵심적인 차이점에 대해 Connection-oriented, Connectionless, Orderly Delivery의 개념을 포함하여 적어보거라(2). 그리고 각 Packet Switching방법을 사용하는 프로토콜(서비스) 에 대해 적어보고, 어느것이 먼저 세상에 나왔는지를 그 이유와 함께 적어보거라(3). 또한 각각의 방법이 가지는 강점에 대해 설명해보아라(4).\n아래와 같은 통신망이 있다고 해보자.\n\n\nB → D로 Virtual Circuit을 이용해 패킷을 전송하려고 할때, Connection Phase, Data Transfer Phase, Disconnection Phase에 대해 이동하는 패킷의 구조와 Virtual Circuit Table의 변화를 포함하여 설명하시오(단, 이동 경로와 Virtual Circuit Number는 임의로 정해도 된다)\n\nPacket은 송신 후 Packet Header는 Hop to Hop을 이동함에 에 따라 변경되고 Frame Header는 최종 수신지에 도착할때까지 변경되지 않는다(O / X)\n아래왜 같은 통신망이 있다고 해보자\n\n\n이때,\n\nConnect: H1 → A → B → D → H2\nConnect: H2 → D → B → E → H4\nConnect: H5 → E → C → A → H1\nConnect: H1 → A → B → D → H3\nDisconnect: H2 → D → B → E → H4\nDisconnect: H1 → A → B → D → H2\nDisconnect: H5 → E → C → A → H1\n\n위와 같은 쿼리에 대해 Virtual Circuit Table의 변화를 보이시오(단, Table의 구조는 다음과 같음 : InPort | InVC# | OutPort | OutVC#)\n\nService Provider, UNI, NNI, External Operation, Internal Operation의 용어에 대해 무엇의 약자인지, 그리고 개념은 무엇인지 적어보거라\nExternal 과 Internal Operation에서의 Packet Switching을 이원화하는 이유와 이원화 경우의 수 대표적인 세가지를 적어보거라\n\nRouting §\n\n2 level Hierarchy Routing Table의 개념과 이것이 필요한 이유를 netid, hostid의 용어를 이용하여 설명하여라\nIP주소 체계의 A, B, C Class의 IP 주소 범위에 대해 적어보거라\nnetid와 hostid가 발급되는 과정에 대해 간략하게 설명해보거라\nGateway router의 개념에 대해 설명하고 그것과 Gateway Router가 아닌 Router의 Routing 방법의 차이에 대해 설명해보거라\n아래 그림의 Gateway Router의 Forwarding Table을 작성하시오(단, Table은 DestinationAddr | SubnetMask | PortNum으로 구성되어 있다고 가정한다). 또한, 각 Port에는 몇개의 Host가 연결될 수 있는지 적으시오\n\n\n\n어떤 라우터가 Default Destination Port를 제외한 모든 Port의 Subnet Mask가 /27이었다면 해당 라우터는 Destination Port를 제외하고 몇개의 Port가 존재하는지(1), 그리고 하나의 Port에는 몇개의 Host가 연결되는지(2) 적으시오(단, 이 라우터에 연결되어 있는 Host의 총 갯수는 256개 이고 모두 같은 C Class netid를 가진다고 가정한다.)\n어떤 라우터의 Forward Table이 아래 그림과 같을 때, 168.188.15.5, 168.188.7.32, 168.192.32.0세 IP가 Routing되는 Port Number를 과정과 함께 적으시오\n\n\n\n어떤 Host의 IP를 설정할 때 IP주소는 192.168.32.5, Subnet Mask는 255.255.255.0, Default Gateway는192.168.32.1로 설정했을 때 해당 Host한테 생성되는 Routing Table을 그리시오(단, Routing Table의 구조는 Destination | Subnet Mask | Gateway | Flag | Interface로 구성되어 있으며 Interface는 0번만이 장착되어있다고 가정한다)\n아래와 같은 그림에서 라우터 R_CE의 Routing Table을 그려라 (단, Routing Table의 구조는 Destination | Subnet Mask | Gateway | Flag | Interface로 구성되어 있다고 가정한다)\n\n\n\n아래와 같은 네트워크 구조에서 CE1에서 CE2로 패킷을 전송하는 과정과 CE1에서 CE3으로 패킷을 전송하는 과정에 대해 전송되는 패킷의 송수신 IP, 물리 주소를 포함하여 설명하시오(단, 물리주소는 Node / Host의 이름과 같다고 가정한다)\n\n\n\n\n장대동에 거주하는 강혜종이는 이번에 새로운 컴퓨터를 사서 IP를 설정하려고 한다. 그가 속한 Subnet은 192.168.2.0/24인데, 실수로 Subnet Mask를 255.255.0.0을 설정했다. 이때, 같은 Subnet에 속하는 Host와 통신이 이루어지는지의 여부와, 다른 Subnet에 속하는 Host와 통신이 이루어지는 경우와 이루어지지 않는 경우애 대해 설명하시오\n아래와 같은 네트워크 구조에서 Proxy Router인 PC Router를 거쳐 CE3과 CE9가 양방향으로 통신하는 과정에 대해 전송되는 패킷의 송수신 IP주소와 물리주소를 포함하여 설명하시오\n\n\n\nRouting Table에서 Hop 혹은 Metric으로 표기되는 값에 대해 설명하시오\nRouting Table을 이용해 알아낸 Next-Hop의 IP주소는 패킷의 Tailer에 붙어 하위계층으로 전달된다(O / X)\n\nIPv4 §\n\nIP가 Datagram을 사용하는 이유를 Heterogeneous Network의 용어를 포함해서 설명하시오\nIPv4를 대표하는 두가지 중요한 특징에 대해 설명하시오\nIPv4의 Header의 필드인 HLEN, Total Length에 대해 설명하고 HLEN의 최솟값과 그 이유, HLEN이 8이고 Total Length가 112일 경우 패킷의 Mandatory Header, Option, Data가 각각 몇 바이트인지 설명하시오\nIPv4에서 Fragmentation이 필요한 이유와 1500byte로 Fragmentation하는 이유를 MTU의 용어를 사용하여 설명하덤둥. 또한, Router에서 단편화된 패킷을 받았을때 어떻게 행동하는지 서술하시오. 마지막으로 IPv4 패킷의 Header에서 Fragmentation과 관련된 필드 세가지를 적으시오\nIPv4 Header의 Protocol, Header Checksum, Time to Live 필드에 대해 간략하게 설명하시오\nIPv4의 Option인 No operation, End of option, Record route, Strict source route, Loose source route, Timestamp에 대해 간단하게 설명하시오\n\nIPv6 §\n\nIPv6의 가장 핵심적인 특징 두가지에 대해 적어보시오\nIPv6의 헤더 구조의 특징에 대해 설명하고, IPv4의 HLEN, Protocol, Header Checksum, Option 필드가 IPv6에서는 어떻게 바뀌었는지 서술하시오\nIPv6의 Next Header Field의 구조와 작동방식, Next Header가 참조되는 경우의 수에 대해 Dst Addr와 Hop-to-Hop Option을 이용해 설명하시오\n어떤 IPv6 패킷 헤더의 모습이 다음과 같다고 할때\n\n\n해당 패킷이 전송되는 과정과 Extension Header의 변화를 서술하거라(단, 위의 그림에 나와있는 Extension Header는 Source Routing이라고 가정한다)\nAddress Mapping §\n\nARP Cache에 대해 개념과 작동과정을 설명하고, 각 Entry의 지속시간에 대해 적어보아라\n자신을 위한 ARP Reply가 아닐지라도 ARP Reply에 적힌 IP - 물리주소를 이용해 자신의 ARP Cache Table을 업데이트한다(O / X)\nARP의 송수신 과정을 ARP Cache를 포함하여 설명하고, Proxy ARP의 작동과정 또한 설명하여라(단, 각 과정에 대해 패킷에 들어가는 송수신 물리주소와 IP주소를 명시하여라)\nARP Packet의 각 Field에 대해 들어가게 되는 값과 연관지어서 설명하시오.(단, Field는 Hardware Type, Protocol Type, Hardware Length, Protocol Length, Operation이 있다)\nRARP에 대해 무엇의 약자인지, 이것의 개념은 무엇인지, 이런 것이 필요하게 된 배경은 무엇인지, 마지막으로 이것의 작동 원리, 한계점에 대해 적어라.\nBOOTP에 대해 (1)이것이 등장하게 된 배경, (2)RARP와의 공통점 및 차이점, (3)어느 Layer에 포함되며 어느 Transport Protocol을 사용하는지, (4)작동 과정에 대해 설명해보시오\nDHCP에 대해 (1)이것이 무엇의 약자이고 이것이 필요한 이유를 BOOTP와 연관지어서 Deterministic Binding의 용어를 포함하여 설명하고 (2) Static Address Allocation일때와 Dynamic Address Allocation일때의 작동 방식을 설명하고 (3) 그 두가지를 종합한 작동방식을 Available Pool의 용어를 포함하여 설명하시오. 또한 (4) DB관점에서의 BOOTP와의 차이점 도 서술하시게\n\nError Reporting §\n\nICMP가 (1) 무엇의 약자인지 (2) 이것이 왜 필요한지 (3) 이것이 어느 계층에서 일어날 수 있는 문제들을 초점으로 하고 있는지 어디한번 설명해보거라\nICMP의 Error Reporting Message와 Query Message, Ping &amp; Pong에 대해 간단하게 설명해보아라\n\nMulticast §\n\n특정 다수에게 패킷을 송신하기 위해 Multiple Unicast와 Broadcast 방법이 갖는 단점에 대해 설명하시오\nMulticast를 함에 있어서 Intermediate Router 간의 통신과 Gateway - Host간의 통신 각각에 대한 프로토콜 이름을 적고, 이렇게 이원화한 이유를 적으시오\nIGMP 의 전반적인 과정에 대해 설명하시오(단, Group ID, Multicast Router, Group ID List, General Query, Membership Report, Leave Report, Special Query의 개념을 포함하여 설명하고 General Query시에 진행되는 Delayed Response Strategy의 개념과 이것을 사용하는 이유를 포함하여라)\nGeneral Query가 도착한 이후에 다음 그림처럼 난수 타이머가 설정되었다고 하자\n\n\n이때 어떤 Host가 어떤 Membership Report를 송신하게 되는지 순서와 이유를 저그시오\n\nMulticast Address에 대해 설명하시오\n한 Subnet에 여러개의 Multicast Router가 존재할 경우, 각각의 Group ID List는 상호배타적이어야 하는지의 여부와 그 이유를 적으시오\nQuery Router에 대해 간단허게 적어보시오\n\nTransport Layer §\n\nProcess to Process Delivery에 대해 간단하게 설명하고 이때 사용되는 주소 체계 이름을 적으시오라\nIP주소가 A인 Host의 Process a가 IP주소가 B인 Host의 Process b에게 송신하는 경우 local-host, remote-host, local-process, remote-process를 적으시오\nClient - Server모델을 Client, Server, Well-known Port, Ephimeral local port의 개념을 이용해 설명해보거라\nPort번호는 065535까지의 범위를 가지게 되는데, IANA는 이 범위를 01023, 102449151, 4915265535 세개로 나눠 각각의 용도를 정의하고 있다. 이때 각 범위의 용도를 서술하시오\nSocket Address에 대해 설명하시오\nTransport Layer에서 등장하는 Multiplexer와 Demultiplexer에 대해 설명하시오\nConnectionless와 Connection-oriented의 개념 및 차이점에 대해 간략히 설명하고 Connection-oriented 통신의 일반적인 작동과정을 간단흐이 설명하시오\nReliable과 Unreliable의 개념 및 차이점에 대해 Flow Control Error, Physical Error의 개념을 이용하여 설명하고 Data link layer에서의 Reliability와의 차이점에 대해 서술하시오\n\nUDP §\n\nUDP가 (1)무엇의 약자인지, (2) 개념과 해당 개념으로 인해 생기는 두가지의 대표적인 특징에 대해 설명하시오\nUDP에서 Client와 Server 각각에 대해 Port 가 열리면 상위 Application 계층과 통신하기 위해 어떤 자료구조 몇개가 어떤 용도로 생성되는지 적고, Server의 경우 Application Layer에서 Message를 식별하기 위해 추가적으로 진행되는 것과 그러한 것이 필요한 이유에 대해 적으시오\n\nTCP §\n\nTCP가 지원하는 다섯가지 핵심적인 서비스를 간략한 설명과 함께 적으시오\nTCP가 지원하는 Stream Delivery Service의 개념에 대해 UDP와 비교하며 설명하고 이것의 장점에 대해 서술하시오. 또한 Stream Delivery Service에서 Flow Control Error를 막기 위해 행하는 작업과 전송 과정, 전송되는 하나의 단위를 일컫는 명칭에 대해 서술하시오\nTCP의 Numbering은 무엇을 단위로 하여 매겨지는지 적으시오\nTCP에서 ACK Number가 의미하는 바를 적으시오\nSequence Number의 계산법에 대해 (1) 초기값 설정법, (2) 2^31 - 1을 넘어갔을때 어떻게 되는지, (3) 보낼 데이터가 있을때와 없을때 Sequence Number가 어떻게 설정되는지 적으시오\nTCP Connection에서 3 Way Handshake의 과정을 서술하되 상태 변화가 어떻게 이루어지는지, 각각의 과정에서 어떤 동작을 하고 어떤 Flag가 올라간 Segment가 전송되는지(+해당 Flag가 어떤 의미를 가지는지), 각 Segment의 Sequence Number와 ACK Number의 변화를 포함하시오\nTCP Connection이 이루어진 뒤에 다음과 같이 Data Transfer가 이루어졌을 때\n\n\nSequence Number와 ACK Number가 왜 저렇게 설정되는지, 그림에 나온 Flag들은 어떤 의미를 가지는지, 과정에 따라 서술하시오. 또한 위의 예제에서 Piggybacking이 이루어지고 있는지 여부를 이유와 함께 서술하시오(단, Data Transfer 바로 직전에 Client로 수신된 ACK가 8001이었다고 가정하고 Sequence Number는 15000인 데이터가 없는 Segment가 수신되었다고 가정한다)\n\nTCP Data Transfer을 하던 도중 ctrl + c를 눌러 전송을 중단했을 경우 어떤 일이 일어나는지를 URG Flag, URG Pointer의 개념과 함께 서술하시오. 또한 이렇게 함으로써 얻는 이점에 대해서도 서술하시오\nTCP Connection Termination에서 4 Way Handshake(Half Close)의 과정을 서술하되 상태 변화가 어떻게 이루어지는지, 각각의 과정에서 어떤 동작을 하고 어떤 Flag가 올라간 Segment가 전송되는지(+해당 Flag가 어떤 의미를 가지는지) 서술하시오\nTCP 4 Way Handshake(Half Close)를 할때는 Server가 먼저 Termination을 제안한다(O/X)\n다음의 그림에서 회색 박스를 채우시오\n\n\n\nTCP Flow Control을 할때는 Receiver의 요청에 따라 Sender의 버퍼 사이즈가 조정된다(O/X)\nrwnd가 무엇의 약자인지 적고 이것에 계산되는 과정을 적으시오\nSegment Header의 Window Size Field는 어떻게 결정되는지 그 이유와 함께 적으시오\n특정 시점에 Sender의 버퍼 상태가 다음과 같았다고 할 때,\n\n\nSender로부터 전달된 Window Size와 Sequence Number 199, 200202, 203208, 209번의 현재 상태에 대해 적어보시오(단, Seqence Num가 작은것부터 전송된다고 가정한다)\n\nTCP가 사용하는 ARQ 종류에 대해 적고 간략하게 설명하시오\nTCP 통신에서 수신측은 Segment Header의 어떤 Field를 보고 Error Detection을 하게 되는지 적고 Error가 있을때, Error가 없을때 어떻게 행동하는지 설명하시오\nTCP 통신에서 송신측은 어떤 경우에 Retransmission을 하게 되는지 RTO, RTT, Three Duplicate ACK Segment의 개념과 함께 설명하시오(단, RTO와 RTT가 무슨 말의 약자인지 적으시오)\nTCP 통신에서는 순서에 맞지 않는 Segment가 도착하면 해당 Segment를 어떻게 처리하고 어떤 ACK를 보내는지 out-of-order flag를 포함하여 서술하시오\nTCP 통신에서 Data Segment가 도착하고 어느정도 기간을 기다렸다가 ACK를 송신하는지 적고 해당 시간 내에 다른 Data Segment들이 추가적으로 수신되었을때 ACK를 어떻게 보내는지 설명하시오\nFast Retransmission에 대해 설명하고 그러한 경우는 Weak Error인지, Strong Error인지 판별하시오.\nFalse Flow Error, Queue Overflow by Congestion Error에 대해 Flow Error와 비교해서 간력하게 설명하시오\nCongestion Control의 세 단계에 대해 아래의 그림을 이용해 설명하되 MSS, ssthresh가 무엇의 약자이고 개념은 무엇인지 포함하고 Exponential Increase, Additive Increase, Multiplicative Decrease의 개념 또한 포함해서 설명하시오\n\n\nSCTP §\n\nSCTP가 무엇의 약자이고 어떤 배경에서 소개되었는지, 그리고 이것의 특징 4가지에 대해 설명하시오\nSCTP의 Multi Streaming과 Multi Homing을 TCP와 비교하여 설명하고, Multi Streaming과 Multi Homing의 차이점과 종합적인 구조를 설명하시오.\nTSN, SI, SSN에 대해 무엇의 약자인지를 포함해 개념을 적으시오. 또한 Chunk가 무엇인지도 같이 설명하시오\nSCTP Packet의 구조에 대해 TCP와 비교하며 설명하시오.\nControl Chunk에도 TSN이 할당된다(O/X)\nSCTP에서의 ACK, Error Control은 어떤 Chunk에 대해 이루어지며 어떤 Numbering을 시용하는지 설명하시오\nSCTP에서의 Connection을 부르는 명칭과, 어떤 방법을 이용해 하게 되는지 간단하게 설명하시오\nSCTP의 Association을 하는 과정에서 데이터도 같이 전송될 수 있다(O/X)\n다음은 SCTP의 통신 모습을 나타낸 것이다\n\n\n위의 통신 과정애 대해 어떤 Chunk들이 송신되고 있는지와 그들의 의미에 대해 설명하고, piggybacking이 이루어지는지 여부와 이유를 설명하시오\n\nSCTP에서의 Association Termination을 할때는 Half Close를 지원하지 않는다(O/X)\n아래 그림은 SCTP의 Flow Control 과정을 나타낸 그림이다\n\n\n이때 그림에 등장하는 모든 용어에 대해 설명하고 SCTP의 Flow Conttrol 과정을 언제 송수신이 불가능해지는지의 조건을 포함하여 설명하시오.\n\nSCTP의 수신측에서 순서가 맞지 않는 Chunk들이 들어왔을때의 처리법과 이때의 cumTSN, winsize에 대해 설명하시오\nSCTP의 송신측의 Retransmission Queue에 대해 간략하게 설명하시오\n\nApplication Layer §\nDNS §\n\nDNS가 무엇의 약자인지 적고, 이것이 필요한 이유를 Socket Addres와 연관지어서 설명하시오\nDNS Client와 DNS Server의 개념에 대해 설명하시오\nNamespace의 개념과 이것이 가지는 중요한 특징을 적으시오. 또한, Namespace의 종류 두가지에 대해 설명하고 각각의 장단점에 대해 설명하시오\nDomain Namespace의 개념에 대해 설명하고 해당 namespace가 사용하고 있는 namespace의 종류, 어떤 자료구조 형태를 갖게 되는지 적으시오\nDomain Namespace에서 Root, Label, Domain, Domain Name의 개념에 대해 설명하시오. 또한 Root의 Label은 무엇인지, Domain Name은 어떻게 알아내는지 적으시오\nFQDN, PQDN이 무엇의 약자인지 적고 각각의 개념에 대해 설명하시오. 또한 어떤 Domain Name이 FQDN인지 PQDN인지 알아내는 방법에 대해 서술하시오\nName Server와 Zone의 개념에 대해 Authority의 개념을 이용해 설명하시오\n어떤 Name Server의 Zone이 Domain과 같아지는 경우와 같지 않은 경우에 대해 Authority Delegation의 개념을 이용해 설명하시오\nRoot Server, Primary Server, Secondary Server의 개념과 특징에 대해 설명하고 Zone Transfer에 대해서도 설명하시오\nSecondary Server는 해당 Namespace에 대해 Authority를 갖고있지 않다(O/X)\n하나의 Name Server가 서로 다른 Zone에 대해 Primary Server와 Secondary Server의 역할을 겸할 수 있다(O/X)\nDomain Namespace에서의 논리적인 위치와 실제 Name Server에서의 물리적인 위치는 같아야 한다. 즉, 어떤 기관에서 사용하는 Domain Name을 관리하는 Name Server는 반드시 해당 기관 내에 있어야 한다(O/X)\nDNS에서의 Domain Namespace는 크게 세개의 Domain으로 구분된다. 각각에 대해 이름을 적고 설명을 하시오\nDNS Client가 DNS Server에게 요청을 보내 응답을 받는 방법 중 Recursive Resolution과 Iterative Resolution에 대해 설명하시오\nDNS Server의 IP를 아는 경우에는 직접 요청을 보내고 받는 것도 가능하다(O/X)\nDNS Server의 Caching기능과 Unauthorized Mark가 필요한 이유에 대해 설명하시오\n다음의 그림은 DNS Message의 Query와 Response Message Format이다.\n\n\n각 필드에 대해 설명하고, 어떤 Record가 들어가는 지 설명하시오\n\nDDNS에 대해 무엇의 약자인지, 개념은 무엇인지, 작동원리는 무엇인지 간략하게 서술하시오\nDNS가 이용하는 Transport Layer의 Protocol 두가지를 말하고, 어느 경우에 해당 Protocol을 이용하는지 Truncate bit의 용어를 포함해 설명하시오\n\nTELNET §\n\nTELNET의 개념을 Time Sharing Environment, Remote Logging, Virtual Terminal 의 개념을 이용해 설명하시오\nTELNET이 필요한 이유를 ASCII Code의 범위별 특징과 운영체제별 인코딩 특징을 이용해 설명하시오\nLocal Logging의 과정을 Terminal Driver가 하는일을 포함해 설명하시오\nNVT가 무엇의 약자인지 적고, 이것의 역할과 하는 일, 그리고 범위별 번역법에 대해 설명하시오\nTELNET의 Remote Logging과정을 TELNET Client, TELNET Server를 이용해 설명하고 이것이 사용하는 Transport, Network에서의 프로토콜을 적으시오. 또한, 이때 Pseudo Terminal Driver의 개념과 이것이 필요한 이유도 포함하시오\n\nElectronic Mail §\n\n모든 참여자가 같은 시스템에 접속해 있을 때 Mailing과정을 UA의 약자와 개념을 포함해서 설명하시오. 또한, 이때 사용되는 프로세스의 종류의 갯수에 대해서도 적으시오\n참여자가 시스템에 직접적으로 접속해 있되, 같은 시스템은 아닌 경우에 대해 Mailing과정을 MTA의 약자와 개념, 어느 쪽이 Clinet이고 어느 쪽이 Server인지를 포함하여 설명하시오. 또한 이때 사용되는 프로세스의 종류와 갯수에 대해서도 적으시오\n한 참여자는 시스템에 직접적으로 접속해있지만, 한 참여자는 접속해있지 않은 경우에 대해 Mailing과정을 설명하고 사용되는 프로세스의 종류와 갯수에 대해서도 적으시오\n모든 참여자가 서로다른 시스템에 접속해있지 않은 경우에 대해서 Mailing 과정을 MAA의 약자와 개념, 어느쪽이 Client이고 Server인지를 포함하여 설명하시오. 또한 이때 사용되는 프로세스의 종류와 갯수에 대해서도 적으시오\nPush Functionality와 Pull Functionality에 대해 적으시오\nMIME의 개념과 이것이 필요한 이유에 대해 적으시오\nSMTP의 약자와 어느 것에 대한 프로토콜인지, 통신의 순서와 Request, Response메세지의 포맷에 대해 적으시오\nPOP3와 IMAP4에 대해 어느 것의 프로토콜인지, 둘의 차이점은 무엇인지 적으시오\nWeb Based Mail에 대해서 설명하시오\nPull Functionality를 할때는 나의 Mail Server로 요청을 보내야되지만, Push Functionality를 할때는 나의 Mail Server로 요청을 보낼 필요는 없다(O/X)\n\nFTP §\n\nFTP는 무엇을 위한 프로토콜인지 설명하고 어떤 Network Layer의 통신을 동시에 몇개 사용하며 각각 통신의 경우 연결이 얼마나 지속되는 지 적으시오\nControl Connection때 사용하는 Encoding방식과 Port, Request / Response Format을 적으시오\nData Communication에서의 어려운 점에 대해 설명하시오\n\nHTTP §\n\n브라우저의 동작과정을 Client Protocol, Controller, Interpreter를 이용해 설명하시오\nURL이 무엇의 약자인지 적으시오\nCookie를 사용하는 이유에 대해 HTTP Stateless를 이용해 설명하고, 세가지 용도인 Session Management, Personalization, Tracking에 대해 설명하시오\nWeb Document의 세 타입인 Static Document, Dynamic Document, Active Document에 대해 설명하시오\nHTTP가 무엇의 약자인지, 그리고 무엇을 위한 것인지 적고 SMTP나 FTP와 차별되는 특징에 대해 설명하시오\nHTTP Request, Response의 포맷에 대해 적고, 이것을 SMTP로 보낸다면 어떻게 연관지을 수 있는지 적으시오\nHTTP Header의 4가지 종류에 대해 적고, 각각을 설명하시오\nHTTP의 Persistent와 Non Persistent에 대해 설명하고 HTTP 1.1이후로는 어떤 것을 Default로 하는지 적으시오\nProxy Server가 제공하는 기능과 Original Server가 제공해주는 Content와의 차이점에 대해 적으시오\nHTTP 1.1의 문제점을 Head of Line Blocking의 용어를 이용해 설명하고 이것을 해결하기 위해 TCP Connection을 여러개 맺으면 안되는 이유에 대해 적으시오\nHTTP/2를 설계함에 있어서 가장 중요한 특징 세가지에 대해 설명하시오\nHTTP/2에서의 Request / Response Multiplexing &amp; Demultiplexing에 대해 Message, Frame, Bidirectional Stream, Stream Identifier, Interleaved Sequence의 개념을 이용해 설명하시오\nBinary Framing Layer가 담당하는 일과 과정, 그리고 계층의 위치를 HTTP API와 Socket Layer를 이용해 설명하고 이걸을 수행했을 때의 이점에 대해 설명하시오\nHTTP/2에서의 Steam Prioritization에 대해 어떤 자료구조인지, 어떻게 그리는지, 어떻게 활용되는지 적으시오\nServer Push기능에 대해 설명하고 이것의 이점애 대해 설명하시오\nHeader Compression에 대해 Static Table, Dynamic Table, Huffman Code를 이용하여 간략하게 설명하시오\n"},"originals/comnet.fall.2021.cse.cnu.ac.kr/부록---실습자료-1)-Network-layer-&-ARP":{"title":"부록 - 실습자료 1) Network layer & ARP","links":[],"tags":[],"content":"\n\n                  \n                  충남대학교 컴퓨터공학과 김상하 교수님의 &quot;컴퓨터 네트워크&quot; 강의를 필기한 내용입니다. \n                  \n                \n\n\n\n                  \n                  다소 잘못된 내용과 구어적 표현 이 포함되어 있을 수 있습니다. \n                  \n                \n\nNetwork Layer의 역할 §\n\nInternetworking : 다른 네트워크(뭐 예를 들면 네트워크 케이블로 직접 연결되어있지 않은)들 간 연결을 해줘 하나의 네트워크처럼 보이게 하는 것\nAddressing : 전 세계의 어느 곳이든 통신할 수 있게 하기 위해 기기들의 고유한 주소를 할당\nRouting : 패킷이 목적지에 도착하기까지의 최적의 경로를 설정하는 역할\nPacketizing : 상위계층으로부터 받은 데이터를 단편화해 패킷화하는 것\nFragmentation : 이건 프레임을 받아 처리한 후 새로운 프레임으로 구성하는 것\n\n패킷화랑은 다르다! - 라우터에서 데이터링크 계층으로부터 받은 프레임을 decapsulation하여 루트를 설정하고 다른 포트로 보내기 위해 다시 프레임화 하는 과정을 떠올리면 됨\n\n\n\nAddress Resolution Protocol §\n\n일단 너가 옛날에 가졌던 의문에 대한 답이 나오는데\n물리주소와 논리주소쳬게를 별도로 분리하는 이유는 찐으로 고유한 값을 가지는 물리주소를 논리주소로도 이용하게 된다면 다른 네트워크로 빠져나가는 과정에서 문제가 생기게 된다\n\n러프하게 생각해보면 모든 단말들의 물리주소가 고유하게 다르기 때문에 특정 주소의 단말로 가기 위해 라우팅 테이블로 다음 목적지를 알아내기 위해서는 이 모든 물리주소들에 대한 정보가 라우팅 테이블에 어느정도 들어있어야됨 - 근데 이게 불가능하기 때문인거같은뎅\n\n\nIP주소는 32bit이고 MAC주소는 48bit이라는거정도는 알고있어야되지 않나\n\n\n\n위의 그림이 ARP에서 사용되는 프레임의 포맷이다\n다른 프레임의 구조와 동일하게, 맨 처음 6바이트는 수신지 물리주소가 들어가게 되고, 그 다음 6바이트는 송신지 물리주소가 들어가게 되며 그 다음 2바이트에는 이 프레임의 타입을 지정하는 숫자가 들어가게 된다\nARP에선 ARP Request, reply 모두 0x0806을 frame type에 넣어 이 프레임이 ARP를 위한 프레임임을 나타낸다\nARP에서는 이전에 배웠다시피 Ethernet destination address에는 broadcast가 들어가게 된다\n그리고 Hard type은 통신에 사용하고 있는 데이터 링크 계층의 프로토콜 종류를 나타내고, Ethernet인 경우에는 0x0001이 들어가게 된다\n또한 Prot type에는 통신에 사용하고 있는 네트워크 계층의 프로토콜 종류를 나타내고, IP인 경우에는 0x0800이 들어가게 된다\nHard &amp; Prot size의 경우에는 데이터링크와 네트워크 계층에서 각각의 프로토콜에 사용될 주소의 길이를 1바이트에 저장하게 된다 - Ethernet인 경우에는 주소의 길이는 6바이트이므로 0x06이 들어가게 되고 IP의 경우에는 주소의 길이는 4바이트이므로 0x04가 들어가게 된다\nOp필드의 경우에는 어떤 패킷인지 나타내는 숫자가 들어가게 되는데, ARP request인 경우에는 1, reply인 경우에는 2, RARP(물리주소로 논리주소 알아내는 프로토콜) request인 경우에는 3, reply인 경우에는 4가 들어가게 된다\n마지막 4개의 필드에는 그림에 보이는것처럼 각각 송수신지의 물리주소와 논리주소가 들어가게 된다\nARP를 통해 물리주소를 알아낸 뒤에는 해당 주소를 캐쉬에 넣어놓고 추가적인 ARP 과정 없이 바로 보내게 된다\n\n니가 아는 그 캐쉬 맞다 - 캐쉬 테이블에는 최근에 통신을 한 대상에 대한 물리주소가 저장되어 있어 IP만 가지고 선형탐색과정 없이 아주 빠른 속도로 물리주소를 알아낼 수 있음\n따라서 ARP를 하기 전에 먼저 캐쉬 테이블에 이미 있나를 먼저 확인하고 없다면 ARP가 진행되는 방식인 것\n물리주소를 찾은 경우 - Completed인 경우에는 캐쉬 테이블에 20분간 저장을 하게 되고 그렇지 않은 Incompleted인 경우에는 3분간 저장을 하게 된다\n주소를 캐쉬에 넣어놓는 작업은 송수신자만 하는게 아니다 - ARP Request를 받은 모든 노드가 이걸 통해 송신자의 IP와 MAC을 매칭시킬 수 있기 때문에 자신한테 온 ARP Request가 아니라 하더라도 송신자의 IP와 MAC을 캐쉬에 넣어놓게 된다\n\n\n실습때 구현할때 request와 reply에 패킷에 저장된 내용의 순서가 바뀌는 것에 유의해라\n\n응답을 보낼때는 받은 패킷의 송신자가 응답 패킷의 수신자가 되므로\n\n\n"},"originals/comnet.fall.2021.cse.cnu.ac.kr/부록---실습자료-2)-Proxy-ARP":{"title":"부록 - 실습자료 2) Proxy ARP","links":[],"tags":[],"content":"\n\n                  \n                  충남대학교 컴퓨터공학과 김상하 교수님의 &quot;컴퓨터 네트워크&quot; 강의를 필기한 내용입니다. \n                  \n                \n\n\n\n                  \n                  다소 잘못된 내용과 구어적 표현 이 포함되어 있을 수 있습니다. \n                  \n                \n\nProxy ARP §\n\n얘는 수신지가 같은 네트워크 상에 없어 라우터를 통해 다른 네트워크로 가야되는 경우에 사용하는 ARP이다\nProxy라는 것은 다른 네트워크에 있는 수신자에게 패킷을 전달해주는 역할을 하는 중간매개정도로 생각하면 된다\n라우팅이랑 프록시랑 뭔차인지 좀 헷갈리긴 하는데 약간 생각해보면\n라우팅이라는 것은 다른 네트워크와의 연결을 위해 라우팅 테이블이 있고 패킷이 들어왔을때 라우팅 테이블을 통해 다음에는 어디로 보내야되는지 결정하는 역할이라면\n프록시는 라우팅과는 달리 패킷을 받은다음에 다음의 경로를 지정하는 것이 아닌 자신한테 연결되어있는 노드인지를 확인해 연결되어있는 노드라면 받아들이고 아니라면 기각하는 방식 - 여러개의 노드들을 대변하는 하나의 노드인 셈\n말단노드가 아닌 중단노드라는 점에서 라우터와 비슷하긴 하지만 경로를 설정해 전달해주는 것이 아닌 자신한테 연결되어있는 노드들에 대해서만 패킷을 받아 전달해주는 차이점이 있는듯\n따라서 프록시에 연결되어있는 노드들은 프록시를 통해 간접적으로 네트워크에 연결되어있는 셈 - 중앙 허브에서 이 각각의 노드로 직접적으로 패킷을 보내지는 못한다\n쨋든 이러한 프록시 기능을 제공하는 노드를 Proxy agent라고 하고 이놈이 패킷을 받아 자신에게 연결된 노드에게 대신 전달해주는 역할을 하게 된다\n\nProxy ARP의 과정 §\n\n\n일단 위처럼 구조가 되어있다고 해보자\n실습수업에서는 약간 한 노드에서 패킷을 보내면 저 위에있는놈이 받아 각자에게 뿌려주는 방식으로 설명하긴했는데 어쨋든\n만약 168.188.129.1에서 168.188.129.130으로 패킷을 보내고 싶다고 해보자\n그리고 168.188.129.130은 네트워크에 직접적으로 연결되어있지 않고 168.188.129.3을 프록시로 하여 간접적으로 연결되어 있음\n\n\n\n프록시를 통해 네트워크에 연결하는 것은 위의 그림처럼 구현해볼 수 있다\n위의 그림에서 Proxy ARP Entry를 보면 일단 Interface0은 129.130의 노드 이름인 것이고\n그다음의 168.188.129.130은 당연히 프록시를 통해 연결된 노드의 IP주소겠지\n근데 이상한 것은 그 다음에 나오는 MAC주소는 프록시를 통해 연결된 노드(129.130)의 MAC주소가 아니라 프록시(129.3)의 MAC주소이다\n\n이건 왜냐하면 129.130으로 보내기 위해서는 129.3으로 보내야 하기 때문에 저렇게 되어 있는 것\n실제로는 129.130의 MAC주소는 08:00:20:81:28:BE가 아니지만 129.130을 129.3이 대변하고있기 때문에 논리적으로는 129.130의 MAC주소가 129.3의 MAC주소인 08:00:20:81:28:BE 인 것이나 다름 없다는 소리다 - 여기로 보내면 무조건 129.130으로 전달되기 때문에\n\n\n\n\n\n쨋든 129.1에서 129.130으로 보내기 위해 위와 같은 구조로 ARP를 보내게 된다\n\n수신 MAC주소를 broadcast로 하고 129.1의 IP와 MAC을 송신지로 넣고, 129.130의 IP를 수신지로 넣은 다음에 129.130의 MAC주소는 모르기 때문에 위 그림에 보면 ????으로 되어있다\n\n\n129.1이 보낸 ARP가 129.3에 도달하면 129.3은 자신에 연결된 노드들을 Proxy ARP Entry를 통해 확인해 129.130이 자신한테 연결되어있다는 것을 확인한다\n\n\n\n확인한 후에는 129.1이 자신한테 보내야 하기 때문에 자신의 MAC주소를 넣되 자신이 129.130을 대변하고 있기 때문에 129.130은 그대로 냅두고 송수신 주소를 Swapping한 후, Opcode를 2로 바꿔서 ARP Reply를 보내게 된다\nARP Reply를 129.1이 받은 다음에는 뭐 패킷 보내고 받고 알아서 하겠지\n"},"originals/comnet.fall.2021.cse.cnu.ac.kr/부록---실습자료-3)-GARP":{"title":"부록 - 실습자료 3) GARP","links":[],"tags":[],"content":"\n\n                  \n                  충남대학교 컴퓨터공학과 김상하 교수님의 &quot;컴퓨터 네트워크&quot; 강의를 필기한 내용입니다. \n                  \n                \n\n\n\n                  \n                  다소 잘못된 내용과 구어적 표현 이 포함되어 있을 수 있습니다. \n                  \n                \n\nGratuitious ARP §\n\n이놈은 자신의 물리주소가 바뀌었을 때 그것을 다른 호스트에게 알리기 위한 용도이다\n즉, 자신의 물리주소가 바뀌었으면 바뀐 물리주소를 ARP Request에 포함하여 전송함으로 다른 호스트가 이것을 받아들고 각자의 Cache table을 업데이트 하는 것이다\n\n\n\n그래서 전체적으로는 위와 같은 구조를 가진다\n해당 그림은 이더넷 프레임의 구조 를 보여주는 그림으로 위의 세 칸은 이더넷 프레임의 헤더이고, 지금까지 너가 알던 대로 Broadcast, 자신의 물리주소, 프레임 타입 0806이 들어간 것 을 볼 수 있다\n이제 그 아래가 네트워크 패킷인데\n다른부분보다 맨 아래 네 칸을 잘 봐라\n먼저 Sender’s hardware address에는 바뀐 자신의 주소가 들어간다\n그리고 Sender’s protocol address는 당연히 자신의 네트워크 주소가 들어가고\nTraget’s hardware address도 당연히 Broadcast로 보내는 ARP Request이기 때문에 알 수 없으므로 ??로 되어있다\n그리고 Target’s protocol address에도 Sender’s hardware address와 같은 자신의 네트워크 주소가 들어가게 된다\n그 이유를 대충 짐작해보면\nARP Request를 받은 수신지는 상대방의 Protocol address를 업데이트하고 Target’s protocol address가 자신의 주소면 ARP Reply를 보내게 되지만 만약 자신의 주소가 아니라면 상대방의 Protocol address만 업데이트 할 것이다\n하지만 Target’s protocol address에 송신지의 주소를 적으면 어느 수신지의 protocol address와도 일치하지 않기 때문에 그 누구도 ARP Reply를 보내지 않게 되고 따라서 그냥 송신지의 물리주소를 통보하는 용도로 사용될 수 있는 것\n"},"originals/comnet.fall.2021.cse.cnu.ac.kr/부록---실습자료-4)-Static-Router":{"title":"부록 - 실습자료 4) Static Router","links":[],"tags":[],"content":"\n\n                  \n                  충남대학교 컴퓨터공학과 김상하 교수님의 &quot;컴퓨터 네트워크&quot; 강의를 필기한 내용입니다. \n                  \n                \n\n\n\n                  \n                  다소 잘못된 내용과 구어적 표현 이 포함되어 있을 수 있습니다. \n                  \n                \n\nLAN §\n\n단순하게 생각하면 ARP Request Packet이 도달하는 범위\nL2 Switch나 Hub로 연결되어있는 경우에는 같은 LAN으로 보고 Router로 연결되어있는 경우에 다른 LAN으로 본다\nRouter의 각 Interface는 각각 서로 다른 LAN에 연결되어 있다\n\n\n\nLAN의 갯수를 세라는 문제 동영이가 낼거같은데 위 그림처럼 Router의 Interface와 연결되어있는 하나의 통신망을 세어주면 된다\n\n\n\n그리고 Hop수를 세라는 문제도 낼거같은데 두 호스트 사이에 존재하는 LAN의 갯수를 세어 주면 된다\n그리고 Routing table을 확인하는 숫자는 Interface를 지날때마다 확인하기 때문에 Hop count의 두배가 된댄다\n\nStatic Router §\n용어정리 §\n\nStatic Router : Routing table을 사람이 직접 손수 적어줘야 하는 라우터\nNetwork Address : 해당 네트워크를 대표하는 IP 주소\n\n이것은 네트워크상의 어떤 한 호스트랑 그 네트워크의 서브넷 마스크를 &amp;해서 얻어낼 수 있음\n그니까 예를 들면\n192.168.3.1~192.168.3.255로 이루어진 네트워크가 있으면\n당연히 Subnet mask는 /24가 되것지\n그리고 이거랑 저중에 아무거나 하나 &amp;하면 192.168.3.0 이 되잖여\n저 값이 Network Address가 되는거임\n즉, 어떤 IP가 속하는 Network의 Network Address를 알아내고 싶다면 그 IP랑 Subnet mask랑 &amp;하면 된다이거야\n\n\nDestination, Destination IP : 이게 단어가 중복돼서 헷갈리는데 일단 여기서는 Destination은 라우팅 테이블에서 Subnet mask를 씌웠을때의 값을 말하는 거고 Destination IP는 패킷에 들어있던 수신지 주소 라고 용어 통일을 해야겠음\n\nRouting table §\n\n\nDestination : NetMask와 Bitwise AND를 해서 나와야 되는 결과값\n\n보통은 Network Address가 들어가는데\n근데 Host Address를 주는것도 가능하댄다 - NetMask를 /32를 줘서 특정한 하나의 Destination IP가 들어왔을때만 매칭시키는 것도 가능하댄다\n\n\nNetMask : 뭔지알제? 서브넷 마스크\nGateway : Destination IP가 다른 네트워크에 있을 경우 거기로 가기 위한 다음 라우터의 IP주소\n\nppt예시에는 ㅂㅅ같이 나와있는데 호스트가 자신과 직접 연결되어있을 경우에는 “*”로 표시해놓으면 된다\n\n\nFlag : 여러 flag들이 있는데\n\nU : UP - 다음 목적지(Hop - 뭐 다음 라우터든 아니면 최종 목적지든)로 정상적으로 도달할 수 있음\nG : Gateway - Destination IP가 현재 라우터랑 직접 연결되어있지 않음\n\n즉, Next Hop이 라우터이고 Gateway에 명시되어있는 주소로 가야된다는 의미\n\n\nH: Host-specific - Destination 열에 적혀있던 값이 Network Address가 아니라 Host Address라는 뜻\n\n\nInterface : 어느 Interface Card로 나가야 되는지\nMetric : 위의 예시에서는 나와있지 않지만 목적지까지 도달하기 위해 지나가야하는 Network(Router)의 갯수\n\n직접 연결되어있는 것을 1로 하고 라우터를 n번 더 거쳐야 된다면 n + 1이 된다\n\n\n\n작동 과정 §\n\n일단 패킷에서 Destination IP를 꺼낸다\nNet Mask(Subnet Mask)랑 Bitwise AND를 한다\n그의 결과와 일치하는 Destination을 찾는다 == Match되는 Entry를 찾는다\n\n난 지금까지 라우팅 테이블을 위에서부터 읽으면서 제일 먼저 매치되는 애를 찾는줄 알았는데\n내가 잘못 알고 있었던거지 - Subnet mask와 Bitwise AND를 했을때 매치되는 Destination이 여러개라면 그 중에서 Longest Prefix Match를 선택한다\nLongest Prefix Match는 선택된 애들중에 Subnet Mask가 가장 큰놈(1이 제일 많이 들어가있는 놈)을 선택한다는 뜻으로 생각하면 될거같음\n\n\n그리고 Next Hop Address를 구함\n\nFlag를 보고 U면 직접 연결되어 있으므로 Next Hop Address가 Destination IP가 되는 것이고\nUG라면 다음 라우터로 가야되기 때문에 Next Hop Address는 Gateway 열에 적혀 있는 값이 되는 것\n\n\n다음으로는 Matched Entry에 있는 Interface를 이용해 패킷을 보내게 된다\n보낼때는 뭐 동일함 - ARP Cache Table보고 있으면 그걸로 보내고 없으면 ARP 요청해서 보내고\n"},"originals/compiler.fall.2021.cse.cnu.ac.kr/(충남대)-컴파일러-개론-강의록":{"title":"(충남대) 컴파일러 개론 강의록","links":["originals/compiler.fall.2021.cse.cnu.ac.kr/01.-어휘분석-&-토큰","originals/compiler.fall.2021.cse.cnu.ac.kr/02.-어휘분석기-만들어보기","originals/compiler.fall.2021.cse.cnu.ac.kr/03.-구문분석-&-파스트리","originals/compiler.fall.2021.cse.cnu.ac.kr/04.-Top-down-구문분석","originals/compiler.fall.2021.cse.cnu.ac.kr/05.-LL문법","originals/compiler.fall.2021.cse.cnu.ac.kr/06.-구문분석기-만들기","originals/compiler.fall.2021.cse.cnu.ac.kr/07.-Bottom-up-parsing","originals/compiler.fall.2021.cse.cnu.ac.kr/08.-yacc","originals/compiler.fall.2021.cse.cnu.ac.kr/09.-LR(0)-파싱-테이블,--SLR-파싱","originals/compiler.fall.2021.cse.cnu.ac.kr/10.-LR(1)-파서,--LALR-파서","originals/compiler.fall.2021.cse.cnu.ac.kr/11.-SDD,-AST","originals/compiler.fall.2021.cse.cnu.ac.kr/12.-IR","originals/compiler.fall.2021.cse.cnu.ac.kr/13.-3-Address-code","originals/compiler.fall.2021.cse.cnu.ac.kr/14.-Semantic-Analysis,-Type-Checking","originals/compiler.fall.2021.cse.cnu.ac.kr/15.-Machine-Dependent-Processing","originals/compiler.fall.2021.cse.cnu.ac.kr/16.-Analysis-&-Optimization"],"tags":[],"content":"개요 §\n강의 정보 §\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n강의 구분소속교수시기학부 수업충남대학교 공과대학 컴퓨터공학과조은선 교수님2021년 가을학기\n실습 자료 §\n\ngithub://haeramkeem/Fall2021-CNU-Compiler\n\n목차 §\n\n01. 어휘분석 &amp; 토큰\n02. 어휘분석기 만들어보기\n03. 구문분석 &amp; 파스트리\n04. Top-down 구문분석\n05. LL문법\n06. 구문분석기 만들기\n07. Bottom up parsing\n08. yacc\n09. LR(0) 파싱 테이블,  SLR 파싱\n10. LR(1) 파서,  LALR 파서\n11. SDD, AST\n12. IR\n13. 3 Address code\n14. Semantic Analysis, Type Checking\n15. Machine Dependent Processing\n16. Analysis &amp; Optimization\n"},"originals/compiler.fall.2021.cse.cnu.ac.kr/01.-어휘분석-&-토큰":{"title":"01. 어휘분석 & 토큰","links":[],"tags":[],"content":"\n\n                  \n                  충남대학교 컴퓨터공학과 조은선 교수님의 &quot;컴파일러 개론&quot; 강의를 필기한 내용입니다. \n                  \n                \n\n\n\n                  \n                  다소 잘못된 내용과 구어적 표현 이 포함되어 있을 수 있습니다. \n                  \n                \n\n컴파일러 전반부의 과정 §\n\n전처리기 : # include, # define, # ifdef등의 명령을 처리해서 전처리가 완료된 소스코드로 변환함\nLexical analysis\nSyntax analysis\nSemantic analysis\n\nLexical analysis §\n\n전처리가 완료된 소스코드를 하나의 문자열로 보고 문법적으로 의미있는 최소단위인 토큰 으로 쪼개는 과정\n토큰은 다음과 같이 5개 정도의 종류가 있다\n\n\n\n키워드나 연산자는 사용자가 마음대로 적는게 아니기 때문에 exact match가 가능하다 - if는 바로 분기문이라는 의미의 토큰으로 분류가 가능\n하지만 식별자와 상수, 문자열의 경우에는 사용자가 지정하는 것이기 때문에 exact match를 할 수 없고 조금 더 처리를 해줘야 한다\n\n어디까지가 하나의 토큰인지, 이놈이 어떤 역할을 하는놈인지 바로 알기 힘든 경우가 많다더라\n\n\n\n토큰을 기술하는 방법 §\n\n토큰을 기술하는 방법중 하나로 정규표현식을 활용한다\n\n\n\n이것만 안까먹으면 너가 알던 정규표현식이랑 똑같더라\n문제\n\n\n\n^a\n100$\n해결못함\n\n토큰을 인식하는 방법 §\n\n그냥 정규표현식 라이브러리 사용하면 된다\n근데 좀 더 원론적인 부분으로 들어와서 우리가 그 라이브러리를 만드는 입장일때 정규표현식으로 토큰을 인식하는 방법으로 FSA 를 사용한다\n\n프언개에서 배운거다 - Finite State Automata 즉, 유한상태 오토마타를 의미하는 것\n\n\n\n\n\n다시 복습해보자면\n\n시작상태와 끝 상태가 있고\n시작상태와 끝 상태 사이에는 유한한 상태들이 존재하며\n특정 조건에 따라 상태가 전이되는 오토마타인 것\n\n\n모든 정규식은 FSA로 표현될 수 있고 모든 FSA는 정규식으로 표현될 수 있댄다\n토큰을 인식하는 절차는 기술된 정규표현식을 FSA로 변환하고 FSA대로 문자열의 문자 하나하나를 처리하게 된다\n근데 FSA로 변환하는 과정에 NFA와 DFA를 거치게 된다\nNFA와 DFA는 모두 FSA의 한 종류인데, FSA는 한 상태에서 뻗어나가는 edge(화살표)에 붙은 레이블(문자)에 대한 제약조건이 없다\n즉, 하나의 상태에서 같은 레이블이 붙은 화살표가 여러개 있어도 된다는 소리이다\n이때, 이것에 대해 제약조건을 준게 DFA이다\n\n즉, DFA(Deterministic Finite Automata) 라는 것은 한 상태에서 뻗어나가는 edge의 레이블은 모두 달라야된다(Deterministic 해야 된다)는 것을 만족하는 FSA를 말한다\n\n\n반대로 DFA에 포함되지 않는 FSA를 Non-DFA라고 해서 NFA 라고 한다\n따라서 토큰 인식은 다음과 같은 순서를 따르게 된다\n\n정규식을 NFA로 변환하고(변환 알고리즘이 알려져 있다)\nNFA를 DFA로 변환하고(이것도 알려져 있다)\nDFA를 돌려서 토큰을 인식하는 그리고 여러 정규표현식에 매칭되어 구분될 수 있는 토큰의 경우에는 Greedy하게 처리 = 제일 길이가 긴놈으로 처리하게 된다\n\n\n\n토큰인식한 토큰을 처리하는 방법 §\n\nLexeme이라는 자료형을 사용 - (토큰번호, 토큰값)의 형태로 처리하게 된다\n\n\n\n위의 예제를 보면 if는 29번, 변수들은 1번, &lt;는 18번 등으로 처리된 것을 알 수 있고\n키워드나 연산자의 경우에는 값으로 0이 들어가지만 변수나 상수는 값으로 그 키워드의 변수 / 상수가 들어가는 것을 알 수 있다\n변수(상수)들에 대해 같은 번호를 쓰고 값을 다르게 하는 이유는 키워드나 연산자의 경우에는 exact match이지만 변수나 상수의 경우에는 사용자가 지정하는 값이기 때문이라고 생각할 수 있다\n그리고 회색글씨처럼 변수번호를 지정해서 값으로 넣어주고 symbol table을 만들어주는 것도 가능한 방법이다\n\n\n\nC언어의 구조체로 표현하면 대략 위처럼 된다\nunion은 타입스크립트에서의 union type과 비슷하다고 생각하면 된다\n\n문자 배열 또는 정수가 저장될 수 있으며 이 문자 배열과 정수가 따로따로 메모리를 할당받는게 아니라 하나의 메모리 공간에 들어가게 되는 것\n\n\nint number에 토큰 번호가 들어가게 되며\nchar id[] 에는 변수(식별자)의 경우 이름이 들어가고\nint num에는 상수의 경우 그 상수의 값이 들어가게 된다\n\n구문문석기 §\n\n\n어휘분석기는 scanner()라는 함수를 제공하고 구분분석기가 이 scanner()함수를 호출함으로 다음 토큰을 받아오는 형식으로 구현된다\n"},"originals/compiler.fall.2021.cse.cnu.ac.kr/02.-어휘분석기-만들어보기":{"title":"02. 어휘분석기 만들어보기","links":[],"tags":[],"content":"\n\n                  \n                  충남대학교 컴퓨터공학과 조은선 교수님의 &quot;컴파일러 개론&quot; 강의를 필기한 내용입니다. \n                  \n                \n\n\n\n                  \n                  다소 잘못된 내용과 구어적 표현 이 포함되어 있을 수 있습니다. \n                  \n                \n\nC언어(와 비슷한거) 만들기 §\nSymbol §\n\nFSA §\n\n\n읽어보면 이해되제?\n\nDomain §\n\n\n이것도 알겟제\n\n\n\nenum 써봤는데 상수 여러개를 한번에 정의할때 쓰면 좋더라\n\n구현 §\n\n\n일단 while(isspace())로 공백을 다 지움\n그리고 superLetter()로 superLetter인지 확인하는데 이름이 superLetter인 이유는 식별자에 ‘_’ 도 올 수 있기 때문\nsuperLetter인 경우에는 식별자나 키워드이므로 뒤이어 나오는 superLetter를 do-while문으로 다 받는다\n그리고 ID_LENGTH보다 i가 크거나 같을 경우에는 입력된 것이 식별자나 키워드의 최대 크기인 ID_LENGTH보다 크다는 뜻이므로 구문 에러를 발생시킨다\n정상인 경우에는 문자 배열에 널문자를 넣어 문자열을 완성시켜주고\n마지막으로 입력받은 superLetter나 숫자가 아닌값은 ungetc()를 통해 다시 버퍼에 넣어줘 안읽은척 해준다\n\n\n\n그 이후에는 keyword배열을 훑으며 입력된 것이 keyword 테이블에 존재하는지 확인하고 존재한다면 for문을 빠져나오게 해준다\n만약 index가 NO_KEYWORD보다 작으면 keyword테이블에 존재한다는 뜻이므로 반환할 토큰의 토큰 번호를 index에 맞는 키워드의 토큰 번호로 채워준다\n하지만 그렇지 않다면 식별자로 처리하기 위해 토큰 번호를 식별자의 토큰 번호로 설정해주고 토큰의 값에 입력된 것을 넣어준다\n그리고 공백 이후 나오는 첫 문자가 superLetter가 아니고 숫자일 경우에는 정수로 처리하기 위해 반환할 토큰의 토큰번호를 tnumber로 해주고 토큰 값으로 문자를 정수로 바꿔 넣어준다\n마지막으로 식별자, 키워드, 숫자도 아닐 경우에는 연산자이기 때문에 switch case문으로 어떤 연산자인지 알아내 토큰을 생성하게 된다\n\n\n\ntoken.number의 초깃값이 tnull이었기 때문에 token.number == tnull이라면 어떤 토큰도 캐치해내지 못했다는 뜻이 된다\n따라서 do-while문을 크게 돌아 tnull이면 다시 한번 위의 과정을 반복하여 토큰을 캐치하게 함\n정상적인 경우라면 token.number가 tnull이 아니기 때문에 do-while문을 빠져나와 토큰 하나를 반환하게 된다\n\nLex §\n\nLex는 1975년에 만들어진 어휘분석기 생성기이다\n옛날에는 Lex를 어휘분석기로, 그리고 yacc을 구문분석기로 해서 두개를 함께 쓰는 경우가 많았고\n지금은 좀 더 발전된 flex를 어휘분석기로, 그리고 OCaml 설치할때 한번 봤던 bison을 구문 분석기로 해서 이 쌍을 많이 사용하더라\n\n처리과정 §\n\n.lex(혹은 .l) 파일에 정규표현식과 여러 C코드를 넣으면 그것을 토대로 어휘문석을 해주는 C프로그램이 반환되는 구조\n즉, 프로그램을 생성하는 프로그램인 것\n\n\n\n반환된 C프로그램을 컴파일할때는 lex library를 링크해서 같이 컴파일되도록 해야됨\n그리고 Lex의 토큰 선택 규칙은 길이가 가장 긴 토큰 혹은 .lex파일에 입력한 정규표현식 중 가장 먼저 매칭되는 토큰 이 선택되어 반환된다\n\n이것은 지금의 많은 어휘분석기나 정규표현식 라이브러리에서도 사용되는 규칙이니 알아둘것\n\n\n\nLex에서 추가적으로 제공하는 정규표현식 §\n\n니가 몰랐던거 두개 있다\n”문자열” : 백슬레시로 escape하는 것 외에 “”를 통한 이스케이프도 제공함\n\n즉, “++”는 ++와 같음\n\n\n문자열/문자열 : / 앞에 나오는 문자열 바로 뒤에 / 뒤에 나오는 문자열이 이어서 나올때 매칭되지만 / 뒤에 나오는 문자열은 소비하지 않고 앞의 문자열만 나온다\n\n즉, ab/cd 는 abcd와 매칭되지만 ab만 결과로 나오게 된다\n\n\n{정규표현식 이름} : 이름 정의 부분에서 정의한 이름을 가진 정규표현식을 사용하고자 할때 {이름}으로 사용해주면 된다\n\n.lex 파일 작성 방법 §\n\n\n맨 위의 %{}% 부분에는 여러 상수 변수 등을 선언하게 됨\n그리고 사이 에 정규표현식을 적어주면 되고\nlex에서는 정규표현식에 이름을 붙여 대신 사용할 수 있는 기능을 제공하는데 이름 정의 부분에 그 이름들을 정의할 수 있음\n마지막으로 사용자 부 프로그램 부분에 lex가 C로 변환될때 C프로그램에 같이 포함되었으면 하는 C 코드를 저기에 넣어주면 된다\n\nlex 에서 사용되는 변수 / 함수 §\n\nlex에서 사용되는 모든 이미 선언된 변수나 함수는 yy로 시작한다\n\n사용자가 선언한 함수나 변수와 이름이 겹치지 않게 하기 위함이랜다\n\n\nyyleng : 주어진 정규표현식들에 의해 매칭된 문자열의 길이를 담고 있는 변수\nyytext : 매칭된 문자열을 담고 있는 변수\nyylval : 반환할 토큰의 값을 담을 수 있는 변수\n\nyylval이랑 yytext랑 헷갈릴 수 있는데 lex는 매칭된 문자열을 반환하는게 아니라 매칭된 문자열에 맞는 토큰을 반환하는 것이 목적이다\n식별자나 상수의 경우 토큰 값을 필요로 하므로 yytext를 형변환하여 yylval에 넣어주면 그 값이 토큰 번호화 같이 반환되는 셈\nyyleng이랑 yytext의 경우에는 매칭 후에 자동으로 채워지는 값이지만 yylval의 경우에는 내가 채우는 값임\n즉, yytext는 매치된 문자열이 들어있고 yylval은 그 문자열에 대한 토큰의 토큰값을 설정하기 위한 변수인 것\n매치된 문자열을 뭐 atoi나 atof같은 함수를 이용해 형변환을 해서 yylval에 넣어주는게 일반적이다\n\n\nyywrap() : lex가 입력의 끝을 만났을 때 호출하는 함수(endOfInputCallback 정도로 이해하면 될듯)\n\n잘 모르겠으면 그냥 무지성으로 yywrap() { return 1; } 이렇게 해줘도 된다\n하지만 없으면 에러가 나기도 하니까 무조건 사용자 부 프로그램 부분에 적어줄 것\n\n\n\nlex 예제 §\n\n\n보면 %{}%에 여러 .h파일들이 선언되어있는것을 볼 수 있고\n그 뒤에 여러 정규표현식들이 이름을 통해 선언되어있는 것을 볼 수 있다\n\n\n\n그리고  사이에 위에서 정의한 정규표현식 이름이나 그냥 정규표현식들을 이용해 매칭되었을때의 action을 정의한 것을 볼 수 있다\nNUMBER나 PLUS 이런거는 뭐 global.h에 선언되어있는듯\n{real}에 의해 실수가 매칭된 경우에 atof()를 통해 매칭된 문자열인 yytext를 실수로 바꿔주고 yylval에 넣어준 후 NUMBER라는 토큰을 반환하는 것을 알 수 있다\n그리고 다른 정규표현식들에 대해서도 그에 맞는 토큰들을 반환하는 것을 알 수 있다\n마지막으로 사용자 부 프로그램 부분에 yywrap() { return 1; }이 무지성으로 들어가있는 것을 확인할 수 있다\n\nlex 예제 - 어휘분석기 말고 하나의 프로그램으로 변환되는 버전 §\n\nlex를 사용하면 토큰을 반환하는 어휘분석기를 생성하는 것 뿐만 아니라 그냥 main함수를 가지는 하나의 프로그램도 생성할 수 있다\n\n\n\n위의 예제를 보면 일단 global 변수로 charCount, wordCount, lineCount가 선언되어 있고\n두개의 정규식도 이름을 달고 있는 것을 알 수 있다\n그리고 한 단어가 매칭되었을 때는 wordCount를 1 증가시키고 charCount에는 매칭된 단어의 길이인 yyleng이 더해지는 것을 알 수 있으며\nnewline이 매칭된 경우에는 charCount와 lineCount를 1 증가,\n마지막으로 위 두가지 어느 경우에도 해당되지 않는 경우에는 걍 charCount만 1 증가하도록 되어 있다\n근데 보면 어떤 정규식에 매칭되어도 return되지 않는다는 것을 알 수 있다 - 즉, 매칭될때마다 토큰을 반환하는 것이 아닌 매칭 후에 위의 action을 취하고 계속 매칭해나간다는 것을 알 수 있음\n\n매칭되었을 때 토큰을 반환하고 싶으면 return을 쓰면 되고 계속 하고싶으면 return을 안쓰면 된다\n\n\n그리고 사용자 부 프로그램 부분에 main함수가 있어 바로 실행할 수 있는 프로그램으로 변환되는데\n여기에 보면 stdin으로 파일 이름을 받아오고 그 파일을 열어 yyin에 넣어주는 것을 알 수 있다\n\n즉, yyin이라는 것은 정규식으로 검토할 input 을 받는 변수라고 생각할 수 있다\n\n\n그리고 yylex() 를 호출하게 되는데 yylex() 는 주어진 정규식으로 input을 검토하는 함수가 되는 것\nyylex()를 호출하고 난 뒤에는 넣어준 파일을 다 점검하고 끝나므로 global 변수들에 값이 다 채워져 있게 된다\n그리고 printf로 이 변수의 값을 stdout으로 출력하는 것으로 프로그램이 끝나게 되는 것\n"},"originals/compiler.fall.2021.cse.cnu.ac.kr/03.-구문분석-&-파스트리":{"title":"03. 구문분석 & 파스트리","links":[],"tags":[],"content":"\n\n                  \n                  충남대학교 컴퓨터공학과 조은선 교수님의 &quot;컴파일러 개론&quot; 강의를 필기한 내용입니다. \n                  \n                \n\n\n\n                  \n                  다소 잘못된 내용과 구어적 표현 이 포함되어 있을 수 있습니다. \n                  \n                \n\n구문분석 (Syntax Analysis &amp; Parser) §\n\n\n토큰들을 저렇게 구조에 따라 Parse tree로 구조화시키는 것으로 생각할 수 있음\n주어진 문장이 정의된 문법에 따라 생성될 수 있는지를 판별하는 과정\n올바른 문장에 대해서는 Parse tree가 나오게 되고 틀린 문장에 대해서는 오류가 나오게 된다\n\nDescribing Syntax §\nCFG §\n\n프로그래밍 언어 개론에서 배운 Context Free Grammar(CFG) 를 이용하여 구문을 기술함\nCFG 는 아래의 4가지로 구성됨\n\nN(Non-terminal) - 치환될 수 있는 기호\n\n보통 알파벳 대문자나 &lt;stmt&gt; 처럼 &lt;&gt;를 이용해 N이라는 것을 표시\n터미널 혹은 다른 논터미널의 집합이라고 생각하면 될거같다\n프언개에서 경유지라는 비유가 딱 맞는듯 - 걍 중간과정인셈\n\n\nT(Terminal) : 토큰이랑 비슷하다고 생각해도 됨(컴파일러에서 토큰이라 부르는 걸 계산이론에서 터미널이라 부르더라) - 치환될 수 없는 기호\n\n작은따옴표나 큰따옴표를 이용해 T라는 것을 표기\n이것도 프언개에서 종착지라는 비유가 잘 맞다 - 최종 결과를 이루는 요소인 셈\n\n\nP : 생성(치환) 규칙 집합\n\n왼쪽 → 오른쪽 : 왼쪽은 오른쪽으로 치환될 수 있음\n어떤 N이 여러 T들로 치환될 수 있다면 | 를 써서 표현할 수 있음\n예를들어 A → ‘0’, A → ‘1’이라면 A → ‘0’ | ‘1’이 되는 것\n\n\nS : 시작 심볼\n\n\n그리고 L(G) 를 이 CFG로 생성될 수 있는 모든 문자열의 집합 - 즉, 이 문법을 따르는 언어가 되는 것\nCFG에는 →, &lt;&gt;, | 정도의 기호밖에 없다 : 이 외의 기호들은 다 그냥 터미널이라 생각하면 됨 - +, - 같은 기호들 걍 다 터미널이다\nS → a | aS 는 정규식에서 a+ 와 같고\nS → e | aS 는 정규식에서 a * 와 같다는거 외워노라(여기서 e는 empty)\n\nBNF §\n\nBackus-Naur Form(BNF) CFG의 문법을 간소화한 것\n논터미널을 &lt;&gt; 기호로 표시, → 대신 ::= 기호 사용, 걍 문자열은 터미널\n그리고 BNF에서 확장된 Extended BNF 라는게 있는데\n\n이건 논터미널 ::= {뭐시기}숫자 형태가 추가된 것이다 - 뭐시기가 숫자만큼 반복된다는 의미를 가지고 있음\n기존의 CFG나 BNF에서는 반복을 표현하기 위해 재귀적으로 정의하는 방법 말고는 없었는데 EBNF에서 재귀적인 방법 말고 반복을 표현할 수 있는 방법이 추가된것\n그리고 java를 기반으로하고있는 ANTLR도 EBNF를 사용하는데 여기서는 * 나 +같은 정규식의 문법도 사용 가능하다\n\n\n\nDetermine Syntax §\n\n문법에서 언어를 유도해 내는 것을 Derivation(유도) 라고 하고\n어떤 문자열이 유도되는지를 확인하면 그 언어를 따르는 것이라 생각할 수 있음\n\nDerivation §\n\n\n위 그림을 쭉 읽어보면 이해가 될건데 주의할 점은\nderive는 반드시 한번에 하나의 N만 치환해야된다는 점 - 프언개에서 배운거처럼 모호성이라는 것이 존재하기 때문\n\n논 터미널이 여러개일때 치환하는 방법이 두가지 있다\n\nRightmost derivation : 오른쪽부터 유도\nLeftmost derivation : 왼쪽부터 유도\n\n\n유도의 방법이 중요한 이유는 모호한 문법의 경우에는 유도의 방법에 따라 다른 트리가 만들어지기 때문\n\n\n그리고 문법에는 -&gt;를 사용했지만 유도할때는 =&gt; 를 사용한다는 점이다\n\nDerivation tree §\n\n그리고 이 유도를 추상화시켜서 그린 트리를 Derivation tree라고 한다\n\n\n\n유도의 과정을 추상화시켰다는 것은 이 유도의 순서가 트리에는 나타나지 않는 다는 것을 의미한다고 볼 수 있다\n\nAmbiguous §\n\n일단 Ambiguous(문법의 모호성) 이라는 것은 어떤 문자열을 유도해내는 유도 트리가 여러개 존재할 경우 문법이 모호하다라고 한다\n모호성을 해결하는 방법은 결과는 같지만 다르게 기술된 문법을 사용하는 것이다\n\n즉, S -&gt; a == S -&gt; A, A -&gt; a인 것을 이용\n\n\n\n1. 연산자 우선순위 도입 §\n\n이게 뭐냐면\n일단 연산자마다 새로운 Non-terminal을 도입하고\nRecursion을 Left나 Right중에 하나에만 두고\n시작심벌과 가까운 쪽에 연산자 우선순위가 낮은 거를 둔다라\n\n\n\n여기 예시 있다\n보면 우선순위가 가장 높은 터미널과 괄호가 가장 멀리 떨어져 있는 것을 볼 수 있고 그다음은 *, 마지막으로 +가 가장 가까이 있는것을 볼 수 있음\n그리고 +의 경우에 T가 도입되었고 * 의 경우에는 F가 도입됨\n또한 T와 F가 도입됨에 따라 Recursive Nonterminal이 연산자의 왼쪽이나 오른쪽에만 도입되어 있는 것을 확인할 수 있다\n마지막으로 E와 T, F를 연결해주는 E → T, T → F까지 만들어주면 완성\n이 예시와 ba*, S → Sa | b 세개 연관지어서 기억하시길 - 뭔가 시험에 나올삘이다 이거야\n\n2. 결합법칙 도입 §\n\n모든 연산자는 좌측 혹은 우측 결합이거나 아니면 결합법칙이 성립하지 않는다는 특성이 있다(모든 연산자가 셋중에 하나를 만족하는 것)\n\n일례로 a + b + c의 경우에는 (a + b) + c의 좌측 결합법칙이 적용된다\n그리고 C언어 등에서 지원하는 x = y = 3의 경우에는 y에 우선 3을 할당하고 그 결과인 3을 x에 할당하는 식으로 진행되어 x = (y = 3)의 우측 결합법칙이 적용된다\n1 &lt; 2 &lt; 3의 경우에는 &lt; 연산자의 경우 결과가 boolean으로 나오기 때문에 어떤 결합법칙도 성립하지 않는다는 특징이 있다\n\n\n문법을 구상하는 데에도 recursion의 위치를 이용해 결합법칙을 강제할 수 있다\n\n예를 들어, A → Ab | b처럼 Left recursion를 넣어 좌측 결합법칙이 되게 할 수 있고\nA → bA | b처럼 Right recursion을 넣어 우측 결합법칙이 되게 할 수 있다\n왜냐하면 우측 결합인 경우 A가 준비되고 b를 앞에 붙이는 것이기 때문에 A가 먼저 연산되게 되는 것\n\n\n뭐라는거야\n\n\n\n\n이런 문제들 좀 여러번 풀어보면서 감좀 익혀야할듯\n\nParsing §\n문장구조를 나타내기 위한 자료구조 §\n\nParse tree : derive tree와 같은 모양이 된다\n\nroot node는 start symbol\nmid node는 non-terminal\nleaf node는 terminal에 대응되는거다 이거야\n\n\n생성규칙 번호 리스트 : 유도하는 과정에서 사용된 생성(치환) 규칙들을 사용 순서에 따라 리스트로 나열한 것\n\n생성규칙은 이미 다 만들어져있으므로 이 번호 리스트만 있어도 트리 구성이 가능함(+ 좌우 결합에 대한 정보까지)\n장점은 리스트만 저장해놓고 트리는 필요할때 만들어도 되기 때문에 저장공간이 비교적 적게 필요하다는점\n하지만 단점은 리스트를 이용해 트리를 재구성해야되기 때문에 그만큼의 오버헤드가 들어간다는 점이다\n\n\n\n유도 vs 구문분석 §\n\n유도는 생성규칙에 따라 문자열을 만들어내는 과정인 반면에\n구문분석은 문자열와 생성규칙을 이용해 root를 찾아내는 역연산이라고 할 수 있다\n\nTop-down vs Bottom-up §\n\n아래의 예시 꼭 기억하랜다\n\n\nTop-down §\n\n\n이 방식은 유도의 과정을 이용하는 것이다\n\n컴퓨터는 모든 경우의 수를 시도해볼 수 있는 빠르기를 가지므로 모든 유도의 경우의 수를 다 해보고 매치되는게 없으면 빠꾸치고 매치되면 그것으로 반환하는 방법\n\n\n하지만 생성규칙이 아주 많은 언어의 경우에는 모든 경우의 수를 해보는 것이 아주 오래 걸릴 수도 있다는 단점이 있다\ntop-down의 경우에는 좌측 유도 중 적용된 생성규칙 리스트(좌파스) 와 같은 리스트가 나오면 트리를 성공적으로 구성하게 된 것이라 할 수 있다\n\n위의 예시의 경우에 구문분석이 아니라 좌측유도를 해서 a + a를 만들어낸다면 생성규칙 리스트는 3155가 될 것이다\n이때의 좌파스는 3155가 되는 것이고 예시의 top-down 구문분석 과정을 보면 좌파스와 동일한 3155인 것을 알 수 있다 - 따라서 제대로 트리가 구성된 것\nbottom-up의 우파스 예시를 보면 이 파스라는게 뭔지 대강 이해가 잡히긴함\n\n\n\nBottom-up §\n\n\n위의 예시의 경우에는 대략 다음과 같은 방식으로 진행된다\n\n( 가 들어왔을 때에는 일단 아무것도 안함\na가 들어오면 5번 규칙에 따라 E로 매핑해줌\n그리고 +가 들어와도 아무것도 못하기 때문에 가만히 있음\n또 a가 들어오면 5번 규칙에 따라 E로 매핑해줌\n매핑하고 나니 1번 규칙을 적용할 수 있는 것을 알고 E + E를 E로 매핑해줌\n마지막으로 )가 들어오면 3번 규칙을 적용할 수 있는 것을 알고 3번을 적용해 트리 구성을 끝냄\n\n\nbottom-up의 경우에는 우측유도 중 적용된 생성규칙 리스트의 역순(우파스) 와 같은 리스트가 나오면 트리를 성공적으로 구성하게 된 것이 된다\n\n위의 예시의 경우에는 우측유도를 해보면 3155인데 이의 역순은 5513이 되며 이게 우파스가 된다\n그리고 위의 bottom-up과정을 보면 5513이므로 제대로 트리가 구성된 것이 된다\n즉, 뭐시기 파스라는 것은 (사람이)유도를 통해 알아낸 정답(구문분석 과정에서는 알 수 없는)이 되는 거고 이 정답을 맞추면 트리가 제대로 구성된 것이 된다 뭐 이런 컨셉인듯\n우파스는 우측유도과정의 역순인 것에 주의할 것\n\n\n위 두가지 방법 다 장단점이 있기 때문에 둘 다 쓰이는 방식이다\n대표적으로 yacc에서 bottom-up을 사용하고 ANTLR의 경우에는 top-down을 사용하고 있다\n\n\n\n이 예시 보고 정신좀 차려라\n"},"originals/compiler.fall.2021.cse.cnu.ac.kr/04.-Top-down-구문분석":{"title":"04. Top-down 구문분석","links":[],"tags":[],"content":"\n\n                  \n                  충남대학교 컴퓨터공학과 조은선 교수님의 &quot;컴파일러 개론&quot; 강의를 필기한 내용입니다. \n                  \n                \n\n\n\n                  \n                  다소 잘못된 내용과 구어적 표현 이 포함되어 있을 수 있습니다. \n                  \n                \n\nTop-down 구문분석 §\n\n시작심벌부터 시작해 가능한 좌측 유도를 다 해보는 것\n물론 전부 다 하는건 아니고 하나씩 맞춰보면서 한다\n\na가 들어왔으면 a로 시작하는 생성규칙 중 첫번째꺼부터 해보는 것\n\n\n매치되는 생성규칙이 없을 떄 Backtracking 을 함\n\n바로 직전의 생성규칙을 롤백시키고, 토큰도 다시 Stream에 넣어주고 다른 생성규칙을 시도\n따라서 Backtracking의 오버헤드는 매우 클 수도 있다\n\n\n더이상 적용할 생성규칙이 없으면 틀린것으로 인식\n\n예제 §\n\naccd에 대해 Top-down방식으로 구문분석을 하면\n\n\n\n일단 시작심벌에서 a로 시작하는 규칙이 두개 있으므로 1번부터 해봄\n그다음에는 c로 시작하는 규칙이 4번이므로 4번을 적용\n논터미널이 더이상 없는데 매칭되지 않으므로 4번을 롤백, 3번을 골라도 안되므로 백트래킹 - 1번를 롤백하고 2번 적용\n2번을 적용한 뒤 c로 시작하는것이 5번 규칙이므로 5번을 적용\n적용후에 논터미널이 더이상 없고, 매치되므로 문법을 준수한다고 판단\n\nLL파싱 §\n\n일단 Left-to right, 즉, 왼쪽에서 오른쪽으로 읽어나가며 파싱한다\n결과적으로 Left Parse 즉, 좌파스가 생성되게 된다\n또한 LL파싱의 제일 중요한 특징은 Deterministic Parsing 이다\n\n입력 문자가 하나 들어오면 해당 입력문자에 적용될 수 있는 생성규칙은 하나여야 된다는 것\n예를 들면 위의 예제에는 S → aAd와 S → aB가 있으므로 a가 들어왔을 때 생성규칙이 두개가 가능하다\n\n이러한 경우에 Deterministic 하지 않다라고 하는 것\n\n\n\n\n입력문자와 생성 터미널이 다르면 백트래킹 안하고 걍 틀린것으로 간주 - 백트래킹을 안한다는 장점이 있지만\n결정적이지 않은 경우에는 걍 파싱을 안한다 - 즉, 파싱할 수 있는 범위가 좁다는 단점이 있다\n따라서 LL파싱은 조금이라도 결정적으로 파싱이 될 수 있는 가능성이 있는 문법만을 받아 결정적이지 않은 곳은 다듬어서 사용하고\n입력문자당 적용될 생성규칙을 key-value쌍으로 미리 뽑아두고 파싱하게 된다.\n따라서 규칙을 보고 필요한 정보가 무엇인지 모으는 작업을 하게 된다\n이때 정보라는 것은 일련의 집합이며 FIRST, FOLLOW , LOOKAHEAD 등등이 존재한다\n\nFIRST §\n\n\nNonterminal A로부터 유도될 수 있는 모든 것들 중 맨 먼저 나올 수 있는 terminal들의 집합이다\n아래 예제 보면 딱이해됨\n\n\n\nS로 유도되는 문자열은 무조건 a로 시작하므로 FIRST(S)는 {a}\nA로 유도되는 문자열은 무조건 b아니면 c로 시작하므로 FIRST(A)는 {b, c}\nB로 유도되는 문자열은 무조건 c아니면 d로 시작하므로 FIRST(B)는 {c, d}인 셈\n만약에 S → Abe가 추가된다면 FIRST(A)가 {b, c}였기 때문에 S로 유도되는 문자열은 b나 c로 시작할 수도 있게 됨 - 따라서 FIRST(S)는 {a, b, c}가 된다\n\nFIRST 계산하는 방법 §\n\n일단 e-생성규칙(여기서 e는 입실론, 즉, 널을 의미함)은 X → e의 형태를 의미한다\n그리고 Nullable nonterminal은 Nonterminal A가 e로 유도될 수 있을 때를 의미함 - 이렇게되면 A는 사라져벌이는 것\nLHS, RHS는 뭔지 알제? 생성규칙의 화살표 기준으로 왼쪽에 있는놈이랑 오른쪽에 있는 놈\nRing Sum은 아래 보면 딱 안다\n\n\n\n즉, 먼저등장하는놈에 널이 없으면 뒤에꺼는 걍 무시\n널이 있으면 앞에놈에서 널을 빼고 뒤에꺼랑 합집합\n\n\n\nFIRST를 계산하는 규칙은 위와 같다\n뭐 1, 2, 3번은 걍 개껌이고\n4번을 좀 잘 봐야되는데 4번에서 = 오른쪽에 있는 FIRST(X)는 1, 2, 3번을 통해 구해낸 FIRST(X)를 의미한다\n그리고 여기다가 Y1부터 Yk까지를 RingSum해서 합집합을 해주면 됨\n이짓을 모든 Nonterminal의 FIRST가 변하지 않을 때까지 반복한다는데 이건 뒤에 가면 이해될거임\n\n\n\n위의 예제를 보면\nFIRST(S)를 구할 때 일단 S → Ab는 제쳐두고 두세번째 규칙을 보면\n일단 두번째 식으로 F(S) = {c}이고 세번째 식으로 F(A) = {e}임\n첫번째 식을 처리하기 위해 F(Ab) 를 뜯어보면\n이건 F(A) (+) F(b)이기 때문에 {e} (+) {b}가 되고 따라서 {b}가 된다\n이것을 두번째 식으로 구한 {c}와 합집합해주면 {b, c}가 되는 것\n따라서 S에서 b나 c가 들어오면 정상이지만 그렇지 않으면 오류를 출력하면 되는 것이다\n\n예제들 §\n\n\n\n\n이거 반드시 시험에 나오니까 그냥 과정 자체를 외워버려라\n\n일단 모든 Nonterminal에 대한 FIRST들을 공집합으로 두고\n1, 2, 3번 규칙으로 가능한 Nonterminal들에 대해 FIRST들을 갱신한다\n그리고 4번 규칙을 이용해 가능한 Nonterminal들에 대해 FIRST들을 갱신하고\n갱신한 것들을 가지고 다시한번 4번 규칙을 적용해 갱신해본다\n만약 갱신되지 않는다면, 완료\n\n\n\nFOLLOW §\n\nFIRST의 문제점 : Non-terminal이 Nullable한 상황에서는 FIRST만을 구하는 것으로는 한계가 있음\n\n\n\n이 예시를 보면 딱 이해된다\n만약에 b가 들어오면 세번째 놈을 선택하면 된다는 것을 우리는 딱 보면 알 수 있다\n컴퓨터 입장에서도 FIRST(S)가 {a, b}이기 때문에 b가 들어오면 구문분석이 가능하다는 것을 깨닫고 첫번째를 선택할 것이다\n하지만 선택하고 난 뒤에는 FIRST(A)가 {a, e}이기 때문에 b를 만들 수 없다고 판단하게 되는것\n즉, 이론적으로는 가능한 상황임에도 FIRST만 생각하면 로직때문에 구문분석이 안되는 경우가 생기더라\n따라서 FOLLOW는 이러한 경우를 대비해 Nonterminal의 바로 뒤에 나오는 terminal들을 모은 집합이 되는 것\n\n\n\n뭐 결과적으로 따져보면 Non-terminal 뒤에 나오는 모든 terminal의 집합이라는 말이나 같다\nFIRST를 구하기 위해서는 해당 Non-terminal이 LHS에 등장하는 경우를 중점적으로 봤다면,\nFOLLOW를 구하기 위해서는 해당 Non-terminal이 RHS에 등장하는 경우를 중점적으로 살피게 된다 - 바로 뒤에 나오는 terminal들을 살피기 위해\n\nFOLLOW를 구하는 방법 §\n\n\n일단. 시작심벌은 EOF를 뜻하는 $를 초기값으로 가진다 - Non-terminal뒤에 EOF이 나와도 문제가 없기 때문\n2번은 우리가 구하고자 하는 Non-terminal 뒤에 나오는 놈이 nullable하지 않다면, 바로 뒤에 나오는 놈의 FIRST를 추가해주면 된다는 말이다\n\n이것도 당연한 말이쥬? 바로 뒤에 null이 안나오면 바로 뒤에 있는 놈의 FIRST가 나 자신의 FOLLOW가 될 수 있는 것이니께\n\n\n\n\n\n얘는 우리가 구하고자 하는 Non-terminal이 생성규칙의 마지막에 있거나, 아니면 마지막에 있지는 않지만 그 뒤에 바로 나오는 놈이 Nullable하다면 해당 생성규칙의 LHS에 있는 놈의 FOLLOW도 넣어주라 이말이야\n얘도 좀만 생각해보면 당연한 말이다 - 만약에 Non-terminal이 시작심볼이면 이놈 뒤에 연달아 나오는 놈은 없으니까 생각할 필요가 없지만\n만약 S → Ab, A → cB인 경우에 B의 FOLLOW를 구한다면 B뒤에는 첫번째 생성규칙에 따라 b가 올 수 있으므로 LHS인 A의 FOLLOW인 b도 추가해줘야 된다는 것이다\n따라서 만약 A → xB, B → xA형태의 경우에는 첫번쨰 생성규칙으로는 B의 FOLLOW는 A의 FOLLOW를 포함하고, 두번째 생성규칙으로는 A의 FOLLOW는 B의 FOLLOW를 포함하게 되므로 이 둘은 동치가 된다\n그리고 FIRST에서마냥 FOLLOW를 구할때도 FOLLOW를 계속 갱신해가며 더이상 갱신이 안될때까지 3번규칙을 반복해주면 된다\n\n예제들 §\n\n\n\n\n얘도 순서를 위의풀이 거의 그대로 외워놓아라\n\n전부 {}로 세팅\n시작심벌을 {$}로 세팅\n뒤에 뭔가 나오는 경우 그놈의 FIRST에서 null을 빼고 전부 넣어줌\n뒤에 암것도 없거나 뒤에 나오는놈이 nullable하면 지금까지 구한 지신의 FOLLOW랑 해당 생성규칙에서의 LHS의 FOLLOW랑 합집합 - 수식 적어가며 계산!\n갱신이 안될때까지 4번 반복\n\n\n"},"originals/compiler.fall.2021.cse.cnu.ac.kr/05.-LL문법":{"title":"05. LL문법","links":[],"tags":[],"content":"\n\n                  \n                  충남대학교 컴퓨터공학과 조은선 교수님의 &quot;컴파일러 개론&quot; 강의를 필기한 내용입니다. \n                  \n                \n\n\n\n                  \n                  다소 잘못된 내용과 구어적 표현 이 포함되어 있을 수 있습니다. \n                  \n                \n\nLL 문법 §\n\n\n일단 위의 정의는 LL 조건이라고 부른다.\n그리고 저 |가 ß에만 묶여있는거다 - a | ß라는 소리 - 헷갈리지 말 것\n어떤 문법이 모든 생성규칙에 대해 LL 조건을 만족하면 그 문법을 LL 문법이라고 한다\n또한 LL 문법에 속하는 문법은 LL 파싱이 가능하다\n\n즉, 모든 생성규칙이 LL 조건을 만족하면 왼쪽에서 오른쪽으로 파싱했을 때 결정적으로 좌파스가 나오게 된다는 소리이다.\n따라서 LL 파싱은 모든 생성규칙에 대해 LL 조건을 만족하는 깔끔한 LL 문법에 대하서만 파싱한다.\n\n\n저 조건을 좀만 생각해보면 당연한 말이다\n\n일단 FIRST(a)와 FIRST(ß)는 교집합이 없어야 한다 - 만약 교집합이 있으면 그 교집합에 속하는 놈이 튀어나왔을 때 A → a를 선택해야 할 지, A → ß를 선택해야할 지 알 수 없기 때문\n그리고 a가 널이 될 수도 있으면, FIRST(A)에는 FOLLOW(A)도 포함되기 때문에 FOLLOW(A)와 FIRST(ß)도 교집합이 있으면 안된다 (위와 비슷한 이유)\n만약 교집합이 있으면, a가 널이 되고 A다음에 올 수 있는 놈들이랑 ß가 될 수 있는 놈들이랑의 교집합이 있다는 소리이고 그럼 교집합에 속하는 놈이 들어왔을 때 어떤 놈으로 생성규칙을 선택해야 할 지 모르기 때문\n\n\n그리고 LL(1) 문법이라는게 있는데 여기에서 (1) 은 뭔소리냐면 토큰 하나만 보고 생성규칙을 선택하겠다 뜻이다\n\n즉, LL(1)문법은 토큰이 하나 들어왔을 때, 그 토큰 하나만 가지고 생성규칙을 고르는 것이 가능해야된다든 것\n\n\n다음과 같은 경우에는 절대로 LL(1) 문법이 될 수 없다\n\nAmbiguous한 문법일 경우\nLeft-factoring이 가능한 부분이 존재하거나\nLeft-recursive한 경우\n\n\n저게 뭔지는 이제 배운다\n일반 문법을 LL문법으로 바꿔주는 알고리즘은 아직 발견하지 못했기 때문에 위와 같은 문제점이 있었다면 하나씩 해결해주며 LL이 맞는지 테스트해본다\n\nLeft Factoring §\n\n\n뭐 간단하다\n생성규칙의 앞부분에 공통되는놈이 있으면 그걸 묶고 그 다음에 올 것을 또 하나의 Non-terminal을 도입해서 표현하는 법\n\n\n\n간단맨\n어쨋든 Left Factoring을 해결해주면 LL(1) 문법이 될 가능성이 높아진다\n\nLeft Recursion §\n\n\n이런놈이 Left Recursion이다\n즉, LHS가 RHS의 앞부분에 재귀적으로 등장하는 경우 - 좌측 결합법칙을 도입하면 무조건 생기게 되더라\n위의 경우에는 뭐가 문제냐\n아래의 예시를 보면 알 수 있다\n\n\n\nE + T + T + T까지는 1번 생성규칙으로 생성해나가다가\n그 다음 T + T + T + T는 2번 생성규칙을 선택해야 되는데 그걸 컴퓨터가 알 방법이 없다\n따라서 다시 1번을 선택하게 되고 그렇게 쭉 나가다가 결국에는 무한루프에 걸리게 되는 것\n즉, Deterministic하지 않다\n따라서 Left recursive하면 절대로 LL(1) 문법이 될 수 없는 것\n\n\n\n위에서 보는거처럼 Right recursive하게 해주고 LL 조건에 맞게 수정해주면 해결이 가능하다\n해결하는 과정을 약간 공식화하면 아래와 같다\n\n\n\n위의 그림에서 파란색이 변환결과고 검은색 수식이 이 두개가 같다는 것을 증명한 것\n약간 공식처럼 하려면 이렇게 해라\n\nLeft-recursion을 제외한 모든 부분을 a로 묶는다\n&lt;| 뒤에 나오는 놈 + 새로운 Non-terminal&gt;형식으로 첫번째 생성규칙을 완성 한다\n그리고 &lt;a로 묶은놈 + left recursive 했던놈 | 널&gt;형식으로 두번째 생성규칙을 완성한다\n\n\n\n\n\n위 그림은 예제\n그리고 간접 Left recursive라는 것도 있다\n\n\n\n위 그림의 왼쪽 위와 같은 경우인데\n일단 이걸 파악하는 것은 Non-terminal을 위에서부터 순서를 매기고 RHS에 LHS보다 작은놈이 나오는지 검사하는 식으로 진행해주면 된다\n이걸 해결하는 방법은\n\n오른쪽 위에처럼 순서가 작은놈의 RHS을 문제가 생긴 부분에 전부 copy해준다 - 위의 예제에서는 S가 |로 묶여있기때문에 d를 분배법칙마냥 붙여줌\nLeft Factoring을 해준다\nLeft recursive를 해결해준다\n마지막으로 Left factoring할 때 임시적으로 괄호를 썻다면 그 괄호는 우리가 붙여준 것이기 때문에 분배법칙으로 풀어준다\n\n\n\nLOOKAHEAD §\n\n\n이놈은 이제\n생성규칙의 RHS에 대한 FIRST라고 생각하면 된다\n즉, 어떤 생성규칙을 적용했을 때 가장 먼저 나올 수 있는 terminal symbol들의 집합인거임\n그래서 보면 저 모든 X들에 대한 FIRST들을 전부 ringsum해주고 마지막으로 LHS인 A의 FOLLOW까지 ringsum해주는 것을 알 수 있다\n즉, 마지막으로 드가는 FOLLOW(A)는 앞에꺼가 전부 null일때 의미가 있는 셈\n\nStrong LL §\n\nLL 조건에는 두가지가 있었던 것을 위에서 배운 LOOKAHEAD를 통해 하나로 합친 것을 Strong LL이라고 한다\n\n\n\n정의는 위와 같다\n(1) 일때는 LL(1)과 Strong LL(1)이 동일하다 - 두 문법이 동치인 셈\n하지만 (1) 가 아닐때는 LL과 Strong LL은 동일하지 않을 수도 있다\n\n예제 §\n"},"originals/compiler.fall.2021.cse.cnu.ac.kr/06.-구문분석기-만들기":{"title":"06. 구문분석기 만들기","links":[],"tags":[],"content":"\n\n                  \n                  충남대학교 컴퓨터공학과 조은선 교수님의 &quot;컴파일러 개론&quot; 강의를 필기한 내용입니다. \n                  \n                \n\n\n\n                  \n                  다소 잘못된 내용과 구어적 표현 이 포함되어 있을 수 있습니다. \n                  \n                \n\nLL(1) 파서 구현 방법 §\n\nRecursive descent parser\n\n이름처럼 recursion을 이용하는 방법이고 Non-terminal마다 한개의 procedure(function이라고 이해해도 될듯)을 두는 방법으로 구현한다\n장점은 직관적이고 쉽다는 것\n단점은 생성규칙이 바뀌면 구문분석기도 바꿔야한다는 점이다.\n\n\nPredictive parser\n\n얘는 생셩규칙이 바뀌어도 구문분석기를 다 뜯어고칠 필요 없이 파싱테이블이라는것만 고치면 된댄다\n장점은 생성규칙이 바뀌어도 바꿀게 많지 않다는 점이다\n\n\n\nRecursive descent parser §\n\n일단 모든 Non-terminal과 Terminal에 대해 procedure을 하나씩 마련한다\n\n\n\n위와 같은 문법에 대한 파서를 구현하려고 할 때\n\n\n\n위 그림처럼 Terminal 마다 하나씩 함수를 마련해놓는다\n\nTerminal symbol의 처리는 위 그림처럼 nextSymbol이 해당 함수가 처리하고자 하는 놈이 맞다면 다음 symbol을 받아 nextSymbol에 넣어주고, 아니라면 에러를 던지는 방식으로 작동한다\n\n\n\n\n\n그리고 Non-terminal에 대해서도 함수를 하나씩 만들되 만드는 방법은\n\n일단 S에 대해서는 S의 FIRST는 {a}이기 때문에 nextSymbol이 a가 맞는지 확인한다\n만약 맞다면 S → aAb이기 때문에 a를 처리하는 함수, A를 처리하는 함수, b를 처리하는 함수를 한번씩 호출해주게 된다\n그리고 A에 대해서는 FIRST(A)가 {a, b}이기 때문에 스위치문을 돌려 nextSymbol이 a일때랑 b일때를 처리해준다\na일때는 A → aS를 적용하기 위해 a를 처리하는 함수, A를 처리하는 함수를 한번씩 호출하고\nb일때는 A → b를 적용하기 위해 b를 처리하는 함수를 호출해준다\n\n\nFIRST()만 보고 switch를 활용해 구현을 하는 방식이므로 아주 간단하고 쉬우며, 이런식으로 구문분석이 가능한 이유는 이 문법이 LL(1)이기 때문인 것이다 - 결정적이기 때문!\ngcc가 RDP로 구현이 되어 있더라\n\nPredictive parser §\n\n일단 얘는 Recursive descent parser 의 구문분석기를 자주 바꿔야 되는 문제점을 해결하고자 나온 것인데\n생셩규칙이 바뀌어도 구문분석기의 구현 방식에는 비슷비슷한 것들이 많다는 점에 착안해 자동화할 수 있는 부분은 최대한 자동화한 방식이다\n즉, 어차피 Terminal은 지금 토큰을 확인하는 과정만 하고 Non-terminal은 FIRST에 따라서 지금 토큰을 switch로 돌려 그에 맞는 생성규칙의 함수만 호출해주면 되니까 이러한 것들은 자동화해서 만들고 대신 문법들만 파싱 테이블에 저장하도록 하여 함수들을 생성할때 파싱테이블을 참조하여 함수들을 생성하고, 수정할 일이 있으면 파싱 테이블만 고치면 되게하는 방식인 것\nPredictive parser의 경우에는 Push-Down Automata(PDA) 를 이론적 배경으로 하게 되는데\n\n이놈은 정규표현식이 Finite State Automata와 동일한 표현력을 가졌고 Lexer를 만들때 이걸 가지고 만들었듯이\nParser에서는 CFG를 사용하므로 이것과 표현력기 같은 Push Down Automata를 이용해 Parser를 만들게 되는 것\nPDA는 FSA의 각 상태에 스택 메모리가 추가된 형태라고 생각하면 된다\n\n\n\n작동방식 §\n\n\n딱 위에 표만 봐도 감이 올거임\n위같은 형태로 표를 만들어 주면\n현재 Non-terminal에 해당하는 행과\nnextSymbol에 해당하는 열이 만나는 지점에 있는 번호의 생성규칙을 기계적으로 적용하는 방식으로 작동하게 된다\n\n\n\n위의 파싱 테이블 정의를 보면 결국에는 맞는말이다\n걍 저 예시 보는게 이해 더 잘됨\n절차는\n\n표를 우선 만들어준다 - 가로축 맨 마지막에 $ 넣는거 잊지 말지어다\n생성규칙 하나에 대해 해당 생성규칙의 RHS의 모든 FIRST 원소에 대해 LHS과 만나는 지점에 생성규칙 번호를 적어준다\n만약 FIRST에 널이 들어가 있다면, FOLLOW(LHS)의 원소들에 대해서도 위와 같은 작업을 해준다\n\n\n\n예제 §\n\n\n파싱 테이블과 모호성 §\n\n\n테이블을 그려봤더니 이것처럼 한 셀에 두개가 나오는 경우에는 결정적으로 생성규칙을 선택하지 못하기 때문에 모호하고 LL(1)이 아니다\n\nPredictive parser의 구조 §\n\n알고리즘 괄호쌍 문제 풀때 스택을 이용했듯이 여기서도 스택을 이용하게 된다\n왜냐면 괄호쌍 문제도 결국에는 트리의 형태이기 때문\n\n전체를 감싸는 괄호와 그 안의 괄호들이 있기 때문에 트리로 표현될 수 있고, 이 문제를 해결하기 위해 스택을 사용하기 때문에 파스 트리를 만드는 것에 있어서도 스택을 이용할 수 있다\n\n\n이것은 예제로 보는게 더 편할거같다\n\n\n\n\n위와 같은 예제가 있다고 해보자\n일단 처음에는 $(EOF)와 시작심벌(S)로 시작한다\n그리고 하는 일은 스택에 있는 Non-terminal이랑 입력스트링의 맨 처음 Terminal을 보고 파스 테이블에서 생성규칙을 가져오는 것이다\n그럼 지금 포인터가 맨 처음의 a이기 때문에 S와 a에 맞는 1번 행동을 하게 되고 이것이 저 파싱 행동에 있는 expand 1이다.\nexpand라는 것은 생성 규칙에 따라서 스택의 내용을 늘린다는 뜻이다. 그리고 이때 중요한 것은 생성규칙에 적혀있는 것의 역순으로 스택에 들어가게 된 다는 것이다\n\n보면 expand 1일때 1번 생성규칙은 aS지만 스택에 들어가 있는 내용은 Sa인 것을 볼 수 있다 - 역순으로 스택에 추가되기 때문\n\n\nexpand한 뒤에는 pop &amp; advance과정이 수행된다\n\n이것은 스택의 제일 위에 있는 Terminal이랑 입력스트링의 nextSymbol이랑 똑같을 경우 스택에서는 pop을 하고 입력 스트링에서는 포인터를 하나 옆으로 움직이기 때문에 advance라는 용어를 쓰게 되는 것이다\n\n\n그리고 이 과정을 반복하게 된다\n\n스택의 top이 Non-terminal이면 nextSymbol을 보고 생성 규칙을 선택하는 expand를 거치게 되고, top이 terminal이라면 nextSymbol과 비교해 같다면 pop &amp; advance를 하는 것을 반복한다\n\n\n그리고 마지막으로 top에 $가 들어있고 입력 스트링에도 $가 남아있다면 정상적으로 파싱이 완료된 것이므로 accept를 하고, 만약에 중간에 terminal이랑 nextSymbol이랑 다르거나 $가 제대로 나오지 않는다면 error를 반환하게 된다\n아래는 예제다\n\n"},"originals/compiler.fall.2021.cse.cnu.ac.kr/07.-Bottom-up-parsing":{"title":"07. Bottom up parsing","links":[],"tags":[],"content":"\n\n                  \n                  충남대학교 컴퓨터공학과 조은선 교수님의 &quot;컴파일러 개론&quot; 강의를 필기한 내용입니다. \n                  \n                \n\n\n\n                  \n                  다소 잘못된 내용과 구어적 표현 이 포함되어 있을 수 있습니다. \n                  \n                \n\nBottom-up parsing §\n\n일단 Bottom-up방식이 더 강력하다고들 한다 - 더 엉망인 문법로 파싱이 가능하기 때문\n\nLeft-recursive한 문법을 보통 엉망인 문법이라고 하고 Bottom-up 방식은 이런놈까지 파싱이 가능하다\n이것은 Bottom-up방식으로는 생성규칙을 선택하는 것을 더 많은 토큰이 들어올 때 까지 미룰 수 있기 때문에 그렇다\n\n\n이 아래 그림을 보면 좀 더 이해될거임\n\n\n\nTop-down방식은 스캔된 토큰을 가지고 루트까지 만들어지기 때문에 만들어야되는 트리가 더 크다\n\n하지만 Bottom-up방식은 스캔된 토큰으로 만들 수 있는데까지만 만들기 때문에 만들어야되는 트리의 크기가 더 작기 때문\n\n\n\nBottom-up의 과정 §\n\n일단 Bottom-up은 Terminal 심벌부터 시작하여 root인 시작 심벌까지 도달하면 성공적으로 완료가 된다\n즉, 생성규칙의 RHS를 보고 매치된다면 LHS로 치환하는 과정을 반복하게 됨\nBottom-up은 왼쪽부터 역 유도를 하기 때문에 결과적으로 우측유도의 역순을 진행하는 것과 동일하며 결과적으로 우파스의 트리가 만들어진다\n\nLL, LR §\n\n\n일단 LL은 니가 Top-down에서 배운 그 LL이 맞다\n그리고 LR파싱이 Bottom-up에서 사용하는 파싱 방식인데 위에 정리되어 있는 것을 좀 보면\nLL, LR에 공통적으로 들어가는 L은 Left-to Right라는 소리이다 - 왼쪽부터 읽어나간다는 소리임\n그리고 LL의 경우에는 좌측유도를 해 좌파스가 생성되므로 L이 하나 더 붙는 것이고\nLR의 경우에는 우측유도의 역순을 해 우파스가 생성되므로 R이 붙게 되는 것\nk는 뭐 전에 배웠던대로 몇개의 심벌을 보고 결정할지를 나타내는 lookahead이고\n근데 여기서 중요한 것은\n\nTop-down, Recursive decent(predictive), LL parsing은 전부 비슷한 맥락의 용어라는 것과\nBottom-up, Shift-reduce, LR parsing은 전부 비슷한 맥락의 용어라는 것 꼭 기억하덤둥\n\n\n그리고 LL의 경우에는 루트를 먼저 방문하기 때문에 트리 방문 순서 중 Pre-order방식이고\n\nLR의 경우에는 자식을 먼저 방문하기 때문에 트리 방문 순서 중 Post-order방식이다\n\n\n\nReduce, Handle §\n\nReduce는 간단하다 - Derive의 반대가 Reduce인 것\n즉, 생성규칙의 LHS를 RHS로 치환하는 것이 Derive였다면, RHS를 LHS로 치환하는 것을 Reduce라고 한다\n따라서 Bottom-up 방식은 시작심벌이 나올 때까지 Reduce하는 과정이라고 이해할 수 있다\nHandle은 Reduce될 부분을 의미하는 것\n예를 들면 다음과 같다\n\nA → aBc라는 생성규칙이 있을 때\naBc를 보고 A로 역유도 하는 것을 Reduce라고 하고\n이때 aBc부분이 reduce되는 것이므로 이 부분을 Handle이라고 함\n\n\n즉, Reduce는 동작이고 Handle은 동작이 아닌 특정 문장형태를 나타냄\nHandle을 보고 이걸 토대로 생성규칙을 뒤져보면 Reduce할 수 있는 생성규칙을 찾을 수 있다는 소리\n\nAmbiguous grammar §\n\n일단 모호한 문법이라는 것은 Left / Right most derivation을 했을 때 여러 형태의 파스 트리가 생성되는 경우를 의미한다는 것 기억나제\n이때 모호한 문법에 대해서는 Bottom-up parsing을 할 때도 모호한 상황이 일어나게 된다\n바로 Handle이 두개 이상 존재해 어떤 놈을 Reduce할 지 알 수 없을때 Bottom-up에서의 모호함이라고 한다\n\n\n\n위의 예제를 보면 E + E * id까지는 똑같은데 이때 id도 handle이 될 수 있고 E + E도 handle이 될 수 있다 - 이때 모호하다라고 하는 것\n\nShift &amp; Reduce §\n\n얘는 Top-down에서의 pop &amp; expand와 유사한놈이다\nPop &amp; expand에서도 스택이 존재했고 여기서 pop과 expand를 반복하며 파싱을 했듯이\nShift &amp; Reduce에서도 스택이 존재하고 Shift와 Reduce를 반복하며 파싱을 하게 된다.\n근데 여기서 중요한 것은 Pop &amp; expand할때는 생성규칙을 뒤집어서 넣었지만 Shift &amp; Reduce할때는 뒤집는거 없이 그냥 넣게 된다는 것주의혀\n일단 Shift는 간단하다 - 스택의 top에 Handle이 보일때까지 입력 심볼을 계속 밀어 넣는 것을 의미한다\n그리고 Reduce는 이제 Shift를 하다 보니 스택의 top에 Handle이 보여 그것을 생성규칙의 LHS로 치환하는 것을 의미한다\n\n\n\n즉, 위 그림처럼 Shift는 스택에 입력 심볼을 밀어 넣는 것을 의미하고\n\n\n\n위 그림처럼 스택에 Handle이 보여 이놈을 LHS로 치환하는 것을 Reduce라 하는 것\n\n따라서 Reduce의 과정에는 입력 버퍼에는 영향을 주지 않는다\n\n\n\n\n\n연습해봐라\n\n\n\n위의 그림이 좀 더 구체적인 작동 과정이다\n보면 초기에는 스택에는 $만 있고 입력버퍼는 입력 문자열과 $로 닫혀있는 것을 볼 수 있다\n그리고 Shift &amp; Reduce를 하며 진행하다가\n마지막에 스택에는 $시작심벌, 입력버퍼에는 $만 남아있으면 accept하며 종료된다\n\nLR Parsing Table §\n\n근데 이런 문제가 있다 - 만약 Reduce가 가능할때, 더 Shift를 할 것이냐 아니면 바로 Reduce를 할 것이냐 결정해야 되는 상황이 올 수도 있다\n또한 Handle의 길이를 하나로 특정할 수 없을 때 얼마만큼을 Handle로 보고 Reduce를 할 것이냐의 이슈가 있다\n\n이건 모호한게 아닌가?\n어쨋든 Reduce를 할 수 있는 Handle이 여러 경우의 수가 존재 할 때 어느 정도를 Handle로 보고 Reduce를 할 것이냐의 이슈가 있다.\n\n\n이런 것을 해결하기 위해서 등장한 것이 LR Parsing table이다\n\n\n\n예시로 이해하는 것이 제일 간단하쥬\n일단 왼쪽 위에가 생성규칙이고\n오른쪽 위에 LR Parsing table 이 있다 - 저렇게 행 index로는 상태가 들어가고 열 index로는 Terminal과 Non-terminal이 차례로 들어간 형태이다\n\n일단 테이블의 왼쪽 부분에는 열 index에 Terminal이 들어가게 되고 이 부분을 Action table이라고 한다\n\n이 부분의 셀에는 세가지의 값이 들어갈 수 있다 - S숫자, 생성규칙, accept\nS숫자는 Shift하고 그 다음 상태를 해당 숫자로 해라라는 의미가 된다\n그리고 생성규칙은 해당 생성규칙으로 Reduce해라 라는 의미가 된다 - 근데 Reduce는 생성규칙의 반대이므로 생성규칙의 화살표대로 가는게 아니고 화살표의 반대로 변환해주면 된다\n뭐 accept는 accept하고 끝내라는 의미겟지\n따라서 어떤 상태와 어떤 Terminal을 매칭한 셀에 있는 action을 취해주면 되는 것이다\n\n\n그 다음으로는 테이블의 오른쪽 부분에는 열 index에 Non-terminal이 들어가고 이 부분을 GOTO Table이라고 한다\n\n여기에는 들어갈 수 있는 값이 하나밖에 없다 - G숫자 - 얘는 해당 숫자의 상태로 가라 라는 의미가 된다\n\n\n\n\n그리고 이 파싱 테이블을 이용해 파싱하는 과정을 보면\n초기 설정에는 스택에는 $0, 입력버퍼에는 입력 문자열과 $가 들어간다\n\n스택에 $로 끝나는게 아니라 0이 들어가는 이유는 0이 초기 상태이기 때문이다.\n\n\n그 다음에는 다음의 두가지 동작을 반복해주면 된다\n\n만약 스택의 top에 상태가 있으면 이놈이랑 입력버퍼의 Terminal을 가지고 Action table에서 하라는 대로 하면 된다\n\n위의 예제에서 맨 첫번째 줄을 보면 top의 상태가 0이고 입력버퍼의 terminal이 a이므로 이 둘을 매칭하면 S3이다\n따라서 shift를 하고 다음 상태를 3으로 만들면 두번째 줄이 된다\n\n\n만약 스택의 top에 상태가 아닌 Non-terminal이 있으면, 해당 Non-terminal의 바로 이전 상태와 Non-terminal을 가지고 GOTO table로 가서 다음 상태를 가져온다\n\n근데 스택의 top에 상태가 아닌 Non-terminal이 있는 경우는 Reduce를 한 뒤에밖에 없다\n따라서 Reduce를 한 뒤에는 반드시 GOTO를 진행해준다고 습관들이면 좋더라\n위의 예제에서 보면 우선 두번째줄에서 3과 콤마를 보고 Reduce를 해야 된다는 것을 알아내게 된다\n여기서 유의할 점은 상태는 사용하고 나면 스택에서 사라진다는 것이다 - 따라서 3이 사라지고 스택의 a를 S로 reduce하게 된다\n그 다음에는 스택의 top에 S밖에 없기 때문에 이놈과 이놈 바로 이전의 상태인 0을 들고 GOTO table로 간다\n가서 보니까 g2라고 적혀있는 것을 볼 수 있고 따라서 다음 상태는 2가 되게 된다\n\n\n\n\n유의할 점 또 하나는 top에 있는 상태만 유의미하다는 점이다\n\n위의 예제에서 10번째 줄을 보면\n상태 5와 terminal $를 매칭해 S → L, S의 Reduce를 하게 된다\n이때 스택 사이사이에 있는 상태들은 전부 날라가게 된다 - 중간중간 껴있는 1, 4는 그냥 버리면 된다는 것\n\n\n파싱 테이블 만드는건 다음의 세 단계를 거치면 된다\n\n가능한 상태에 대해 정의하고\n상태들의 상태 전이도를 Deterministic Finite Automata를 정의하고\n잘 Parse table에 녹여내면 된다\n\n\n근데 얘네들은 다음시간에 배운댄다\n\n\n\nLR의 종류 §\n\n지금까지 배운 것은 일단 shift를 해놓고 보는 것이므로 Lookahead 가 0이다 - 따라서 이런 것을 LR(0) 이라고 함 - Shift-reduce 가 LR(0) 의 대표적인 예라고 생각하면 된다\n그리고 lookahead를 하나 보는 LR(1) 등이 있는데\nLR(0)은 간단한 대신 할 수 있는게 별로 없고 LR(1)는 너무 어렵기 때문에 이 중간에 SLR, LALR등이 더 있다\n"},"originals/compiler.fall.2021.cse.cnu.ac.kr/08.-yacc":{"title":"08. yacc","links":[],"tags":[],"content":"\n\n                  \n                  충남대학교 컴퓨터공학과 조은선 교수님의 &quot;컴파일러 개론&quot; 강의를 필기한 내용입니다. \n                  \n                \n\n\n\n                  \n                  다소 잘못된 내용과 구어적 표현 이 포함되어 있을 수 있습니다. \n                  \n                \n\nyacc 의 구조 §\n\nyacc은 일단 Bottom-up방식의 구문분석기를 생성해주는 프로그램이라는 것을 알고 있을 것\n그리고 LALR(1) 이라는 파싱 기법을 사용한다는 것 - LR(1)의 성능과 LR(0)의 가벼움을 적절히 취하는 파싱 기법\n\n\n\nyacc은 .y 확장자의 파일을 받아들인다\n그리고 이놈으로 구문분석기를 생성하면 y.tab.c이라는 구문분석기가 탄생한다\n그리고 여기에는 yyparse() 라는 함수가 있고 이놈이 중심적인 역할을 하게 된다\n\n\n\n.y파일은 lex와 비슷하게 위와 같은 구조로 되어있다\n선언부는 lex마냥 # include나 여러 변수들의 선언이 들어가게 되고\n그 중간에는 Rule(생성규칙) 들이 들어가게 되며\n마지막에도 lex처럼 함수들이 들어가게 된다\n생성규칙을 선언할때는 → 대신 :를 사용하게 되고\n하나의 생성규칙이 끝날때 세미콜론으로 마감을 하게 된다 - OR로 연결할때는 당연히 생성규칙이 안끝난거니까 안씀\n\nLR Conflict §\nAmbiguouty §\n\nyacc은 모호한 문법에 대해서는 구문분석기 실행시에 에러를 낸다\n즉, Reduce를 해야 할 지 Shift를 해야 할 지 알 수 없을 경우에 에러가 나게 된다는 것\n구문분석기가 에러가 났을 때에는 구문분석기를 뜯어서 확인해야되지만 모호성의 경우에는 문법에 오류가 있을 확률이 아주 높으므로 문법을 고쳐야된다\n이러한 경우에는 생성규칙간의 우선순위를 지정해서 해결이 가능하다\n\nreduce할 생성규칙의 우선순위가 token보다 높으면 reduce하고 아니면 shift하는 것\n\n\n또한 결합법칙의 경우에도 모호성이 발생할 수 있기 때문에 결합법칙을 명시해서 모호성을 줄여줘야 한다\n\n좌측 결합법칙의 경우에는 reduce를 더 우선순위를 높게 둬서 shift하지 않고 reduce를 하도록 유도\n\n\n\nyacc에서의 해결법 §\n\n\n일단 토큰의 우선순위를 정해줄때는 위처럼 우선순위가 높은 것을 아래에 두고, %어쩌고를 통해 결합법칙을 지정해줄 수 있다\n\n\n\n그 다음으로는 생성규칙의 우선순위를 정해줄때는 위와 같이 해줄 수 있다\n보면 일단 토큰의 우선순위를 정해줄때처럼 하되 이때의 이름은 임의로 지정해준다. 그리고 해당 우선순위를 지정할 생성규칙 옆에 %prec을 적어주면 해당 우선순위가 적용된다\n약간 우선순위에 이름을 붙이고 그 이름을 생성규칙에 할당해준다고 생각하면 됨\n\n\n\n위의 예제는 if then else 모호성 해결하는 예이다\n위같은 방식으로 if만 있는 케이스에는 낮은 우선순위를 둬서 else가 나오면 무조건 shift해서 else까지 매핑되도록 하는거임\n"},"originals/compiler.fall.2021.cse.cnu.ac.kr/09.-LR(0)-파싱-테이블,--SLR-파싱":{"title":"09. LR(0) 파싱 테이블,  SLR 파싱","links":[],"tags":[],"content":"\n\n                  \n                  충남대학교 컴퓨터공학과 조은선 교수님의 &quot;컴파일러 개론&quot; 강의를 필기한 내용입니다. \n                  \n                \n\n\n\n                  \n                  다소 잘못된 내용과 구어적 표현 이 포함되어 있을 수 있습니다. \n                  \n                \n\nLR Parsing table §\n\n일단 파싱 테이블을 만드는 과정을 다시 정리하면\n\n파서 상태가 될 수 있는 후보들 선정 - LR(0), Closure을 이용\n파서 상태들 간의 Deterministic Finite Automata 정의\n파싱 테이블로 변환\n\n\n\n파싱 테이블을 만드는데 알아야 할 개념들 §\nLR(0) 아이템 §\n\n얘는 생성규칙의 RHS에 찍을 수 있는 모든 곳에 점을 찍은 생성규칙을 의미한다\n예시로 보는게 더 빠름\n\n\n\n\n뭔지 알것제?\n\nClosure §\n\n얘는 LR(0)아이템 집합을 인자로 받아 원소의 갯수가 더 불어난(혹은 동일할수도 있음) LR(0)아이템 집합을 반환하는 함수이다\n일단 작동방식은 다음과 같다\n\n하나의 LR(0)아이템에 대해 점(.)뒤에 있는 놈이 Terminal이면 자기자신이 전부임\n하나의 LR(0) 아이템에 대해 점(.)뒤에 있는 놈이 Non-terminal이면 그 뒤에 있는 Non-terminal을 LHS로 하는 모든 생성규칙들도 포함하되 각각의 가져온 생성규칙 맨앞에 점(.)을 찍어준다. 그리고 새로이 포함된 모든 생성규칙들에 대해서도 Closure연산을 재귀적으로 돌려준다\n이짓을 집합내에 있는 모든 LR(0) 아이템에게 반복한다\n\n\n예시 보면서 하자\n\n\n\n점(.) 뒤에 Terminal이 있으면 걍 암것도 안하고 반환한다.\n\n\n\n점(.)뒤에 S가 있으므로 S → (L)와 S → id를 추가하되 앞에 점을 찍어 S → .(L)와 S → .id를 추가한다. 그리고 추가한 원수들에 대해서도 closure를 해보지만 .뒤에가 터미널이므로 이게 전부임\n\n\n\n결과를 보고 얘기를 하면\n\n먼저 [S’ → .G] 는 자기자신이고\n[G → .E=E] 와 [G → f] 는 자기자신의 점 뒤에 G가 있었기 때문에 추가된거고\n[E → .E+T] 와 [E → .T] 는 [G → .E=E] 에서 점 뒤에 E가 있었기 때문이고\n[T → .T*f] 와 [T → .f] 는 [E → .T] 에서 점 뒤에 T가 있었기 때문이다.\n\n\n\nGoto §\n\ngoto(A, B) 에서 일단 A는 LR(0)아이템 집합을 의미하고 A의 원소 중 점 뒤에 나왔으면 하는 심벌이다\n그리고 이것의 연산은 다음의 단계를 거친다.\n\n일단 집합 A에서 RHS에 “.B”가 등장하는 애들을 다 긁어모은다\n그리고 걔네들의 “.B”를 전부 “B.”으로 바꿔준다.\n그리고 얘네들을 Closure연산한다.\n\n\n즉, A의 원소들 중 B바로 앞에 있어서 B뒤로 건너갈 수 있는 놈들을 다 건너보내고 closure하는 것이다\n당연한얘기지만 A → null의 LR(0)의 goto는 없다\n예시봐라\n\n\n\n일단 .+가 나오는 놈이 I에서는 [E → E.+T] 하나밖에 없기 때문에 이놈을 [E → E+.T] 로 바꿔준다\n그리고 이넘을 closure을 해주면 됨\n결과가 저모양인 이유는 사실 이 예제가 Closure에서의 마지막 예시 연장선이기 때문임\n\n\n\n.T가 나오는게 [E → .T], [T → .T*f]이기 때문에 이 둘을\n[E → T.], [T → T.*f] 로 바꿔주고\n얘네들을 closure해주면 어차피 .뒤에게 터미널이니까 그대로 나온다.\n하나의 꿀팁은 논터미널 뒤에는 터미널이 나올 가능성이 높으니까 논터미널을 건너가는 goto의 경우에는 closure을 취해도 그대로 나오는 경우가 많고, 터미널 뒤에는 논터미널이 나올 가능성이 높으므로 closure연산을 추가적으로 해줘야 한다\n\n\n\n직접해봐라\n\n상태전이도 §\n\n\n보면 일단 네모박스가 LR(0)아이템 집합이고 화살표가 해당 집합에서의 goto를 했을때 결과 집합을 연결해주게 된다\n뭐 하나씩 보면 별로 어려울 건 없고\n오른쪽 집합에서 goto(오른쪽집합, ‘(‘)를 해주면 그의 결과가 오른쪽 집합으로 동일하게 나오기 때문에 환형으로 그려져있는 거심\n모든 심벌에 대한 goto가 표현되어있으므로 끝난거임 - 이거 그릴줄 알아야 한다\n\n각각의 의미 §\n\n일단 LR(0)아이템에서의 점은 약간 포인터임 - 이 앞까지는 처리를 끝냈고 점 뒤에 있는놈(마크심벌이라고 하더라)이 나오기를 기대하고 있는 거다\n그리고 어떤 LR(0)아이템에 대해 Closure은 점 뒤에 나올 수 있는 모든 가능성(심벌)을 전부 계산하는 것이라고 생각할 수 있다\n\n파싱 테이블 만들기 §\nItem 분류 §\n\n\n위의 예제에서 볼 수 있듯이 맨 위의 아이템은 점이 이동한 직후의 item이고 이걸 kernel item 이라고 부른다\n그리고 그 아래에 있는 것들은 kernel item을 closure해서 나온 것이므로 closure item 이라고 한다\n\n\n\n또한 이놈처럼 점이 맨 뒤에 있어 더이상 goto를 하지 못하고 전부 다 처리를 한 생태를 reduce item이라고 한다.\n\n상태 정의 §\n\n일단 생성규칙 [S’ → S] 를 추가한다 - Augmented Grammar라고 불림\n그리고 시작 상태는 closure([S’ → .S])이다\n\n의미를 생각해보면 아직 아무것도 들어온게 없는 상태인거고, 이제 S뿐 아니라 S다 대체될 수 있는 모든 애들이 뒤이어 나올 수 있는 상태가 시작 상태가 되는 것이다\n\n\n이 시작상태에서 goto를 하게 되면 그 다음 상태들이 나오게 되는 것임\n\n그 다음 상태들을 C0라고 하는데 이놈의 정의는 모든 타당한 LR(0)에 대해 goto를 적용하여 얻어낼 수 있는 모든 LR(0)아이템 집합을 의미한다\n\n\n또한 상태들을 막 거쳐서 결과적으로 [S’ → S.]이 되면 accept가 되는 것이다\n\n이 말뜻이 약간 헷갈릴 수 있는데 막 goto를 하다가 .이 맨 뒤에 갔을 때 .앞에 있는 것들이 S로 Reduce되면 S.가 되고 그때 accept가 되는 것이다\n근데 아직도 뭔소린지 잘 감이 안오긴함 이건\n\n\n\n\n\n그래서 그림으로 그려보면 위처럼 된다\nAugment grammar와 그것의 closure가 시작상태(0)가 되고\n여기에서 goto를 ㅈㄴ게 한 상태들이 회색으로 표현된 곳 이고\n마지막으로 시작상태에서 goto(시작상태, S)를 하게 되면 (3)번 상태가 되며 accept가 된다\n\n\n\n해봐라\nAugment grammar추가하기, goto 빼먹지 않기, closure item 빼먹지 않기, 중복된 아이템 집합 만들지 않기 - 실수하지마셈\n\n테이블로 만들기 §\n\n아래의 규칙을 잘 지키면서 해라\n터미널을 건너가는 goto는 shift로 바꾸고\n논터미널을 건너가는 goto는 goto로 하고\n시작심벌이 아닌 심벌 뒤에 점이 있고 그게 마지막이라면 그 행 전체를 reduce로 하고\n시작심벌 뒤에 점이 있고 그게 마지막이면 accept로 하면 된다\n\n\n\n이래 하면 된다 - 직접 해보기!\n\n\n\n\n생성규칙에서 아이템과 goto만들고 그림 그려서 파싱 테이블 만든 후, 파싱 화정 따라가는거 시험공부를 위해 반복하라\n\nSLR 파싱 §\n\n얘는 LR(0)와 나머지는 다 똑같고 하나만 다르게 해줌으로써 파싱의 범위를 많이 늘린 파싱 기법이다\n일단 LR(0)의 문제점은 reduce의 경우에 한 행 전체를 생성규칙으로 도배를 했고 따라서 별 문제가 없어보이는 문법도 테이블의 한 셀에 액션이 두개가 들어가는 모호한 경우가 생기게 됨\n따라서 Simple LR(SLR) 의 경우에는 도배를 하는게 아니고 reduce item인 경우에는 follow를 구하고, follow의 원소가 등장한 경우에만 reduce를 하게 하는 방식이다\n\n\n\n결과적으로 위의 예시는 다음과 같이 reduce의 갯수가 많이 줄어들고, 액션이 겹치는 모호한 경우가 발생하지 않더라\n"},"originals/compiler.fall.2021.cse.cnu.ac.kr/10.-LR(1)-파서,--LALR-파서":{"title":"10. LR(1) 파서,  LALR 파서","links":[],"tags":[],"content":"\n\n                  \n                  충남대학교 컴퓨터공학과 조은선 교수님의 &quot;컴파일러 개론&quot; 강의를 필기한 내용입니다. \n                  \n                \n\n\n\n                  \n                  다소 잘못된 내용과 구어적 표현 이 포함되어 있을 수 있습니다. \n                  \n                \n\nSLR의 문제점 §\n\n\n위 그림을 보면\ni2상태에 Reduce item과 Kernel item이 같이 존재하는데 그럼 이때에는\nA → a로 reduce를 해야할지 shift b를 하고 5번 상태로 갈지 알 수 없다\n즉 지금까지 봐온 예제에는 Kernel item이 reduce item이어서 별 문제가 없었지만 위 예제에서 보다시피 SLR으로 해도 Shift-reduce conflict를 피할 수 없더라\n\n\n\n일단 위 그림만 보고 대강 진행과정을 생각할 수 있어야 한다\n그림만 보고 할때는 Reduce를 하면 왔던대로 다시 갔다가 Reduce해서 생긴 논터미널로 움직여줘야되는것 잊지말\n어쨋든 위의 예제에서 보면\nab같은 경우에는 2번에서 shift b를 하고 5번으로 가야되고\nac같은 경우에는 2번에서 Reduce A → a를 하고 0번으로 갔다가 3번으로 가야된다\n하지만 2번에서는 A의 Follow에 b와 c가 모두 있기 때문에 SLR가지고는 위와같은 세밀한 컨트롤이 안된다 이거임\n\nLR(1) Parsing §\n\n이것을 해결하고자 그냥 Follow가 아니라 그 path를 타고 왔을때 Follow는 누구냐? 이 뭔소리여\n어쨋든 그냥 Follow가 아니라 좀 더 조건을 세분화할 필요가 있는 것\n따라서 LR(1) Item을 좀 변형해 해당 생성규칙으로 Reduce되었을 때 다음에 나와야 되는 토큰도 같이 명시하게 된다\n이제는 그냥 Reduce를 하는게 아니라 그 다음에 나오는 토큰(Lookahead라고 부름)까지 확인을 하고 Reduce를 하는거고 따라서 그 다음 토큰 하나를 더 확인하기 때문에 LR(1) 이 되는거다\n\nLL에서의 Lookahead와의 차이점은 LL(1)이면 그다음 토큰 하나를 보고 다음 액션을 결정해주는 것이었다면\nLR(1)은 그 다음 토큰 하나를 보고 테이블을 만들겠다는 약간의 의미상으로 차이가 있다\n\n\n\nLR(1) Item §\n\n\n일단 LR(0) Item과의 차이점은 맨 뒤에 콤마(,)를 찍고 해당 생성규칙으로 Reduce를 한 다음에 기대하는 토큰이 명시되게 된다는 점이다\n\n즉, LHS도 Reduce한 다음에 나올 토큰이기 때문에 SLR처럼 Follow를 고려해주는 셈이지만 SLR에서는 모든 Follow 원소에 대해 Reduce를 하는 것이었다면 여기서는 이제 Follow원소 중 부분집합에 대해서의 액션을 좀 더 세분화해서 명시하게 되는 것\n\n\n따라서 위의 식의 의미를 생각해보면 X → a.b에서 b가 나오면 X → ab.가 되므로 reduce를 해야하지만 reduce를 한 다음에 y가 등장해야만 reduce를 하라는 의미가 되는 것\n\nLR(1) Closure, goto §\n\nLR(1) Item이라는게 새로 확장되었으므로 LR(1) Closure도 확장해줘야 한다\n그리고 goto의 경우에도 점을 이동하고 Closure를 해주는 것은 동일하지만 Closure가 바뀌었기 때문에 조금 달라지게 되는 것\n\n\n\n일단 시작상태의 Augment grammar가 위처럼 $가 Lookahead로 추가된 것으로 바뀐다\n\n\n\nClosure의 진행과정을 보면\n일단 점 뒤에 터미널이 오면 끝나는건 매한가지이다\n그리고 점 뒤에 논터미널이 있으면 그 논터미널에 대한 생성규칙에 점찍어서 갖고오고 재귀적으로 Closure을 구해줘야 하는 것도 동일하다\n근데 달라지는 것은\n이제 LR(1) Item의 경우에는 Lookahead까지 같이 계산해서 명시해야 하기 때문에 추가적인 연산이 더 들어감\n어케하냐면 점 뒤에 논터미널인 경우에는 해당 논터미널을 갖고 오되 논터미널 뒤로 점이 움직였을 경우 등장할 수 있는 토큰들을 Lookahead로 넣어주면 된다\n\n위의 예제에서 보면 [S’ → .S , $] 에서 일단 S에 대한 생성규칙을 다 갖고와 점을 찍어준다 - 즉, [S → .E+S] 와 [S → .E]\n그리고 [S’ → .S , $] 에서 S뒤로 점이 이동했을 때 나올 수 있는 것은 $밖에 없으므로 Closure Item에 대해서도 $를 Lookahead로 추가해준다 - 즉, [S → .E+S , $] 와 [S → .E , $]\n그리고 확장된 애들에 대해서도 Closure를 해주기 위해 점 뒤에 있는 E에 대한 생성규칙도 다 가져온다 - [E → .num]\n근데 [S → .E+S , $] 와 [S → .E , $] 에서 보면 E 뒤에는 $말고도 +도 올 수 있으므로 [E → .num] 의 Lookahead로 + / $가 들어가게 되는 것이다 - 즉, [E → .num , + / $] 가 되는 것\n\n\n\n\n\ngoto 예제이다 - LR(0)와 동일한데 Closure이 변경되면서 그에대한 여파로 달라지게 된 것\n\n\n\n풀어봐라\n\n상태전이도 §\n\n\n뭐 LR(0)에서처럼 그려주면 된다\nLR(0)에서의 상태전이도가 C0였듯이 LR(1)에서의 상태전이도는 C1라고 부른다\n\n파싱 테이블 만들기 §\n\n파싱 테이블 만드는 것도 LR(0)와 거의 동일한데\nReduce Item을 처리할때는 그냥 전부 Reduce로 꼬라박는게 아니고 Lookahead에 포함된 토큰에 대해서만 Reduce를 박아주면 된다\n\n\n\n빨간색 부분 처리할때 이래해주면 된다는거임\n\n\n\n풀어봐라\n\nLALR Parsing §\nLR(1) 파싱의 단점 §\n\n얘는 이제 문제가 너무 정교해서 상태의 갯수가 너무 많아진다는 것이다\n따라서 상태의 갯수는 줄이고 거의 동일한 성능을 가지는 LALR이 등장하게 되는 것\n\n상태 갯수 줄이기 §\n\n\n일단 LR(1) Item에서 Lookahead를 빼고 그 앞부분을 Core라고 하는데\n두 상태의 원소가 Lookahead만 다르고 Core은 같다면 이것을 합쳐서 하나의 상태로 만든 것이 LALR이다\n\nLALR 만들기 §\n\n뭐 LR(1)을 만든 다음에 상태들을 병합할 수도 있지만 이방법은 조따 복잡하기 때문에 안쓰고\nSLR을 만들어 LR(0)와 C0를 다 만들고 shift, accept, goto는 동일하지만 Reduce Item을 처리해 Reduce를 할때만 Lookahead를 고려하여 액션을 구성하게 된다\n\n총정리 §\n\n\n어떤 문법이 ~라는 것은 ~테이블에 conflict가 없다는 것이다\n\n\n\n참고로 문법들간의 표현범위는 다음과 같음\n문법을 정교하게 만들면 컴파일러가 할게 많지 않고 문법을 대충만들면 컴파일러가 수정해야되니까 할게 많더라\n\n기출문제 §\n\n\n2, 3번문항 스택과 입력스트링 그려서 설명하라\n"},"originals/compiler.fall.2021.cse.cnu.ac.kr/11.-SDD,-AST":{"title":"11. SDD, AST","links":[],"tags":[],"content":"\n\n                  \n                  충남대학교 컴퓨터공학과 조은선 교수님의 &quot;컴파일러 개론&quot; 강의를 필기한 내용입니다. \n                  \n                \n\n\n\n                  \n                  다소 잘못된 내용과 구어적 표현 이 포함되어 있을 수 있습니다. \n                  \n                \n\nSemantic analysis 이전에 할거 §\n\nLexical analysis와 Syntax analysis를 끝내면 그 결과로 나온 Parse tree로 Semantic analysis를 하는데\nSemantic analysis로 들어가기 전에 Parse tree에 좀 살을 붙이는 작업을 한다\n\nSDD(Syntax-Directed Definition) 혹은 SDT(Translation) 이나\nAST(Abstract Syntax Tree) 의 도구를 이용하더라\n\n\n\nSyntax Directed Definition / Translation (SDD / SDT) §\n\n얜 뭐냐\n과제에서 했던게 사실 SDD였던거임 - 어떤 생성규칙을 방문했을때, 그리고 빠져나왔을때의 Action을 설정해서 파싱 과정에서 다양한 정보를 생산할 수 있게 하는 것\n따라서 생성규칙마다 Action을 적어놓으면 파싱 과정 혹은 파싱된 이후에 노드를 방문하며 Action들을 수행하게 된다\n\n보통은 트리가 생성된 다음에 순회하지만 생성되면서 순회하는 방법도 있댄다\nLR은 Bottom-up으로 생성되면서 하고 LL같은 경우에는 Recursive descent parser구현에서 심볼마다 할당된 함수가 return될때 방문하게 됨\n\n\n그럼 이 Action은 어떻게 적느냐\nNon-terminal마다 ‘값’이 있고 그 ‘값’들로 코드를 짜면 그게 Action이 됨\n이렇게 말하면 뭔 소린가 싶은데\n\n\n\n이게 Yacc / Bison에서의 예시임\n보면 일단 생성규칙이 있고\n{} 에 Action을 적어주게 되는데\nYacc에서는 RHS의 값은 저 $$ 라는 변수에 저장되게 되고 LHS는 앞에서부터 차례대로 $n 의 변수에 저장되게 된다\n\n\n\n위 그림처럼 된다는거임\n따라서 위의 예시에서는 RHS의 값인 $$ 으로 첫번째 expr의 값인 $1 과 두번째 expr 값인 $3 을 더하게 되는 것\n여기서 주의할점은 여기에서 등장하는 변수들은 scope가 해당 생성규칙에 한정된다는 것\n\n뭔소리냐면 만약에 $1 이 10이고 $3 이 30이었다면 $$ 의 값은 40이 되것지\n근데 이때의 root는 또 다른 서브트리의 leaf가 될 수 있것지\n그럼 그때 40이라는 값은 $$ 에 저장되는게 아니라 $n 에 저장된다는 거다\n즉, 하나의 서브트리에 한정해서 루트의 값이 $$ 이고 리프의 값이 $n 이 된다는 소리임\n\n\n\n\n\n위 그림 보면 뭔소린지 감은 잡힐거임\n뭐 Terminal에 대해서는 값이 없다고 생각할 수 있는데 Lex에서 던져주는 식으로 값을 가져올 수도 있댄다 - 따라서 Terminal에 대해서도 별도의 변수가 할당되어 있는 것\n\n\n\nANTLR에서는 위처럼 표현된다는거임\nANTLR는 파싱트리가 생성되고 난 후에 Post order traversal로 순회하며 Action을 취한다\n따라서 BaseListener라는 클래스 원형과 Listener 라는 인터페이스를 제공하여 얘네들을 상속 / 구현해 Action들을 명시하게 되어 있음\n생성규칙 서브트리로 진입했을 때와 나갔을때 호출되는 enter뭐시기, exit뭐시기 메소드들이 있고 얘네들 안에 코드를 적어주면 그 코드가 실행되는 것\n자세한건 과제 참고해라\n\nAttribute §\n\n위의 예제에서는 $$, $n 의 값이 정수인것으로 가정했는데\n$$, $n 을 정수가 아닌 구조체로 명시할 수도 있다 - 이때의 구조체 Property를 Attribute 라고 부름\n\n\n\nval이라는 Attribute가 있다고 어딘가에서 명시했다는 가정 하에 위처럼 사용할 수 있는 것\n\n\n\nAttribute를 명시하는 방법은 위처럼 하면 된다\n일단 Lex에서도 yylval에 해당 Attribute가 있다고 생각하고 코드를 짠 후에\nyacc의 선언부(맨 위)에 %union {} 으로 Attribute 목록을 적어주고 각각의 심벌들에 대해서 어떤 Attribute를 가지는지 명시해줄 수 있는 것\n근데 중요한점은 위에서는 구조체라고 했지만 사실은 Union type인 것 - Attribute마다 각각의 메모리가 잡히는게 아닌 메모리를 한덩이 잡아놓고 Attribute 각각에 따라 자료형만 바뀌는거다\n즉, 하나의 심벌이 여러개의 Attribute를 가질 수는 없는 셈\n따라서 위처럼 명시하게 된다 - $$, $n 를 union type으로 명시하고 각각의 심벌마다 specific type을 지정해 주는 셈임\n심벌 각각에 Attribute를 지정해 줄 때는 Non-terminal일때는 %type &lt;attr&gt; N 이런식으로 명시하고\nTerminal에 대해서는 %token &lt;attr&gt; T 이런식으로 명시한다\n\nAttribute의 종류 §\n\n\n이런 생성규칙에 대해\n\n\n\n위처럼 children의 attribute를 이용해 parent의 attribute를 채우는 경우 Synthesized Attribute라고 부르고\n\n\n\nparent, sibling의 attribute를 이용해 child의 attribute를 채우는 경우 Inherited Attribute 라고 부른다\nSynthesized Attribute 의 경우에는 Bottom-up방향으로 attribute값이 propagation되고 Inherited Attribute 의 경우에는 Top-down방향으로 attribute값이 propagation되게 된다\n당연히 Terminal의 경우에는 Synthesized Attribute밖에 가지지 않는다\n\nSDD를 이용한 자료형 선언 예시 §\n\n\n일단 위의 예시에서 intType과 floatType은 상수로 선언되어있다고 가정한다\n그리고 AddType(id, type)이라는 함수를 이용해 해당 id(변수)의 자료형으로 type을 가지게 한다고 가정한다\n마지막으로 D1저거는 그냥 D랑 똑같다고 생각하셈 - recursive declaration 이어서 RHS랑 이름이 겹치니까 걍 좀 다르게 적었다는 느낌\n그럼 이 예시에서는 Bottom-up방식으로 propagation되며 변수의 자료형이 선언된다는 것을 알 수 있을것이다\n\nRHS의 attribute를 채울 때 LHS의 attribute값을 이용하면 Bottom-up방식으로 attribute가 채워지며 propagation된다\n\n\n위의 예시에서 D의 타입도 지정해주는 이유는 두번째 생성규칙 보면 D가 재귀적으로 나오고 그 뒤에 id가 뒤이어 오기 때문에 D뒤에 나오는 id는 D의 타입을 따르게 해주기 위함\n\n\n\n또 다른 예시임\n이번에는 자료형 명시부분 T와 변수 명시 부분 L로 나누어 TL로 D가 표현되는 방식인데\n보면 위의 예시에서는 Bottom-up 방식 뿐 아니라 Top-down방식으로도 propagation되며 자료형이 선언된다는 것을 알 수 있다\n\nLHS의 특정 attribute를 채우는데 RHS가 사용된다면 이때는 Top-down 방식으로 attribute가 채워지면 propagation되는 것\n\n\n\nAST(Abstract Syntax Tree) §\n\n\n뭔지는 프언개때 배워서 알거임\nParse tree에서 문법적인 부분은 모두 제거하고 의미적인 부분만 남겨서 트리구조를 단순화시킨 것\n보면 괄호같은 경우에는 우선순위를 잡아주는 역할을 하는데 파스트리에서는 트리의 깊이도 우선순위가 녹아있기 때문에 다 제거가 되고\nNon-terminal의 경우에도 Terminal로 바로 치환해서 불필요한 것들을 다 제거하게 된다\n\n구현 예시 §\n\n\n일단 자바로 짠 자료구조이다\n객체지향 언어에서는 Polymorphism을 이용해 저래 표현할 수 있다더라\n\n\n\n이건 C로 짠 코드인데\n객체지향 언어가 아닌 경우에는 임의 자료형 자식 n개를 갖는 것을 표현하기 어렵댄다\n\n자바같은경우에는 뭐 임의 자료형을 일반화해서 하나로 묶는게 되지만 C언어에서는 안되니까\n\n\n임의 갯수의 자식을 가지는 것을 표현하기 위해 저렇게 N-ary tree를 binary tree로 바꾸는 방법을 이용한다\n자식 포인터와 형제 포인터 두개만으로 n번째 자식에 도달하기 위해서는 첫번째 자식으로 간 다음에 링크드 리스트마냥 쭉 옆으로 따라가는 것\n\nAST 만들기 §\nLL파싱 하는 와중에 만들기 §\n\n\n왼쪽 위에가 옛날에 배운 Recursive descent parser이고 오른쪽 아래가 AST생성하는 버전\n자식이 준 AST 서브트리를 모아다가 합쳐서 반환하는 방식으로 구현\n\nLR 파싱 하는 와중에 만들기 §\n\n\nAST이기 때문에 당연히 의미있는 것에 대해서만 Node를 생성함\n그래서 위처럼 Shift-reduce할때\n의미있는 Terminal을 Shift할때 단말 노드를 만들고\n의미있는 생성규칙을 Reduce할때 단말 노드를 합쳐 Subtree를 만든다\n\n\n\n그래서 좀 더 자세히 보면 위처럼 됨\n일단 심벌들마다 추가적인 공간이 있어 여기에 서브트리가 저장이 되고\nReduce되고 난 뒤에 트리가 저렇게 합쳐지는 것을 볼 수 있음\n\nSDD로 만들기 §\n\n\n별거 없다\nnode라는 attribute가 있어서 각각 expr에 대한 서브트리를 저장 하게 되고\nAction에서 자식의 노드를 이용해 나 자신의 노드를 채우는 연산을 수행 하게 된다\n\nEvaluation §\n\nParse Tree혹은 AST에서 각각 노드를 방문하며 명시된 Action을 작동시키는 것을 Evaluation 이라고 하는데\n그 방법중 하나로\nOn-the-fly Evaluation 은 AST Node 방문 순서대로 Evaluation하는 것인데\n가장 효율적이긴 하나 제약조건이 있다\n\nS-attributed SDD : Synthesized Attribute만 가지고 있는 경우\nL-attributed SDD : Synthesized Attributed와 더불어 parent가 아닌 sibling attribute 만 이용해 attribute를 계산하는 경우\n위 두가지 경우에만 Evaluation이 가능하다\n\n\n"},"originals/compiler.fall.2021.cse.cnu.ac.kr/12.-IR":{"title":"12. IR","links":[],"tags":[],"content":"\n\n                  \n                  충남대학교 컴퓨터공학과 조은선 교수님의 &quot;컴파일러 개론&quot; 강의를 필기한 내용입니다. \n                  \n                \n\n\n\n                  \n                  다소 잘못된 내용과 구어적 표현 이 포함되어 있을 수 있습니다. \n                  \n                \n\nIntermediate Representation §\n\n고급언어와 기계어와 무관한 언어이고\nTree나 Instruction List의 형태를 띄고 있댄다\n\nTreeNode나 Instruction이 적어야 최적화나 번역에 좀 더 유리함\n\n\n\n\n\n그리고 위에서 보는것처럼 여러 종류를 사용해 표현 - 소스코드와 가까워 보통 코드 최적화의 역할을 위한 HIR(High IR) 와 기계어에 좀 더 가까운 LIR(Low IR) 로 사용한댄다\n\nHigh Level IR §\n\n일단 High Level과 Low Level은 상대적인 개념으로 명확하게 나누어져있는 경우도 있지만 그렇지 않은 경우도 있고 3개 이상의 IR을 사용할 때도 있댄다\nHigh Level IR 은 형태나 표현력은 AST와 동일하나 여기에 반복문 처리나 함수 복붙 등의 추가적인 연산을 더 해주게 된다\n\n\n\n위처럼 변수 자료형에 맞게 변환해주는 기능도 함\n\n즉, 좀 더 구체적이게 AST를 변형해 Node를 추가하게 됨\n\n\n\nLow Level IR §\n\nRISC같은 assembly language를 흉내낸 단순한 Instruction들로 구성된다\n따라서 arithmetic(+logic, unary)연산, data movement(뭐 move, load, store같은)연산, 함수 call / return, goto등의 기능을 제공하는 instruction들로 구성된다\n\nLow level IR의 종류 §\n\nN-tuple 표기법으로 표현할 수 있음 - 지금은 4-tuple인 Quadrauple 을 주로 사용한댄다\n얘는 (연산자, 피연산자1, 피연산자2, 결과) 이렇게 4개를 튜플로 묶어 하나의 Instuction을 표현하는 것\n\n이전에는 결과를 저장하지 않고 그냥 명령의 주소로 결과를 퉁치는 방법인 3-tuple방법이 유행이었으나 최적화시에 명령의 주소가 바뀌는 경우가 많아 문제가 됨\n근데 이제 Quadruple 의 경우에는 결과를 할상 저장해야되므로 임시변수 문제가 생기게 된다\n뭐 저장할 필요가 없는데 저장해야 되는 문제가 생긴다네 - 컴파일러 최적화하는 것으로 해결이 가능하다네\n\n\n그리고 Tree로 표현하는 것도 가능하고 - 얘는 기계어 생성에 용이하댄다\nJVM용 언어같은 애들도 중간언어로 분류한다면 얘네들은 Stack Machine Code 라고 부른다 - 기계어와 매우 흡사함 - 뭐 AST로부터 생성이 용이하다네\n\nQuadruple(3-address) code §\n\nOP를 제외하고 연산자 두개와 결과를 저장할 메모리 주소 3개가 필요하므로 3-address code 라고도 불린다\n\n반드시 3개여야되는건 아님 - 3개 이하여야 된다 - Unary operation은 피연산자가 한개니까\n\n\n\n\n\n위처럼 HIR을 변환해서 Quadruple로 만들 수 있다\n무조건 연산자 하나와 피연산자 두개(혹은 하나), 그리고 그의 결과로 표현하는 방식\n여기서 t1, t2들이 임시변수 이다 - 연산 하나에 대한 결과를 임시적으로 저장해 사용하기 위한 것\n\nInstructions §\n\n\n보면 뭐 별로 새로울건 없고\n여기서 [] 는 C언어에서 * 에 대응되는 dereference라고 생각하면 되고\naddr 는 C언어에서 &amp; 에 대응되는 reference라고 생각하면 된다\n\n\n\n이전까지 봤던 Instruction들과 크게 다를건 없다\nFunction call의 경우에는 인자때문에 엄밀하게는 3-address는 아니지만 여기에 포함시키기도 한댄다\n따라서 Quadruple은 어떤 상상속의 기계에서 작동하는 Instruction이라고 생각해도 된댄다\n\n3-Address code : GIMPLE, LLVM §\nGIMPLE §\n\n\n일단 뭐 gcc는 3개의 IR을 거쳐 컴파일하고\nGIMPLE은 gcc의 3-address 중간언어다\n뭐 저기 보면 &lt;&gt;사이에 값 4개 들어가있제? Quadruple이라는 소리다\n\n\n\n예시임 - GCC는 C언어를 이렇게 컴파일한다\n\nLLVM Bit Code §\n\n너가 coc깔때 clangd를 llvm으로 깔았잖어 이놈이 그놈임\nclang 의 중간언어가 LLVM Bit Code이다\n장점으로는 뭐 최적화가 잘되어있고 인터페이스가 깔끔해 Frontend와 Backend를 붙이기 좋댄다\n\n\n\nLLVM Bit Code는 위처럼 생겼다\ni32는 자료형과 자료형 크기를 나타내는 거임 - unsigned이기 때문에 32비트 integer여서 i32인것\n@ 는 전역변수를 나타내는 것인 % 는 지역변수를 나타내는 기호임\n그리고 여기서도 add쪽 보면 Quadruple을 사용하는 거 알 수 있고\nalloca는 memory allocation, align 4라는 건 4의 배수가 되는 주소에 할당하라는 소리\n\n\n\nglobal 은 전역변수에 대한 memory allocation이고\nnounwind 는 Exception이 발생하지 않는다는 것\nstruct 선언은 선언부를 그대로 먼저 적어주고 type { i32 }는 값이 아닌 자료형이고 그 안에 i32가 하나 들어가있다는 의미\n배열은 [숫자 X 자료형] 형태로 표현되고\nzeroinitializer 는 전부 0으로 초기화\n어쨋든 저거 읽어보면서 3-address code 번역하는거 연습해라 - LLVM은 아니어도 뭔가 번역하거나 역번역하는거 시험에 나올삘\n\nStack Machine Code - JVM Byte Code §\n\n일단 Stack Machine 은 JVM생각하면 편하다\n\n가상머신으로 Stack Machine을 하나 만들고 여기에서 돌아가는 Assembly code로 컴파일한 것이 Stack Machine Code 인 것\n\n\n\n\n\n일단 왜 이름이 Stack Machine 이냐면 위와같은 구조때문에 그렇다\n일단 위의 구조는 메소드 하나의 구조임\n\n지역 변수는 배열 형태로 저장하고\n오른쪽 아래 부분은 Constant pool 로 전역변수와 상수가 저장된다\n그리고 Operand Stack 은 쉽게 설명하면 임시변수 스택이라고 생각하면 된다\n\n하지만 임시변수는 생성되지 않는데 그 이유는 그냥 이 스택에 Push하면 임시값이 저장되고 Pop해서 임시값을 가져오기 때문\n따라서 임시변수가 생성되지 않아 코드가 더 깔끔해진댄다\n\n\n\n\n\nJVM Byte Code 예시 1 §\n\n\n.class 파일을 javap -c로 생성했을때 모습임\n일단 위에 세 줄은 원래 코드 모습을 보여주는 것 - JBC읽을때 같이 보면서 읽으라고 적어놓은거\n\n이부분 보면 일단 Employee 클래스에 대한 생성자 라는 것을 알 수 있다\n\n\n그리고 &lt;&gt; 안에 있는 내용들도 마찬가지로 참고용으로 적혀있는것들이다\n먼저 aload_n 은 n번 인덱스에 있는 객체를 스택에 넣으라는 것\n\nArray of local variables의 0번 인덱스는 무조건 this임 - aload_0 은 this를 스택에 넣으라는 것\n그리고 무조건 this는 스택에 넣어놓고 뭔가를 한다 - 뭐 하려고 할 때마다 aload_0 이 불리는 것을 볼 수 있음\n반대로 스택에 있던것을 배열로 옮기는 것은 store 라는 말을 사용한댄다\n또한 iload_n 은 integer값을 스택에 넣으라는 거다 - 자료형에 따라 맨앞글자가 달라지는거임\n\n\n그리고 invoke~ 은 메소드를 호출하는 부분임\n\ninvokespecial 은 생성자나 private method를 호출하는거다\n#3 은 자바의 Object 클래스 생성자이다\n생성자가 호출될때는 무조건 부모클래스의 생성자가 호출되므로 invokespecial#3 이 불려진것\n\n\n왼쪽에 숫자는 byte를 나타내는 것\n\n뭔소린가 하니 aload_0은 1바이트짜리 명령어이기 때문에 그 다음 숫자가 1이 된거고\ninvokespecial도 1인데 Constant pool에 있는 애들은 byte를 더 넉넉하게 잡기 때문에 # 3이 2바이트를 먹어서 총 3바이트가 되는 것\n따라서 그 다음 번호가 4가 되는 것이다\n마찬가지로 putfield다음에 3이 건너뛰는 것도 이러한 이유임\n\n\n또한 invokespecial이나 putfield같은 애들이 불리면 무조건 스택이 비워진다\n\n따라서 invokespecial이후에 aload_0으로 this를 다시 넣어준다\n\n\nArray of local variable의 인덱스 1에는 첫번째 지역변수인 strName이 저장되어 있어 aload_1로 strName을 스택에 넣어줌\nputfield는 필드에 스택의 top에 있던 것을 넣으라는 거다\n\n#5 에는 필드 this.name이 저장되어있나봄\n따라서 strName이 this.name으로 들어가게 된다\n\n\n뭐 나머지는 동일한거 반복이기 때문에 읽어보면 됨\n\nJVM Byte Code 예시 2 §\n\n\n맨 위에는 클래스 정보와 버전에 드가있는거고\nConstant pool 에 보면 저렇게 #번호 를 달고 상수들이랑 전역변수가 설정되어있는 것을 알 수 있음\n메인함수 작동과정은\n\nC++에서와 동일하게 new로 Malloc을 해준 후 스택에 넣는다 - new #2 이고 #2 가 MovingAverage 클래스니까\n그리고 new로 생성되어 스택탑에 있던걸 dup으로 복사해주고 - 스택에는 그럼 두개가 들어가는거\ninvoke special #3 으로 MovingAverage 생성자 호출하고\nastore_1로 생성된 객체를 LocalArray[0] 에 넣는다\n\n\n\n\n\n위 그림이 이 예제에 대한 바이트 배열 모습임\n#숫자 가 2바이트를 먹는다는것 - new, invokespecial같은애들 전부 Constant pool을 사용하기 때문에 2바이트가 추가된 3바이트를 먹게 된다\n\nJVM Byte Code 예시 3 §\n\n\n7번 바이트 코드까지는 예제 2번하고 동일하고\n지역변수에 상수값을 넣는 과정은 다음과 같다\n\n일단 iconst_n으로 상수를 스택에 넣는다 - i로 시작하면 integer, n에는 그 숫자가 들어감\n그리고 istore_n으로 스택 탑에 있던 정수를 LocalArray[n] 에 넣는다\n\n\n맨 아래 Array of local variables 그림이 있다 - 보면 뭐 맨 위에 있는거부터 차례대로 들어가있는 것을 알 수 있음\n\n\n\nma.submit을 호출하기 위한 과정인데\nma객체가 필요하므로 aload_1로 ma객체를 스택에 넣어준다\nnum1 을 submit 메소드에 넣기 위해 iload_2로 스택에 넣는다\n그리고 i2d를 통해 integer을 double type으로 바꾼다 - submit메소드는 double을 인자로 받기 때문\n그리고 invokevirtual_#n가 public method 호출하는 부분이다\n\n즉, ma.submit을 호출하게 되는 것\n\n\n그 담에 18 19 20 21은 같은과정 반복이다\n\nJVM Byte Code 예시 4 §\n\n\n7번까지는 객체생성해서 지역변수에 넣어주는 것\ngetstatic_#n으로 Constant pool에 있던 필드값을 스택에 넣어주게 된다\n\n옆에 주석 보면 필드에 있던 배열 하나 갖고 온걸 알 수 있다\n\n\n그리고 astore_2로 배열을 LocalArray[2]에 넣은거고\naload_2로 배열을 다시 스택에 넣은 다음\narraylength를 통해 스택탑에 있던게 배열이었다면 걔를 pop해서 걔의 크기를 push해준다\nistore_3으로 배열 크기를 LocalArray[3]에 저장해줌\niconst_0으로 0을 스택에 넣고\nistore_4로 0을 LocalArray[4]에 넣고\niload_4로 LocalArray[4]를 다시 스택탑에 넣고\niload_3으로 배열 크기였던 LocalArray[3]을 스택탑에 넣고\nif_icmpge는 cjump같은 조건부 분기문인데 i는 int, cmp는 비교, ge는 greater or equal이라는 뜻\n\n조건에 맞다면 43번 바이트코드로 분기 - return해라 이거야\n\n\n그리고 40번까지 갔다가 다시 goto로 반복문을 도는 구조임\n결과적으로 원본코드는 아래와 같다\n\n\nStack Machine Code - CIL(MSIL) §\n\n마이크로소프트의 C# 중간언어가 CIL(Common Intermediate Language)이다\n뭐 옛날이름은 MSIL이었댄다\n얘도 JVM처럼 CLR(Common Language Runtime)이라는 가상머신에서 작동한다\n근데 JVM과의 차이점은 JVM은 바이트코드를 인터프리트하는 것이 주된 일이지만 CLR에서는 VES라는 놈이 JIT컴파일이라는 과정을 거처 CIL을 기계어로 번역하는게 주된 일이고 가끔씩 인터프리트를 하게 된다\n\n예시 §\n\n\nldloc.0은 지역변수 배열의 첫번째를 스택에 넣으라는 의미\nldloc.1은 지역변수 배열의 두번째를 스택에 넣으라는 의미\nadd를 통해 스택에 있던 두 값을 더함\nstloc.0은 지역변수 배열의 첫번째에 스택 top을 넣으라는 의미\n\n\n\nldstr &quot;&quot;으로 문자열을 스택에 넣음\ncall ~로 스택에 있는 값들을 이용해 함수를 호출함\n.assembly라는 것은 자바에서 모듈처럼 버전 미스매치를 막기 위해 코드와 리소스를 한대 묶어 포장해놓은 것 - 어셈블리 하나는 그 자체로 완성본이어서 버전이 안맞아도 작동되고 다른 의존관계를 갖지 않는다는듯\n\nTree Code §\n\n\n이거처럼 Instruction로 묶일 수 있는 것을 트리로 만든 다음에 Architecture에 따라서 묶어서 Instruction으로 번역하는 셈\n뭔소린가함은\nCPU에서 Move to memory기능의 Instruction 밖에 지원하지 않는다면 MEM과 MOVE를 묶어 해당 Instruction으로 번역하는거고\nMove memory to memory기능의 Instruction을 지원하면 MEM, MOVE, MEM을 묶어 해당 Instruction으로 번역하는 셈\n\nGCC RTL §\n\nGCC의 Tree Code가 RTL(Register Transfer Language) 이다\n\n\n\n맨 아래 코드가 그 위에처럼 번역되고 이건 형태를 S-expression이라고 한댄다\n"},"originals/compiler.fall.2021.cse.cnu.ac.kr/13.-3-Address-code":{"title":"13. 3 Address code","links":[],"tags":[],"content":"\n\n                  \n                  충남대학교 컴퓨터공학과 조은선 교수님의 &quot;컴파일러 개론&quot; 강의를 필기한 내용입니다. \n                  \n                \n\n\n\n                  \n                  다소 잘못된 내용과 구어적 표현 이 포함되어 있을 수 있습니다. \n                  \n                \n\nHIR to LIR §\n\n\n기호 [[ ]] 를 LIR = [[HIR]] 로 정의한다\n이때, [[ ]] 안에는 C언어같은 고급언어 표현식이 들어가고 그의 결과로 LIR이 나오는 연산자인 것\n위 그림에서 보이는 것처럼 t = [[variable]] 은 변수의 값을 주소공간 t에 넣으라는 의미가 된다\n\nExpressions §\nBinary Operation §\n\n\ne = e1 OP e2 에 대해 t = [[e]] 는 t = [[e1 OP e2]] 가 되고 이것은 곧\n\nt1 = [[e1]]\nt2 = [[e2]]\nt = t1 OP t2\n\n\n의 형태로 재귀적으로 연산된다는 것\n\nUnary Operation §\n\n\n마찬가지다\ne1의 값이 [[ ]] 를 통해 재귀적으로 구해지고, 그것을 OP로 연산하게 됨\n\nArray Access §\n\n\nv의 타입이 T이고 T 타입이 차지하는 메모리 크기(sizeof T)를 S라고 할때\n\n\n일단 v의 시작주소를 구해주고\n\nC언어에서는 v가 곧 시작주소를 의미하지만 다른언어는 그렇지 않으니까\n\n\ne의 값은 [[ ]] 로 재귀적으로 구해주고\n재귀적으로 구해준 e에 S를 곱해 offset을 구하고\n시작주소와 offset을 더해 원하는 주소를 구해준 뒤\n결과값을 담을 주소인 t에 load해주면 끝\n\n[] 연산은 C언어에서 dereference와 같다 - * 임\nt = *t4 인 셈인거지\n여기서 주의할 점은 우리 수업에서 t~ 는 임시 공간을 의미하는 것이고 이것이 주소인지 그냥 값인지는 문맥으로 파악해야 된다\n위의 예시에서 t4는 주소값이기 때문에 해당 주소에 있는 값을 t에 저장하게 되는 것\n\n\n\nStructure Access §\n\n\n간단하다\nv의 시작주소를 구하고 structure 내에서 f의 위치(offset)인 S를 더해 load해주면 되는 것\n\nShort-circuit OR §\n\n\nShort-circuit OR 는 C언어의 || 연산을 의미하는 거다\n즉, 앞부분이 참이면 뒷부분을 연산하지 않고 무조건 참을 반환하고 거짓이면 뒷부분의 값을 반환하는 구조\n따라서 앞부분이 참이면 뒷부분이 실행되지 않기 때문에 조심해야된다더라\n어쨋든 이걸 LIR로 바꿔보면\n\n[[e1]] 을 계산한다\ne1 계산값이 참이면 Lend로 점프하고\n거짓이라면 [[e2]] 를 계산해 결과값으로 넣어준다\n\n\n\nShort-circuit AND §\n\nShort-circuit AND 도 C언어에서의 &amp;&amp; 연산을 의미하는거임\n앞부분이 거짓이면 뒤에를 연산하지 않고 결과는 무조건 거짓이고 앞부분이 참이면 뒷부분의 결과가 전체의 결과가 되는 셈\n따라서 t = [[e1 SC-AND e2]] 는 이정도로 번역될 수 있다\n\nt = [[e1]]\nt1 = NEG t\ncjump t1 Lend\nt = [[e2]]\nLend:\n\nStatement §\n\n프언개에서 배운것처럼\n결과로 값이 나오는 것을 Expression이라고 하고\n결과로 상태가 바뀌는 것(변수의 값이 바뀐다던가)을 Statement라고 한다\n\nStatement Sequence §\n\n\n단순하게 이어주면 됨\n\nAssignment §\n\n\n걍 변수에 값을 넣는 것은 당연하게도 위처럼 된다\n\n\n\n배열에 값을 넣는 것은\n위 그림에서 t4까지가 적재될 주소를 찾는 과정이고\nt5 = [[e2]] 로 e2값을 구해서 저장한 뒤\n[t4] = t5로 t4의 위치에 넣게 되는 것\n\nIf then else §\n\n\n보면 이해되긴할건데\n이 트릭은 좀 기억해둘 것 - e의 결과를 반대로 해서 e가 참일때는 cjump를 안하고 e가 거짓일때 cjump를 해서 s의 계산을 건너뛰게 된다는 것\nif-then-else의 경우에도 e가 참일때는 cjump를 안하고 Lthen이 실행된 후 Lend로 점프하고 e가 거짓일때만 Lelse로 cjump를 하게 된다\n\nWhile §\n\n\n이것도 간단하다\n여기서도 결과뒤집기 트릭을 이용한다\n\ne를 계산하여 거짓이면 뒤집어 참이 되므로 cjump에 걸러 Lend로 가고\ne가 참이면 뒤집어 거짓이 되므로 cjump에 걸리지 않아 연산이 됨\n그리고 s를 계산한 후 jump를 이용해 다시 e를 계산하는 것으로 되돌아오는 식\n\n\n\nSwitch §\n\n\nswitch문도 비슷하게\nneq 를 이용해서 같지 않으면 cjump로 다음 것으로 넘어가고 같다면 cjump에 걸리지 않고 아래 문장이 실행되는 구조\n근데 switch문은 Table lookup을 이용해서 구현되기도 한댄다\n\n\n\n얘처럼 Hash Table이 있고 값과 주소가 저장되어있어 매칭되는 값의 주소로 바로 jump하게 되는 구조\nO(1)이어서 좋긴 하나 보안에 취약하고 컴파일러가 최적화하기 어렵다는 일장일단이 있다\n\nFunction call &amp; return §\n\n\n보면 쉬운데\n이건 왜냐하면 call이랑 return이라는 keyword가 있다고 가정하기 때문인 것 - call이랑 return이 구체적으로 어떻게 더 low하게 번역되는지는 나중에 배움\n\nStatement Expression §\n\n이건 말그대로 상태도 바뀌고 결과값도 반환되는 것이다\nBlock statement, If-then-else statement, Assignment statement이 세개에 대해서 Expression화 시킬 수 있다더라\n\n\n\n결과적으로 위처럼 s의 결과가 t에 담기게 됨\n\n\n\n읽어보면 바로 알 수 있다\n이전에는 [[s]] 로 statement를 계산만 했다면, 이제는 그걸 변수 t에 저장\n위의 예시에서 봐야될게\n이전에는 if-then-else 할때 e를 neg로 뒤집어서 거짓일때 cjump에 걸리게 했는데 이번에는 neg를 안써서 참일때 cjump에 걸리게 했다는 차이점이 있다\n이건 Statement expression이라서 이렇게 번역했다기보다는 이렇게 했을때 Instruction 갯수가 하나 줄어드니까 이렇게도 한다는 것을 그냥 보여주기 위한거인듯\n\nNested Expression / Statement §\n\n말그대로 중첩된 Expression을 말한다 - 시험에서 정답을 쓸 때는 [[ ]] 기호가 있으면 안되고 그걸 다 3-Addr-Code로 바꿔야 함\n\n\n\n\n뭐 별 다른 개념은 없고\n팁은 전체적인 큰 구조를 먼저 잡고 분할정복하는게 편하다 - AST에서 제일 최상단에 들어갈만한 놈이 뭔지를 찾고 그 아래의 Subtree를 재귀적으로 찾아가며 더이상 쪼갤 수 없으면 그때 3-Addr-Code로 바꿔보라\n\n\n\n얘네는 이제 변수나 상수를 처리할때 팁 이다\n읽어보면 당연한건데 변수나 상수를 무분별하게 꺼내면 실수할 수 있기 때문에 위와 같은 경우만 변수나 상수를 바로 꺼내는 것으로 연습을 하랜다\n\nStorage Management §\n\n일단 뭐 일겠지만 프로세스의 저장공간에는 Register와 Memory가 있다\nRegister빠르지만 용량이 작고 간접접근(주소이용해서 접근)할 수 없고\nMemory는 느리지만 용량이 크고 간접접근(주소 이용해서 접근)할 수가 있다\n변수를 메모리에 둘 것인지 레지스터에 둘 것인지를 1차적으로 중간언어 생성에서 하게 된댄다\n방법으로는 All Memory Approach하고 Standard Approach가 있는데\n\nAll Memory Approach : 모든 변수를 Memory에 넣고 Register로 올려도 되겠다 싶은것만 올림\nStandard Approach : All Memory Approach에서 레지스터로 올리는 것을 좀 규칙화하면 좋겠다고 해서 나온 것\n\n일단 global, static은 모두 메모리에 들어가고 주소를 이용한 연산이 필요한 변수(구조체나 배열, 혹은 Scalar(일반 변수) 중에서도 주소참조 연산이 있는 경우)도 메모리에 들어감\n그리고 나머지 - 주소참조 연산이 없는 Scalar은 Virtual Register에 들어간다\n여기서 Virtual Register라는 것은 Register는 원래 수량이 한정되어 있고 그 수량은 아키택처에 따라 다르지만 일단 지금은 이런 제한사항을 무시하고 Register가 무한하게 있다고 생각하는 것\n\n\n\n\n\nMemory Organization §\n\n\nCode는 프로그램의 코드가 저장되는 공간 - readonly면 더 빠르댄다\nStatic Data는 Global이나 Static같은 프로그램의 라이프타임과 수명을 같이하는 변수들이 담기는 공간\nStack은 Block Scope가 담기는 공간 - 지역변수들과 함수들이 들어감 - 알다시피 함수가 호출되면 스택에 push되고 리턴되면 pop되는 형식\n\n여기서 중요한점은 위 그림에서 아래쪽이 주소값이 작고 위쪽이 주소값이 크다 - 스택탑의 주소가 줄어드는 것이 스택이 늘어나는 거고 주소가 커지는 방향이 스택이 줄어드는거다\n\n\nHeap은 new나 Malloc처럼 동적으로 메모리를 할당받았을때 저장되는 공간\n\n그리고 뭐 알다시피 스택과 힙이 마주보는 방향으로 되어 있어서 최대크기를 벗어나지 않고 그 안에서 둘이 융통성있게 공간을 땅따먹기하게 된다\n또한 Heap의 영역은 Malloc을 했을때 OS로부터 할당받게 된다 - 컴파일러 마음대로 줄 수 있는게 아니다 이거야\n뭐 알다시피 Malloc과 Free를 항상 짝으로 사용해야 하고 그렇지 않으면 예상치못한 오류가 남 - Garbage Collection을 지원하는 언어를 사용하면 이런것을 방지할 수 있더라\n\n\nCode와 Static Data는 컴파일러에 의해 크기가 결정되고 Stack과 Heap은 프로세스가 진행됨에 따라 크기가 변동되더라\n참고 - 윈도우에는 Windows PE라는 프로그램 포맷이 있고 리눅스에는 ELF라는 프로그램 포맷이 있는데 여기서 Windows PE에는 Mappable Sections에, ELF에는 .text와 .data에 Code하고 Static data가 들어가 된댄다\n그리고 또 알아야 할 것이 이러한 일련의 구조를 정하는 것이 OS가 하는게 아니고 컴파일러가 하는것이다 - OS가 하는 것은 Heap의 공간을 요청했을 때 공간을 할당해주는 것 정도 - 따라서 컴파일을 할때 이러한 구조를 만들고 스택을 늘리고 줄이는 것에 대한 코드를 같이 생성해야 됨 - 뒤에 배운다\n\nEnvironment, Binding §\n\n기억나는지는 모르겠는데\n&lt;변수이름-변수의 주소&gt; 들의 집합을 Environment라고 하고 - 변수의 이름과 그 변수의 주소 간의 관계들이 저장되는 저장소라고 생각\n&lt;변수이름-변수의 값&gt; 들의 집합을 State라고 한다 - 변수의 이름과 그 변수에 담긴 값 간의 관계들이 저장되는 저장소\n그리고 Binding이라는 것은 Environment혹은 State의 원소를 추가한다는 의미를 가질 수 있는데 우리 수업에서는 좀 더 좁은 의미로 Environment에 원소를 추가하는 것을 Binding이라고 함\n\n즉, 어떤 변수와 그 변수의 주소를 매핑시키는 것을 Binding이라고 한다 이거지\n\n\n\nStack Management §\n용어정리 §\n\nActivation Record : 함수가 하나 Call되었을 때 마다 생성되는 하나의 단위. Local variable이 제일 많이 차지하고 Parameter나 Return value, 3-Addr-Code에서 많이 생성되는 임시변수들이 들어간다\nRun time stack : 프로세스가 실행되는 동안의 Activation record를 스택의 형태로 저장하는 공간\n\n당연히 함수가 call되면 Run time stack에 Activation record가 push되고\n함수가 return되면 Run time stack에서 Activation Record가 pop된다\n그리고 Run time stack의 top에는 지금 실행동인 함수의 Activation record가 들어감\n\n\nStack Pointer(SP) : Runtime stack의 top에 있는 Activation record의 top의 주소\nFrame Pointer(FP) : Runtime stack의 top에 있는 Activation record의 base(bottom)의 주소\n\n보통 일반적으로 코딩할때는 스택의 top에 접근할때 걍 integer index등으로 접근했었는데\n여기서는 Activation record들의 크기가 각기 다르기 때문에 이런식으로 index로는 접근할 수 없다\n그래서 Activation Record의 시작주소과 끝주소를 가지고 하나의 스택 원소 위치를 알아내게 되는 것\n이런식의 2포인터 접근을 하면 좋은점이 뭐냐면\n어떤 변수의 주소는 절대주소가 아닌 상대주소를 쓰는데 이때의 기준점이 SP, FP임 - SP로 부터 얼만 떨어져 있는 놈, FP로부터 얼마 떨어져 있는 놈\n따라서 해당 offset의 값이 항상 Activation record의 크기의 절반을 넘지 않기 때문에 더 작은 수를 이용해 주소를 표현하는 것이 가능하더라\n그리고 당연히 SP의 값이 FP의 값보다 작음 - 주소값이 작을수록 더 Top이기 때문\n\n\n\nELF example §\n\n\nELF 포맷은 좀 알아두자\n일단 연두색으로 된 부분이 디스크에 저장되는 부분이다 - 컴파일 후 a.out으로 생성되는 부분이 저부분임\n\n보면 코드랑 초기화되어있는 글로벌변수 들이 디스크에 저장되어있음 - 초기화되어있지 않은 글로벌변수는 굳이 지금 안만들고 프로세스 생성시에 만들게 된다\n그리고 흰색부분이 프로세스가 개시되면 추가적으로 할당받는 부분 이다 = 스택과 탑, 초기화하지 않은 글로벌변수 등이 메모리공간을 할당받게 됨\n\n\nELF에서는 SP, FP라는 용어 대신 esp, ebp라는 용어를 사용함 - ebp에서 bp가 base pointer의 약자인것 생각하면 헷갈리지는 않을듯\n따라서 만약 func가 실행되면 ebp는 esp였던 곳으로 이동하고 esp는 새로운 func의 top을 가리키게 됨\n\nRuntime Stack의 작동과정 §\n\n\n함수를 Call하는 과정\n\nCall할 함수의 parameter들을 전부 스택에 넣는다\n함수가 return되면 돌아가야 할 Instruction의 주소를 넣어준다 - Return address\n새로운 Activation Record를 위한 Stack Frame을 할당받고 - 이 할당받는다는 것이 결국에는 SP를 적절한 위치로 옮기는 것을 의미함\n이전 FP의 값을 Stack frame에 제일 먼저 넣어주고 FP를 이전의 SP로 옮겨준다\nCallee함수의 지역변수들도 넣어주고 (만약에 새로운 함수를 Call했을 경우에) Parameter들도 넣어준다\n\n\n함수를 Return하는 과정\n\n현재의 FP로 SP를 옮겨준다\nPrevious FP를 보고 거기로 FP를 옮겨준다\n\n\n\n\n\n예시 여러번 연습할 것!\nmain에서 g를 호출할때\n\na + b를 넣고\nmain에서 되돌아와야 할 instruction주소를 저장하고\nSP를 적당한 위치로 옮겨주고\n이전의 FP를 넣고\nFP를 이전의 SP로 옮김\n\n\ng에서 f를 호출할 때도 마찬가지고\n뭐 리턴될때도 위에서 말한것과 같은 과정이 일어남\n\n함수 호출 코드 생성하기 §\n\n이전에 함수를 호출할때는 call만 해서 되는게 아니고 더 추가적인 작업이 필요하다는 것과\nheap allocation만 OS가 해주고 나머지는 컴파일러가 알아서 해야되는 거라고 했었자네\n저런 일들을 어떻게 할 것인지 설명함\n\n함수 호출의 자세한 과정 §\n\n\n함수 호출 과정을 자세히 알아보자고\n\nCaller가 할일 : 함수 호출 전에는 parameter하고 return address를 스택에 넣고 Callee의 Instrunction으로 jump하는 코드를 생성함\nCallee가 할 일 : 함수 진입 직전에는 FP와 SP를 옮겨서 스택을 늘리고 이전의 FP와 함수에 사용되는 local variable들을 다 넣음 - 이부분을 Prologue라고 한다\n\n\n그래서 위의 그림에서 초록색 부분이 Prologue에서 생성되는 값인 거임\n\n\n함수 리턴 과정은\n\nCallee가 할 일 : 함수가 리턴되기 직전에는 리턴값을 적절한 위치에 넣고 SP와 FP를 조정하여 해당 frame을 pop하며 저장해놓았던 return instruction address로 jump하는 코드를 생성한다 - 이부분을 Epilogue라고 함\nCaller가 할 일 : 함수 리턴 직후에는 저장해놓았던 리턴값을 사용하는 코드를 생성함\n\n\n그리고 참고로 함수 호출 전의 register값을 저장해놓아야 할 필요가 있는데 Caller가 보관하거나 Callee가 보관하거나 둘이 나눠서 보관하는 방법이 있댄다\n이것도 참고로 알아두셈 - Nested function이 가능한 경우에는 outer function의 frame 위치를 inner function에 저장하게 되고 이걸 Static link 라고 한다. 근데 위처럼 Nested function이 아닌 외부의 함수를 호출하는 경우에는 그냥 이전 함수에서의 FP를 현재의 frame에 저장하고 이걸 Dinamic link 라고 부른댄다\n\n\n\n\n예제를 보자고\n함수 호출 전에\n\n첫번째 인자를 넣어주기 위해 sp가 가리키던 곳에 3을 넣어줌\n\n[sp] = 3 (C언어식으로 번역하면 *sp = 3; 이라고 생각하면 됨)\n\n\n두번째 인자를 넣어주기 위해 첫번째 인자를 넣어준 곳 다음에 5를 넣어줌\n\n[sp - 4] = 5 (즉, *(sp - 4) = 4;)\n\n\nReturn address를 저장\n\n[sp - 8] = return address (즉, *(sp - 8) = retAddress;)\n\n\n인자 두개와 리턴주소가 들어왔으니까 sp를 top으로 재조정해줌 - 4바이트 값 3개가 들어왔으니가 12바이트 아래로 내려가면 되것지\n\nsp = sp - 12 (즉, sp -= 12;)\n\n\n\n\n그리고 프롤로그 실행\n\n일단 이전의 fp를 먼저 넣어줌 - sp가 가르키는 위치에 넣으면 되겠지\n\n[sp] = fp (즉, *sp = fp;)\n\n\nfp를 sp위치까지 내림\n\nfp = sp (즉, fp = sp;)\n\n\n새로운 sp 설정 - 일단 이전의 fp저장한다고 4바이트 사용했고 위의 예제에서는 Local variable이 3개랬으니까 3 * 4 해서 12바이트 더 사용함 = 16바이트 더 내리면 된다\n\nsp = sp - 16 (즉, sp -= 16;)\n\n\n\n\nreturn할 때 에필로그\n\nfp값을 프롤로그에서 저장해놓았던 값으로 복원시킨다\n\nfp = [fp] (즉, fp = *fp;)\n\n\nsp를 다시 올려서 Stack에서 pop한다\n\nsp = sp + 16 (즉, sp += 16;)\n\n\n\n\n함수 호출이 끝난 후\n\n일단 어딘가에 저장해놨던 리턴값을 사용하고\n함수 호출때문에 늘렸던 공간을 다시 복원해준다 - 아까 인자 두개랑 리턴주소 저장하느라 12바이트 늘려놨으니까 다시 복원\n\nsp = sp + 12 (즉, sp += 12;)\n\n\n\n\n\n변수 사용하기 §\n\nFP가 이전의 프레임과 현재의 프레임의 경계에 있기 때문에 양쪽의 값을 다 접근하기에 용이하다\n\n\n\n그래서 FP + n으로 이전의 프레임에 접근해 인자값들을 사용하고 FP - n으로 현재의 프레임에 접근해 지역변수값들을 사용한다\n\n함수 호출 코드 생성 §\n\n\n이게 함수 호출 코드 생성 전 모습임\n왼쪽이 Callee이고 오른쪽이 Caller\n그래서 오른쪽에서 call f(10, 20)을 하면 왼쪽으로 딱 넘어갔다가 돌아오고싶다 이거야\n\n\n\n그래서 이런식으로 코드들이 추가된다\n읽어보면 위에서 했던 내용 그대로임\n\nParameter, register저장하고\nReturn address 저장하고 - 이때 return address는 jump한 직후의 instruction 주소임\nCallee로 jump하고\nPrologue수행해서 이전 FP저장하고 새로 FP, SP옮기고 지역변수 넣어주고\n함수 실행하고\nEpilogue수행해서 리턴값 저장하고 FP, SP다시 롤백시키고 저장해놨던 return address로 jump\n리턴값 사용하고\nSP조정해서 저장해놨던 parameter랑 register 다 달려버리기\n\n\n"},"originals/compiler.fall.2021.cse.cnu.ac.kr/14.-Semantic-Analysis,-Type-Checking":{"title":"14. Semantic Analysis, Type Checking","links":[],"tags":[],"content":"\n\n                  \n                  충남대학교 컴퓨터공학과 조은선 교수님의 &quot;컴파일러 개론&quot; 강의를 필기한 내용입니다. \n                  \n                \n\n\n\n                  \n                  다소 잘못된 내용과 구어적 표현 이 포함되어 있을 수 있습니다. \n                  \n                \n\nSemantic Analysis §\n\nStatic Semantic : 컴파일 단계에서 잡아낼 수 있는 프로그램 문맥 분석\n\n거의 Type checking이랑 같은 의미라고 생각해도 무방하다\n\n\nDynamic Semantic : 런타임 단계에서 잡아낼 수 있는 프로그램 문맥 분석\n여기서 Semantic이란 그냥 프로그램의 Construct들 (변수, 객체, 식, 문장 등) 이 올바르게 사용되었나 확인하는 것\n보통 Scope적인 측면 - 변수의 접근 가능 범위와 Type적인 측면 - Declaration과 Assignment의 자료형이 맞는가를 체크하게 된다\n\nScope §\n\nLifetime하고 Scope은 엄연히 다른것이다\n\nLifetime은 어떤 변수가 존재하는 시간 적인 개념이고\nScope은 어떤 변수에 접근할 수 있는 영역, 공간 적인 개념이다\n\n\nLexical Scope : 이건 Scope의 풀네임이라고 할 수 있는데\n\n문자적(Textual)으로 봤을 때 어떤 변수에 접근할 수 있는 특정 범위 라고 생각하면 됨\n이게 말이 어려워서 그런데\n그냥 Textual이라는 것은 우리가 코드를 눈으로 봤을때 i번째줄에서 k번째 줄까지가 이 변수의 Scope 이라는 것을 알 수 있듯이 말 그대로 코드를 우리가 글읽듯이 읽었을 때 알아낼 수 있는 변수의 범위를 말하는 거다\n\n\n그래서 식별자의 Scope은 그냥 그 식별자 선언을 참조할 수 있는 Lexical scope인 것\n뭔말알?\n참고로 C언어에서 goto는 label이 선언된 scope 내에서만 사용해야된다 - label이 딴데있으면 걸로 가면 안된다 이말이야\n\nSymbol Table §\n\n말그대로 식별자들에 대한 정보들을 Table의 형태로 저장하는 것이다\n\n\n\n위처럼 식별자 이름과 분류(함수, 변수, 인자 등등), 자료형, 여러 속성들(scope지정자, 상수 등등)들을 저장하게 된다\n식별자가 선언될때 저러한 정보들을 테이블에 저장해놓고 의미분석할때 이거 보면서 자료형 체크하거나 코드 생성단계에서 메모리 할당할때도 보면서 얼마나 할당해야할지 알아낸다\n\nHierarchical Symbol Table §\n\n일단 Lexical Scope이 달라지면 참조할 수 있는 식별자의 범위도 당연히 달라지기 때문에 Lexical Scope마다 Symbol Table을 둘 수도 있다\n\n하지만 대부분의 Block-structured language에서 Lexical Scope는 Nested구조, Hierarchical한 구조를 갖는 경우가 대부분이므로 Symbol Table도 이러한 구조로 만들게 된다\n\n\n\n\n\n그래서 위 그림처럼 테이블을 구성하는거임\n\n\n\n이러한 구조에서 식별자를 참조할때는 현재의 Scope에서 상위 Scope으로 올라가며 식별자가 존재하는지 확인하고 없다면 에러를 출력하게 한다\n\nImplementation §\n\n일단 AST가 만들어진 후에 Symbol Table을 만들 수 있다\n\nAST가 Symbol Table의 선행조건인 셈\n\n\n그리고 Symbol Table이 제공해야되는 기능은\n\n식별자가 선언될때 Insert하는 기능이 있어야 할 것이고\n식별자가 참조될때 Lookup - 검색하는 기능이 있어야 하것제\n\n\n실제로 Symbol table을 구현할때는 위에서 본 계층구조를 그대로 본뜨지는 않는다\n\n효율성을 위해서 다르게 함\n일단 식별자의 이름은 식별자 문자열 크기가 가변적이고 관리가 힘들기 때문에 식별자 문자열만을 모아놓는 String pool을 만들어놓고 여기의 한 원소를 참조하는 포인터로 대체한다\n뭐 Table한개에 대해서는 그냥 Hash table을 사용함\n그리고 계층구조를 만들때에는 N-ary tree를 쓸거같지만 실제로는 Stack을 사용한다\n\n생각해보면 Nested구조는 Stack을 통해서 구현될 수 있기 때문\n뭐 옛날에 괄호쌍문제 같은거 풀때도 Stack을 이용했잖여\n프로그램이 실행되는 과정에서도 block이 끝나면 그 scope에 대한 Table은 어차피 필요가 없기 때문에 전체 구조에서 유지시키는게 아니라 버리는게 더 효율적\n\n\n\n\n\n\n\n위 그림 보면 딱 감올거임\n스택에는 Hash Table이 원소로 들어가게 되고\n아래 빨간글씨가 스택의 변화를 보여주고 있다\n그래서 살펴보면 Scope이 열리면 그 Scope에서의 Symbol table이 Stack에 push되고 Scope이 끝나면 pop되게 됨\n{int i, j; … }에서 {int x; l: …}로 코드가 진행될때 스택의 변화를 보면\n어차피 두번째 scope로 가면 첫번째 scope은 참조할 수 없으니까 func f의 자식으로 두는게 아니라 버려버리는 것\nSymbol Table은 코드를 한줄한줄 읽어나가며 생성되고 한번 생성된 뒤에 계속 사용하는게 아니라 분석단계에서 동적으로 생성되면서 분석하게 되는듯\n그래서 위 예제에서 func f scope에서는 g는 Symbol Table에 추가되지 않은 상태인 것이다\n\nImplementation (2) §\n\n근데 실제로는 위와같은 방법도 안쓰고 더 최적화시킨 방법을 사용한다\nStack과 Hash map, Array를 섞어서 구현하게 됨\n\n\n\n위 그림이 저 int x;부분에 있을 때에의 스택과 해쉬맵, 배열의 모습이다\n오른쪽 아래에 각 식별자들의 hash값들이 나와있음\n이걸 이제 차근차근 따라가보자고\nint x, y : x의 hash값은 1이므로 hash table의 1에 array의 index 0이 들어가고 거기에 x에 대한 정보가 담긴다. 마찬가지의 방법으로 y의 hash값은 7이므로 hash table의 7에 array의 index1이 들어가고 거기에 y에 대한 정보가 담기게 된다\nchar name; : 이것도 마찬가지로 흘러감\n\nname의 hash값은 2이므로 hash table의 2에 array의 index 2가 들어가고 array에는 name에 대한 정보들이 들어가게 된다\n\n\nvoid m1() : 마찬가지긴 한데 m1의 hash값이 1인데 이미 hash table의 1에 뭔가가 연결되어있어 충돌 이 나게 됨 - 이때는 새로 들어온놈을 hash table에 적어주고 기존에 있던 놈은 새로 들어온 놈이 가리키게 하는 Linked list방식으로 구현된다\n\n뭐 특별하게 새로운 방법은 아니고 원래 Hash table의 작동방식 그대로 따라가는거임\n따라서 m1이 array의 index 3에 들어가고 hash table의 1에는 array의 index 3이 채워지며 array의 index 3은 index 0을 가르키게 된다\n그래서 옛날놈을 찾을때는 Linked link를 따라가는 방식으로 진행된다\n옛날놈을 찾을때는 hash값을 보고 Hash table로 간 뒤에 그게 가리키는 곳을 갔다가 내가 찾는놈이 아니라는 걸 깨닫고 그놈이랑 연결된 놈으로 가서 내가 찾는놈이 맞나를 반복하는 것\n만일 위의 예제에서 x를 찾을 때는 먼저 hash 1을 통해 array index 3으로 갔다가 그놈이 m1이기 때문에 array index 0으로 이동해 x를 찾게 되는 것\n\n\n{ : 여기서 새로운 Scope이 시작되게 된다 - 새로운 Scope가 시작될때는 Stack에 새로운 Scope에 대한 정보들이 담길 array의 index가 push된다\n\n이전에 배웠던 Stack Frame 이랑 동일한 방식으로 작동하는거임 - 스택에 frame이 담기는게 아니고 frame의 시작지점이 담기는 방식\n따라서 이제 새로운 scope가 시작되었고 array의 index 4부터 저장될꺼니까 Stack에 4가 들어가 Stack top에 대한 frame이 array index 4부터 시작된다는 것을 저장 하게 됨\n\n\n(int ind) : 이건 뭐 이전에 하던거랑 똑같다 - array index 4에 드가고 hash값이 4니까 hash 4번칸에 index 4가 채워지게 되는 것\nint x; : 이번에도 충돌이 나기 때문에 원래 있던놈을 치우고 새로운게 들어간 뒤 새로운놈이 원래 있던놈을 가리키게 한다\n\n근데 여기서 신기한 것은 Global과 Local의 식별자 이름과 타입 등이 같으면 Global은 Shadowing되고 Local에만 접근할 수 있는 기능이 자동으로 구현된다는 것을 알 수 있다\n왜나면 Hash를 통해서 Linked list를 타고 가면서 만나게 되는 식별자 선언의 순서가 최근에 선언된 순서대로 방문하기 때문\n따라서 제일 먼저 같은 이름과 타입 등을 가진 놈이 찾아지기 때문에 제일 최근에 선언된 놈이 선택되고, 따라서 오래전에 선언된 Global은 선택되지 않게 된다\n\n\n\n\n\n위 그림은 Scope가 끝났을때를 보여주는 그림이다\nScope가 끝났을때는 그냥 Stack에서 pop만 해주면 되는게 아니고 연결관계를 다 정리해줘야 한다\n즉, Frame이 pop되며 무효화되는 array의 index들을 Hash table에서 가리키지 않게 조정해주는 작업이 필요함\nArray에서 다른 array index를 가리키지 않는 경우에는 그냥 hash table에서의 값을 nullptr로 바꿔주면 되고\nArray의 index에서 다른 array index를 가리키는 경우에는 가리키는 array index가 Stack top의 frame에 들어올때까지 재귀적으로 index를 타고 가다 Stack top frame에 들어오면 그것의 index를 hash table에서의 값으로 넣어주는 과정을 거침\n그래서 위의 예제에서는 어케되는가\n우선 array index 4번에 있던 ind의 경우에는 그놈 하나만 달랑 있기 때문에 hash 4에 저장되어있는 것을 array index 4가 아니라 nullptr로 바꿔준다\n이제 array index 5번에 저장되어있던 x의 경우에는 hash 1에 저장되어있는 것을 nullptr가 아니라 x가 가리키고있던 array index 3로 바꿔주게 된다 - array index 3은 Stack top frame에 들어오기 때문에 더이상 재귀적으로 array index를 찾지 않고 3을 hash 1에 넣어줌\n뭐 나머지 m2에 대해서는 위에서의 진행방식 동일하게 진행됨\n\nType §\n\n뭐 아는것처럼 Type은 어떤 변수같은애들이 가지게 되는 값 에 대한 설명이다\n뭐 Predicate하기도 하다네 - 가질 수 있는 값의 범위가 제한되니까\n그래서 Type Error는 값을 부적절하게 사용했을때를 말하는거고\nType Error가 없을때를 타입 안정성이라고 하는데\n\nType Binding - 타입 선언 - 을 하고\nType Checking - 타입 체크 - 를 해서 타입 안정성을 보장한댄다\n\nType Checking을 할때는 타입 규칙 - 뭐 int끼리 더한값은 int가 된다 같은거 - 를 세운 뒤 이것에 대해 검사하는 방식으로 진행된다네\n\n\n\n\n\nStatic &amp; Dynamic §\n\nChecking : 타입 검사 시점 에 대한 것\n\nStatic Checking은 컴파일시점에 타입 검사\nDynamic Checking은 런타임에 타입 검사\n\n\nTyping : 타입 정의 시점 에 대한 것\n\nStatic Typing : 컴파일 전에 타입이 모두 정의되어있어야 함\nDynamic Typing : 런타임에 타입이 정의될 수 있음\nChecking과 Typing의 차이점에 대해서는 별로 생각하지 마라 - 정의만 다르고 실질적으로는 비슷한 의미임\n\n\nStrong Typing : 타입 오류를 엄격하게 방지하는 언어\nWeak Typing : 타입 오류를 어느정도 허용하는 언어\nSound Type System : 모든 타입 오류를 방지하도록 하는 시스템이나 타입 규칙이 잘 정의된 것\n\nType Expression §\n\n기본 타입 - int, float, char등등\n타입 표현식\n\n배열 : T[]\n구조체(객체) : {id: T … }\n포인터 : T*\n함수 : T x T1 x … -&gt; Tret\n\n\n\n타입 규칙 §\n\n뻔한얘기긴 한데\n뭐 int와 float의 덧셈은 int형이어야 한다 이런 타입끼리의 연산의 결과가 뭐가 된다는 것에 대한 규칙들을 타입 규칙이라고 함\n\nType judgement §\n\n뭔가 타입얘기가 나오면서 여기 나오는 표현들이 타입스크립트랑 비슷하다는것을 느꼈을거임\n아마 타입에 대한 이론적인 부분에서의 표현법을 타입스크립트에서 차용했기때문이 아닐까\n타입에 대해 명시하는 표현법도 타입스크립트에서 하던거 생각하면 된다 - Expression : Type의 방식으로 명시함\n그리고 강의듣다보면 unit이라는게 나오는데\n이건 Expression이 아니라 Statement여서 값으로써 계산결과가 나오지는 않지만 이것을 계산하는 동안에는 타입오류가 일어나지는 않을때 unit이라고 표현한다\n\nType Checking §\n\n여기서는 너가 프언개시간에 지겹도록 그려댄 Proof Tree를 사용한다\n그리고 이걸 그리면서 또 프언개시간에 많이 써본 기호가 나오는데\nㅏ 기호이다\n\n\n\n그래서 위의 Proof Tree가 자명하고 규칙만 주어진다면 그릴수 있을거같으면 된거임\n\n\n\n위의 그림은 Assignment에 대한 타입 규칙 예시이고\n\n\n\n위 그림은 if-else에 대한 타입 규칙 예시이다\n물론 예시이긴하지만 많은 언어들이 차용하고있는 보편적인 규칙들이니까 읽어보도록\n그리고 위의 예시에서 else가 없는 if문이면 거짓일 경우에 어떠한 값으로 계산된다고 말할 수 없기 때문에 else가 없는 if문은 unit이 되는 것\n\nControl Flow Analysis §\n\nSemantic Analysis에서는 Scope나 Type check외에 Control Flow Analysis도 수행하는데 이것은\nbreak이나 continue같은 애들이 올바른 위치(예를들면 반복문 안)에 들어가있는지, goto의 label이 접근할 수 있는 scope에 존재하는지 등을 검사하는 것이다\nAST를 따라가다보면 어렵게 않게 알아낼 수 있는 것들을 분석하는 것\n"},"originals/compiler.fall.2021.cse.cnu.ac.kr/15.-Machine-Dependent-Processing":{"title":"15. Machine Dependent Processing","links":[],"tags":[],"content":"\n\n                  \n                  충남대학교 컴퓨터공학과 조은선 교수님의 &quot;컴파일러 개론&quot; 강의를 필기한 내용입니다. \n                  \n                \n\n\n\n                  \n                  다소 잘못된 내용과 구어적 표현 이 포함되어 있을 수 있습니다. \n                  \n                \n\n컴파일러 후반부 §\n\n\n컴파일러 후반부는 일단 Acritecture를 신경쓰지 않고 최적화를 하는 Machine-indepentent Optimization를 하고\n그 다음부터는 Architecture에 대해 신경쓰는 Machine Dependent Processing을 하게 된다더라\n\nInstruction Selection §\n\nInstuction Selection은 트리 형태의 Low-level IR을 보고 트리의 노드 몇개를 묶어 Machine Instruction으로 변환하는 단계이다\n\n근데 Architecture마다 Instruction이 다르기 때문에 해당 Architecture에서 지원하는 Instruction을 활용해서 최대한 효율적인 Instruction을 선택하는 것이 중요한 것\n이따가 예시 보면 알 수 있다\n\n\n\n(from tiger book) Tree-IR §\n\n뭐 Tiger book 이라는 곳에서 소개하는 트리 형태의 IR로 수업에서 설명을 하는데\n\n공간에 접근하거나 공간에서 가져오기 §\n\nMEM(e) : 포인터 연산(Reference)\n\n그냥 C언어에서 * 연산자라고 똑같이 사용하면 됨\n즉, 메모리 주소에서 값을 가져오거나 메모리 주소에 값을 넣는 연산\n\n\nTEMP(t) : 뭐 레지스터에 대한 Reference연산이라고 생각하면 됨\n\n할당(Assign) §\n\nMOVE(dst, src)\n\n오른쪽 자식을 왼쪽 자식에 넣는 명령어\n그냥 C에서의 = 연산자로 바꿔서 생각하면 된다\n근데 중요한 것은 Low-level IR에서는 변수나 그딴게 없기 때문에 dst에 무조건 포인터나 레지스터 연산 드가야 한다는 것이다\n즉, MOVE의 왼쪽 자식은 MEM이나 TEMP가 드가야된다는 소리임\n따라서 MOVE(MEM(e_dst), MEM(e_src)) 이 코드는 다음과 같다\n\n\ne_dst = *e_src\n근데 C언어에서도 * 연산자를 =의 왼쪽에 사용하면 그 포인터가 가르키는 곳에 넣으라는 의미가 되고(Store) 오른쪽에 사용하면 그 포인터가 가르키는 것을 가져오라는 의미(Fetch)가 되듯이\nMOVE의 왼쪽 자식으로 MEM이 드가면 그 포인터가 가르키는 곳에 값을 넣는 의미가 되고 오른쪽 자식에 들어가게 되면 그 포인터가 가르키는 곳에서 값을 가져오라는 의미가 되는 것\n\nStatement §\n\nSEQ(s1, s2)는 Statement 1을 실행하고 그 상태에서 Statement 2를 실행하라는 의미\nESEQ(s, e)는 Statement를 실행하고 그 상태에서 Expression을 계산하라는 의미\n따라서 SEQ의 경우에는 결과값이 나오지 않고 상태만 바뀌지만 ESEQ는 상태가 바뀌고 그 바뀐 상태에서의 결과값이 나오는 것\n\nBinary Operation, Const §\n\nBINOP(o, e1, e2) : e1 결과값과 e2결과값을 o에 따라서 연산하겠다는 것\n\n헷갈리지말어라 - 세 자식중에 중간에 opcode가 드가는게 아니고 첫번째에 opcode가 드가게 된다\n\n\nCONST(i) : 정수 상수 i\n\n동치관계 §\n\n트리가 다르게 생겨도 같은 일을 하는 동치관계가 존재하고 이걸 이용해서 더 효율적인 트리를 선택할 수 있고 이런식으로 Optimization을 하게 된다\n\n\n\n딱 읽어보면 동치라는걸 알 수 있을거\n\n\n\n이것도 동치인데\n이건 왼쪽의 트리를 선택하는 경우가 종종 있다 - 저 레지스터에 담긴 값을 자주 써야되는 경우 트리가 좀 복잡해도 그걸 선택하기도 함\n\n\n\n이건 조건부 동치임\n\n왼쪽과 중간의 트리는 s를 수행함으로 변경되는 상태가 e1에 영향을 준다면 동치가 아니지만 영향을 주지 않는다면 동치가 되는 것\n당연히 중간과 오른쪽은 동치이다\n\n\n\nInstruction Selection §\n\n\n그래서 이런 Low-level IR Tree에서 Node들을 모아 하나의 Instruction으로 묶게 되는데\n왼쪽의 경우에는 Memory-to-Memory STORE를 지원하지 않기 때문에 MOVE와 왼쪽 자식만 묶고 오른쪽 자식은 또 따로 묶어서 Instruction을 구성했다면\n오른쪽의 경우에는 Memory-to-Memory STORE를 지원해서 MOVE와 두 자식까지 묶어서 instruction을 구성하게 된 것\nMemory-to-Memory STORE를 지원하면 이걸 쓰는게 더 효율적이랜다\n\nRegister Allocation §\n\n옛날에 Low-level IR에서는 레지스터가 무한히 있다고 가정하고 레지스터를 막 가져다가 썼었는데\n이제는 레지스터의 갯수가 한정되어있기 때문에 각각의 가상 레지스터를 실제 레지스터에 할당해주는 작업이 필요하고\n이것은 일단 레지스터에 넣을 수 있는때까지 넣고 안되면 Memory로 내리게 된다\n그래서 일단 처리속도를 최대로 하기 위해 자주 사용되는것들을 Physical register에 매핑하고\n레지스터가 부족해 Memory로 내리는 것을 Spilling이라고 한다\n\nGraph Coloring §\n\n일단 이 문제가 지도에 색칠하는 문제와 비슷하다는 것을 이해해야됨\n\n\n\n봐봐라\n일단 Live Range라는 것을 알아야 됨 - 이건 어떤 변수가 사용되는(살아있는) 기간(범위)이라고 생각하면 된다\n\n그래서 위의 예시의 왼쪽 코드에 대해 각각의 Live Range 를 구해본 것이 오른쪽이다\n변수 a의 경우에는 0번에서 선언 되고 5번에서 마지막으로 사용되었으므로 Live range가 0~5가 되는거고\n변수 b의 경우에는 2번에서 선언되고 3번에서 마지막으로 사용되니까 Live range가 2~3이 되며\n변수 c의 경우에는 4번에서 선언되고 5번에서 마지막으로 사용되기 때문에 Live range가 4~5가 되는 것\n실제로 컴퓨터에서 Live range를 어떻게 구하는지는 몰라도 된다\n\n\n그리고 Interference라는 것은 두 변수의 Live range가 겹치는 경우에 Interference가 있다고 한다\n그래서 각 변수를 Node에 적고 Interference관계를 Edge로 표현하면 하나의 그래프가 만들어지고 이 그래프에 대해 Graph coloring을 하면 되는 것이다\n\n위 그림에서 가운데 그래프가 그거임\n이제 좀 왜 레지스터 할당이 그래프 색칠문제로 변환되는지 알것제?\n\n그래프에서 인접노드는 Live range가 겹치기 때문에 하나의 레지스터에 할당하면 안됨\n따라서 인접노드에 대해서는 다른 레지스터에 할당했을때 필요한 레지스터의 갯수를 최소화시켜야만 제한된 레지스터에 최대한 많은 변수를 넣을 수 있게 되는 것\n\n\n\n\n\nKempe’s Algorithm §\n\n그래프 색칠하기 문제에서 굉장히 오래되었고 그만큼 많이 쓰이는 알고리즘임\n정답이 존재해도 그 정답을 도출해내지 못하는 경우가 있지만 쉽기때문에 컴파일러에서도 쓰인다\n\nStep 1 - Simplify §\n\n만약 색깔이 k개로 한정되어 있다면 그래프에서 k - 1개의 Edge를 갖는 노드들을 Stack에 넣어준다\n그래서 과정은 다음과 같음\n\n일단 k - 1개의 Edge를 가지는 Node들 중 하나를 Stack에 Push함\n그리고 Stack에 들어간 Node와 연결된 Edge는 없다고 생각하고 다시 k - 1개의 Edge를 갖는 Node들 중 하나를 골라 Stack에 Push하는 과정을 더이상 드갈게 없을때까지 반복힌디\n\n\n\n\n\n예시임\n여기서 2개의 색으로만 칠한다 했을때\n첫번째에서 Edge가 1개인 노드는 c, d, e이고 이중 하나인 c를 넣는다\n그리고 c-a Edge를 제외하고 다시 Edge가 1개인 노드를 다 구해보면 a, d, e이고 이중에 하나인 e를 넣는다\nb-e Edge를 제외하고 Edge가 1개인 노드는 a, d이고 이중에 a를 넣는다\na-b Edge를 제외하고 Edge가 1개인 노드는 b, d이고 이중에 b를 넣는다\nNode가 하나밖에 안남았으므로 Step 1이 종료됨\n\nStep 2 - Coloring §\n\n남아있는 노드를 칠하고\n스택에서 하나씩 꺼내면서 인접한 노드와 다른색깔로 칠해주면 됨\n\n\n\n위 그림 보면 알 수 있을거임 - Stack에서 하나씩 꺼내면서 색깔을 칠해준다\n\nSpilling §\n\n위에서도 말했듯이 Kempe’s Algorithm을 사용하면 해가 있음에도 해결하지 못하는 경우가 생기긴 한다\n\n\n\n이거 보면 d를 Stack에 넣은 뒤에 모든 Node의 Edge가 2개이기 때문에 더이상 진행하지 못하지만 위 그림처럼 정답이 존재한다 - 뭐 이런 해를 구하지 못하는 경우에는 어케하는지 설명 안했으니까 고민하지마셈\n\n\n\n그리고 위처럼 해가 아예 없는 경우도 있음\n이럴때는 레지스터에 넣지 않고 메모리로 내리는 Spilling을 진행한다\nSpilling을 할때는 새로운 Live range가 아주 짧은 새로운 Virtual Register를 도입해 명령을 재작성하는데 과정은 다음과 같음\n\n일단 어떤 Virtual Register를 Spilling할건지 정함\n그리고 해당 Virtual Register를 메모리의 한 공간과 연결한다\n해당 Virtual Register가 등장하는 부분 바로 위에 할당된 메모리 공간에 있던 값을 임시 레지스터로 옮기는 코드를 추가하고\n임시 레지스터를 이용해 Instruction을 수행하도록 코드를 바꾼다\n\n\n예시를 보면 좀 더 이해가 될거임\n\n\n\n일단 t2를 Spilling하기로 정했고\nt2를 메모리의(Stack frame의) 한 공간인 [ebp - 24] 와 연결해줌\n그리고 임시 레지스터인 t35를 도입해 t2를 사용하는 Instruction직전에 mov t35, [ebp - 24]를 한다\n마지막으로 t2대신 t35를 Instruction에서 사용하도록 바꿔줌\n\n\nInterference나는 Virtual register를 해결하기 위해 또 다른 Virtaul Register를 도입하는게 약간 이상하지만\n보면 이렇게 새로 도입한 Virtual Register는 Live range가 한두줄밖에 안되기 때문에 아주 짧음 - 이렇게 바꾸고 Kempe’s Algorithm으로 색칠해보면 Interference가 거의 나지 않는다\n\nInstruction Scheduling §\n\n일단 이것을 해야하는 이유는\n어떤 Instruction이 끝나야 다음 Instruction이 실행되야 하는 경우가 아니라면 두개의 Instruction을 1사이클 차이로 실행시킬 수 있기 때문\n따라서 어떤 Instruction을 실행시키기 위해 앞선 Instruction이 종료되는 것을 기다리느라 CPU 가 놀고있는 걸 Stall이라고 하는데\n이러한 Stall 등의 비효율을 줄이기 위해 Instruction을 재배치 하는 것을 Instruction Scheduling이라고 함\n\n\n\n그래서 위의 예시를 보면\n1, 5, 9, 13사이클에서 실행되는 LOAD의 경우 Dependency가 없기 때문에 바로 실행이 가능한데 중간중간에 Dependency가 있는 Instruction이 포함되어 있어 그만큼 지연되는 것을 볼 수 있음\n따라서 왼쪽처럼 Dependency가 없는 몇개의 Instruction을 처음에 다 돌려놓음으로 Stall을 줄일 수 있더라\n\nChanllenges §\n\n근데 당연하게도 이건 쉬운일이 아님\n일단 당연하게도 동일한 동작을 하는 코드로 바꿔야 되고\n최적화하는 것이기 때문에 Wasting time을 줄여서 최종적으로 걸리는 시간이 줄어야 하고\nRegister Spilling을 되도록이면 피해야 함 - Memory 접근은 비용이 큰 연산이기 때문\n\nInstruction을 옮겼을때 use-def의 길이가 길어져서 Life range가 늘어날 수 있기 때문에 Interference가 일어날 확률이 늘어남 - 이러한 위험부담을 항상 고려해야 한다\n\n\n\nScheduling의 종류 §\n\nStatic Scheduling : 컴파일 타임에 스케줄링하는 것\n\nLocal Basic Scheduling : 반복문이나 분기문이 없는 하나의 Block 내에서 스케줄링하는 것\nLoop Scheduling : 반복문이 들어간 상황에서 스케줄링하는 것\nGlobal Scheduling : 전체적으로 스케줄링하는 것\n\n\nDynamic Scheduling : 런타임에 스케줄링하는 것\n\nList Scheduling §\n\nLocal Basic Scheduling의 하나로 Instruction을 Heuristic을 이용해 Greedy하게 선택하는 방법\n간단하게 설명하면 Dependency Graph(Precedence Graph)를 만들고 Topological sorting을 하되 선행노드가 없는애들중에 하나를 고를때는 Heuristic을 기준으로 Greedy하게 선택하는 방법\n\nDependency Graph(Precedence Graph) 만들기 §\n\n\n뭐 이거 그리는건 어렵지 않음\n그냥 의존관계 고려해서 그려주면 된다\n\nHeuristic Priority 산출 §\n\n\nList Scheduling을 할 때는 Latency를 Heuristic으로 둔다\n이걸 어떻게 구하냐면 맨 마지막 Instruction부터 시작해 위로 올라가면서 각 Instruction에 걸리는 시간을 누적해주면 됨\n위 예시를 보면서 해보자고\n\n일단 마지막인 i를 할때는 이놈이 3이 걸리다고 가정했을때 Latency는 3이 됨\n그리고 그 위의 h의 경우에는 이놈이 2가 걸린다고 가정하면 이놈을 하고 i까지 하려면 2 + 3으로 5이 걸린다 - 이게 Latency가 되는 것\ng의 경우에 3이 걸리고, f의 경우에 2가 걸린다면 각각의 경우에 i까지 마무으리하려면 h의 Latency인 5에다가 2, 3을 각각 누적해 f의 경우에는 7이 되고 g의 경우에는 8이 되는 것\n이런식으로 Precedence Graph의 모든 노드에 대해 Latency를 기준으로 Heuristic을 구해준다\n\n\n\nReady-operation Priority Queue만들어서 진행 §\n\n\n그래서 이제 바로 실행 가능한 Instruction들을 Heuristic을 기준으로 하는 Priority Queue에 넣고(얘를 Ready-operation Priority Queue라고 하드라) 하나씩 빼면서 정렬해주면 되는 것\n위 예시를 보면\n\n일단 {a, c, e, g}가 들어가게 될거임\n제일 우선순위가 높은놈 고르면 당연히 a가 골라지겠지\n그럼 그놈을 지우고 바로 실행 가능해진놈을 큐에 넣음 - b가 들어가고 {c, e, b, g}가 된다 - 우선순위가 같을때는 뭐가 먼저 오든 상관없음\n그리고 c가 top에 있으니까 c을 빼고 실행가능해진놈을 넣음 - 아무것도 없으니까 바로 다음으로 진행\n그 다음은 e가 top에 있으니까 e를 빼고 실행하능해진놈을 넣음 - 이번에도 실행가능해진놈은 아무것도 없음\n이런식으로 계속 진행해서 Topological sorting을 하게 된다\n\n\n\n기타 Optimization §\n\nOptimization에는 Scheduling말고 딴게 더 있는데\nArchitecture에서 지원해주는 다양한 기능을 이용한다던지\n\n뭐 예를들면 1 더하는 기능을 inc라는 걸로 지원해서 1더할때는 add를 사용하는것보다 inc를 사용하는 것이 더 좋다거나 - 특수목적의 명령어\njump address만을 위한 레지스터를 제공한다거나 - 특수목적의 레지스터\n\n\n아니면 Register간 mov를 줄일수도 있다\n\n레지스터간 mov는 어차피 같은값을 가지니까 기존의 레지스터를 계속 사용하는 식으로 mov를 제거\n근데 이건 Live range가 늘어날 가능성이 있으므로 주의해야된다\n\n\n아니면 중복된 LOAD를 제거할 수도 있음\n\n\n\n뭐 위처럼 store을 한 다음에는 r1에 여전히 x의 값이 남아있기 때문에 굳이 다시 load해주지 않고 바로 사용할 수 있다\n"},"originals/compiler.fall.2021.cse.cnu.ac.kr/16.-Analysis-&-Optimization":{"title":"16. Analysis & Optimization","links":[],"tags":[],"content":"\n\n                  \n                  충남대학교 컴퓨터공학과 조은선 교수님의 &quot;컴파일러 개론&quot; 강의를 필기한 내용입니다. \n                  \n                \n\n\n\n                  \n                  다소 잘못된 내용과 구어적 표현 이 포함되어 있을 수 있습니다. \n                  \n                \n\nAnalysis &amp; Optimization §\n\n최적화(Optimization) 은 동등한 동작을 수행하되 실행시간이 짧거나 저장공간을 적게 먹는 코드로 바꾸는 것을 의미함\n최적화는 당연히 Instruction의 수를 줄이거나 Cycle이 더 적은 Instruction을 사용하는 방법으로 진행되는데\n최적화에서 가장 중요한 것이 최적화 이후에도 동일하게 동작해야 하는것 이기 때문에 분석(Analysis) 을 통해 동일하게 동작하는지를 확인하게 된다\n\nControl Flow §\n\nControl Flow는 프로그램이 수행되는 순서를 말하는건데\n그냥 Program Counter가 1씩 증가하며 Instruction이 쭉 실행되는 경우에는 별로 분석할게 없다\n중요한건 분기(Branch) 로 프로그램의 다른 부분으로 점프하는 흐름에 관한 것이 Control Flow 인 것\nDynamic Control Flow 는 Input값이 주어진 상태에서의 프로그램 실행 순서라고 생각하면 된다\n\nInput값을 알기 때문에 어디로 분기할지 알 수 있고, Control Flow를 보다 정확하게 예측할 수 있음\nInput값이 다르게 들어오면 다르게 실행되므로 Dynamic이 붙는 것\n\n\nStatic Control Flow는 Input 값을 모르는 상태에서의 프로그램 실행 순서를 말하는거다\n\n따라서 Input을 모르기 때문에 정확한 예측은 불가능하고 Worst Case를 생각해서 예측하게 된댄다\n컴파일 단계에 하게 된다는 듯\n\n\n\nStatic Property, CFA §\n\n일단 Static Property는 프로그램 분기 방향과 무관하게 도출되는 성질을 의미한다\n그리고 CFA(Control Flow Analysis) 는\n\n먼저 CFG(Control Flow Graph) 라는 것을 만든다\n이건 프로그램이 어떻게 분기될 수 있는지의 경우의 수를 그래프 형태로 나타낸 것\n그리고 이걸 만든 후에 Static Property를 도출하고\n코드를 최적화 하는 것이 목적인 분석이다\n\n\n\nBasic Block(BB) §\n\nBasic Block(BB) 는 분기 없이 한번에 쭉 실행되는 Instruction 모음이라고 생각하면 됨\n뭐 동일한 실행 조건(Execution Condition) 을 적용받는 Instruction 모음이라고도 표현하는데\n\n이말은 BB의 첫번째 Instruction이 실행된다면 마지막까지 무조건 실행된다는 뜻이다\n\n\n따라서 다음의 조건을 만족하는 Instruction 묶음을 BB라고 한다\n\n일단 BB의 시작은 무조건 첫번째 Instruction이다 - 다른곳에서 분기되어 들어와 BB의 중간에서 갑자기 실행되면 안됨\n그리고 BB의 끝은 무조건 마지막 Instruction이고 이거 외에는 분기가 없다 - 말그대로 BB의 중간에서 갑자기 다른데로 분기하면 안됨\n\n\nBB를 구하는 방법은 간단하다\n\n우선 Leader를 구해야 됨 - 이건 BB의 첫번째 Instruction을 의미하는 거임\n\nLeader를 구하는 방법도 간단함\n프로그램의 시작 Instruction은 무조건 Leader겠제\n그리고 분기해서 도착하는 Instruction도 Leader가 된다 - 분기해서 도착했으니까 거기서부터 시작이 되겠지\n마지막으로 분기문의 바로 아래에 있는 Instruction도 Leader이다\n왜냐하면 이전의 기억을 더듬어보면 특정한 조건일때 분기하고 그 조건에 안맞으면 그냥 다음 Instruction이 실행되게 하는 방식으로 두 갈래를 나누기 때문\n\n\n이렇게 Leader를 다 구하고 한 Leader에 대해 다음 Leader이전까지의 부분이 하나의 BB가 되는 것\n\n\n\n\n\n위 예시에서 보면\n일단 L1이 프로그램의 시작지점이니까 Leader가 되고\nL2하고 L10이 분기되어 도착하는 곳이니까 이곳도 Leader가 된다\n또한 분기문의 직후인 L4, L7, L8도 Leader임\n따라서 BB를 묶어보면 L1-L1, L2-L3, L4-L6, L7-L7, L8-L9, L10-L11이 됨\n\nControl Flow Graph(CFG) §\n\nBB를 노드로 하고 그것들의 실행 순서를 화살표 Edge로 연결한 그래프를 일컫는 말임\n모든 BB가 노드가 되고 여기에 시작지점과 끝나는 지점을 나타내는 가상의 노드인 Entry Node와 Exit Node를 붙인다\n\n당연히 가상의 노드이기 때문에 프로그램상에는 표현되지 않음\n\n\n\n\n\n위의 예시 BB대로 그린 CFG의 예시임\n물론 여기에는 Entry Node와 Exit Node가 표현되어있지 않지만 그냥 보통 그런 Node들을 붙인다는거지 무조건 붙여야되는건 아니다\n일단 무조건 분기하는 부분이 없으니까 모든 BB들을 다 이어주고\nL3에서 L10으로 분기하니까 L3가 속한 BB2에서 L10이 속한 BB6으로 Edge가 연결된다\n마찬가지로 L6에서 L2로 분기하니까 BB3에서 BB2로 Edge가 연결되어있고\nL7에서 L10으로 분기하니까 BB4에서 BB6으로 Edge가 연결되어 있는 것\n\nWeighted CFG §\n\nProfiling이라는 것이 있는데 얘는 프로그램을 몇번 돌려보고 여러가지 통계를 내는 것이다\n\nEdge Profile : 각 Edge들을 몇번 지나치는지\nBlock Profile : 각 BB들을 몇번 지나치는지\nPath Profile : Edge들과 BB들로 구성된 CFG의 일부분을 몇번이나 지나치는지\n\n\n그래서 이런 다양한 Profile들을 그래프에 같이 적은게 Weighted CFG이다\n보통 최적화를 하다 보면 분기하는 상황에서 한쪽을 최적화하면 다른 한쪽이 안좋아지는 Trade-off가 일어나기도 하는데 이때 빈도수에 따라서 Optimize하면 더 좋겠제\n\nOptimization §\nAcyclic Code Optimization §\n\n반복문이 없는 코드에서의 최적화\n하나의 BB내에서 최적화 하는 Inner Basic Block Optimization하고\nBB간의 관계를 보며 넘나들며 최적화 하는 것을 Inter Basic Block Optimization이 있다\n\nInner Basic Block Optimization §\n1. Common Subexpression Elimination §\n\n\n공통된 연산을 여러번 하는 경우 한번만 하고 그걸 갖다쓰기만 하는 것\n\n2. Algebraic Simplication §\n\n\n수학적인 대수법칙을 이용해 식을 간소화하는 것\n뭐 0을 더하는거나 1을 곱하는 등의 의미없는 연산을 다 죽인다던가\n위 그림처럼 대입법칙을 적용했을때 식이 간소화되는 경우\n\n3. Strength Redution §\n\n같은 의미를 가지지만 연산의 비용이 작은것으로 바꾸는 것\n예를들어서 제곱연산의 경우에는 b^2보다는 b*b가 더 낫고\n2나 3정도의 작은 수를 곱하는 경우는 두세번 더하는 것으로 바꾸거나\n나눗셈의 경우 비용이 크므로 5로 나누는 등의 유한소수를 곱하는 것으로 해결되는 것이나 2의 지수를 나누는 것을 bit shift로 바꾸는 등의 최적화\n\n4. Constant folding, Propagation §\n\n\n일단 Propagation은 고정된 값을 갖는 변수를 상수로 바꿔주는 것을 의미하고\nFolding은 Propagation한 뒤에 수식이 상수간의 연산으로 바뀌었다면 그걸 계산해서 그것 또한 상수로 바꿔주는 것\n그리고 Folding을 한 뒤에도 또 다른 수식이 상수간의 연산으로 바뀔 수 있으므로 이것을 반복해주게 된다\n근데 주의할것은 Propagation / Folding 을 할때 그 값이 추후에 바뀌지 않는 상수라는 것이 보장이 되어있어야 한다 - 바뀌는 경우에는 상수로 치환하는 것이 좋지 않으므로\n\nInter Basic Block Optimization §\n\n일단 여기서도 Inner Basic Block에서 사용했던 최적화 기법들을 적용시킬 수 있다\n\n1. Global Common Subexpression Elimination §\n\n\nBB간에 걸쳐서 동일한 연산을 반복해서 하면 한번만 하고 가져다 쓰는 식으로 바꾸는 것\n근데 Inner Basic Block Optimization에서와는 달리 Global Common Subexpression Elimination에서는 기존의 변수를 그대로 갖다 쓰는게 아니고 공통연산을 담을 임시변수를 하나 더 마련한다\n그냥 갖다 쓰게 되면 해당 BB에서 값이 바뀌면 다른 BB에도 영향을 끼치기 때문\n\n2. Global Constant Folding / Propagation §\n\n\n이것도 Inner Basic Block Optimization에서처럼 고정된 값을 가지는 변수를 상수로 치환하고(Propagation), 치환 후 상수간의 연산또한 그의 결과를 상수로 박아놓는것(Folding)\n위의 예제에서도 1 → 2로 갈때 x와 y가 모두 상수값을 가지므로 t의 x와 y를 전부 상수로 치환하고\n2 → 3으로 갈때는 상수간의 연산도 그냥 계산해서 상수로 때려박되 그 아래부분이 2 == 2로 항상 참이 되어 분기가 일어나지 않기 때문에 분기를 지워버리는 방식의 Folding 이 일어난다\n그리고 Inner Basic Block Optimization에서의 최적화 기법 외의 최적화도 있는데\nBranch의 숫자를 최대한 줄이는게 좋다 - Branch의 경우에는 Program Counter나 Next Program Counter등의 레지스터에 저장되는 값을 새로 초기화하는 등의 새로운 Pipeline이 형성되기 때문에 비용이 많이 드는 연산이기 때문\n따라서 BB들을 합쳐서 더 크게 만들거나 분기를 지워 코드의 길이를 줄인다거나의 최적화가 이루어짐\n\n3. Branch to Unconditional Branch §\n\n\n위 그림처럼 분기해서 조착한 지점이 무조건 분기인 경우에는 굳이 그 지점으로 분기할게 아니라 무조건 분기했을때의 지점으로 한번에 가게 만들어주는 방법이다\n그리고 이렇게 바꾸고 나서 무조건분기문의 위치로 분기하는 경우가 없다면 해당 Instruction을 지워버림\n\n4. Unconditional Branch to Branch §\n\n\n이건 반대로 무조건 분기를 해서 도착한 부분이 분기문일 경우에 무조건 분기하는 지점이 무조건 분기일 필요가 없다\n따라서 이러한 경우에 무조건 분기를 조건 분기로 바꿔주고 기존의 조건 분기문은 그쪽으로 분기하는 경우가 없다면 그놈을 지워버리게 되며 기존의 조건분기문 바로 아랫줄은 조건이 맞지 않을 경우 실행되어야 하므로 기존의 무조건 분기문 아래에 무조건 분기를 넣어서 해당 지점으로 뛰도록최적화가 가능함\n이게 말로 설명하니까 좀 장황한데 위 예시 보면 알 수 있음\nL1에서는 L2로 무조건 뛰는데 L2가 조건분기이기 때문에 L1에서 바로 조건분기를 해버리면 된다\n그리고 L2 아래 L4는 원래 L2에 있던 조건분기문에 걸리지 않았을 경우 도달하는 지점인데 이제 그 조건분기문이 L1로 옮겨졌기 때문에 L1의 조건분기에 걸리지 않았을 경우 L4로 움직이게 해줘야 됨 - 따라서 L1아래에 goto가 들어가게 된 것이다\n마지막으로 이렇게 바꾸고 L2로 분기하는 경우가 없다면 L2는 필요가 없어지므로 걍 지워버려도 되는 것\n\n5. Branch to next BB, BB Merging §\n\n\nBranch to next BB는 분기의 도착점이 바로 다음 Instruction일 경우 분기할 필요가 없으므로 해당 분기문을 지워버리는 것을 의미하고\nBB Merging의 경우에는 BB의 Leader가 다른 BB에서 분기해서 들어오는 경우가 없다면 그냥 위의 BB와 합쳐버리는 것을 뜻함\nBranch to next BB를 통해 분기문을 지워버리고 난 후에 다음 등장하는 BB의 Leader로 아무도 분기하지 않는다면 Basic Block Merging으로 그냥 두개의 BB를 합쳐버리게 된다\n\n6. Branch to Same Target §\n\n\n조건분기를 하나 안하나 동일한 지점으로 점프하는 경우 조건분기를 무조건 분기로 바꿔벌임\n\n7. Branch Target Expansion §\n\n\n얘는 분기를 한 후 간단한 동작이 이루어지면 걍 그걸 분기하지 않고 그자리에서 해버리고 분기 도착지점으로 아무도 분기하지않게 되면 그걸 지워버리는 것이다\n\n8. Unreachable Code Elimination §\n\n위에서 계속 아무도 그곳으로 분기하지 않으면 그냥 그곳을 지워버린다고 했는데 Unreachable Code Elimination이 그거임\n이건 Garbage Collection의 방법하고 유사하다 - 일단 전부 1로 체크해놓고 쭉 돌면서 방문한 곳은 0으로 바꾼 후 여전히 1로 남아있는 부분을 지움\n\nLoop Optimization §\n\n일단 여기에도 위에서 배운 각종 Optimization을 적용할 수 있다\n그리고 Loop의 Block은 여러번 실행되기 때문에, Optimization하는 것이 다른 Block들 보다 더 효과가 크게 나타난다\n위에서 소개한 Optimization말고 Loop만의 Optimization을 소개해보면\n\n1. Loop Unrolling §\n\n\n위 예시처럼 한번에 초기화를 두개씩 하는 코드로 바꾸면 반복횟수를 반타작낼 수 있다\n이건 Loop body를 펼쳐서(코드를 추가해서?) 반복횟수를 줄일 수 있으면 줄이는 방법이다\n\n2. Loop Invariant §\n\n\nLoop을 돌면서 변하지 않는 값들 - Loop invariant - 들은 반복문 돌기 전에 연산하고 끌고들어오는 방식으로 동일한 값을 반복해서 계산하지 않도록 수정하는 방법\n이것처럼 비용이 많이들지만 항상 연산결과가 동일한 cos와 sin을 밖에서 계산한 후 반복문 안에서 사용하도록 할 수 있다.\n\n3. Count up to zero §\n\n\n보통 왼쪽과 같은 방법으로 for문을 짜는데\nfor문의 경우에 종료조건을 비교할때 큰지 작은지를 비교하는게 아니라 n을 뺀 다음 0이랑 비교하는 식으로 컴파일됨\n따라서 처음부터 0이랑 비교하는 식으로 코드를 적으면 빼는 과정이 들어가지 않아 좀 더 최적화할 수 있댄다\n근데 요즘은 뭐 최적화 기술이 좋아져서 별차이 없다는듯\n\nData Flow Analysis §\n\n일단 Data Flow Analysis는 프로그램내의 Data(보통 변수) 들이 생성되고 소멸되는 것을 추적하고 정보를 모으는 것을 의미한다\n이걸 하는 이유는\n위에서 Common Subexpression Elimination을 할때 공통된 연산을 진짜 하나의 변수로 퉁쳐도 되는지 - flow마다 다른 값이 연산에 사용된다면 하나로 묶으면 안되기 때문에\n아니면 Registaer Allocation을 할때 서로 다른 Virtual Register를 Actual Register에 할당해도 되는지 - Live range를 구할때 Data flow를 보고 Virtual Register에 할당되는 variable definition이 언제 생성되고 언제 죽는지를 알 수 있음\n이건 Control Flow에서의 CFG를 활용함 - 각 BB에서 생성되거나 죽거나 들어오거나 나가는 Data들을 CFG에 추가적으로 적어주는 식으로 진행된다\n이번 학기에는 Reaching Definition Analysis만 배운다\n\nReaching Definition Analysis(RDef) §\n\n이건 말 그대로임 - Definition이라는 것은 변수의 선언을 의미하는 거고 따라서 RDef라는 것은 해당 선언이 다른 Point까지 도달하는지 아니면 그 전에 죽어버리는지를 분석하는것\n여기서 Point라는 것은 그냥 한 Instruction Line이라고 생각해도 된다\n그리고 Kill이라는 것은 CFG의 Path중 하나를 따라가는 과정에서 변수가 재선언되어 앞선 선언이 Shadowing되는 것을 의미한다고 생각하면 된다\n\n\n\n그래서 간단한 예제를 보면\n일단 위의 그림에서 보이는것처럼 모든 Definition에는 저렇게 ID를 붙이고 시작한다\n편의상 위의 그림에서 BB를 위에서부터 BB0, BB1, BB2 라고 부르면\nBB0에서 생성된 1, 2번 Definition은 BB0 → BB1 Path를 따라올때는 당연히 BB2에 도달한다\n근데 BB0에서 생성된 2번 Definition은 BB0 → BB1 → BB2 Path를 따라올때는 BB1에서 4번 Definition에 의해 죽어버린다 - 따라서 해당 Path의 도착지점에 도달하는 Definition은 1, 3, 4밖에 없는 것\n그리고 BB2를 진행하는 과정에서 5번 Definition이 2, 4번을 Kill하기 때문에 BB2를 빠져나가는 지점에서는 살아있는 Definition이 1, 3, 5, 6밖에 없는 것\n\nGEN, KILL, IN, OUT §\n\n이제 컴퓨터가 이걸 추적하는 과정은 GEN, KILL, IN, OUT네개의 집합을 연산하면서 진행된다\n\n1. GEN, KILL §\n\n\nGEN은 말그대로 변수가 Definition되는 것이고 해당 BB에서의 Definition ID를 그대로 적어주면 된다\n\n위의 예시에서 봐도 해당 BB에서의 GEN집합은 BB에 존재하는 Definition 들의 집합과 동일히디는 것을 알 수 있음\n\n\n그리고 KILL은 한 BB내에서 변수가 Define되어서 Shadowing되는 다른 Definition들을 적어주면 된다\n\n여기서 중요한것은 CFG에서의 선후관계(Edge)는 무시하고 그냥 자기가 아닌 모든 BB에서의 Definition들을 봐야 한다는 것이다\n이건 왜냐하면 코드에서는 Loop도 있는 등 BB의 진행순서를 명확하게 파악하기 어려운 경우가 많음 - 그냥 모든 BB가 자기보다 먼서 수행됐다고 가정하고 KILL되는 Definition을 찾는 것이다\n그래서 첫번째 BB를 보면 Def1에 의해 Def4, Def9, Def11이 Kill되는거고 Def2에 의해 Def7이 Kill되며 Def3에 의해 Def5, Def12가 Kill되는 것을 알 수 있음\n\n\n근데 조심해야될것은 같은 BB내에서도 Kill되는 경우 또한 존재한다는 것 - Kill되는 Definition을 찾을때 다른 BB에 있는 거만 보지 말고 같은 BB내에서도 Kill되는지 확인해야 한다\n\n2. IN, OUT §\n\n\nIN은 Predecessor BB의 모든 OUT을 합집합해주면 된다\n\nPredecessor BB가 없으면 당연히 공집합임\n뭐 수식으로 표현하면 PredO1 U PredO2 U … PredOn정도임\n\n\n그리고 OUT은 IN에서 KILL을 차집합해주고 GEN을 합집합해주면 된다\n\n이것도 수식으로 표현하면 GEN U (IN - KILL)이 됨\n\n\n근데 보면 IN을 계산할때 다른놈의 OUT이 필요하다는 것을 알 수 있음\n\n근데 그 다른놈의 OUT을 구해줄때도 그놈의 IN이 필요하고 따라서 또 다른놈의 OUT이 필요한 상황이 생기게 된다\n\n\n그래서 IN, OUT을 구할때는 일단 모든놈의 IN, OUT을 공집합으로 해준 뒤 모든 BB의 IN, OUT을 구해주면 되는데 이 과정에서 어떤 BB의 OUT이 변경되면 또다시 모든 BB의 IN, OUT을 계산하는 것을 모든 BB의 OUT이 더이상 변하지 않을때까지 수행 해주게 된다\n\n\n\nPseudo Code를 보면 위와 같은데\n뭐 IN, OUT구하는 공식은 별거 없고\n저기서 if old_OUT != OUT(X) then change = 1부분에서 OUT이 변경되었으면 플래그를 1로 바꿔 while(change) do로 인해 OUT이 더이상 바뀌지 않을때까지 수행해주는 것을 알 수 있다\n"},"originals/datacommunication.spring.2021.cse.cnu.ac.kr/(충남대)-데이터-통신-강의록":{"title":"(충남대) 데이터 통신 강의록","links":["originals/datacommunication.spring.2021.cse.cnu.ac.kr/01.-Bitrate","originals/datacommunication.spring.2021.cse.cnu.ac.kr/02.-D2D,-A2D-Conversion","originals/datacommunication.spring.2021.cse.cnu.ac.kr/03.-D2A,-A2A-Conversion","originals/datacommunication.spring.2021.cse.cnu.ac.kr/04.-Bandwidth-Utilization","originals/datacommunication.spring.2021.cse.cnu.ac.kr/05.-Data-Link-Control","originals/datacommunication.spring.2021.cse.cnu.ac.kr/06.-ARQ-Protocol,-HDLC","originals/datacommunication.spring.2021.cse.cnu.ac.kr/07.-MAC","originals/datacommunication.spring.2021.cse.cnu.ac.kr/08.-Ethernet","originals/datacommunication.spring.2021.cse.cnu.ac.kr/09.-Wireless-LAN-(1)","originals/datacommunication.spring.2021.cse.cnu.ac.kr/10.-Wireless-LAN-(2)","originals/datacommunication.spring.2021.cse.cnu.ac.kr/11.-Layer-Architecture","originals/datacommunication.spring.2021.cse.cnu.ac.kr/12.-Network-Layer,-Routing","originals/datacommunication.spring.2021.cse.cnu.ac.kr/13.-Routing","originals/datacommunication.spring.2021.cse.cnu.ac.kr/부록---실습자료-1)-MAC,-ARQ","originals/datacommunication.spring.2021.cse.cnu.ac.kr/부록---실습자료-2)-Peer-2-Peer-process","originals/datacommunication.spring.2021.cse.cnu.ac.kr/부록---실습자료-3)-단편화","originals/datacommunication.spring.2021.cse.cnu.ac.kr/부록---실습자료-4)-프로토콜","originals/datacommunication.spring.2021.cse.cnu.ac.kr/부록---시험대비)-싱하형배-데이터통신-모의고사","originals/datacommunication.spring.2021.cse.cnu.ac.kr/부록---시험대비)-싱하형배-데이터통신-모의고사-정답"],"tags":[],"content":"개요 §\n강의 정보 §\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n강의 구분소속교수시기학부 수업충남대학교 공과대학 컴퓨터공학과김상하 교수님2021년 봄학기\n목차 §\n\n01. Bitrate\n02. D2D, A2D Conversion\n03. D2A, A2A Conversion\n04. Bandwidth Utilization\n05. Data Link Control\n06. ARQ Protocol, HDLC\n07. MAC\n08. Ethernet\n09. Wireless LAN (1)\n10. Wireless LAN (2)\n11. Layer Architecture\n12. Network Layer, Routing\n13. Routing\n부록 - 실습자료 1) MAC, ARQ\n부록 - 실습자료 2) Peer 2 Peer process\n부록 - 실습자료 3) 단편화\n부록 - 실습자료 4) 프로토콜\n부록 - 시험대비) 싱하형배 데이터통신 모의고사\n부록 - 시험대비) 싱하형배 데이터통신 모의고사 정답\n"},"originals/datacommunication.spring.2021.cse.cnu.ac.kr/01.-Bitrate":{"title":"01. Bitrate","links":[],"tags":[],"content":"\n\n                  \n                  충남대학교 컴퓨터공학과 김상하 교수님의 &quot;데이터 통신&quot; 강의를 필기한 내용입니다. \n                  \n                \n\n\n\n                  \n                  다소 잘못된 내용과 구어적 표현 이 포함되어 있을 수 있습니다. \n                  \n                \n\n그래프 용어정리 §\n\nData : 보내고자 하는 내용\nSignal : Data를 보내는 방식\nAnalog : 자연적이고 연속적인거\nDigital : 인공적이고 이산적인거(0/1로 이루어진 것)\nPeriod : 신호가 반복되는 주기\nFriquency : 단위시간당 몇번 반복되는지(주기의 역수)\nAmplitude : 진폭\nPhase : 위상 - 달의 위상(moon phase)을 생각하면 쉬움 - 특정시간에의 모양(신호에서는 값)\n\n주파수-진폭 그래프 분석 §\n\n\n시간-진폭 그래프는 신호세기의 시간에 따른 추이이므로 그래프가 끊김없는 모양새로 나온다\n하지만 주파수-진폭 그래프는 해당 주파수를 갖고있는 신호의 세기를 나타내므로 단일 주파수의 신호의 경우 막대기 하나로만 나오게 된다\n12p 신호를 주파수별로 구성요소로 나눠서 분석할 때\n\n12p 의 신호는 13p 의 세 색깔의 신호가 합성되어 나타난 결과인데\n시간-진폭 그래프로 분석하면 13p 의 위 그래프처럼 비교적 복잡하고 한눈에 알아보기 힘들게 분석이 되지만\n주파수-진폭 그래프로 분석하면 13p 의 아래 그래프처럼 단순하게 분석을 할 수 있다\n\n\n주파수-진폭 그래프는 신호를 분석하는 또 하나의 툴이 될 수 있다는 것이다\n\n대역폭(Bandwidth) §\n\n어떤 복합 신호의 주파수별 구성요소를 분석했을 때 가장 큰 주파수를 가지는 요소하고 가장 작은 주파수를 가지는 요소의 주파수 차이를 대역폭이라고 한다.\n\n디지털 신호 §\n\n\n디지털 데이터의 경우 0과 1만의 값을 가질 수 있지만 그것을 보내는 방식인 디지털 신호는 그 세기가 반드시 0과 1이어야 하는 것은 아니다\n두 비트를 묶어 00 01 10 11 즉, 0 1 2 3의 세기로 신호를 보낼 수도 있고 더 많이 묶어 더 많은 비트를 한번에 보낼 수 있다 - 이렇게 묶는 것을 encoding 이라고 한다\n이때 묶은 하나의 단위를 signal element라고 하고\n하나의 signal element가 가질 수 있는 신호의 세기 범위를 Level이라고 한다\n신호가 초당 몇개의 signal element를 송출하는지를 baud rate라고 한다\nbit rate는 초당 송출되는 비트의 수를 말하며 단위로는 bps(bits per second)\nLevel이 클수록, baud rate가 클수록 bit rate도 커지게 된다\n\nImpairment - 데이터의 손상 §\n\nAttenuation : 신호의 감도가 낮아지는 손상(단위 : dB = 전송측과 수신측의 세기 비율*상수)\nDistortion : 신호의 형태가 변화하는 것 - 예) 넓은 대역폭의 신호를 장거리로 쏘게 되면 진동수 간의 전송 속도 차이가 있기 때문에 신호 구성요소들의 위상이 변해 다른 형태의 신호로 수신될 수 있다\nNoise : 기타 잡음(단위 : SNR = Signal/Noise Ratio 신호세기 평균과 노이즈 세기 평균의 비율. SNR이 클 수록 왜곡없이 수신하는것이 용이해진다)\n\nBit rate 상한선 구하기 §\n\nBit rate는 무조건 빠를수록 좋다. 전송속도가 빠르다는 뜻이기 때문이다\n하지만 안타깝게도 bit rate는 상한선이 존재한다. 내맘대로 올릴 수 있는 게 아니라는 뜻이다\n\nShannon Capacity §\n\n\nShannon capacity공식은 우리에게 bitrate의 상한선을 정해준다\nShannon capacity는 노이즈가 존재하는 실생활에서의 bit rate 상한선을 추정할 수 있게 해주는 공식이다\n\nBandwidth : 내가 맘대로 설정할 수 있는게 아니고 신호가 전달되는 매개체에 따라 달라진다. 많은 사람들이 이용하는 매개체일 경우(대표적으로 공기) 여러 국제적 약속에 따라 내가 사용할 수 있는 주파수의 영역은 한정될 수 밖에 없다. 즉, 내가 정하는 값이 아닌 나에게 주어지는 값이라는 소리다. 대역폭을 늘리기 위해서는 더 넓은 대역폭을 수용할 수 있는 매개체를 발굴해낸다던가 더 넓은 주파수 대역을 할당받는 수 밖에 없다.\nSNR : 신호의 세기를 무한정 세게 할 수도 없고 노이즈의 세기를 내 맘대로 조절할 수 있는 것도 아니다. 따라서 이 값도 내가 정하는 값이 아닌 나에게 주어지는 값이란 소리다\n\n\n이 두 소식을 종합해보면 Shannon capacity에 의해 결정되는 bitrate의 상한선은 내가 바꾸고싶다고 쉽게 바꿀 수 있는 값이 아닌 어느정도 나에게 주어진, 정해진 값이라는 소리다\n\nNyquist Bit rate §\n\n\n일단 Nyquist bitrate는 노이즈가 없는 가상공간에서 적용되는 공식이고\nShannon capacity를 통해 내가 이용할 수 있는 최대 bitrate을 알았다면 이것을 Nyquist공식에 대입해 encode방식을 알아낼 수 있다\n즉, BitRate는 Shannon공식을 통해 알아내고, Bandwidth는 주어지는 값이기에 L을 알아낼 수 있다는 것\n그리고 L을 알아내면 몇개의 비트를 묶어 하나의 signal element를 구성해야되는지 알 수 있기 때문에 encoding방식을 결정할 수 있는 것이다\n"},"originals/datacommunication.spring.2021.cse.cnu.ac.kr/02.-D2D,-A2D-Conversion":{"title":"02. D2D, A2D Conversion","links":[],"tags":[],"content":"\n\n                  \n                  충남대학교 컴퓨터공학과 김상하 교수님의 &quot;데이터 통신&quot; 강의를 필기한 내용입니다. \n                  \n                \n\n\n\n                  \n                  다소 잘못된 내용과 구어적 표현 이 포함되어 있을 수 있습니다. \n                  \n                \n\nD2D, A2D §\n\n통신이 이루어지는 순서를 보면\nAnalog Data → Digital Data → Analog Signal 혹은 Digital Signal → Digital Data → Analog Data\n의 순서로 이루어진다\nDigital Data → Digital Signal의 변환을 Digital To Digital Conversion이라고 하고\nAnalog Signal → Digital Signal로의 변환을 Analog To Digital Conversion이라고 한다\n\nDigital To Digital Conversion §\nSynchronization의 중요성 §\n\n\n신호는 bit들을 매우 빠른 속도로 송출하기 때문에 송신자와 수신자 간의 Synchronization이 맞지 않으면 신호가 정확하게 전달되지 않아 해석과정에서 다른 데이터를 얻게 된다\n위의 예제를 보면 뭔소린지 알 수 있다 - 같은 신호를 수신했지만 baud rate를 다르게 나눠 다르게 신호가 해석된 것을 알 수 있다\n따라서 이렇게 baud rate를 동일하게 가져가 signal element 한칸의 시간을 동일하게 만들어 의도한대로 해석되게끔 하는 것이 Synchronization이다\nDigital data를 그대로 보내지 않고 굳이 Digital signal로 변환하여 전송하는 이유가 Synchronization을 맞춰주기 위해서이다\n\nConversion Algorithm §\n\n딴건 다 몰라도 되고 Manchester Scheme이랑 Block Coding만 좀 알아두면 된다\n\nManchester scheme §\n\n\n이 알고리즘은 단순히 신호의 세기로 0과 1을 판단하는게 아닌 세기의 변화에 집중한다\nManchester Scheme 알고리즘은 신호가 떨어지면 0으로, 신호가 강해지면 1로 판명하는 구조이다 - 첫번째 그림\n얘가 Line Coding의 한 종류라는 것 정도는 알아두자\n근데 저기 보면 00이 수신된 경우 한번 내려주고 또 내려야되는 상황이 되는데 이것을 위해 한번 내린 뒤 또 올렸다가 다시 내리는 것을 볼 수 있다\n그리고 11인 경우에도 마찬가지의 일이 벌어진다 - 한번 올려주고 또 올려주기 위해 내렸다가 올리게 된다\n근데 이것은 오해의 여지가 있다 - 00인 경우에는 다시 내리기 위해 올려주는 건데 이것을 1로 판단하는 경우가 있을 수도 있고 11인 경우에도 다시 올리기 위해 내려주는건데 이것을 0으로 판단할 여지가 있다\n따라서 파형을 보고 대략적으로 시간을 나눠주긴 한다 - 위의 예제에서 처음에 0이어서 한번 떨어졌다가 1이어서 다시 올라가기까지의 중간지점이 하나의 bit가 끝나는 지점이라고 생각하고 그 시간간격으로 나눠서 신호가 떨어지는지 아닌지를 가지고 0과 1을 판단하는 것\n하지만 비트 하나를 보내기 위해 두개의 signal element가 필요하므로 제일 bitrate가 느리다는 단점이 존재한다\n15p의 biphase scheme에 바로 이 방식이 포함된다\n보면 나머지는 다 n이 b의 배수인데 비해 biphase는 n=b로 매우 느리다\n따라서 요즘에는 별로 쓰이지 않는 기법이란다\n\nBlock coding concept §\n\n비트를 m개로 묶은 데이터를 전송하려고 할 때 이것보다 비트를 n개로 묶어서 전송할때 더 동기화 등에서의 이점이 있다면 이것을 n개로 묶어서 전송한 후 수신 후에 다시 m개로 묶는 것이 더 효율적일 것이다 - 이런 기법이 Block coding 기법이다\nmB/nB encoding이 m비트 데이터를 n비트로 변환한다는 뜻이다\n\n\n\n23p에서 NRZ-I line coding scheme으로 신호를 전송하기 위해서는 5B를 이용하는 것이 더 효율적이기 때문에 4B데이터를 5B데이터로 전환해 전송하고 수신하는 과정을 보여준 것이다 - 24p가 변환 테이블이며 이 4B/5B encoding은 자주 사용되는 특별한 알고리즘이다 - 이정도만 알아두면 될듯\n\nAnalog To Digital Conversion §\n\n아날로그 데이터를 디지털 데이터로 바꾸는 것\n\nPCM encoder §\n\n\nSampling : 일정한 시간 간격으로 잘라 세기를 측정하는 것\n\nsampling rate - 초당 몇개의 시간 간격으로 자르는지\n간격당 신호의 세기를 PAM이라고 하는듯\n\n\nQuantization &amp; encoding : sampling 된 결과를 정수값으로 변환하는 과정\n\n\n\nNormalized PAM Values : 일정한 값(D)으로 나눠서 값들의 편차를 줄인다\n\n일단 결과론적으로 값들을 5로 나누면 저 Normalized PAM Value가 나온다\n이 5라는 도대체 어디서 나온 것이냐\n일단 우리는 쟤네들을 3비트로 표현하고 싶기 때문에 8개의 등급으로 나눠야 되고\n그리고 PAM최댓값이 약 20이므로 -20~20이면 모든 PAM값들이 포함되므로\n40을 8로 나눈 5를 PAM들에다 나눠주면 -4~4의 범위 안에 값들이 다 들어오게 된다\n이렇게 PAM / {(PAM 절대값의 최대값) * 2 / 2^비트수} 를 해줘 PAM값들의 분포 범위를 줄이는 작업을 뜻한다\n\n\nNormalized Quantized Values : normalize한 값을 일정한 기준으로 반올림하여 모든 값을 기준에 맞춘다\n\n위 예제에서는 결과가 x.5가 되도록 반올림을 해준거다\n\n\nNormalized Error는 Normalized 값과 Quantized 값과의 차이를 의미함\nQuantization Code가 normalized quantized value에 3비트 숫자를 할당한 것이고 그것을 3비트로 변환한 것이 Encoded Words이다\n더 많은 비트로 표현해 구간을 더 세밀하게 만들수록 데이터의 양은 커지지만 더 정확하게 값을 디지털로 표현할 수 있게 된다\n"},"originals/datacommunication.spring.2021.cse.cnu.ac.kr/03.-D2A,-A2A-Conversion":{"title":"03. D2A, A2A Conversion","links":[],"tags":[],"content":"\n\n                  \n                  충남대학교 컴퓨터공학과 김상하 교수님의 &quot;데이터 통신&quot; 강의를 필기한 내용입니다. \n                  \n                \n\n\n\n                  \n                  다소 잘못된 내용과 구어적 표현 이 포함되어 있을 수 있습니다. \n                  \n                \n\nWireless communication §\n\n무선통신의 경우 digital의 형태로는 보내기 힘들어서 보통 analog한 형태로 보내게 된다\n그래서 디지털 → 아날로그 로 변환하여 전송한 후 아날로그 → 디지털로 다시 고쳐서 정보를 받아오게 된다\n\nDigital To Analog Conversion §\n\nDigital Data를 Analog Signal로 변조하는 방법이다\n\nBinary Amplitude Shift Keying(BASK) §\n\n\n사인파같은 아날로그 신호의 진폭을 0과 1을 다르게 해서 아날로그 형태로 디지털 데이터를 전송하는 것\n0과 1을 구분하기 때문에 Binary\n진폭을 건들기 때문에 Amplitude Shift인 것이다\n\nBinary Frequency Shift Keying(BFSK) §\n\n\n이번에는 진폭을 건드는게 아니라 주파수를 건드려서 0과 1을 나누는 기법\n0과 1을 구분하기 때문에 Bianry\n주파수를 건들기 때문에 Frequency Shift인 것이다\n\nBinary Phase Shift Keying(BPSK) §\n\n\n이번에는 신호의 위상을 180도 바꿔서 0과 1을 나누는 기법\n0과 1을 구분하기 때문에 Binary\n위상을 건들기 때문에 Phase Shift인 것이다\n\nQuadrature Phase Shift Keying(QPSK) §\n\n\n위상을 바꾸되 BPSK처럼 위상을 180도씩 바꿔서 0과 1만을 표현하는게 아니고 위상을 90도씩 바꿔서 00, 01, 10, 11을 표현하는 것이다\n위의 예제에서는 첫번째 비트에 대한 0과 1을 표현이 위의 그림이고\n두번째 비트에 대한 0과 1의 표현이 아래의 그림이다\n첫번째 비트가 1일때를 기준으로 0일때는 이것의 180도 회전\n그리고 두번째 비트의 1은 기준에서 90도 회전하고 0일때는 여기서 180도 회전\n따라서 합성해보면 맨 아래의 녹색그래프처럼 나오게 되는 것이다\n00, 01, 10, 11 네개를 표현하므로 Quadrature\n위상을 바꾸므로 Phase Shift인 것\n\nQuadrature Amplitude Modulation(QAM) §\n\n이건 ASK와 PSK를 모두 사용하는 방법이다\n자세히 설명 안함\n\nConstellation Diagram §\n\n\n얘는 Phasor와 유사한 표현법이다\n원점으로부터 떨어진 거리 = 진폭, x축으로부터의 각도 = 위상으로 표현한다\n저 diagram에 찍히는 점이 많을수록 더 많은 비트를 한번에 보내므로 더 빠르다\n\n표현 예시 §\n\n\nBASK의 경우에는 진폭만을 이용하여 구분하므로 1일 경우에는 진폭이 존재하고 0일때는 진폭이 없는 것으로 표현 가능하고\nBPSK의 경우에는 위상을 이용해 구분하므로 진폭은 같지만 1일때는 0도의 위상, 0일때는 180의 위상을 갖게 된다\nQPSK의 경우에는 저렇게 진폭은 같고 90도의 위상차만 보이며 표현되게 된다\n\n\n\nQAM의 경우에는 각각의 좌표가 위상이나 진폭 둘중 하나는 다르기 때문에 그것을 이용해 각각의 Level을 구분하는 것\n\nAnalog To Analog Conversion §\n\n얘는 Analog Data를 Analog Signal로 바꾸는 방법인데\n걍 간단하게만 알아두면 된다\n\nAmplitude Modulation §\n\n\n진폭을 data의 세기에 따라 결정되게 하는 것\n\nFrequency Modulation §\n\n\n주파수를 data의 세기에 따라 결정되게 하는 것\n\nPhase Modulation §\n\n\n그림만 보면 잘 모르겠긴한데 위상을 data의 세기에 따라 결정되게 하는 것\n"},"originals/datacommunication.spring.2021.cse.cnu.ac.kr/04.-Bandwidth-Utilization":{"title":"04. Bandwidth Utilization","links":[],"tags":[],"content":"\n\n                  \n                  충남대학교 컴퓨터공학과 김상하 교수님의 &quot;데이터 통신&quot; 강의를 필기한 내용입니다. \n                  \n                \n\n\n\n                  \n                  다소 잘못된 내용과 구어적 표현 이 포함되어 있을 수 있습니다. \n                  \n                \n\nBandwidth Utilization §\n\n대역폭이 넓을수록 전송속도가 빨라지기 때문에 넓은 대역폭을 현명하게 활용하는 것이 중요하당\n대역폭을 현명하게 활용하는 방법이 Bandwidth Utilization이며 여기에는 아래의 두가지 방법이 있다\nMultiplexing : 효율성에 조금 더 중점을 둠\nSpreading : 보안에 조금 더 중점을 둠\n\nMultiplexing §\n\n전송속도가 빠른 전송매개체가 있는데 그정도의 전송속도를 필요로 하지 않는 데이터하나만 주고받는다면 너무 비효율적이다\n그래서 이러한 데이터들을 여러개를 섞어서 빠른 대역폭의 매개체로 보낸 다음 수신할때 다 분리하는 방법\n대신 서로 간섭하지 않고 나중에 분리해 낼때 문제가 생기지 않게 합성하는 것이 중요하다\n이렇게 간섭없이 합성하는 방법에는\n\nFDM(Frequency-Division Multiplexing) 과\nTDM(Time-Division Multiplexing) 이 있다\n\n\n\nFrequency-Division Multiplexing §\n\nFrequency-Division Multiplexing : 얘는 큰 대역폭의 캐리어를 잘게 나눠 작은 대역폭의 신호 여러개를 보내는 방법이다\n\n\n\n큰 대역폭을 가진 매개체(트렁크라고 부르더라)에서 주파수 범위를 여러개로 쪼갠 다음 나뉘어진 대역폭(각각을 Channel이라고 부른다)에 신호를 하나씩 실어 보내는 방법\n이 신호들는 하나로 합성되어 전송되지만 수신측에서 주파수 별로 분리하는 필터를 이용해 분리해내면 하나의 채널만 분리해서 수신할 수가 있다 - 이렇게 ::분리하는 것을 Demodulate혹은 Demultiplex라고 한다\n\n\n\n대역폭이 4인 세 신호를 20-24, 24-28, 28-32의 주파수 범위에 합쳐서 보내면 이 합쳐진 트렁크의 대역폭은 12이므로 더 빠르게 전송할 수 있다. 그리고 이때의 20, 24, 28을 세 신호의 Carrier Frequency라고 부른다. 이 carrier frequecy를 가지로 신호를 분리해 낼 때는 합성신호를 주파수 4씩 세개로 분리한 다음 carrier frequency를 각각 빼주면 원래의 신호가 나오게 되는 것이다\n\n\n\n크기가 1mb인 데이터를 16-qam으로 변조한다는 것은 하나의 시그널 엘리먼트가 16개의 레벨을 가진다는 뜻으로 결과적으로 하나의 시크널 엘리먼트에 4비트가 담기게 된다. 따라서 이것이 대역폭이 250khz의 신호로 바뀌게 되고 이걸 4개를 합쳐서 1mhz의 트렁크로 보내게 되는 것이다 - 별로 중요한 예시는 아니다\n\nAnalog hierarchy §\n\n\nFDM은 Analog Signal을 전송할떄 주로 사용된다\n작은 데역폭 신호를 한꺼번에 때려박는게 아니라 몇개씩 모아서 보내게 된다\n4khz짜리 12개를 모아서 하나의 group이 되고 또 이걸 5개 모아서 supergroup이 되고 이런식으로 작은 대역폭의 신호들을 계층적인 구조로 FDM으로 묶어서 보내는 방식을 취한다\n\nTime-Division Multiplexing §\n\n\n대역폭에 따라 bitrate가 달라지므로 대역폭은 시간당 얼마만큼의 데이터를 보낼 수 있는지에 대한 수치가 되기도 한다\n18p의 예제를 보면 얘네를 따로따로 보내게 되면 단위시간당 하나씩밖에 못 보내게 되지만 이것을 하나의 단위시간에 시간을 분배하여 하나로 합친다음 보내게 되면 같은 단위시간에 3개의 데이터를 보낼 수 있게 된다\n단위시간당 데이터A를 보낼 수 있는 시간은 한정되어 있는데 그러면 남는시간이 시간이 생기므로 이 시간을 데이터B, 데이터C로 채워서 남는시간을 없애는 거다\n그니까 기본 원리는 이거다 - Multiplexing 단계에서 작은 대역폭의 신호를 큰 대역폭의 캐리어로 보내면 더 일찍 전송되기 때문에 남는 시간동안 다른 신호를 더 보내게 되는 구조다\nDemultiplexing단계에서는 이것을 다시 시간별로 쪼개서 가져오게 된다\n\nDigital hierarchy §\n\nTDM은 주로 Digital Signal을 전송할때 사용된다\n\nT 회선 §\n\n\n사람의 목소리인 4000hz는 이것을 8bit로 샘플링을 하면 대략 64khz가 나오게 된단다 이것을 DS-0이라고 한다. 즉, DS-0은 하나의 Voice Channel인 셈\n얘를 24개를 묶은게 DS-1, 또 묶은게 DS-2 … 이런식으로 계층구조를 가지고 데이터가 전송되게 된다\n그리고 뭐 얘네들을 보내는 회선(line)을 T-1, T-2 … 뭐 이렇게 이름을 지어놨댄다\n이 T회선은 미국의 표준이다\n\nE회선 §\n\n\n하지만 유럽표준은 이거랑은 좀 다르다 → 유럽에서는 T표준이 아닌 E표준을 쓰게 된다\n유럽은 30개, 120개, 480개 이렇게 묶어서 E-1, E-2, E-3으로 명명해서 사용한다\n\nSpread Spectrum §\n\n얘는 효율성보다는 정확성에 더 초점을 맞춘다 → 넓은 대역폭에 그냥 작은 대역폭의 데이터 하나를 보낸다\n이렇게 하는것은더 많은 데이터를 보낸다는 관점에서는 손해이지만,\n데이터 간의 간섭이 줄어들기 때문에 더 정확하게 보낼 수 있게 된다\n군사용으로 계발된 보안에 중점을 맞춘 통신법이기 때문에 이런 비효율적인것처럼 보이지만 보안성은 강화된 통신을 하게 되는 것\n따라서 무선통신같은 간섭신호가 많이 존재하는 환경에서는 이런식으로 Spread Spectrum의 방식을 사용해 데이터를 보내게 된다\n\nFrequency Hopping Spread Spectrum(FHSS) §\n\n말그대로 주파수(frequency)를 넘나드는방식(hopping)으로 데이터가 전송된다.\n\n\n\n\n위의 예시를 보면 데이터가 000이면 100khz대로 보내고, 001이면 200khz대로 보내고 하는 규칙이 테이블에 지정되어 있다\n따라서 규칙에 따라서 데이터를 전송하는 주파수를 변경하는 것이다 → 즉, 데이터가 전송되는 주파수가 수시로 변경된다\n주파수가 변경되는 규칙을 알지 못하면 이것을 도청하기 아주 힘들게 된다 따라서 보안성면에서 아주 큰 장점이 있다\n이것의 단점이라고는 여러 주파수로 변경되면서 전송되기 때문에 적은 대역폭의 신호 일지라도 넓은 대역폭이 필요로 하다는 단점이 있다\n\n\n\n하지만 이 단점도 보완할 수 있다. 35p의 예제처럼 일반적인 FDM의 경우 왼쪽처럼 여러 신호가 일정한 주파수로 전송되게 되는데 이것을 FHSS의 개념을 합쳐서 오른쪽의 그림처럼 각각의 신호가 규칙에 따라 섞이게 만들어 놓으면 보안성과 효율성 모두를 어느정도 취할 수 있게 된다\n\nDirect Sequence Spread Spectrum(DSSS) §\n\n오리지날 데이터의 하나의 비트를 정해진 규칙에 따라 여러 비트로 나타내어 보내는 것을 의미한다\n예를 들면 1의 경우 1010으로 보내고 0의 경우 0101로 보내게 된다\n원래의 1에 1010을 곱하면 그대로 1010이 나올 것이고, 0을 곱하면 (논리적 곱셈이므로 0곱하기 0은 1이 된다) 0101이 나오게 된다\n이때의 곱해지는 1010값을 Spreading Code라고 부른다\n\n즉, Spreading Code는 하나의 비트를 여러개의 비트로 구성하는 규칙을 말한다\n\n\n수신자도 이미 spreading code를 갖고 있는데 수신된 신호에 spreading code를 곱하면 원래의 데이터를 끄집어낼 수 있다\n하지만 spreading code를 모르는 사람은 이것을 알아내기 힘드므로 보안수준이 높아지게 된다\n또한 spreading code는 오류 판별 코드로도 사용될 수 있다 → spreading code를 곱했는데 정확하게 나온다면 정확하게 수신된 것이고, 일부분이 좀 이상하게 나온다면 정확하게 수신이 되지 않은 것이라고 판별하는 용도로도 사용할 수 있다.\n몇 비트가 잘못 수신되었을때 이런일이 일어나게 된다 - 예를 들어서 +1을 11비트로 보냈는데 2비트가 잘못보내져서 이 두개만 -1로 수신되어도 결국에는 나머지 9개의 비트가 +1이기 때문에 다 더해보면 +7이 되어서 1의 신호로 판단하게 된다\n\n즉, 몇 비트가 잘못 수신돼도 더해보면 결국에는 값의 부호가 바뀌지는 않기 때문에 정상적으로 수신된다\n\n\n그리고 이 spreading code를 잘 짜게 되면 FDM도 사용 가능하다 → 으케하는지는 나중에 배운댄다\n\n전송매체 §\n\n전송매체는 단순히 매체일 뿐이고 physical layer는 통신 전반의 계층적 프로토콜을 말하는 것으로 이 두개는 같지 않다\nguided media : 가이드가 있다 = 유선통신을 말함\nunguided media : 가이드가 없다 = 무선통신을 말함\n\nGuided media §\n\nTwisted pair cable, coaxial cable, fiber optic cable 이 세가지 종류가 있다\n\nTwisted pair cable §\n\n송신용도의 선, 수신용도의 선 이렇게 두가지의 선을 꼬아놓은 형태이다 인터넷선\n꼬아놓은 이유는 도선에 의한 자연발생적인 인덕턴스(기억안나면 전자회로 강의 참고)를 막기 위함 → 이렇게 꼬아놓으면 인덕턴스가 상쇄되어 더 효율적이랜다\n**UTP(Unshielded Twisted Pair)**선 : 그냥 두 선을 플라스틱 커버를 이용해 묶어놓은 것\n**STP(Shielded Twisted Pair)**두 선을 금속소재의 커버로 덮고 그 다음에 플라스틱 커버를 씌운 것 → 이렇게 하는 이유는 이 금속커버가 피뢰침의 역할을 해서 외부의 간섭을 줄이게 된다 → 하지만 비싸기 때문에 보통 우리가 utp케이블을 쓴댄다\n10p에 보면 utp의 종류들이 나와있다 → 얼마나 촘촘하게 꼬았는지에 따라서 속도가 달라지고 이걸 가지고 카테고리를 나눈 것 이다\n\nCoaxial cable §\n\n얘는 수신용도의 도선밖에 없다 - 이 도선을 절연체와 금속 쉴드로 감은 케이블이다 유선 tv케이블\n\nFiber-optic cable §\n\n뭔지알제? 매질의 밀도차이에 따라 특정 각도에 따라서는 빛이 반사된다는 성질을 이용한 광섬유케이블이다\nmultimode : 빛이 반사되며 진행되는 구조\n\nstep index : 빛이 경계면에서 각지게 반사되는 구조\ngraded index : 빛이 다초점 반사되어 각지게 반사되는게 아닌 둥글게 휘어서 반사되는 구조\n\n\nsinglemode : core의 지름을 좁혀서 빛의 직진성만 이용하는 구조\n\nUnguided media §\n\nradio wave, microwave, infrared(적외선)의 종류가 있다\nground propagation : 지면을 따라 진행되는 형태(~2MHz)\nsky propagation : 전리층에 반사되어 진행되는 형태(~30MHz)\nLine-of-sight propagation : 공기중으로 직접 전달되는 형(300MHz~)\n21p에 주파수에 따은 propagation이 정리되어있음\n주파수가 클수록 우리가 다루기 어렵다\n\nRadio wave §\n\nOmnidirectional : 방향성 없이 구형으로 퍼져나가는 성질\n라디오 등에 사용한댄다\n\nMicrowave §\n\nUnidirectional : 직진성이 강하다는 성질\n위성네트워크 등에 사용한댄다\n\nInfrared §\n\n직진성이 더 강하다\ntv리모컨 등에 쓰인다 → tv리모컨의 방향이 잘 안맞으면 작동 안하는게 다 이 강한 직진성때문이다\n"},"originals/datacommunication.spring.2021.cse.cnu.ac.kr/05.-Data-Link-Control":{"title":"05. Data Link Control","links":[],"tags":[],"content":"\n\n                  \n                  충남대학교 컴퓨터공학과 김상하 교수님의 &quot;데이터 통신&quot; 강의를 필기한 내용입니다. \n                  \n                \n\n\n\n                  \n                  다소 잘못된 내용과 구어적 표현 이 포함되어 있을 수 있습니다. \n                  \n                \n\nDatalink Layer의 목적 §\n\n신뢰도가 높은 - 통신에 있어 단 하나의 에러도 발생기키지 않기 위한 목적\nPhysical Layer의 경우에는 한번 전송할때 최대한 에러를 적게 내려는게 목표라면\nDatalink Layer의 경우에는 재전송하는 한이 있더라도 완벽한 데이터를 받게 하는것이 목표이다\n이것을 위해서 프레임, 패킷이라는 단위로 전송을 한다\n\n에러의 종류 §\n\nSingle-bit Error : 하나의 비트가 잘못 수신되는 것\nBurst Error : 여러개의 비트가 뭉탱이로 잘못 수신되는 것\n\n에러처리 §\n\nParity(Redundant, Extra) bit나 data를 추가로 더 보내게 된다\n\n\n\n위의 그림 예시를 보면 even parity의 경우에는 extra bit를 하나 추가로 두어서 1의 갯수가 항상 짝수가 되게 만들어주는데 1의 갯수가 홀수면 잘못 수신됐다고 판단할 수 있는 것이다\n이때 Error Detection는 오류가 났는지 안났는지를 확인만 하는거고 Error Correction의 경우에는 어디서 에러가 났는지를 알아서 고칠 수 있게 하는 것이다\n\nDetection §\n\ndetection의 경우에는 잘못 수신된 데이터를 원래의 데이터로 복구는 하지 못한다 - 이렇게 잘못 수신되면 다시 송신하라고 요청해서 제대로 수신될때까지 송신을 반복하게 하는게 detection을 활용한 통신이다\n많은 에러를 detection하려면 당연히 많은 비트의 redundancy가 필요하다\n\nCorrection §\n\ncorrection의 경우에는 redundancy를 추가해서 unique한 패턴으로 만들어서 보내게 된다. 이 경우에는 한 비트가 에러가 나도 금방 원래의 데이터를 추론할 수 있기 때문에 원 데이터로 correction할 수 있다\n예를 들어 01111로 수신됐는데 패턴 중에 01011이 존재한다면 세번째 비트가 오류가 났다는것을 금방 추론하고 01011로 수정해서 상위계층으로 올리게 된다\n\nFrame, Packet의 필요성 §\n\n데이터가 크면 이놈을 위해 필요한 redundancy도 엄청 커지고 이것을 오류가 날때마다 계속 보낸다면 비효율적이다\n따라서 이런 큰 데이터를 송신할때는 작게 잘라 보내게 되는데 이것을 Framing이라고 하는 것 이다\n이 나눠진 한 단위를 Packet이라고 하며 이것이 데이터 링크를 지날 때에는 Frame이라는 이름으로 부른다\nFixed-size framing의 경우 크기가 정해져있기 때문에 데이터의 시작과 끝을 구별해내기 쉽지만 데이터가 작을 경우 비트 낭비가 있다는 단점이 있다\n\n운체에서 internal fragment가 발생하는 원리랑 같은 원리이다\n\n\nVariable-size framing의 경우 데이터의 크기에 따라, 그리고 전송매체에 따라 사이즈를 가변적으로 활용할 수 있다는 장점이 있지만 데이터의 시작과 끝을 나타내는 Delimiter가 추가로 필요하다는 단점이 있다\n전송매체에 따라서도 자르는 프레임의 크기가 다른 이유는 에러가 적은 전송매체로는 많은양의 데이터를 보내도 괜찮고 에러가 많은 전송매체로는 적은양의 데이터밖에 보낼 수 없기 때문에 이렇게 하나의 데이터를 여러 사이즈로 프레이밍해서 각기 다른 매개체로 병렬적으로 보내게 되는 것 이다\n\nCharacter-Oriented Protocols §\n\n데이터들이 8비트 문자의 묶음 형태로 전송되는 것을 의미\nFlag : 데이터의 시작과 끝을 나타냄\nHeader : 송수신 주소에 대한 정보를 담고 있음\nTrailer : redundancy가 담겨있음\n\nByte Stuffing, Unstuffing §\n\n\n만약에 전송하는 문자열에 flag가 들어있으면 얘는 진짜로 flag인게 아니라 “flag”라는 데이터일 뿐이므로 프레이밍 과정에서 앞에 ESC(escape)문자를 붙인다\n이렇게 데이터를 프레이밍하는 과정에서 ESC를 붙여 뒤에 나오는 놈이 어떤 의미를 갖는 표식이 아닌 그냥 데이터의 일부일 뿐이라는 것을 명시하는 것을 Byte Stuffing이라고 한다\n\n마치 Like 문자열 escape character 와 같다\n\n\n따라서 ESC 뒤에 있는 놈은 프레임의 구조를 분석할때 제외된다\n프레임에서 데이터를 다시 끄집어 낼 때에는 이 ESC는 다시 지우게 되는데 이 과정을 Byte Unstuffing이라고 한다\n근데 이때 데이터에 “ESC”라는 문자열이 들어있으면 얘를 byte stuffing에 의해 추가된 놈이라고 생각해 지울 염려가 있다\n그래서 데이터로써의 “ESC”가 있어도 그 앞에 ESC를 하나 붙여 ESC를 지워도 데이터로써의 “ESC”는 남아있을 수 있도록 한다\n프레이밍을 할때는 ESC를 “ESC”나 “FLAG”앞에 기계적으로 붙이고 다시 데이터를 끄집어낼때는 데이터 내의 ESC를 기계적으로 지우기 때문\n\nBit-Oriented Protocol §\n\n사진, 동영상, 음악같은 경우에는 문자로 표현이 안되기 때문에 그냥 커다란 bit 덩어리로 보내게 된다\n따라서 특정한 bit stream을 flag로 지정해 시작과 끝을 나타내게 된다\n\nBit Stuffing, Unstuffing §\n\n\n얘도 동일한 문제가 발생할 수 있다. 만약에 1이 6개가 연속될때를 flag라고 지정했을 때, data bit에 1이 연속 6개가 들어있으면 얘를 flag로 인식할 수가 있다\n따라서 데이터에 1이 5개가 연속되어 있으면 그 뒤에 0을 무조건 붙이는 방식으로 Bit Stuffing 을 하고\nUnstuffing과정에서는 1이 5개 연속되어있는 다음의 0은 제거하는 방식으로 진행 하면 이런 혼동을 막을 수 있다\n\n가상의 Noiseless Channel에서의 Protocol §\nSimplest Protocol §\n\n\nSimplest protocol : 아무짓도 안하는 프로토콜\n그냥 redundancy같은거 필요없이 프레임을 주고 받으면 된다\n\nStop-and-Wait Protocol §\n\n\nFlow error : 프레임이 도착한다고 해서 바로바로 상위계층으로 올라가는게 아니다 - 프레임이 도착하면 버퍼에 저장되어 있다가 이 버퍼를 비우고 다시채우고 하는 과정을 반복하게 되는데 버퍼를 비우는 프로세스가 블락을 먹거나 하는 등의 이슈로 멈추게 되면 새로 들어온 프레임은 기존에 버퍼에 들어있던 프레임을 덮어쓰게 된다. 이렇게 수신자의 처리속도와 송신자의 처리속도의 차이에 의해 에러가 나는것을 flow error라고 한다\n따라서 noiseless channel이어도 에러가 날 수 있다는 것\nStop-and-wait protocol : 이러한 flow error를 해결하기 위한 프로토콜. 수신자가 수신 완료 후 ACK(QSL같은놈 - 수신 잘 됐다는거)날리면 그때서야 다음 프레임을 전송하는 구조\n\n실제 Noisy Channel에서의 Protocol §\nStop-and-Wait ARQ(Automatic Repeat reQuest) §\n\n\nStop-and-Wait ARQ프로토콜은 기존의 Stop-and-Wait Protocol에서 노이즈에 의해 ACK가 오지 않았을때를 해결하는 프로토콜이다\n\n프레임 송신중 에러가 날 때 §\n\n이게 수신자가 아직 수신을 못해서 ACK가 안온건지 아니면 에러가 나서 ACK가 안온건지 알 수 없기 때문에 송신자는 일정시간 기다린 후에 이 프레임을 다시 보내게 된다( - automatic repeat의 말 뜻이 이거다)\n\nACK송신중 에러가 날 때 + 종합적 통신과정 §\n\n하지만 수신자는 잘 받았는데 ACK가 에러가 나서 송신자측에서 프레임을 못받았다고 판단해 다시한번 보내게 되면 중복 데이터가 수신되는 셈이다\n이를 방지하기 위해 프레임에는 Sequence Number라는게 존재한다 - 즉, 이 프레임이 몇번째 프레임인지를 나타내는 숫자\n그리고 ACK Number는 수신자 측이 잘 받았고 이제 나는 ~번째 프레임이 필요하다 라는 뜻을 가지게 된다\n수신자 측에서는 seqNum이 0인 프레임을 정상적으로 수신해서 ACK 1을 보냈는데 송신자측에서 못알아듣고 seqNum이 0인 프레임을 한번 더 보내면 수신자측은 seqNum을 통해 중복수신이라는 것을 파악하고 seqNum 0인 프레임은 폐기하고 ACK1 를 한번 더 보내게 된다\n그리고 이번엔 프레임 유실이 생겼다고 해보자. ACK1을 송신자가 받아서 S1을 보냈는데 그 다음 ACK가 안오면 잠시 뒤에 S1을 다시 보내게 된다. 그리고 이때 수신자가 받으면 이때에는 자기가 원하던 데이터를 받은 것 이므로 저장하게 된다 - 즉, seqNum은 프레임 유실을 방지하기 위한 숫자는 아니라는 소리\n"},"originals/datacommunication.spring.2021.cse.cnu.ac.kr/06.-ARQ-Protocol,-HDLC":{"title":"06. ARQ Protocol, HDLC","links":[],"tags":[],"content":"\n\n                  \n                  충남대학교 컴퓨터공학과 김상하 교수님의 &quot;데이터 통신&quot; 강의를 필기한 내용입니다. \n                  \n                \n\n\n\n                  \n                  다소 잘못된 내용과 구어적 표현 이 포함되어 있을 수 있습니다. \n                  \n                \n\nStop - N - Wait ARQ의 단점 §\n\n하나 받고 ack를 보내고 그 다음 또 하나를 보내고 하는 것에는 하나받고 ack를 보낸 다음에는 다음 프레임이 올 때까지 수신측에 놀게 된다는 비효율성이 존재함\n이것을 해결하기 위해 한번에 하나의 프로레임을 보내는게 아닌 여러개의 프레임을 보내고, 이때에는 시간차를 적당히 주어서 바나의 프레임을 버퍼에서 지우기 전에는 다음 프레임이 들어오지 않게 하는 방식으로 해결할 수 있다\n\nGo-Back-N ARQ §\n\n이 프로토콜의 핵심은 프레임을 연속적으로 보내다가 실패하면 실패한 시점으로 돌아가 다시 보낸다는 것이 핵심이다 - 그래서 이름이 Go Back인 것\n프레임들을 연속해서 계속 보내므로 송신측은 내가 어디까지 냈는지를 기억할 필요가 있다. 따라서 프레임 하나를 보내고 그것을 Slide Window라는 메모리 버퍼에 저장한다.\n\n통신과정 §\n\n송신측의 기본적인 진행과정을 살펴보자\n\n프레임을 보낼때마다 보낸 프레임을 Slide Window 버퍼에 저장하게 된다.\n수신측으로부터 잘 받았다는 ack를 모두 받으면 이 버퍼에서 프레임을 전부 지운다\nACK가 들어오지 않았다면 timeout걸릴때까지 잠시 기다렸다가\n만약 ack가 보낸 프레임들에 대해 전부 들어오지 않으면 수신자가 아무것도 받지 못했다고 판단해 Slide Window에 있던 프레임들을 전부 다시 보낸다\n만약 ack가 보낸 프레임들에 대해 일부만 들어오면 들어온 ack중에서 가장 ackNum이 높은 것부터 다시 보낸다\n\n이 경우에는 두가지의 상황이 존재한다 - 먼저 0123을 보냈는데 012만 들어온 경우면 01까지는 갔지만 2부터는 안들어왔다는 소리이므로 2부터 다시 보내게 된다\n만일 위와 동일하게 보냈을 때 02가 들어왔으면 1이 안들어왔다고 1부터 다시 보내는 것이 아니다 - 2가 들어왔으므로 1까지도 당연히 받았다고 판단하고 2부터 다시 보내게 된것이다\n즉, ACK number는 “이거 이전까지는 전부 정상적으로 받았으니 이거나 내놓아라”라는 뜻이므로 중간에 ACK가 안들어온게 있어도 그것부터 재전송을 시작하지 않는다\n\n\n\n\n이제 수신측의 기본적인 진행과정을 살펴보자.\n\n프레임이 정상적으로 들어오면 ACK를 보낸다. 프레임이 연속해서 들어오므로 ACK도 수신 완료될때마다 연속해서 보내게 된다\n만일 하나의 프레임이 수신 실패하게 되면 그 다음에 들어오는 프레임을 모두 폐기한다. 그리고 수신 실패한 순간부터 ACK를 보내지 않는다.\n\n\n\n예시 §\n\n\n우선 위의 예시는 ACK2가 중간에 유실됐지만 그럼에도 ACK3, 4가 수신됐기 때문에 송신자는 3번까지 다 받은것으로 판단해 Slide Window를 다 비우게 된다\n\n\n\n위의 예시는 Frame 1이 유실되어 수신자는 이후 들어온 2와 3을 모두 폐기하고 ACK를 보내지 않는다. 따라서 timeout이 걸리고 송신자는 수신자가 아무것도 못받았다는 판단 하에 Frame 1부터 재전송한다.\n\n특징 §\n\n송신측의 slide window 는 Circular Queue를 사용하게 된다 - 즉, 차례대로 프레임들이 쌓여 있다가 송신을 한 후 이것들을 제대로 받았다는 ack를 받으면 제대로 받은 애들을지운 후 아직 안보내서(혹은 수신측이 받지 못해서) 보내야 할 프레임들을 앞으로 땡기는게 아닌 ACK를 받은 프레임이 있던 자리를 비우고 앞으로 더 보내야되지만 slide window에 자리가 없어서 들어오지 못했던 프레임들이 차례로 들어오게 되는 것\n\n즉, 012345에서 012에 대한 ACK가 들어오면 345678이 되는게 아니라 678345이 된다는 소리이다\n\n\nGo-Bask-N ARQ의 경우에 수신측은 이전의 프로토콜과 동일하게 하나의 프레임만 저장할 버퍼밖에 가지고 있지 않다\n중간에 수신누락이 생겨 폐기해도 정상적인 상황에 연속적으로 프레임이 수신되므로 stop-n-wait보다는 더 빠르게 작동하게 된다\n그리고 저기 사진에는 안나오지만 수신측에서 해당 seqNum부터 다시 보내달라는 의미로 NAK 패킷을 보내기도 한다\n\nSelective Repeat ARQ §\n\n\n앞의 프레임이 죽어 그 이후 정상적으로 수신된 놈도 폐기하는것이 너무 아까웠던지 그 뒤의 것도 저장하고 못받은 놈만 다시 보내라고 하는 방식이다\n수신측에서 중간에 프레임이 빌 경우 ACK를 보내지 않고 NAK를 보내게 된다\n\nack의 경우 내가 이전까지는 다 잘 받았고 이제 난 이게 필요하다 라는 뜻을 가지게 되는데\n지금의 경우에는 지금 이게 안들어와서 이것만 다시 보내달라 라는 뜻을 가진 메세지가 필요하므로 ACK말고 NAK이라는 놈을 새로 고안하게 된 것이다\n\n\n이제 수신측은 내가 어디까지 받았고 이제 어디를 받아야 하고 어디가 비었는지를 확인하기 위해 수신측도 Receive Window라는 버퍼를 필요로 한다\n\nPiggybacking Go-Back-N ARQ §\n\n이제 얘는 양방향 통신을 위한 go-back-n arq이다\n내가 쟤한테 프레임을 받고있고 나도 쟤한테 데이터를 보내야 하는 경우에는 그냥 ack를 데이터에 붙여서 같이 보내게 된다\n만약 양방향 통신이 이루어지지 않고있다면 그냥 ack만 날리겠지만 양방향 통신이 시작되면 이제부터는 쟤나 나나 데이터에 수신 완료된 프레임에 대한 ACK를 붙여서 보내게 되는 것 - 이 piggybacking이라는 것을 항상 사용해야 된다는 것은 아니더라\n\n버퍼에 저장되는 프레임의 갯수, seqNum 정하기 §\n\n일단 여기서 알아야될 점은 seqNum은 무한한 숫자가 아니고 유한한 숫자이며 01230123이런식으로 순환되며 프레임에 할당되게 된다\n따라서 seqNum가 너무 크다면 이 seqNum을 저장하기 위해 데이터에 포함되어야 할 비트의 수도 커질 것이고 그러면 배보다 배꼽이 더 커지는 상황이 생길 수도 있다 - 따라서 적당히 해야됨\n일단 seqNum을 잘못 설정해 오류가 나는 경우는 Go-Back-N이나 Selective나 전부 정상수신했지만 ACK가 전부 유실되는 경우 송신자가 처음부터 다시 보낼때 수신자는 그것을 재전송된 프레임이라고 판단하지 않고 아직 안받은 프레임이라고 판단해 폐기하지 않고 받아들이는 경우이다\n\nseqNum과 버퍼 사이즈의 관계 - Go-Back-N의 경우 §\n\n\n버퍼 사이즈 &lt; seqNum인 경우\n\nseq num이 2비트인 0, 1, 2, 3이고 버퍼에 저장되는 프레임의 갯수가 3개이며 0, 1, 2를 송신했다고 해보자.\n이때 수신자는 0, 1, 2를 모두 정상수신했지만 전부 ack누락이 된 경우 송신측은 쟤가 암것도 받지 못했다고 판단해 0부터 다시 보내게 된다.\n수신자는 0부터 다시 오니까 전부 폐기시키며 3번 프레임이 필요한 상황이므로 ack3을 날린다\n만약 이게 성공적으로 송신측 귀에 들어가면 3번부터 보내게 되는 것이다. 따라서 오류 없이 전송이 되었다고 볼 수 있다\n즉, 송신버퍼 사이즈 &lt; seqNum인 경우에는 ACK가 전부 유실되어 송신자가 아무것도 못받았다고 판단해 다시 처음부터 보내도 수신자는 폐기시키므로 오류가 나지 않는다\n\n\n버퍼사이즈 = seqNum인 경우 :\n위와 동일하게 지금까지 보낸 프레임들이 다 수신되었지만 ack가 다 죽어버린 경우를 생각해보면\n\n0, 1, 2, 3을 수신측은 다 수신해 이제 새로운 0번을 받아야 되는데 송신측은 ack가 하나도 들어오지 않으므로 보냈던 0번을 다시 보내게 된다.\n이렇게 되면 수신 측은 이미 받았던 데이터인데 이것이 새로운 데이터라고 인식하지 않고 그대로 받게 되어 수신 오류가 생긴다.\n따라서 Go-Back-N의 경우 송신버퍼 사이즈 = seqNum이면 ACK가 전부 누락된 경우에 수신자는 새로운 0번을 받아야되는데 송신자는 이전의 0번을 재전송하므로 통신 오류가 생긴다\n\n\n\nseqNum과 버퍼 사이즈의 관계 - Selective Repeat의 경우 §\n\n\n일단 위의 예제에서 m은 seqNum을 나타내는 비트의 수를 의미하는데 2^m가 결국에는 seqNum의 갯수와 같으므로 그냥 seqNum으로 표기합니다\n송수신버퍼 사이즈 = seqNum / 2인 경우 - 예시 a\n\n이번에도 ACK가 전부 유실된 경우를 봐야 된다. 프레임 0, 1이 수신되었지만 ACK가 모두 유실된 경우 송신자는 ACK가 들어오지 않았으므로 0을 다시 보낼 것이다.\n하지만 수신자의 버퍼에는 0이 없기 때문에폐기하고 2를 요청한다 - 따라서 이 경우에는 정상적으로 작동한다.\n즉, 송수신버퍼 사이즈 = seqNum / 2인 경우에는 ACK가 모두 유실돼도 송신자가 재전송한 프레임이 수신자의 버퍼에 없기 때문에 폐기하게 되어 정상작동한다\n\n\n송수신버퍼 사이즈 &gt; seqNum / 2인 경우 - 예시 b\n\nACK가 모두 유실된 경우를 보면 송신측은 0, 1, 2를 모두 보냈고 수신측도 모두 받았지만 보낸 ACK가 전부 유실된 상황이다.\n이때 송신측은 당연히 ACK가 들어오지 않았으므로 0번부터 다시 보내게 되지만 수신측 버퍼에는 다음 0번이 대기상태이기 때문에 3번을 비워두고 재전송한 0번을 다음의 0번이라고 판단해 넣게 된다 - 수신 오류가 나는 것\n즉, 송수신버퍼 사이즈 &gt; seqNum / 2의 경우에는 ACK가 모두 유실됐을 때 송신자가 재전송한 프레임이 수신자의 버퍼에 다음 대기 프레임으로 채워지기 때문에 수신오류가 난다\n\n\n\nHigh-level Data Link Control(HDLC) §\n\n지금까지 배운 것들로 만든 실제 통신 프로토콜\n\n통신의 방향성 §\n\nNormal response mode : 단방향 통신. 한쪽이 데이터를 보내면 한쪽에서 받는(받는쪽이 항상 같은놈이면 point-to-point, 다를수도 있으면 multipoint라고 한다) 구조\nAsynchronous balanced mode : 양방향 통신을 의미함\n다만 여기서 통신의 방향성이라는 것은 통신을 먼저 시작할 수 있는 놈이 한쪽이냐 아니면 양쪽이냐에 따라 나눈 것\n\n패킷의 종류 §\n\n\nI-frame : 데이터를 보내는 프레임, S-frame : ACK, U-frame : 통신 모드 변경 등의 관리 패킷이다\nFLAG는 시작과 끝을 알리는 부분\nADDRESS는 송수신주소를 명시하는 부분\nCONTROL은 패킷의 종류를 구분하는 부분\nFCS는 FLOW CONTROL, 즉, 오류검출용 bit들이 내장된 부분이다\n\nControl 헤더의 구성 §\n\n\n일단 컨트롤이 0으로 시작하면 I-frame, 10이면 S-frame, 11이면 U-frame로 판단한다\nN은 seqNum을 의미한다. 그리고 S는 Sender, R은 Receiver를 의미한다.\n따라서 N(S) 는 자신이 보내는 데이터의 seqNum인 것이고\nN(R) 는 자신이 받은 데이터에 대한 ACK이다\n둘 다 데이터를 보내는 경우 - Piggybacking인 경우\n\n데이터에 양측의 ack가 붙게 되는데 이때\nI-frame의 N(S)와 N(R)를 모두 사용해서 자신이 보내고 있는 데이터에 대한 seqNum과 자신이 받은 데이터에 대한 ACK를 보내는 거다\n\n\n한쪽만 데이터를 보내고 한쪽은 그냥 듣는 경우\n\n송신자는 데이터랑 ACK랑 같이 보낼 필요가 없으니까 I-frame에서 N(R)는 필요가 없으므로 N(S)만 사용하게 된다\n그리고 마찬가지로 수신자는 ack만 날려야 되기 때문에 이때 S-frame을 사용하는 것\n\n\nI-frame의 code부분은 이 사진을 봐라\n\n\n\n00일 경우에는 송신 속도 양호. 앞으로도 계속 이 속도로 보내면 된다는 뜻이고\n10은 너무 빨리 보내 데이터 덮어쓰기가 발생할때이다. 속도를 좀 줄여달라는 의미\n01은 GBN에서의 NAK로 쓰인다. 해당 seqNum부터 다시 보내달라는 뜻\n11은 SR에서의 NAK이다. 해당 seqNum만 다시 보내달라는 뜻\nU-frame의 code 부분은 통신 모드 변경, 확인 등의 목적으로 쓰인다. 뭐 현재 모드에서 Normal response mode라던지, Asynchronous balance mode 등등의 모드로 전환(SABM)하자 혹은 ㅇㅋ알았다(UA) 등의 확인 메세지 이런 용도로 쓰인다\n"},"originals/datacommunication.spring.2021.cse.cnu.ac.kr/07.-MAC":{"title":"07. MAC","links":[],"tags":[],"content":"\n\n                  \n                  충남대학교 컴퓨터공학과 김상하 교수님의 &quot;데이터 통신&quot; 강의를 필기한 내용입니다. \n                  \n                \n\n\n\n                  \n                  다소 잘못된 내용과 구어적 표현 이 포함되어 있을 수 있습니다. \n                  \n                \n\nMultiple Access Control(MAC) §\n\nData link layer에서 Data link control(지금까지 배운 거)와 함께 제일 중요한 내용이다\n하나의 매체(회선)을 여러명이 접근할 수 있게 하는 기술 - 이럴 때 혼선/충돌이 일어나지 않게 하는 기술\n한사람이 데이터를 보낼때는 다른사람은 보내지 않다가 이사람이 끝나면 그때기 보내기 시작하는 방법을 이용한다\n에러는 회선에서의 자연적인 노이즈때문에 에러가 나기도 하지만 다른사람의 데이터랑 충돌해서 에러가 나기도 한다 - 이때 충돌에 의한 에러는 자연적 요인이 아니므로 우리가 어느정도 제어가 가능하다. 따라서 이러한 에러를 최대한 줄이고자 하는 것이 **Multiple Access Control(Resolution)**이며, 자연적이거나 충돌에 의한 에러가 있음에도 ACK, NAK등의 기법을 이용해 제대로 수신할 수 있는 방안을 마련한 것이 Data Link Control이다\n즉, 정리해보면 다음과 같다\n\nPhysical Layer는 자연적으로 일어나는 노이즈 등으로부터 최대한 에러가 발생하지 않게 막는 계층이고\nData Link Layer의 Data Link Control은 에러가 나도 재전송받거나 correction등의 방법을 통해 에러가 전혀 없게 하는 역할이고\nData Link Layer의 Media Access Control은 데이터들 간의 충돌에 의한 에러를 막는 역할인 것이다\n\n\nMAC은 크게 Random Access Protocol, Controlled Access Protocol, Channelization Protocol이렇게 나누어진다 - 하지만 얘네들이 별개가 아니라 다 통합되더라\n\nRandom Access §\n\n데이터를 보내고자 하는 포인트들이 경쟁을 통해 그 매체의 이용권을 얻는 것\n순전히 경쟁을 통해 이용권을 얻으므로 랜덤하게 이용권이 주어진다 - 즉, 운나쁘면 한놈이 오랫동안 점유하는것도 가능하다 이말이야 - 이러한 특성을 Memoryless property라고 한다\n\nALOHA 알고리즘 §\n\n봐봐라\n만약에 프레임 여러개가 겹쳐서 충돌이 났다 쳐봐라\n그러면 이제 충돌난애들은 ack가 안오므로 타임아웃이 걸려 다시 보내것제?\n근데 만약에 컴퓨터들마다 타임아웃 걸리는 시간이 다 똑같이 설정되어있으면\n아까처럼 똑같이 보내고 다같이 충돌나게 되더라 이말이여\n이러한 문제를 해결하는게 ALOHA 알고리즘이다\n\n\n\n여기서 Tp란 데이터가 한번 전송되는데 걸리는 시간이다. 근데 데이터를 보내고 ack를 받아야 하므로 왕복이니까 2를 곱해주는거\n여기서 이제 ACK를 받지 못하면 시도 횟수를 뜻하는 K를 1 올리게 된다 이 K는 일반적으로 15를 최대치로 두며 이 최대치를 넘어가면 Abort(포기)한다 - 15번을 반복해서 보내보고 안되면 포기한다는 뜻\n그리고 이번에는. 임의의 시간간격동안 기다린 다음 프레임을 전송한다.\n\n위에서 말한 저 충돌 이후에도 모두가 같은시간을 기다린후 다같이 보내 또다시 충돌이 일어나는 문제를 해결하기 위해 다른 컴퓨터와의 랜덤한 시간차를 두는 것 이다\n여기서 난수는 0~(2^k - 1) 중에 아무 숫자나 랜덤으로 고르는 과정을 거치는데 이것을 Binary Back-off 라고 하고 이로부터 결정을 R로 표현한다\n그리고 R * Tp를 통해 대기시간을 산정하고 대기한다\n\n\n하지만 단점이 있다 - 실제로 써보니까 딴놈의 전송이 거의 다 끝나갈때쯤에 또 딴놈이 전송시작하고 이런식으로 걸치는 일이 많이 일어나더라 - 효율을 계산해봤더니 매체의 최대 전송 역량중 20프로밖에 발휘를 못하더라\n\nSlotted ALOHA 알고리즘 §\n\n얘는 이제 그냥 ALOHA 알고리즘과 동일하나 슬롯을 정해서 이때만 보낼 수 있다는 개념이다\n\n\n\n이게 뭔말인가 하면 내가 상위 계층으로부터 프레임을 받으면 바로 보내는게 일반적인 ALOHA 알고리즘이다 - 얘는 그럼 프레임이 출발할 수 있는 시간이 정해져있지 않고 연속적으로 분포한다\n슬롯으로 정해져있다는 말은 위의 그림 보면 이해될거다\n\n프레임이 출발할 수 있는 시간이 일정한 시간간격으로 정해져 있어 이때만 프레임을 보낼 수 있다는 것\n따라서 중간에 걸쳐있으면 잠깐 기다렸다가 슬롯이 시작되는 시점에 전송되는 것\n\n\n그리고 슬롯 오면 바로 전송하는게 아닌 여기서도 랜덤을 사용한다 - 랜덤하게 숫자를 하나 뽑아 그 수만큼 슬롯을 넘기고 그 다음에 전송을 시작하는 것\n얘는 이제 장점이 완전히 겹치는 경우는 존재하지만 애매하게 겹치는 경우는 존재하지 않는다는것이다 - 따라서 충돌의 확률이 줄어드는 것\n얘는 이제 효율이 36.8프로로 기존 알로하보다 2배나 개선시킬 수 있다\n\nCarrier Sense Multiple Access(CSMA) §\n\nCarrier Sense라는 것은 이제 전송매체에 귀를 기울이고 듣고 있다는 것을 뜻한다\n이 방법은 이제 계속 주시하고있다가 아무도 매체를 이용하지 않는 시점에 전송을 시작하는 방법이다\n충돌이 일어나는 경우는 두가지가 있다\n\n\n\n첫번째는 위의 경우처럼 저쪽에서 전송을 시작했는데 아직까지 내가 있는 위치까지는 전달이 안돼서 내가 전송을 시작하게 되는 경우이다.\n\n위의 그림에서 보면 B가 전송을 시작했는데(노란색) C까지 아직 도달하지 않아 idle하다고 판단해 프레임을 전송한다(파란색). 하지만 B의 프레임이 오던 중이었기 때문에 충돌이 일어난다(회색).\n하지만 보통 전파속도가 아주 빠르기 때문에 흔하게 일어나지는 않는다\n\n\n두번째는 지금 이미 한놈이 데이터를 보내고 있고 그게 끝나기만을 기다리는 놈들이 여러명 있을 때 이제 보내던 애가 끝나자마자 얘네들이 한꺼번에 들어오게 되는 경우이다\n\n기다림이 끝났을 때 어떻게 행공할것인가 §\n\n\n위 그림은 좀 이상하긴 함\n1-persistant : 계속 주시하다가 전송이 끝나자마자 바로 드가는 것 - 얘는 위에서 말한거처럼 여러명이 한꺼번에 들어올 수 있게 된다 - 근데 이더넷에서는 이것을 주로 사용한댄다\nnon-persistant : 얘는 계속 주시하고있는게 아니고 처음에 한번 보고 아직 보내는 중이면 랜덤한 시간을 기다렸다가 본다음 없으면 그때 드가는 방법이다 - 없음이 감지되면 바로 드가긴 하지만 그 감지하는 시점을 랜덤하게 불연속적으로 가지는 것\np-persistant : 얘도 슬롯의 개념을 이용한다\n\n보면 위의 그림은 좀 잘못되었는데\n\n\n일단 Channel이 idle한지 확인한다\n\nidle하면 다음단계로 가고 아니면 다시 확인한다\n\n\nProbability outcome을 하나 뽑는다. 난수를 하나 뽑는다는 소리이다. 그리고 그 수가 p라는 특정한 수보다 작은지 아닌지 확인한다\n\n작으면 내보내고 아니면 다음단계로 넘어간다\n\n\n다음 슬롯을 기다리고 슬롯이 오면 Channel이 idle한지 아닌지 다시 판단한다\n\nidle하면 다시 2번으로 가고 busy하면 다시 1번으로 간다\n\n\n\n\n쟤네들 중에 뭘 사용하든 별 상관은 없다\n\nCSMA with Collision Detection(CSMA/CD) §\n\n위와 같은 CSMA기술을 이용해도 충돌을 없앨수는 없다\nCSMA에서 충돌이 일어났는지를 알아내는 방법을 **CSMA with Collision Detection(CSMA / CD)**라고 하는 것\n보면 파동의 중첩을 기본 원리로 한다 - 즉, 파동 두개가 겹쳐지면 중첩이 일어나 진폭의 세기가 세지는 현상을 이용하게 되는 것\n따라서 Carrier Sencing을 했을 때 신호의 세기에 따라 구별해보면 다음과 같다\n\n세기가 0 : idle한(비어있는) 상태\n세기가 정상 : busy(누군가가 전송중)인 상태\n세기가 비정상 : 충돌이 일어난 상태\n\n\n\n충돌을 감지했을때 좋은점 §\n\n\n봐봐라\n위에 그림 보면 A가 보낼 데이터의 양이 많아 t1시간부터 그 이후로 계속 신호를 보내는 중이다\n근데 C는 그걸 모르고 t2시간에(A가 보낸 데이터가 아직 도달하기 전에) 데이터를 전송했다고 치자\n그럼 저 둘이만나는 지점에서 충돌이 일어나게 되고 그럼 C한테는 t3의 시점에 충돌이 감지되고, A한테는 t4의 시점에 충돌이 감지되게 된다\n그럼 A는 저 t4시점에 신호를 끊게 된다 - 어차피 충돌이 일어났으므로 더 이상 보내는 것은 무의미하므로\n따라서 아래 그림처럼 t4이후에 신호를 더 이상 보내지 않고 신호가 끊기게 되는 것이다\n신호를 보내는 중에 충돌이 감지되면 신호를 더 보내지 않고 끊음으로써 무의미한 작업을 줄이고, 시간도 더 효율적으로 사용할 수 있게 된다\n\n그냥 CSMA의 경우에는 충돌이 일어나도 다 보내게 되는데 CSMA / CD는 충돌을 감지하고 일찍 전송을 끊는다는 차이점이 있다\n\n\n이때 충돌이 일어나는 베스트와 워스트 경우의 수를 보면\n\n송신측과 가까운 쪽에서 총돌이 일어나 송신측이 바로 알게 되는 경우가 제일 베스트\n수신측과 가까운 쪽에서 충돌이 일어나 송신측이 늦게 알게 되는 경우가 제일 워스트이다\n\n\n그리고 이렇게 송신측이 충돌을 알게 되는데 걸리는 최대 시간은 워스트 케이스인 경우이므로 2 * 편도시간(Tp) 이다.\n\n근데 만약 송신을 하는데 걸리는 시간이 이것보다 작고 최악의 경우가 일어나 송신을 끝내고 난 후에 충돌을 감지하게 되면 CSMA / CD 기술은 아무 효용도 없게 된다\n따라서 CSMA / CD를 사용하려면 적어도 송신시간이 저것보단 길어야 된다\n\n\n따라서 CSMA / CD에 대한 플로우 차트는 다음과 같다 :\n\n\n\n먼저 시도횟수(K) = 0으로 시작한다\n그다음 Persistence중 하나를 골라 수행하여 적정한 시간에 프레임을 전송한다. 그리고 전송이 끝나거나 충돌이 감지되는지 수시로 확인한다\n\n전송이 끝나거나 충돌이 감지되지 않으면 다시 확인하고, 둘 중 하나에 해당하면 다음 단계로 넘어간다\n\n\n전송 완료된 것인지 아니면 충돌에 의해 중단된 것인지 판단한다\n\n만일 완료된 것이면 전송 성공인 것이고\n중단된 것이면 다음단계로 넘어간다\n\n\nJamming Signal을 보낸다는데 이게 뭔지는 모르겠고 시도횟수(K)를 하나 올려 시도횟수 최대값(15)보다 작은지 판단한다\n\n만일 최대값보다 크다면 전송 취소(Abort)하고\n그렇지 않다면 Binary Back-off를 실시해 난수 R를 하나 고르고 Tb = R * Tp를 통해 대기시간을 산정하고 대기한다\n대기시간이 만료되면 다시 2번으로 돌아간다\n\n\n\nCSMA with Collision Avoidance(CSMA / CA) §\n\n그냥 CSMA의 경우에는 무선의 환경에서도 사용 가능하나 CSMA / CD의 경우에는 무선환경에서는 사용하지 못한다\n\nCollision Detection과정에서 사용되는 진폭에 따른 충돌 감지는 무선환경에서는 진폭변화가 크지 않기 때문에 충돌에 의한 것인지 아닌지를 판단하기가 힘들기 때문\n\n\n\nInter Frame Space(IFS) §\n\n\n일단 통신의 과정은 그냥 보낸다고 끝이 아니라 보내고 나서 ack까지 받는 것까지 해야 하나의 프레임을 전송 완료한것이다라고 말할 수 있다\n이때 전송이 완료되고 회선이 비워지더라도 바로 보내지 않고 ACK보내는 시간을 배려해주기 위해 무조건적으로 대기해야되는 시간을 IFS라고 하며 IFS의 종류에는 여러가지가 있다\n\n먼저 수신자 입장에서 프레임을 수신하고 ACK를 송신할때 바로 보낼 수 있는게 아니라 수신 모드에서 ACK 송신모드로 전환하는 과정이 필요한데 이 과정에 소요되는 시간을 Short Inter Frame Space(SIFS) 라고 하는 것 이다\n즉, SIFS는 수신 이후 ACK전송까지 걸리는 시간이므로 최소한적으로 대기해야되는 시간인 것이다\nSIFS말고 다른 IFS들은 차차 등장하게 된다\n\n\n그래서 엿듣고있는 놈들은 중간의 SIFS시간까지 전부 포함해서 회선이 busy인 것으로 판단하게 되는 것 이다\n이제 CSMA / CA에서는 회선이 idle해지면 바로 보내는게 아니라 일단 SIFS만큼의 시간을 기다리고, binary back-off만큼의 시간을 추가적으로 기다린 후 회선이 여전히 비었으면 보내게 된다\n\nCSMA / CD에서는 저 binary backoff를 충돌이 났을 때에 주로 사용하는데 CSMA / CA에서는 SIFS이후 기다리는 시간에 사용한다는 것이 차이점이다\n\n\n\n\n\n여기서 이제 Contention window라는 말이 나오게 되는데 이게 뭐냐면 binary backoff를 통해 난수를 하나 뽑을 때 2^시도횟수(K) - 1개의 상자가 있고 여기에서 그것중에 하나를 고르는 식으로 난수의 생성이 이루어지는데 이때의 상자를 저거라고 부르는 것 이다.\n\n\n\n위 그림이 이 CSMA / CA에 대한 플로우 차트이다\n\n\n마찬가지로 시도횟수(K)로 시작한다\n그리고 Channel이 idle한지 계속 확인한다\n\nidle해지면 다음단계로 넘어간다\n\n\n그리고 우선 IFS(SIFS) 를 대기하고 아직도 idle한지 확인한다\n\n여전히 idle하면 다음단계로 넘어가지만 busy하다면 다시 2번으로 돌아간다\n\n\nBinary Back-off를 시도하고 나온 난수 R만큼의 슬롯을 넘긴다. 그리고 프레임을 전송한뒤 타임아웃될때까지 ACK를 기다린다\n\n만일 ACK가 수신되면 성공이지만 그게 아니라면 다음단계로 넘어간다\n\n\n시도횟수(K)를 1 증가시키고 이게 최댓값보다 큰지 검사한다\n\n최댓값보다 크다면 전송 취소(Abort)하고 아니라면 2번으로 돌아간다\n\n\n\n\n근데 보면 binary backoff로 구한 난수만큼의 슬롯을 지나치고 그 난수에 해당하는 슬롯이 왔을때 프레임을 전송하는 것으로 보아 p-persistance에 IFS시간을 추가한 것과 유사하다는 것을 알 수 있다\nCSMA / CA는 지금의 와이파이 프로토콜의 기반이 되는 기술 이라고 할 수 있다\n\nControlled Access §\n\nControlled Access는 회선에 접근하는 station들을 잘 컨트롤해서 충돌이 아예 일어나지 않게 하는기법이다\n얘는 이제 Reservation, Polling, Token Passing의 방법이 존재한다\n\nReservation §\n\n얘는 이제 “어떤” 기준점을 잡는 놈이 송신할 순서를 미리 정해 이것을 미니 프레임에 담아 전송을 한다\n그러면 나머지가 이것을 수신하고 자기 차례가 몇번째인지 확인한 후, 자기 차례가 오면 송신을 하는 구조\n하지만 이론적이 내용일 뿐 실제로는 쓰이지 않는댄다\n\nPolling §\n\n\n얘도 이제 기준점이 필요한데 이 중앙 시스템을 Primary라고 한다\n\nStation에서 Primary로 데이터를 보내고자 할 때 §\n\n먼저 primary가 Poll을 보내 보낼 데이터가 있는지 묻게 된다\n\nPoll은 보낼 데이터가 있는지 station에게 묻는 것을 말함\nprimary의 중앙 통제 하에 모든 통신이 이루어지므로 station이 먼저 데이터를 보낼 수는 없고 primary의 poll이 들어오면 그때 데이터를 보낼 수 있는 권한을 얻게 되는 것이다\n\n\n그리고 만약에 station이 보낼 데이터가 없으면 NAK을 보낸다\n하지만 station이 보낼 데이터가 있으면 Data를 보내고 primary는 수신했다는 뜻으로 ACK를 송신한다\n\nPrimary에서 Station로 데이터를 보내고자 할 때 §\n\n이것도 먼저 primary가 먼저 보내게 되는데 이때는 SEL을 보내게 된다\n\nSEL은 보낼게 있는데 받을 준비가 되었느냐는 뜻이다 - QRV같은놈이제\n\n\n이때 station이 준비가 되었으면 ACK를 보내고\n그럼 primary는 Data를 보내게 된다\nstation이 제대로 수신했으면 ACK를 보내는 것으로 통신이 마무리되게 된다\n\nStation -&gt; Station §\n\n일단 Polling방식에서는 아까말한대로 통신이 primary의 통제 하에 이루어 지므로 station이 먼저 데이터를 보낼 수는 없다\n\n\n따라서 송신 station은 primary의 Poll을 기다렸다가 오면 Data를 먼저 primary로 보낸다\n그리고 primary가 수신 station으로 SEL을 보내 Data를 전송하는 방식으로 station간의 통신이 이루어지게 된다\n\n\n따라서 station이 station으로 바로 데이터를 보낼 수는 없고 primary를 거쳐야만 station → station의 통신이 가능하다\n\nToken Passing §\n\n얘는 이제 약간 수건돌리기같은거다\n회선을 사용할 권한을 갖고있는 놈한테 Token이 주어지는데\n이것을 갖고있는 놈이 데이터를 다 보내고, 데이터를 다 보냈으면 다른놈한테 이 Token 을 전달하는 방식으로 통신이 이루어짐\n하지만 얘도 별로 사용하지 않는댄다\n\nChannelization Protocol §\n\n이제까지는 한 station이 대역폭 전체를 사용해 통신할 떄 순서를 나눠서 충돌이 일어나지 않게 하는 방법이었다면, 얘는 대역폭으로 사용시간에 따라, 주파수에 따라, 그리고 코드라는 것에 따라 나눠서 통신하여 충돌을 줄이는 개념이다\n넓은 대역폭을 잘라 통신하는 방법이라 하니 앞에서 배운 무언가가 막 생각나쥬? - Multiplexing이랑 Spreading을 활용하는 방법이다\n이용하는 사람이 많아지면 그만큼 더 조밀하게 자르고(더 느려짐), 적어지면 더 널찍하게 대역폭을 잘라 사용(더 빨라짐) 하게 되는데 그래도 한번에 여러 station이 동시에 회선을 사용할 수 있다는 장점이 있다\n요즘은 이 방법들을 한가지만 사용하는게 아니고 다 모아서 장점들만 살려 통신하는 기법을 사용한다고 한다네\nFDMA와, TDMA, CDMA등의 방법이 있다 - 하지만 학부때는 FDMA와 TDMA는 자세하게는 설명하지 않는댄다\n\nFrequency-Division Multiple Access(FDMA) §\n\n회선의 대역폭 주파수를 잘라 통신하는 기법\nFDM과 대응되는 개념인거지\n\nTime-Division Multiple Access(TDMA) §\n\n회선을 사용하는 시간을 나눠 통신하는 기법\nTDM과 대응되는 개념인거지\n\nCode-Division Multiple Access(CDMA) §\n\n얘는 이제 DSSS를 활용하는 방법이다 - 뭔지 기억 안나면 Spread Spectrum부분 다시 읽고 와라\n만약에 spreading code를 절묘하게 짜게 된다면 데이터의 충돌이 일어나도 원 데이터를 꺼낼 수 있다 - 한 대역폭에 시간차를 두지 않고 통신해 당연히 충돌이 나지만 그럼에도 불구하고 잘 짜여진 Spreading Code를 이용해 충돌 데이터에서 원 데이터를 꺼내는 방식으로 충돌을 무시하는 방법이 CDMA의 개념이다\n\n작동방식 §\n\n\n봐봐라\n일단 맨 위에 있는게 진폭 설정 방식이다 - 데이터0은 진폭(-1) 으로, 1은 진폭(+1) 으로, 데이터가 없을때는 진폭(0) 으로\n그리고 저 박스들이 다 station이다\n저 박스들은 각자의 spreading code를 가지고 있다 - 저 분홍색 []가 spreading code이다\n그리고 박스 안으로 진폭이 들어오면 저 spreading code와 곱해지고 이 곱해진 결과가 박스와 channel사이에 있는 검은 []다\n얘네가 이제 충돌이 일어난 결과가 노란색 박스가 되는데\n근데 신기하게도 여기에 각자의 spreading code를 곱하면 원래의 데이터를 뽑아낼 수 있게 된다\n\n만약에 station 2 가 보낸 데이터가 뭔지 알고 싶으면 station 2 의 spreading code인 C2를 곱해서 더하면 -4가 나오게 된다\n근데 -4는 음수이므로 데이터0으로 판단하게 되는데 이것은 정확하게 station 2 가 보낸 데이터와 동일하다\n나머지 station이 보낸 데이터를 확인하고 싶어 각자의 spreading code를 곱해봐도 원래의 데이터가 나오게 된다\n\n\n\nSpreading Code 만드는법 §\n\n\nWalsh table을 사용하면 Spreading Code를 손쉽게 만들어 낼 수 있다\n위쪽이 귀납법으로 만들어진 table의 생성규칙, 아랫쪽이 생성 예시이다\n“Wn바”는 Wn의 모든 부호를 반대로 바꿔준다는 뜻이다\n저 생성된 행렬의 행(열)단위로 읽으면 그게 spreading code가 되는 것\n"},"originals/datacommunication.spring.2021.cse.cnu.ac.kr/08.-Ethernet":{"title":"08. Ethernet","links":[],"tags":[],"content":"\n\n                  \n                  충남대학교 컴퓨터공학과 김상하 교수님의 &quot;데이터 통신&quot; 강의를 필기한 내용입니다. \n                  \n                \n\n\n\n                  \n                  다소 잘못된 내용과 구어적 표현 이 포함되어 있을 수 있습니다. \n                  \n                \n\nIEEE 802 Standards §\n\nIEEE 802 표준 : LAN환경에서의 물리계층과 데이터 링크 계층의 여러 함수들을 표준화 함\nLAN이라는 것은 Local Area Network즉, 단거리 지역통신망을 뜻한다\n얘는 OSI나 인터넷 모델과는 관련이 없는 표준이다\n\nData Link Layer, Physical Layer §\n\n\n데이터 링크 계층은\n하나의 LLC(에러 잡는 기능 - 앞에서의 Data Link Control과 동일)\n여러개의 MAC으로 구성된다\n\nIP같은 상위 계층 프로토콜은 이 LLC의 서비스를 이용하지 않는다 - IP는 오류에 그렇게 민감하지 않댄다\n그리고 MAC에는 Ethernet이나 Token ring, Token bus들의 여러 프로토콜이 존재하며 각각의 프로토콜에 대한 Physical Layer가 개별로 존재한다\n\n\n\nData Link Layer Header §\n\nHDLC의 헤더가 IEEE 802에서는 어떻게 구현되는지 함 봐라\n\n\n\n일단 HDLC의 ADDRESS는 DSAP와 SSAP의 이름으로 LLC PDU로 들어가게 된다\n\n우선 LLC PDU가 Data Link Control용도의 header가 붙은 프레임이라고 생각하면 된다\nDSAP는 수신지 주소이고\nSSAP는 송신지 주소이다\n\n\n그리고 CONTROL과 DATA도 LLC PDU로 들어간다\n그리고 이 LLC PDU는 MAC frame의 MAC payload로 들어가게 된다\n\nMAC입장에서 상위에 있는 LLC의 프레임이 MAC의 DATA로 그대로 들어가게 되는 셈\n그리고 이 MAC payload가 MAC header와 FCS가 붙으며 MAC frame가 생성되는 것이다\n\n\n\nEthernet §\nStandard Ethernet §\n\n옛날에는 컴퓨터 간 통신을 하기 위해 네트워크 장비를 하나 두고 그것을 통해서 통신을 했는데\nLAN(Local Area Network) 즉, 단거리 통신의 경우 통신을 위해 네트워크 장비를 하나 두자니 너무 비싸고\n그렇다고 모든 컴퓨터들을 모두 랜선을 이용해 연결하자니 너무 복잡하고 지저분해서 어떻게 할까 하다가\n회선 하나에 컴퓨터들이 그냥 다 달라붙는 Bus Topology을 이용하고 이러한 이더넷 방식인 Bridged Ethernet을 이용하는 것으로 아이디어를 내게 된다\n근데 앞에서 배운대로 이렇게 통신하면 충돌의 위험이 있으므로 MAC의 프로토콜을 이용해 충돌을 제어하는데 Ethernet의 기반이 되는 MAC 프로토콜은 1 - persistent CSMA / CD이다\n가장 기본이 되는 FStandard Ethernet는 10Mbps의 속도를 가지며 속도가 더 빠른 애들도 있다\n\n데이터 링크 계층 §\n\n\n위 그림이 프레임의 헤더 구성이다. 물리계층 헤더인 Preamble, SFD가 존재하고\nCSMA / CD를 사용하기 때문에 데이터의 최솟값이 정해져있다(최소 46바이트, 최대 1500바이트)(너무 짧으면 CSMA / CD기술을 사용하는 의미가 없다고 전에 설명했었쥬?) 그리고 너무 커도 오류가 많이 나 재전송이 많이 일어나기 때문에 데이터의 최댓값도 정해져있다\n\n물리 계층 §\n\n신호의 세기 변화에 따라 0과 1을 나누는 Manchester scheme을 사용한다 - 기억안나면 앞에보그라\nManchester scheme의 경우에는 1bit의 데이터를 보내기 위해 2개의 signal element를 사용하므로 굉장히 비효율적이지만 10Mbps의 속도로 전송하는 standard ethernet에서는 낫배도더라\n왜냐하면 보통 ethernet 통신을 위한 회선은 100M-baud를 사용하는데(Mbaud라는 것은 초당 그만큼(메가)의 signal element를 보내는 것을 말한댄다 - 이것도 옛날에 설명했었넹) 10Mbps를 보내기 위해서는 20Mbaud만 가지고도 충분하므로 저걸 이용한댄다\n그리고 10Base5혹은 10Base2(10Mbps, 디지털 신호, 500미터 혹은 200미터)의 Coex cable, 그리고 10BaseT(10Mbps, 디지털신호, Twisted pair(UTP))케이블, 10BaseF(10Mbps, 디지털신호, Fiber)케이블을 이용한댄다\n\n물리계층의 발전 §\n\n처음에 등장한 이더넷은 Bus Topology을 이용한 이더넷 방식인 Bridged Ethernet를 사용했었다\n근데 이제는 회선 하나에 다 달라붙지 않고 중앙 Switch에 달라붙는 방식을 사용하는데 이런 방식을 Star Topology라고 한다\n\n여기에는 두가지 방식의 이더넷이 존재하는데\nSwitched Ethernet은 중앙 switch에서 스위치마냥 station을 하나씩 켜주면서 통신 carrier를 한번에 한놈만 사용할 수 있도록 해주는 것이다\nFull-duplex switched Ethernet은 중앙 Switch에 각 station에 대응되는 입출력 메모리 버퍼가 있어서(입력버퍼 하나, 출력버퍼 하나로 station마다 2개의 버퍼를 갖게 됨) station이 switch로 보내면 버퍼에 저장되고 한 station의 버퍼에서 다른 station의 버퍼로 switch가 패킷을 옮겨주는 방식으로 통신을 하게 됨 - 그럼 그 버퍼에서 station으로 패킷을 옮겨주는 것으로 통신이 이루어지는 셈\n\n\n\n\n어쨋든 이제 중앙 회선이 단순히 구리선 하나가 아니라 네트워크 장비가 되어서 더 좋고 얘가 컨트롤하니까 충돌도 안일어나고 좋다 이거야\nToken 방식은 station이 하나 추가되었을 때 얘한테도 토큰이 넘어가야되도록 바꿔주고 에러가 났을때 아무도 토큰을 받지 못하는 등의 귀찮은 것들이 있었는데 이제는 그런게 없더라\n\nFast Ethernet(IEEE 802.3u) §\n\n더 빨라 광섬유 통신과 경쟁할 목적으로 만들어짐\n속도만 빠르게 하고 나머지 frame구조라던가 크기제한은 그대로 가져간다더라\nFull-duplex switched ethernet만 사용해 bus-topology와 CSMA / CD는 더 이상 사용하지 않는다 - 하지만 기존버전과의 호환성을 위해 남겨두긴 했다네\n\n\n\ncable으로는 위와 같은애들을 사용한댄다\n그리고 encoding방법도 더 이상 Manchester scheme을 사용하지 않고 저 위의 세 cable마다 다른 encoding 방법을 사용한다\n\nGigabit Ethernet(IEEE 802.3z) §\n\n얘도 프레임 구조와 크기제한을 그대로 가져가 호환성을 유지한다\nStar Topology를 그대로 사용한다. 대신\n허브끼리 연결하는 multiple stars\n허브도 계층적으로 구조화 한 hierarchy of stars등의 방법도 추가해서 사용한다\n\n\n\n위 그림이 그소리임\n\n\n\n그리고 이런 cable을 사용한댄다\n그리고 encoding 방식도 cable마다 다른 encoding방식을 사용한댄다\n그냥 다르다는것만 알고 구체적인것은 지금 몰라도 된다\n\nTen-Gigabit Ethernet(IEEE 802.3ae) §\n\n뭐 위에와 거의 동일하다\n다만 이전까지는 MAC기능을 넣어놓되 사용하지 않았지만 얘는 MAC의 기능을 아예 넣어놓지 않았다\n"},"originals/datacommunication.spring.2021.cse.cnu.ac.kr/09.-Wireless-LAN-(1)":{"title":"09. Wireless LAN (1)","links":[],"tags":[],"content":"\n\n                  \n                  충남대학교 컴퓨터공학과 김상하 교수님의 &quot;데이터 통신&quot; 강의를 필기한 내용입니다. \n                  \n                \n\n\n\n                  \n                  다소 잘못된 내용과 구어적 표현 이 포함되어 있을 수 있습니다. \n                  \n                \n\nWifi - IEEE 802.11 §\nArchitecture - BSS, ESS §\n\nBSS : station들이 서로에게 프레임을 보낼 수 있을 만큼 가까이 붙어있는 환경을 말함\n\n하나의 공유기를 공유하는 환경이라던가, 공유기 없이도 그냥 무선으로 프레임을 주고받을 수 있을 정도로 가까이 있는 환경\n공유기같은걸 AP라고 생각하면 된다 - station과 무선으로 통신해 인터넷이랑 연결해주는 장치\n\n\nESS : 반면에 얘는 station들이 멀리 떨어져 있어서 station - AP - 유선망 - AP - station 이렇게 연결되는 경우를 말한다\n\nMAC Sublayer - PCF, DCF §\n\n앞에서 배운 대로 station과 AP모두 프레임 큐가 있어서 이것으로 프레임을 보낸다\n다만 충돌이 일어나지 않아야 하므로 누군가가 프레임을 보낼때는 다른 모두는 프레임을 보내지 말아야 하며 이것을 CSMA / CA나 polling등으로 제어하게 된다\nPCF(Point Coordination Function) : 하나의 중앙장치를 기준으로 무선통신을 하는 것\n\nAP가 이 중앙장치의 역할을 함\n중앙장치가 존재하기 때문에 Poilling방식을 사용할 수 있고 따라서 contention-free 즉, 충돌이 없다\n\n\nDCF(Distributed Coordinated Function) : 중앙장치 없이 무선통신하는 것\n\n중앙장치가 없기 때문에 CSMA / CA의 방식으로 통신을 하며 즉, contention하다 - 충돌이 가능하다\n\n\nAP가 존재하는 BSS통신에서는 PCF를 사용할 수 있기 때문에 PCF와 DCF를 모두 사용한다. 다만 우선순위는 당연히 PCF가 DCF보다 높다\n반면에 AP가 존재하지 않는 BSS통신에서는 PCF를 사용할 수 없기 때문에 DCF만 사용할 수 있다\n따라서 상황에 따라서 DCF와 PCF를 골라서 사용하기 때문에 MAC layer에는 이 둘을 지원하는 부분이 모두 존재함\n\nIEEE 802.11에서의 CSMA/CA §\nIFS 종류 §\n\n\nSIFS : 뭔가를 수신하고 그에 대한 응답을 준비해서 보내고 상대방이 응답을 받을 때 까지의 최소의 시간 - 프레임을 받고 나서 ACK를 보내기까지 걸리는 시간이나 ACK를 받고 나서 다음 프레임을 보내기까지 걸리는 시간 등\nPIFS : AP가 기다리는 시간. AP는 다른 station보다는 우선권을 가지기 때문에 DIFS보다 더 짧은 시간인 PIFS만을 기다리고 데이터를 보내는 것이 가능하다\nDIFS : 다른 station이 기다리는 시간. Carrier sensing을 했을 때 그것이 ACK가 아닌 프레임이면 프레임의 전송이 끝나고 idle해지면 IFS를 기다려야 되는데 일반 station의 경우에는 AP보다 우선권이 없기 때문에 IFS중에 제일 긴 DIFS을 기다리고 룰렛을 돌리게 된다\n즉, 경쟁을 하는 상황이라면 DIFS의 시간을 기다리는 거고 우선권이 있는 상황이라면 SIFS의 시간을 기다리며 AP의 경우에는 경쟁상황에서 우위에 있어야 하기 때문에 SIFS보다는 길지만 DIFS보다는 짧은 PIFS의 시간만을 기다리게 되는 것\n\nVirtual Channel Sensing in CSMA / CA §\n\n\nDCF에서의 CSMA / CA는 좀 다르다\n\n먼저 Idle해지면 DIFS를 기다리고 RTS(Request To Send) 를 보낸다\n\n얘는 아주 작은 프레임으로 사이즈가 작기 때문에 detection을 하기도, correction하기도 아주 쉬움\n\n\n만약 송신하고자 하는 놈이 얘 혼자뿐이면 수신자가 SIFS를 가다리고 회선이 비어 송신해도 된다는 뜻의 CTS(Clear To Send) 를 보내게 된다\n\n그럼 송신자가 CTS를 받고 SIFS를 기다린 후 패킷 전송을 시작한다.\n중요한 점은 RTS나 CTS를 수신했을 때에도 SIFS만큼의 시간만 기다리고 데이터를 보내게 된다\n왜냐면 RTS나 CTS를 정상적으로 수신했을 때에는 자기가 우선권을 획득했기 때문에 데이터의 충돌을 우려하지 않아도 돼 SIFS만큼의 시간만을 기다리고 송신하는 것\n\n\n만약 송신하고자 하는 놈이 얘만이 아니면 어떻게 되냐 - RTS가 깨져서 수신자에게 수신되기 때문에 지금 송신하려는 애들이 더있구나라는걸 알게 된다.\n\n따라서 수신자는 CTS를 보내지 않고 그럼 송신자 또한 지금 통신하면 안된다는 것을 깨닫고 Back-off를 실시한다\nBack-off과정에서 대기시간이 랜덤으로 정해지기 때문에 대기시간 이후 여러명의 송신자가 RTS를 동시에 보내는 일이 없어진다\n\n\n\n\nRTS를 먼저 보내는 것은 만약 큰 데이터를 보냈다가 충돌이 나면 그것을 다시 보내거나 복구하는 데에 자원이 많이 필요하기 때문에 아주 작은 데이터를 먼저 보내서 충돌이 나는지 안나는지를 먼저 검사하는 것\n\n\n그리고 기존의 CSMA / CA와 다른 점은 **Network Allocation Vector(NAV)**라는 것이 존재한다는 것이다 - 얘는RTS와 CTS의 헤더에 들어가 있는 필드인데 내가 데이터를 보내는데 ~만큼의 시간이 걸릴 거 같은데 이 시간동안만큼은 좀 양보해 달라 라는 의미이다\n\n이 NAV가 존재함으로써 RTS나 CTS를 수신한 다른 station들은 이제 그 시간만큼은 쟤한테 양보해 sensing조차 하지 않고 그냥 잠수하게 된다\n불필요한 sensing을 하지 않아도 되기 때문에 더 효율적이라는 장점이 있음\n저 위의 그림에서는 D station은 A가 송신한 내용은 듣지 못하지만 B가 송신한 내용은 들을 수 있는 위치에 있는 station이어서 저렇게 CTS수신 이후 NAV만큼 기다리는 예시랜다\n\n\n\nIEEE802.11에서의 PCF, DCF통신 §\n\nCFP - Contention Free Period : 중앙 AP를 이용해 통신하여 충돌이 일어나지 않는 기간(PCF)\nCP - Contention Period : 중앙 AP을 이용하지 않고 통신해 충돌이 일어날 수 있는 기간(DCF)\n와이파이에서는 이런 AP를 통한 통신과 통하지 않는 통신을 모두 지원한다\n어떻게 지원하냐면 일단\n\n\n\nAP에서 PIFS를 기다린 후에 Beacon(Management Frame) 이라는 애를 먼저 보낸다 - PIFS가 DIFS보다 짧기 때문에 AP가 우선권을 갖고 Beacon을 보낼 수 있다\n이 Beacon 패킷에는 PCF로 통신할 시간과 DCF로 통신할 시간, 그리고 다음 Beacon을 보낼 시간(이 과정을 반복할 시간 간격 - Repetition Interval)이 들어있다\n\n예를 들면 지금부터 10분동안은 PCF로 통신하고 그 이후 10분동안은 DCF로 통신하자 + 총 20분 뒤에 다시 Beacon을 보낼 것 이다 라고 Beacon 패킷에 명시되어 있는 셈이다\n이렇게 AP가 통신 시간을 미리 통보하는것이 결국에는 Virtual Carrier Sensing을 지원하는셈인것 - PCF로 통신하는 동안에는 station들은 Carrier Sensing을 하지 않아도 되므로 - 즉, 위에서 배운 NAV를 설정함으로써 PCF로 통신할 시간을 명시하는 것 이다\n만약 AP에 있는 송신할 내용이 담긴 큐가 거의 다 차서 송신할게 많은 경우에는 PCF시간을 길게 잡고 DCF시간을 짧게 잡거나 없애는 식으로 유동적으로 변경한다\n\n\n그래서 PCF시간 동안에는 AP를 중심으로 Polling방식의 통신이 이루어진다\n\n위에 예시 보면 먼저 A에게 Data를 보내고 너도 보낼 데이터가 있냐는 뜻의 Poll을 보내게 된다\n그러면 A에서는 잘 받았다는 ACK와 함께 자신도 보낼 데이터를 보낸 뒤\nAP서는 잘 받았다는 ACK를 A한테 송신하고 B에게 보낼 데이터가 있냐고 Poll을 보내면\nB도 보낼 데이터가 있어 AP한테 Data를 보내고\nAP에서는 잘 받았다는 ACK와 함께 이제 PCF를 종료하고 DCF로 넘어가도 된다는 뜻인 CF-End를 보내게 되는 것\n\n\n\n\n보면 처음에 Beacon을 보내는 것은 AP한테 우선권이 있어야 하므로 PIFS만을 기다리고 보내게 되고\nPCF동안에는 충돌의 위험이 없으므로 SIFS만을 기다리고 패킷을 보내며\nPCF가 동료된 후에는 DCF로 통신하기 때문에 DIFS를 기다리는 것을 알 수 있다\n그리고 Beacon 송신과 PCF통신의 경우 충돌의 위험이 없으므로 CFP가 되는 것 이고\n그 이후의 DCF통신의 경우 퉁돌이 일어날 수 있으므로 CP가 되는 것 이다\n그리고 CFP와 CP를 합친 이 반복되는 단위를 Super Frame이라고 한다\n\nFrame Format - 프레임의 구조 §\n\n얘는 일단 Frame의 구조를 일반화한 그림이다\n\n\n\nType과 Subtype을 이용해서 그 뒷부분을 어떻게 해석해야되는지 명시한다\nType 00 이면 Management type인데 이때 Subtype 1000이면 얘가 Beacon으로 기능한다는 것을 나타낸다\n\n\n\nType 01이면 Control type인데\n\nSubtype 1011이면 RTS\nSubtype 1100이면 CTS\nSubtype 1101이면 ACK로 기능한다는 것을 나타내며\n더 자세한 것은 위에 나와있다\n\n\nType 10이면 Data type이고 그냥 얘가 Data 전송용 프레임이라는 것을 나타내는 것 - 얘도 Subtype에 뭔가를 넣어서 그냥 데이터인지, 데이터랑 ACK를 같이 보내는 것인지 등을 알려준다\n\n\n\n얘는 Beacon Frame의 구조이다\n\n보면 일단 저 Time Stamp에는 AP의 현재 시간을 알려준다 - 혹시나 Station들의 시간이 AP와 다르면 오작동하므로 현재시간을 다 일치시키는 것(동기화하는 것)\n그리고 저기 Beacon Interval에 전체 시간(다음 Beacon을 보낼 시간 - Super Frame의 시간)을 명시하고\nDuration에 NAV시간을 명시함으로 이 시간까지는 PCF로 동작할꺼니 Carrier Sensing을 하지 말아라 라고 알려주는 것\n보면 프레임의 일반화된 구조를 나타낸 그림에서는 Address1라고 돼있던 부분이 여기서는 DA가 되었고 Address2라고 돼있던 부분이 SA가 되는 등 차이가 난다 - Frame의 type에 따라 뒷부분이 다르게 해석된다는 것이 이것을 말하는 것\n\n\n\n\n\n얘는 Control Frame의 구조인데 여기서 봐도 일반화된 구조랑은 차이가 나는 것을 알 수 있다\n"},"originals/datacommunication.spring.2021.cse.cnu.ac.kr/10.-Wireless-LAN-(2)":{"title":"10. Wireless LAN (2)","links":[],"tags":[],"content":"\n\n                  \n                  충남대학교 컴퓨터공학과 김상하 교수님의 &quot;데이터 통신&quot; 강의를 필기한 내용입니다. \n                  \n                \n\n\n\n                  \n                  다소 잘못된 내용과 구어적 표현 이 포함되어 있을 수 있습니다. \n                  \n                \n\nAddressing Mechanism §\nIntra, Inter BSS §\n\n\nIntra-BSS Communication : 애는 앞에서 배운 BSS 즉, 가시적인 거리에 있어 직접적으로 무선통신이 가능한 경우 - 얘는 송신주소와 수신주소인 Address 1과 Address 2만 있으면 된다\nInter-BSS Communication : 얘는 앞에서 ESS라고 배운, 거리가 멀리 떨어져 있어 직접적으로 통신하지 못하고 AP와 유선망을 통해서 통신하는 구조 - 얘는 Address 1, 2뿐만 아니라 뒤에있는 3, 4까지 사용한다\n\nAddressing Mechanism §\n\n\n이건 저 위에서 빨간점선박스인 To DS와 From DS에 따라 Address 1, 2, 3, 4가 어떻게 사용되는지 보여주는 그림이다\nAddress 1 : 현재의 통신에서 받는놈의 주소\nAddress 2 : 현재의 통신에서 보내는 놈의 주소\nAddress 3 : 최종 목적지 혹은 원래 송신지\nAddress 4 : 원래 송신지\n이게 뭐냐면 일단 Intra-BSS의 경우에는 두개의 station이 직접적으로 통신하기 때문에 보내는 놈의 주소와 받는놈의 주소만 있으면 된다 - 따라서 Intra-BSS 통신임을 나타내기 위해 DS bit에 00이 들어가고, Address 1과 2만 사용하는 것(BSS ID는 몰라도 된다)\n근데 이제 Inter-BSS 즉, ESS통신의 경우에는 다음과 같은 과정을 거친다\n\nstation A → station B로 ESS를 통해 보낸다 할 때\n\n\n먼저 A가 인접한 AP로 보낸다(A → AP1)\n그리고 그 AP가 B와 인접한 AP로 보낸다(AP1 → AP2)\nB와 인접한 AP가 B로 보낸다(AP2 → B)\n\n\n위와 같은 과정을 지원하기 위해 Address 1, 2뿐 아니라 3, 4까지 존재하게 되는데\n\n1번 과정 (A → AP1) 에서는 궁극적으로는 A → B 지만 일단 지금은 AP1으로 먼저 보내야 하기 때문에\n\n현재의 통신에서 받는놈의 주소(Address 1)은 AP1\n현재의 통신에서 보내는 놈의 주소(Address 2)는 A\n최종목적지(Address 3)은 B가 되는 것\n즉, (A → AP1) 은 ToDS와 FromDS를 10 으로 하는 주소 표기법을 사용한다\n\n\n2번 과정 (AP1 → AP2) 에서는 궁극적으로는 A → B 지만 일단 지금은 AP1이 AP2으로 먼저 보내야 하기 때문에\n\n현재의 통신에서 받는놈의 주소(Address 1)은 AP2\n현재의 통신에서 보내는 놈의 주소(Address 2)는 AP1\n최종목적지(Address 3)은 B\n원래 송신지(Address 4)는 A가 되는 것\n즉, (AP1 → AP2) 은 ToDS와 FromDS를 11으로 하는 주소 표기법을 사용한다\n\n\n3번 과정 (AP2 → B) 에서는 마지막으로 B에게 최종 전달이 되어야 하기 때문에\n\n현재의 통신에서 받는놈의 주소(Address 1)은 B\n현재의 통신에서 보내는 놈의 주소(Address 2)는 AP2\nAddress 3이 원래 송신지를 나타내는 용도로 쓰여 여기에는 A가 들어가게 된다\n즉, (AP2 → AP2) 은 ToDS와 FromDS를 01으로 하는 주소 표기법을 사용한다\n\n\n\n\n따라서 이 세가지 과정에 대해서도 프레임에 나타내기 위해 DS bit를 각각 과정에 따라 다르게 설정해서 Address 1, 2, 3, 4에 저장된 내용이 어떤 의미인지 나타내는 것\n\n위의 예시를 그림에 있는 표에 따라 살펴보면\n\n\n01일 경우에는 (3)번 과정으로 B, AP2, A 순으로 Address가 저장되고\n10일 경우에는 (1)번 과정으로 AP1, A, B순으로 Address가 저장되고\n11일 경우에는 (2)번 과정으로 AP2, AP1, B순으로 Address가 저장되는 것 이다\n\n\n간단하게 정리하면\n\n일단 Address 1, 2는 현재의 통신에 직접적으로 관여하는 station의 주소를 송-수신 수신 순서대로 적어준다\nAddress 3는 현재의 통신에 직접적으로 관여하지 않는 station의 주소를 적어주되 그런 station이 2개면 Address 3, 4에 송-수신 순서대로 적어준다\nInter-BSS통신에서는 DS Bit가 2 → 3 → 1인 순으로 주소체계를 사용한다\n\n\n\n\n\n위의 그림이 이 과정을 그림으로 나타낸 것 - 순서가 좀 섞이긴 했지만 Case 3 → Case 4 → Case 2 순으로 A → B 통신이 이루어지는 것 이다\n\nISM Band §\n\n이 회선은 Industrial, Scientific, Medical의 약자로 해당 목적을 가지고 있는 경우 공공의 목적으로 사용하기 위해 주파수 대역폭을 할당한 밴드이다\n하지만 파워가 너무 높은 경우(파워가 뭔지는 잘 모르게슴) 주변영역에 방해를 줄 수 있기 때문에 낮은 파워만 사용하게 한댄다\n이건 이정도만 알면 된댄다\n\nIEEE 802.15 - Bluetooth §\nArchitecture §\n\n\n일단 Piconet은 Primary 하나와 여러개의 Secondary로 이루어진 아주 소규모의 Contention-Free 네트워크를 의미하고\nScatternet은 Secondary 하나가 sub-Primary의 역할(Primary / Secondary)을 해서 또 다른 Secondary와 통신을 하는 구조를 의미한다\n블루투스의 Secondary는 Slave라고도 하는데 얘네를 아주 저렴하고 작게 만들어 다양한 곳에 집어넣기 위해 얘네의 프로세스는 아주 단순하게 만들고 프로토콜 또한 단순하게 설계했댄다\n\nLayer 구조 §\n\n\n위 그림이 블루투스의 계층구조를 나타낸 것인데 다 알필요는 없고\n\n일단 상위계층에서 만들어낸 음향이 아닌 데이터를 저 L2CAP으로 받아 데이터링크계층인 Baseband로 보내거나\n음성이나 음악같은 것들은 저 Audio를 통해 바로 Baseband로 들어오게 된다.\n그리고 그 아래 Bluetooth Radio가 물리계층이 되는것\n\n\n저 L2CAP 위의 부분들을 Bluetooth Protocol Profiles이라고 부르는데 얘네들과 L2CAP이 Upper Stack Layer(소프트웨어의 영역) 이고\n하위계층인 Baseband와 Bluetooth Radio는 Lower Stack Layer(하드웨어적 영역)\n이며 이 둘을 저 HCI(Host Controller Interface) 로 연결하는 구조랜다\n\nBluetooth Radio Layer §\n\n그냥 1Mhz짜리 79개로 이루어진 ISM Band를 이용하고 FHSS를 이용한다는 것 정도만 알면 된다\n\nBaseband Layer §\n\n얘는 이제 데이터링크 계층에 해당하는데\nCDMA를 좀 변형시킨 TDMA를 사용한다\n\n일단 시간을 625밀리초로 나눈 슬롯을 사용하고\n짝수번째 슬롯은 Primary만 이용하고\n홀수번째 슬롯은 Secondary만 이용하며\n충돌 방지를 위해 이것도 Primary가 특정 station을 polling하는 방식으로 진행된다\n\n\n\n\n\n위와 같은 그림처럼 진행됨 - 보면 625밀리초 단위로 슬롯이 나뉘어져 있고 짝수번째는 Primary만, 홀수번째는 Secondary만 사용하며 Primary가 Hop이라는 형태로 Poll을 보내면 Secondary 또한 Hop이라는 형태로 Data를 보내는 것을 알 수 있다\n\n\n\n위의 그림을 이해하기 위해서는 일단 데이터 링크가 두종류가 있다는 것을 알아야 한다\nSCO(Synchronous Connection Oriented) : 얘는 이제 전화통화처럼 완벽한 데이터 전송이 아니라 빠른 데이터 전송을 하고자 할 때 사용하는 방식이다. 얘는 빠르게 데이터들을 통신해야하기 때문에 첫번째 그림처럼 하나의 슬롯에 하나의 데이터를 주고받으며 신속하게 데이터를 전송한다\nACL(Asynchronous Connectionless Link) : 얘는 느리긴 해도 완벽한 데이터 전송을 하고자 할 때 사용하는 방식이다. 두번째와 세번째 그림처럼 여러개의 슬롯에 걸쳐 큰 크기의 패킷을 전송하여 여기에 data correction등의 기능까지 넣어 느리지만 정확한 전송을 지향한다(최대 5개의 슬롯까지 걸치는 것을 허용함)\n데이터 링크는 저렇게 SCO와 ACL로 두개의 link로 구성된 Physical link로 구성되어 있고 상위계층으로부터 전달받은 Frame의 Format이 SCO방식이냐 ACL방식이냐에 따라 다르게 전송하는 것\nAudio의 경우에는 딜레이가 없는 것이 중요하므로 SCO방식의 패킷을 전달하고\nL2CAP의 경우에는 소리가 아닌 중요한 데이터를 전송하므로 ACL방식의 패킷을 전달한다\n\nL2CAP §\n\n이더넷에서의 LLC Sublayer에 해당함\nAudio를 전송하지 않으므로 ACL방식의 패킷을 생산함\n데이터의 크기가 클 경우 실습시간에 한것처럼 Fragmentation(Segmentation) 을 이용하여 쪼갠다\n그리고 다양한 데이터를 하나의 패킷에 넣어서 보내는 Multiplexing도 지원한다\n\n전화걸고 받는 과정 §\n\n일단 통화가 개시되기 전에 상대방에게 전화가 왔다는 신호를 보내야 하기 때문에 이 과정은 L2CAP을 이용해 전화번호등의 데이터들을 ACL방식으로 신호를 보낸다\n그리고 상대방이 전화를 받으면 이제 Audio로 전환되어 SCO방식의 통신A이 이루어지게 되는 것\n"},"originals/datacommunication.spring.2021.cse.cnu.ac.kr/11.-Layer-Architecture":{"title":"11. Layer Architecture","links":[],"tags":[],"content":"\n\n                  \n                  충남대학교 컴퓨터공학과 김상하 교수님의 &quot;데이터 통신&quot; 강의를 필기한 내용입니다. \n                  \n                \n\n\n\n                  \n                  다소 잘못된 내용과 구어적 표현 이 포함되어 있을 수 있습니다. \n                  \n                \n\nProtocol §\n\nProtocol : 약속, 규칙 - 통신을 하려면 나혼자만 하는게 아니고 누군가 상대방이 있어야 하기 때문에 그 상대방과 이런식으로 통신을 하자고 약속을 한 것을 프로토콜이라고 하는 것\nStandards : Protocol은 그냥 규칙, 약속이기 때문에 많은 프로토콜들이 만들어질 수 있다. 하지만 이 프로토콜들이 전부 표준이 되는 것은 아님 - 프로토콜중에 제일 성능이 좋은 것을 하나 골라 표준으로 정하고 대부분의 사람들이 지키도록 만든 프로토콜이 스탠다드인 셈\nAlgorithm : 프로토콜을 알고리즘이란 말하고 섞어서 쓰기도 한다 - 알고리즘은 문제를 풀기 위한 기법인데 프로토콜은 컴퓨터들간의 양방의 문제를 풀기 위한 기법이므로 알고리즘이라는 말과 유사한 의미를 가진 셈 - 일반적으로 말하는 알고리즘은 하나의 컴퓨터에서의 문제를 해결하는 방법인것과는 다르게 프로토콜은 여러대의 컴퓨터들간의 통신에서 일어날 수 있는 문제를 해결한다는 차이점이 있지만 문제를 해결한다는 점에서는 동일하기 때문\n\n프로토콜의 구성요소 §\n\nSyntax : 프레임의 구조, 형식, 포맷, 즉, 첫 몇비트는 뭐고 그다음 몇비트는 뭐고 이런식으로 통신하는데 사용되는 프레임의 틀이라고 생각하면 됨\nSemantics : 얘는 Syntax로 표현된 형식, 포맷이 어떤 의미를 가지는 지 알려준다 - 즉, 하나의 프레임을 어떻게 자르는 지를 규정하는 것이 Syntax라면, 그 자른 부분들을 어떻게 사용할것인지를 명시하는 것이 Semantics인 것\nTiming : 얘는 flow control에서처럼 송수신 타이밍을 말한다 - 통신이라는 것이 쌍방이기 때문에 아직 수신자가 받을 준비가 안됐으면 보내면 안되는 등의 통신에 참여한 놈들끼리 이런 시간적인 약속또한 하는 것\n\nNetwork Model(Architecture) §\n\n통신을 하기 위한 소프트웨어를 만드는 일은 그 양이 너무 크고 방대하기 때문에 이것 전체를 한꺼번에 개발하는 것은 불가능하다\n그래서 이 전체 시스템을 여러 계층으로 쪼개어서 분업하자는 생각이 나오게 된 것 - 이것에 네트워크 계층의 시작이다\n따라서 사람들을 자기 분야의 계층만 연구하면 되고, 이것을 이어붙이기만 하면 전체 시스템이 완성되는 방향으로 네트워크 개발이 이루어지고 있다\n이렇게 해서 완성된 모델은 OSI 7 layer라고 하는 지금은 잘 사용되지 않지만 그래도 이 네트워크 계층이라는 개념의 근간을 이루고 있는 선언적인 시스템과\n인터넷 네트워크의 표준인 TCP / IP가 있다\n\nLayered Architecture §\n\n위에서도 말했지만 아주 크로 방대한 것을 계층적으로 잘라 각각을 개발하고 이어붙이는 기법 을 말하는데\n일단 Layered Architecture(계층적 구조) 라는 것은 다음과 같은 말이다 - 상위계층에서는 하위계층의 기능을 사용할 수 있지만, 하위계층에서는 상위계층의 기능들을 사용하지 못함\n이 계층들을 구현한 것을 모듈(module) 이라고 한다\n그리고 이것을 이어 붙이는 것은 인터페이스(Interface) 라는 것을 사용한다 - 얘는 계층들을 이어주는 다리라고도 생각할 수 있으며 인터페이스가 존재함으로써 하나의 계층이 내부적으로도 수정되어도 인터페이스만 동일하다면 이 계층을 사용하는 다른 계층은 수정할 필요가 없다는 장점이 존재한다 - 마치 OOP에서의 추상화처럼\n여기서 Peer-to-Peer통신이라는 것은 계층간의 통신을 말한다.\n\n여기서 계층간의 통신이라는 것은 진짜로 계층간에 회선이 연결되어 계층끼리 통신한다는 소리가 아니다\n\n\n\n\n\n위의 그림에서 보이는 것 처럼 계층x에서 하위계층으로 어떤 패킷을 내려보내면 다른station의 해당 계층x에서도 동일한 패킷을 받으므로 계층간 통신을 하는 것으로 간주한다는 것\n그리고 다른계층에서 어떤일이 일어나는지는 전혀 상관할 바가 아니기 때문에 그냥 전선 하나 띡 이어져 있는것처럼 생각해도 된다는 소리이다\n이렇게 함으로써 얻을 수 있는 장점은 station간의 통신이라는 거대한 문제를 계층간 통신이라는 작은 문제들로 나눠서 해결하게 되므로 더 쉬워진다는 것이다\n위의 그림에서 볼 수 있듯이 하나의 계층은 상위계층에서 뭔가 전달받으면 그것 전체를 그냥 데이터로 간주해 거기다가 자신의 헤더나 그런것들을 붙여 하위계층으로 내려보내는 거고 하위계층에서 전달받으면 거기에서 상대방이 붙인 헤더만 떼어서 상위계층으로 올려보내는 작업만을 한다\n\nOSI Model §\n\nIBM이 개발해 표준으로 채택된 모델\n\nPhysical Layer §\n\n\n얘는 이제 최하위 계층으로 상대방의 Physical layer로 최대한 오류가 적게 나는 방법으로 전송하는 것에만 신경쓴다 - 오류가 안난다는 말이 아니고 오류를 최대한 줄여 상대방이 이해할수는 있게\n즉 어떻게 비트들을 인코딩하여 보내고 그렇게 받은 비트들을 어떻게 디코딩하는지에만 집중하는 계층이다\n\nData Link Layer §\n\n\nData Link Layer의 역할은 Reliable Control 을 수행하는 것인데 이것은 다음처럼 다섯가지로 나눠질 수 있다\n\nError Control : Error Detection하는 일\nFlow Control : Flow Error를 막기 위해 흐름을 제어하는 것\nAccess Control : 패킷의 충돌을 막기 위해 제어하는 것\nFraming : 데이터의 크기가 너무 커지면 Redundancy Bit도 너무 커져서 프레임단위로 나누는 것\nAddressing : 물리주소를 할당하여 패킷이 제대로 도착할 수 있도록 하는 것\n\n\n이 계층은 오류가 전혀 없는 완전무결한 통신, 즉, Reliable Control을 위한 작업만 수행한다\n\n\n\n근데 여기서 Reliable Control이라는 것은 Hop-to-Hop Delivery에서의 완전무결한 전달을 의미한다.\n즉, station하나에서 다른 station으로 갈 때 여러개의 정거장을 거치게 되는데 data link layer가 보장하는 reliable control이라는 것은 station에서 station까지의 완전무결한 통신이 아닌 정거장 하나에 대한 이동(이것을 Hop-to-Hop이라고 한다)에 대한 완전무결한 통신인 것이다\n\n안타깝게도 컴네때 배우겠지만 이렇게 부분구간을 완벽하게 한다고 해서 전체구간이 완벽해지는건 아니랜다\n\n\n\nNetwork Layer §\n\n\n데이터 링크 계층까지는 hop-to-hop통신을 보장하지만 네트워크 계층은 hop-to-hop통신을 넘어 결과적으로 Source-to-Destination까지의 통신을 보장한다\n즉, 단순히 다음 정거장까지 무사히 가는것 뿐만 아니라 원하는 목적지까지 무사히 가는것을 목표로 하는 계층인 셈\n\nTCP / IP §\n\n일단 얘는 Physical layer와 data link layer에 대해서는 별로 관심을 갖지 않는다\n그리고 상위 3개의 계층인 Application layer, Presentation layer, Session layer를 하나로 묶어 Application layer로 퉁치고\n그 아래 계층인 Transport layer로 TCP를 사용하며\n또 그 아래 계층인 Network layer로 IP를 사용하는 프로토콜을 의미한다\n그리고 이런 IP 모듈을 사용하는 통신망에 연결했을 때를 우리가 인터넷에 연결되었다 라고 하는 것\nTCP / IP는 OSI 7 layer보다 먼저 나왔다 - 그래서 상위 3개의 계층이 통합된게 아니라 사실은 분리되지 못한셈임\nOSI가 더 구조적으로 이상적인 모습을 하고 있지만 결국에는 TCP / IP에 밀려 사용되지 않았다 - 구조적으로 분리하는 것이 더 알아보기 쉽고 좋지만 그만큼 성능에의 하락이 존재하기 때문\n그리고 물리계층과 데이터 링크 계층에 대해 관심을 갖지 않는다는 것은 어느것을 써도 유연하게 연결이 가능하다는 의미이기도 하다 - 물리계층과 데이터 링크 계층을 어느걸 써도 IP에만 연결되면 인터넷에 연결된 것이라고 하게 된다\n"},"originals/datacommunication.spring.2021.cse.cnu.ac.kr/12.-Network-Layer,-Routing":{"title":"12. Network Layer, Routing","links":[],"tags":[],"content":"\n\n                  \n                  충남대학교 컴퓨터공학과 김상하 교수님의 &quot;데이터 통신&quot; 강의를 필기한 내용입니다. \n                  \n                \n\n\n\n                  \n                  다소 잘못된 내용과 구어적 표현 이 포함되어 있을 수 있습니다. \n                  \n                \n\n통신의 전체적인 구조 §\n\n\n통신의 전체적인 구조를 OSI의 관점에서 보면 위처럼 구성이 된다\n중간에 Intermediate Node를 다른말로 Router라고 하는데 이게 바로 station두개를 이어주기 위한 중간다리인 셈\n그리고 Router들은 Network Layer까지만 이용한다 - 패킷을 보내는데 직접적으로 관여하는 계층은 Physical layer, Data link layer, Network layer 이 세개인 셈\nNetwork layer의 모듈로 IP를 사용하는 통신망을 이제 IP망이라고 하는 것\n\nAddressing §\n\n택배가 제대로 전달되려면 주소가 필요하듯이 패킷이 제대로 전달되기 위해서도 주소가 필요하다\n주소에는 Physical Address, Logical Address, Port Address, Specific Address가 있는데 specific address에서는 이번학기에서는 다루지 않는댄다\n\nPhysical Address §\n\nPhysical Address는 Link Address라고도 불리고 LAN이나 WAN로 연결된 노드의 주소를 의미한다\n근데 보통 LAN환경, 즉, Local 한 환경에서 주로 쓰인댄다\n이 주소는 데이터 링크 계층의 프레임에서 Hop-to-Hop Delivery를 위해 사용되는 주소라고 알고있는게 이해하기 쉽고 데이터 링크 계층의 프로토콜 중 하나인 MAC 프로토콜에서 쓰이는 MAC Address나 Ethernet 프로토콜에서 쓰이는 주소인 Ethernet Address가 포함된다\n데이터 링크 계층이 랜카드라는 물리적인(하드웨어적인)형태로 출시가 되고 있어 Physical Address라고 이름이 붙은거지 Physical Layer에서 사용하는 주소여서 이름이 저렇게 붙은게 아니다\n이게 뭔지 잘 이해가 안될수도 있는데 Physical Address는 랜카드마다 붙는 주소라고 생각하면 된다\n\nLogical Address §\n\n일단 Logical Address라는 것은 Network Layer에서 Source-to-Delivery를 위해 사용하는 주소라고 알고있으면 된다\nIP주소가 여기에 해당되는 것\n\nStation들의 통신 과정 이제 Address를 곁들인 §\n\n\n이 그림이 패킷이 실제로 이동하는 모습이다\n일단 위의 예시에서 알파벳 주소는 Logical Address 이고 숫자 주소는 Physical Address 이다\nA에서 P로 보내기 위해서 일단 A는 Router 1로 보내게 된다\n\nRouter는 중간다리 역할을 하기 때문에 많은 패킷을 수신하고 그것들을 송신하기 위해 보드가 여러개 달려 있다 - 그림에서 라우터에 붙어있는 저게 보드이고 여기를 통해 패킷들이 들어오고 나간다 - 여러개의 Logical Address, Physical Address를 갖게 되는 셈 - Router 1으로 보면 F / 20, T / 99, X / 44 이렇게 세개의 보드가 있는 셈이다\nA가 P로 보내기 위해 Router 1로 먼저 보내야 된다는 사실은 Routing Table을 통해 알아낸다 - 이건 뒤에서 설명한댄다\n그래서 A는 Network Layer 패킷에는 송신주소 A, 수신주소 P를 데이터에 붙여 하위계층으로 내려보내고\n하위계층인 Data Link Layer 에서는 일단 Router 1로 먼저 보내야 하므로 자기의 Physical Address인 10와 Router 1의 Physical Address인 20을 붙여 보내게 된다 - Router 1의 Physical Address를 알아내는 과정은 ARQ라는 프로토콜을 이용해 알아낸다 - 이것또한 뒤에서 설명한다\nRouter 1까지 가는 과정에 많은 station이나 router를 거칠수도 있지만 다 자신한테 온 패킷이 아니기 때문에 폐기하고 Router 1에 도달해서야 자기꺼로 인식하고 받게되는 것\n\n\nRouter 1에서는 Router 2로 보낸다\n\nRouter 1에서 Network Layer까지 올라가게 되면 패킷의 헤더에 따라 이게 P한테 가야되는 놈이라는 것을 알게 된다\n따라서 ARP를 이용해 Router 2로 가야된다는 것을 알아내고 Network Layer에서는 패킷을 그대로 하위계층으로 내려보내 데이터 링크 계층에서 Physical Address를 재구성하도록 한다\n그림에서는 Router 1에서 T 보드를 이용해 송신을 했기 때문에 자신의 Physical Address를 99로, 받는사람 주소로 Router 2의 Physical Address인 33으로 포장해서 보내게 된다\n\n\nRouter 2는 마지막으로 P로 보내게 된다\n\nRouter 2에서도 마찬가지로 Network Layer까지 올라가서 P로 보내야 된다는 사실을 알게 되고 P는 자신의 관할 안에 있기 때문에 P로 바로 보내게 된다\n그림에서는 Router 2에서 Z보드를 이용해 송신을 했기 때문에 자신의 Physical Address를 66로, 받는사람 주소로 P의 Physical Address인 95으로 포장해서 보내게 된다\nP는 이제 자신한테 온 패킷임을 깨닫고 Data Link Layer, Network Layer를 거처 상위 계층으로 가게 된다\n\n\n이 과정을 잘 보면 Data Link Layer의 헤더만 바뀌고 Network Layer의 패킷은 바뀌지 않는다\n즉, Network Layer의 패킷이 어디로 가야할지 길잡이 역할을 해주는 셈 - Router들의 Network Layer에서 이 패킷의 헤더를 보고 다음에는 어디로 가야 할 지 방향을 잡게 되는 셈\nData Link Layer에서는 Hop-to-Hop통신만을 위한다는 것이 위의 예시에서도 확인되는 셈이다\n\nPort Address §\n\n\nPort Address는 Network Layer의 상위계층인 Transport Layer에서 사용하게 되는데 이 계층에서는 실제로는 컴퓨터간의 통신이 아니라 컴퓨터의 한 프로세스와 다른 컴퓨터의 한 프로세스 간의 통신이기 때문에 컴퓨터로 도착한 다음 어느 프로세스로 가야할지를 알려주는 역할을 하고\nPort Address는 컴퓨터에 도착해서 어느 프로세스로 패킷이 가야할 지를 알려주는 주소이다\n\nInternet Routing §\n\nRouter가 하는 일을 좀 예를 들어서 설명하면\n\n니가 서울대학교에 갈일이 생겼다고 해보자\n그럼 일단 Logical Address는 충남대 → 서울대 일 것이다\n하지만 지금은 일단 대전역으로 가야되기 때문에 대전역까지 가는 버스 노선을 정해야 하고\n대전역까지 도착해서도 서울역까지 가는 기차를 골라서 타야되고\n서울역에 도착해서도 서울대까지 가는 버스 노선을 타야 서울대까지 갈 수 있다\n\n\n이렇게 각 지점들에서 최종 목적지까지 가기 위해서는 일단 내가 어디로 가야되는지 판단하는 역할을 Router와 Network Layer가 하게 되는 것이다\n\nRouter의 원리 §\n\n\nRouter에는 위 그림에서의 노란색 테이블처럼 Routing Table을 갖고 있다\nRouting Table을 한마디로 말하면 입력받은 Logical Address를 가지고 이 주소로 가려면 어느 보드로 나가야 되는지 정리돼있는 표이라고 생각하면 된다\n따라서 어떤 Logical Address가 들어오면 해당 주소를 가지고 Routing Table에서 찾아서 어느 Router로 가야할지를 알아내게 되는 셈\n근데 만약 Hierarchy가 없다면 Router2에 매핑되는 모든 Logical Address를 전부 저장하고 있어야 한다 - 따라서 테이블의 크기가 엄청나게 커지고 검색을 할때도 오래걸리게 된다\n따라서 Hierarchy를 도입해서 netid라는 것을 이용하게 된다\n이것의 작동원리를 위의 그림으로 살펴보면\n\nRouter 1의 경우 00으로 시작하는 주소는 전부 1번 보드로, 10으로 시작하는 주소는 전부 2번 보드로 내보내고 이게 아니라면 전부 3번 보드로 내보내게 된다\n3번 보드로 나가면 Router 2에 도달하는데 여기에서는 01으로 시작하면 전부 1번 보드로, 11로 시작하면 전부 2번 보드로 내보내게 되는 것\n이렇게 주소값 전체에 대해 테이블을 생성하지 않고 주소의 첫 몇개의 비트들만을 이용해서 테이블을 만드는 것을 2-Level Hierarchy라고 한다\n이 예제에서 주소의 첫 2비트가 바로 netid가 되는 것이고 이 netid만 보고 어떤 라우터로 가야할지, 어떤 보드로 나가야 할 지를 알아내는 셈이다\n저 netid는 NIC(Network Information Center) 라는 특정 기관에서 발급해준다\n\n어떤 기관이 ip주소를 사용하기 위해서는 NIC에서 netid를 할당받고 hostid부분만 그 기관 내부에서 자체적으로 할당해서 사용하게 되는 것\n\n\n물론 한 기관에서 netid를 하나만 발급받아서 사용하지는 않는다 - 충남대의 경우에는 2~3개를 발급받아서 사용한댄다\n\n\n\n\n\n그래서 보면 이 Logical Address에는 다섯 레벨이 존재한다\n하나의 라우터를 사용하는 station이 많을수록 hostid가 많아야 되므로 ClassA로 올라가고 적을수록 내려가게 된다\n그리고 이 클래스를 구분하는것은 앞의 몇개의 비트를 사용하며 위 그림보면 0, 10, 110등이 그 비트의 값인것\nClass A 는 1.x.x.x부터 127.x.x.x까지를 의미하고 netid가 7비트 이므로 전세계에 128개의 라우터가 존재하며 한 라우터마다 1600만정도의 station이 연결되는 것이고\nClass B는 128.x.x.x부터 191.x.x.x까지이며 전세계에 16000개의 라우터, 한 라우터마다 64000개정도의 station이 연결된다\nClass C는 192.x.x.x부터 233.x.x.x까지이며 전세계에 100만개의 라우터, 하나의 라우터마다 64개의 station이 연결된다\n비트로 표현된 주소를 십진수로 읽는 방법은 그냥 8비트씩 끊어서 읽으면 된다\n\n클래스를 구분하기위해 존재하는 맨 처음의 몇비트를 제외하고 netid는 7비트, hostid는 8비트 이게 아니고\n구분용 비트까지 합쳐서 8비트씩 끊어읽는거다\nA클래스의 경우에는 맨 처음 숫자가 0000000101111111이므로 1127이 되는거고\nB클래스의 경우에는 맨 처음 숫자가 1000000010111111이므로 128191까지인 것이다\n\n\n\nSubnet §\n\n주소의 첫 몇비트와 테이블을 이용해 다른 라우터로 가는 라우팅도 있지만\n\n이때의 라우터를 AS라고 부르고 AS들간의 통신은 주소 전체가 아닌 netid만을 이용해서 이루어진다\n\n\n라우터에서 각 station들로 뿌려주는 라우팅도 있다\n\n즉, 라우터에서 하나의 보드로 나왔을 때 다른 라우터로 가는게 아니라 station들로 가는 경우\n\n\n라우터에서 station들로 뿌려줄때는 하나의 회선에 모든 station을 전부 연결해줄수도 있지만\n회선을 여러개로 나누고 그 회선에 여러 station을 연결하는 방법을 주로 사용하는데 이것을 Subnet이라고 한다.\n이렇게 함으로써 좋은점은 봐봐라\n\n만약에 Class C여서 station을 256개를 연결할 수 있다고 해보자\n이때 한 라우터의 한 보드를 4개의 부서가 사용하고 각 부서마다 64개의 station들을 연결한다고 하면\n하나의 회선에 256개의 station을 모두 연결해 4개의 부서가 나눠가질 수도 있지만\n하나의 부서마다 한 회선을 받아 여기에 각각 64개의 station을 연결하는식으로 hostid들을 마구잡이로 나눠갖는게 아닌 정리해서 나눠가질 수 있게 된다\n\n\n그럼 이제 회선을 나눴으니 하나의 주소가 들어왔을 때 이것을 어느 회선으로 보내야 되는지 결정해야 되는 문제가 생기게 되는데 이때 사용되는 개념이 Subnet Mask이다\n얘는 예시로 이해하는게 좋다 - 아주 중요한 내용이고 시험에 무조건 나오니까 반복숙달해라\n\nSubnet Example 1 §\n\n\n일단 이렇게 만들고싶은거다 - 하나의 보드로 나와서 거기서 Router를 거쳐 4갈래로 나누는 것(이때의 라우터는 AS와는 다른 subnet을 위한 라우터이다)\n일단 이 예제에서는 C클래스를 사용하는데 198.66.168 로 netid가 설정되어 있다\n그리고 여기에 198.66.168.65 라는 주소가 들어왔을때 어떻게 처리하는지 보면\n\n\n\n이게 바로 출력 포트를 결정하는 테이블이다 - 주소가 하나 들어오면 이 테이블의 첫번째부터 mask를 AND연산하고 연산결과가 Dst. Addr이랑 같은지 확인한다.\n처리하는 과정을 좀 더 자세히 보면 일단 들어온 주소에다 첫번째 subnet mask를 AND연산한다.\n\n보면 255라는 숫자가 많이 나오는데8비트에 전부 1이 들어있으면 255라는 숫자가 나오게 된다\n따라서 어떤 숫자에 255를 AND하면 255의 비트가 전부 1이므로 입력된 숫자가 그대로 나오게 되는것\n위의 예제에서 들어온 주소가 198.66.169.65이므로 여기에 255.255.255.192를 AND하면 255는 그대로 나온다고 했으므로 198.66.169까지는 그대로 나오고 192랑 65을 AND하면 [11000000 &amp; 01000001] 이므로 [01000000] 인 64가 나오게 된다\n근데 이 값은 dstAddr인 198.66.168.0이랑 다르므로 두번째로 넘어간다\n\n\n첫번째 subnet mask랑 AND한 결과가 dst랑 같지 않다면 그의 결과가 같을때까지 아래로 내려간다\n\n두번째의 경우에도 subnet mask가 동일하므로 그 결과는 198.66.168.64인데 이건 dst와 동일하므로 여기에 매칭이 된다\n매칭이 되면 해당하는 Port number로 빠져나가게 된다\n\n\n그리고 아무데도 매칭되지 않으면 이 보드에 해당하는 주소가 아니기 때문에 다시 뒤로 되돌려 보낸다\n\n아무데도 매칭되지 않은 애들을 subnet mask를 0.0.0.0로 주고 dst도 0.0.0.0으로 주어서 캐치한다 - subnet mask가 0.0.0.0이면 어떤값이 와도 그 결과가 0.0.0.0이기 때문 - 이럴때를 default라고 하더라\n\n\n\nSubnet Example 2 §\n\n이 예제에서는 클래스B의 168.188을 netid로 사용 하고\n168.188.129.51 이 들어오게 된다\n\n\n\n\n저 /숫자에 대해 알아보면\n/숫자를 통해 subnet mask를 간단하게 표현할 수 있다\n\n뭔말인가 하면 전체 32비트중에 “숫자”만큼 앞에가 1로 채워지고 나머지는 0이 채워지는 숫자를 subnet mask로 사용하겠다는 소리이다\n위의 예제에서는 /24 이므로\n\n[11111111 - 11111111 - 11111111 - 00000000] 가 되므로168.188.12.0의 subnet mask는 255.255.255.0인 것\n\n\n그리고 /숫자를 이렇게 활용할 수도 있다\n\n전체가 32비트이고 그중에 앞의 “숫자”개가 1로 채워져있기 때문에 0으로 채워진 “32 - 숫자”비트에는 뭐가 오든 AND의 결과가 dst랑 같다면 매칭된다 - 이 “32 - 숫자”비트로 만들수 있는 경우의 수를 전부 따져보면 2^(32 - 숫자) 이기 때문에 이만큼의 station이 하나의 회선에 연결된다고 해석할 수도 있다\n위의 예제에서는 /24이기 때문에 2^8 해서 256개의 station이 한 포트의 회선에 연결되는 것이다\n따라서 위의 그림에서는 168.188이지만 0, 1, 2에서 매치되지 않은 애들을 3번 포트로 내보내게 되는데 이때의 subnet mask는 255.255.0.0이므로 168.188.0.0/16으로도 표현할 수 있는 것\n\n\n\n\n\nSubnet Example 3 §\n\n\n\n이 예시처럼 게이트웨이 라우터를 여러개 사용할 수도 있다\nR1에서 130.50.4.0/22에 매치된다면 0번 포트로 나가게 되지만\n만약 매치되지 않는다면 다시 1번으로 나가 그 아래 R2에 걸려 130.50.12.0/22로 매치를 시도하게 되는 구조이다\n"},"originals/datacommunication.spring.2021.cse.cnu.ac.kr/13.-Routing":{"title":"13. Routing","links":[],"tags":[],"content":"\n\n                  \n                  충남대학교 컴퓨터공학과 김상하 교수님의 &quot;데이터 통신&quot; 강의를 필기한 내용입니다. \n                  \n                \n\n\n\n                  \n                  다소 잘못된 내용과 구어적 표현 이 포함되어 있을 수 있습니다. \n                  \n                \n\nPhysical Address, Logical Address §\n\n계층이 달라서 다른 주소를 사용하는거라고 심플하게 생각하자\n\nARP §\n\nARP(Address Resolution Protocol)\n이게 뭐냐면 Logical Address로 Physical Address를 알아내는 방법이 바로 ARP인 것\n상대방의 Logical Address를 알아도 Physical Address는 다른 계층이므로 알지 못하지만 Physical Address는 Logical Address보다 하위계층에서 사용되므로 Physical Address를 알지 못하면 패킷을 전송할 수 없다\n\n상대방이 같은 서브넷에 존재할때 §\n\n\n일단 여기서 CE1에서 CE2로 보내야 한다고 해보자\n\n\n\n그리고 위의 첫번째 테이블이 라우터의 테이블이고, 두번째가 각 station들이 갖고있는 테이블이다\n그럼 우선\n\n\nCE1의 routing table을 이용해 CE2가 같은 서브넷에 존재하는지를 확인한다\n\nsubnet mask가 255.255.255.0이므로 168.188.129.52랑 AND하면 168.188.129.0이 나오므로 dst와 매치되어 같은 서브넷에 존재한다는 사실을 알 수 있다(gateway가 connect이므로 - router나 gateway나 next hop이나 다 같은말이라고 생각해도 된다)\n\n\n같은 서브넷에 존재하므로 CE1은 ARP request을 보낸다\n\nARP request는 먼저 수신지의 Physical Address를 Broadcast로 하고 Logical Address를 Routing table을 통해 알아낸 주소로 하여 송신하는 것을 의미한다.\n\n\nARP request를 보내게 되면 같은 서브넷에 존재하는 모든 station이 받게 되는데 걔네들이 수신한 후에 network layer로 올려보내 Logical Address를 확인한다\n만약 논리주소를 확인하여 자신과 다를 경우에는 그냥 버리게 되지만 논리주소가 같다면 답장하게 된다\n\n답장할때는 송신지의 Physical Address를 자신으로 하고, 수신지의 Physical Address를 ARP Request를 보냈던 놈으로 한다\n\n\n그럼 처음에 ARP를 보냈던 놈이 상대방의 물리주소를 알게 되므로 그 물리주소를 이용해 데이터 패킷을 보내게 된다\n\n\n이때 저 router table은 어떻게 만드느냐\nRouter의 router table은 router가 설치될때 관리자가 설정해줘야 되지만\nstation의 router table은 자동으로 생성된다\n\nstation의 router table을 생성하려면 세가지가 필요하다\n자신의 논리주소, subnet mask, destination\n자신의 논리주소와 subnet mask를 입력해주면 이 둘을 AND연산해 destination을 알아내고 이때의 gateway는 connect로, destination이 아닌 경우에는 default에 걸리게 해 router로 갈 수 있도록 gateway를 router의 논리주소로 설정한다\n그리고 저기 테이블에 보면 G Flag가 있는데 이것은 해당 주소가 유효하다는 의미이다\n\n\n\n다른 서브넷에 존재할 때 §\n\n\nCE1에서 CE3로 보내야 한다고 하고\n\n\n\n이게 걔네들에 대한 routing table이라고 해보자\n\n\n기본 로직은 동일하다. 상대방의 논리주소를 자신의 routing table에 넣어 같은 서브넷인지 아닌지부터 확인한다\n\n168.188.128.30을 CE1의 routing table에 넣어 255.255.255.0과 AND했더니 168.188.128.0이므로 destination이랑 달라 서브넷에 존재하지 않고 default의 gateway로 가야한다는 것을 알게 된다\n\n\n그럼 이제 gateway의 논리주소에 대해 ARP request를 하게 된다\nARP에 대한 답장이 와 gateway의 물리 주소를 알아낸 후에는 거기로 데이터 패킷을 보내게 된다\ngateway에서는 자신의 routing table과 데이터 패킷의 논리주소를 이용해 원래 목적지가 속한 서브넷을 알아낸다\n\n패킷에는 목적지 논리주소가 168.188.128.30으로 되어있으므로 255.255.255.0과 AND를 해보면 첫번째 행에서 매치돼 gateway가 connected인 것을 알고 0번 인터페이스로 내보내야된다는 것을 알게 된다\n\n\n서브넷을 알아냈다면 해당 서브넷에서 다시 ARP를 날리게 된다\n그럼 목적지의 station이 ARP에 대한 답장을 보내 목적지의 물리주소를 알게 되고, router에서 그곳으로 데이터 패킷을 전송하는 것으로 통신을 종료된다\n\n외부망으로의 통신 §\n\n위의 예시를 그대로 사용하여 외부망으로의 통신이 어떻게 이루어지는지 확인해보자\nCE1에서 외부망의 133.40.53.2로 데이터 패킷을 보내야 한다고 해보자\n\n\n그럼 또 자신의 subnet에 속해있는지 알아내기 위해 자신의 routing table로 확인한다\n\n255.255.255.0과 133.40.53.2를 AND하면 133.40.53.0이므로 매치되지 않아 gateway로 가야된다는 것을 알게 된다\n\n\n자신이 속한 subnet에 속하지 않으므로 gateway로 보내기 위해 gateway의 논리주소에 대해 ARP를 날린다\n\n따라서 CE1은 168.188.129.1의 물리주소를 알기 위해 얘에 대해 ARP를 날리게 되는 것\n\n\n답장이 오면 그 물리주소로 데이터 패킷을 보낸다\n데이터 패킷이 gateway에 도착하면 얘는 또 자신한테 연결되어있는 subnet들 중 어디에 속하는지 알아내기 위해 routing table을 돌린다\n\n데이터 패킷의 논리주소가 133.40.53.2이므로 이것에 대해 routing table을 돌려보면 어느 서브넷에도 속하지 않는다는것을 알게 된다\n\n\n따라서 gateway에서도 subnet을 찾지 못했기 때문에 default의 gateway로 가야된다는 것을 알게 된다\n\n당연히 이것은 gateway에서 다른 gateway로 보내는 통신이다 - 뭐 default gateway라고 따로 뭔가가 존재하는게 아니더라\n\n\ndefault의 gateway에 대한 물리주소를 알기 위해 ARP를 날리게 되고, 답장이 오면 그 물리주소로 데이터 패킷을 보내어 외부망으로 방출시키게 된다\n뭐 그 이후로는 계속 routing table확인하고 논리주소 알아내고 ARP보내 물리주소 알아내고 거기로 패킷을 전달하는 과정을 반복하며 목적지까지 도달하게 되는 것이다\n\nSubnet mask를 제대로 설정해야 하는 이유 §\n\n\n지금까지 사용하던 예시를 계속 사용하여 설명을 해보면\nCE1에서 subnet mask를 255.255.255.0이 아닌 255.255.0.0으로 설정했다고 해보자\n그럼 같은 서브넷이나 외부망으로는 통신이 되는데 다른 서브넷으로는 패킷이 보내지지 않는 이상한 상황이 벌어진다\n\n그 이유는 일단 subnet mask가 255.255.0.0으로 되어있고 CE3인 168.188.128.30으로 보내야 한다고 해보자\nSubnet Mask가 255.255.0.0으로 돼있으면 Destination이 168.188.0.0으로 바뀌게 된다\n이때 CE3에 subnet mask를 씌우면 168.188.0.0이 되는데 이것은 Destination과 같므로 실제로는 같은 서브넷이 아니지만 같은서브넷이라고 판단하게 된다\n따라서 gateway로 보내지 않고 CE1의 서브넷에서 ARP를 날리지만 당연히 CE1의 서브넷에 CE3가 없기 때문에 답장이 오지 않는다 - 통신이 실패하게 되는 것\n\n\n하지만 외부망으로의 통신은 가능 하다 - 만약 133.40.53.2로 보내야 한다고 해보자\n\n255.255.0.0으로 masking을 해보면 133.40.0.0인데 이것은 Destination과 다르기 때문에 gateway로 가게 되고 여기서부터는 정상적으로 subnet mask가 설정되어있기 때문에 정상적으로 상대방을 찾아가게 되는 것\n\n\n만약 CE1의 subnet mask가 255.255.255.192로 설정되어있을때는 어떻게 동작하는지 알아보자\n이 경우 제대로 통신은 되지만 이상한 방식으로 작동한다\n\n만일 CE1과 같은 서브넷에 존재하는 168.188.129.65로 보낸다고 해보자\nSubnet Mask를 255.255.255.192로 비꾸게 되면 Destination은 168.188.129.0으로 설정된다\n하지만 168.188.129.65와 255.255.255.192를 masking하면 168.188.129.64가 된다\n이 둘의 결과가 같지 않으므로 CE1는 gateway로 ARP를 요청해 데이터 패킷을 보내게 되는데\ngateway에서는 이놈이 CE1가 속한 서브넷에 같이 존재한다는 것을 자신의 routing table을 통해 알아내므로 gateway에서 목적지로 보내게 된다\n즉, CE1에서 상대방으로 바로 가야 정상인데 CE1에서 gateway를 거쳤다가 상대방으로 가게 되는 것\n\n\n\n망 전체에 대한 예시 §\n\n\n이 예시에서는 저 Routing table을 읽을 수 있을 정도만 되면 된다\n일단 Dest. 는 지금까지의 Destination과 같고\nNext가 Gateway랑 같다고 생각하면 된다\n그리고 Hop은 Next까지 가기 위해 얼마나 걸리냐는 말이다\n\nR2 Table에서 130.10.0.0은 자신 관할의 Subnet에 존재하기 때문에 Connect인 것이고\n한번에 갈 수 있기 때문에 Hop-to-Hop을 한번만 하면 된다는 의미에서 Hop의 값은 1로 설정되어 있는 것\n하지만 130.11.0.0의 경우에는 자신의 관할에 있지 않기 때문에 일단 R1까지 가야되고 따라서 Next에 130.10.0.2가 들어있는 것이다\n그리고 R1까지 갔다가 해당 주소로 가기 때문에 Hop의 값이 2인 것이다\n\n\n"},"originals/datacommunication.spring.2021.cse.cnu.ac.kr/부록---시험대비)-싱하형배-데이터통신-모의고사-정답":{"title":"부록 - 시험대비) 싱하형배 데이터통신 모의고사 정답","links":[],"tags":[],"content":"\nPhysical Layer §\n\nBitrate, Baud rate, Signal Element, Signal Level, Bandwidth의 개념을 한번 설명해보라\n\nBitrate는 초당 몇개의 비트를 보내는지의 수치\nBaud rate는 초당 몇개의 Signal element를 보내는지의 수치\nSignal Element는 신호의 값이 일정하게 나타나는 단위구간\nSignal Level은 한 Signal Element가 가질 수 있는 값의 범위\nBandwidth는 신호를 구성하는 사인파들의 최대주파수와 최소주파수의 차이\n\n\nShannon Capacity와 Nyquist Bitrate가 각각 어떤 Channel에 적용되는 공식이냐\n\nShannon capacity는 Noisy Channel에 적용되는 공식이고 Nyquist Bitrate는 Noiseless Channel에 적용되는 공식\n\n\nShannon Capacity와 Nyquist Bitrate를 이용해 Signal Level을 구하는 방법을 서술해보라\n\nShannon Capacity의 Bandwidth와 SNR값은 이미 주어지는 값이므로 이것을 이용해 Bitrate의 상한선을 구한다. 그리고 이것을 Nyquist Bitrate 공식에 적용해 Signal Level을 구할 수 있다\nBandwidth와 SNR은 전송 매체가 정해지면 자동으로 정해지는 값이라는 것을 알아야 함. 그리고 이것을 이용해 해당 매체에서 사용할 수 있는 최대의 Bitrate를 Shannon공식을 이용해 구하고, 그 값과 Bandwidth값을 Nyquist 공식에 적용해 Signal Level을 구하여 Digital Data를 인코딩 하면 최대의 Bitrate를 낼 수 있는 방식으로 인코딩 된다\n\n\nDigital Data를 Digital Signal로 변환할때 Synchronization이 중요한 이유를 설명해보라\n\nSynchronization을 하지 않으면 송신자와 수신자가 Signal Element구간을 다르게 설정해 다른 값으로 해석할 여지가 있기 떄문\n\n\nLine Coding의 한 종류인 Manchester Scheme에 대해 설명해보아라 그리고 이 방식의 단점도 적어라\n\nManchester Scheme은 단순히 신호의 세기를 가지고 0과 1을 구분하는 것이 아닌, 신호의 세기 변화에 따라 0과 1을 구분하는 방법이다. 세기가 감소하면 0으로, 세기가 증가하면 1로 판단하는 방식이다. 이 방식의 단점은 세기의 변화를 보여줘야 하기 때문에 하나의 비트를 표현하기 위해 두개의 Signal Element가 필요해 Bitrate가 절반으로 감소한다는 것이다\n\n\nBlock Coding의 개념에 대해 사용하는 경우, 작동방식을 간단히 지껄여보아라\n\nBlock Coding을 사용하는 경우는 신호의 인코딩 방식을 바꿔 송신하는것이 더 효율적일때 사용한다. Signal Level이 m으로 인코딩된 신호를 Signal Level을 n으로 바꿔 송신한 후 다시 m으로 바꿔 원본 데이터를 수신하는 방식으로 작동한다.\n\n\nPCM Encoder에 대해 어떤 신호에 대해 사용하여 어떤 신호를 생성해내는 과정인지, 그리고 작동 과정을 설명해보아라\n\nAnalog 신호를 Digital 신호로 변환하는 과정이다\n우선 Analog 신호를 일정한 시간간격으로 잘라 각 구간에 대한 신호의 세기를 측정한다.\n이 신호 세기의 절댓값의 최댓값을 구한다\n그 최댓값의 두배를 Signal Level로 나눈다. 가령 최댓값이 20이고 3비트로 인코딩하는 경우라면 Signal Level은 8이므로 40을 8로 나눈다\n나눈 값을 각 구간의 신호 세기값에다 나눈다.\n위의 결과를 일정한 기준에 따라 반올림한다.\n반올림한 값들에 대해 Signal Level에 해당하는 비트의 숫자를 할당한다. 가령 Signal Level이 8인 경우, 3비트 이므로 0~7의 값을 할당한다.\n할당한 숫자를 3비트로 변환해 인코딩한다.\n각 구간에 대한 신호의 세기를 PAM이라고 하고\nSignal Level로 나눈 값을 Normalized PAM이라고 하고\n반올림한 값을 Normalized Quantized Value라고 하고\n나눈값에서 반올림한 값을 뺀 것이 Normalized Error이고\n비트 숫자를 할당한 것이 Quantization Code이고\n비트로 변환한 것이 Encoded Word이다\n\n\nASK, FSK, PSK, Constellation Diagram 각각의 개념을 말해보아라\n\nASK는 Digital Data의 0과 1에 따라 Analog Signal의 진폭을 변화시켜 표현하는 방법이다\nFSK는 Digital Data의 0과 1에 따라 Analog Signal의 주파수를 변화시켜 표현하는 방법이다.\nPSK는 Digital Data의 0과 1에 따라 Analog Signal의 위상을 180도 반전시켜 표현하는 방법이다.\nConstellation Diagram은 Digital Data의 모든 Signal Level에 대해 Analog Signal를 변조한 방법을 그림으로 나타낸 것이다. 변조한 Analog Signal의 위상을 각도로, 진폭을 거리로 하여 각좌표계에 표시한다.\n\n\nMultiplex의 개념과 사용하는 이유를 말해보아라\n\nMultiplex는 넓은 대역폭의 Carrier에 하나의 신호만 전송하는 것이 아닌 여러개의 신호를 간섭없이 합쳐서 전송하고, 수신후에 각각의 신호를 분리해내는 방법이다.\n신호의 전송 속도는 Bandwidth와 밀접한 관련이 있는데, Multiplex를 사용하면 같은 신호를 전송하더라도 더 넓은 Bandwidth를 가지는 Carrier를 이용해 전송할 수 있으므로 더 빠르게 전송할 수 있기 때문에 사용한다.\n\n\nFDM의 작동 원리에 대해 말해보아라\n\nFDM은 Carrier의 Bandwidth를 여러 주파수로 나눠 각각의 주파수에 하나의 신호를 할당하는 방식으로 작동한다.\n주파수로 나눈 각각의 구역을 Channel이라고 하고\n이때의 주파수값들을 Carrier Frequency라고 한다\n신호를 합치는 것을 Modulation, 신호를 다시 분리하는 것을 Demodulation이라고 한다\nFDM의 경우 Analog Signal에 대해 주로 적용한다\n\n\nTDM의 작동 원리에 대해 말해보아라\n\nTDM은 같은 신호를 전송할 때 넓은 Bandwidth로 보내면 더 빨리 전송된다는 것에 착안해 여러 신호를 연속적으로 전송하는 기법이다\n\n\nSpread Spectrum의 개념과 사용하는 이유에 대해 말해보아라\n\nSpread Spectrum신호 하나를 더 넓은 대역폭으로 전송하는 기법이다. 이렇게 하면 적은 대역폭만을 필요로 하는 신호를 넓은 대역폭을 사용해 보내므로 비효율적일 수 있지만, 그민큼 간섭이 없어 정확하게 송신이 가능하고 보안성이 강화된다는 장점이 있다\n\n\nFHSS의 개념에 대해 설명해보아라. 그리고 이것의 단점을 상쇄할 수 있는 방법도 설명해보아라\n\nFHSS는 신호를 송신할 때 여러 주파수를 넘나들며 전송하는 방식이다. 송신자와 수신자는 모두 주파수가 변경되는 규칙을 알고 있고, 이 규칙에 따라 주파수가 변경되며 송신된다. 하지만 이러한 규칙을 모르는 경우 도청이 어렵기 때문에 보안성이 강화된다는 장점이 있다. 하지만 송신하기 위해 더 넓은 대역폭을 사용함에도 속도상의 이점이 없다는 단점이 있으나 Frequency Division Multiplexing과 혼합해서 사용하면 여러 신호가 주파수가 변경되며 송신되므로 이러한 단점도 상쇄시킬 수 있다.\n\n\nDSSS의 작동원리와 장점에 대해 설명해 보아라\n\nDSSS는 하나의 비트에 Spreading Code를 곱하여 여러 비트로 표현하여 송신하고, 수신할때는 다시 Spreading Code를 곱하여 하나의 비트로 변환하는 과정을 통해 통신하는 것이다. Spreading Code를 모르는 경우 데이터를 해석할 수 없으므로, 보안성이 강화된다는 장점이 있다.\n\n\n\nData Link Layer §\nData Link Control(Logical Link Control) §\n\nError Detection과 Correction의 차이에 대해 설명해보아라\n\nError Detection은 단지 오류를 탐지하는것만을 가능하게 하지만, Correction의 경우에는 탐지 후 잘못된 부분을 고치는 작업까지 가능하게 하는 것이다.\n\n\nFixed-size Framing과 Variable-size Framing의 차이와 Delimiter에 대해 설명해보아라\n\nFixed-size Framing은 프레임의 길이를 고정시키는 것이고, Variable-size Framing은 프레임의 길이를 가변적으로 하는 것이다. 그리고 가변적으로 프레임의 길이를 설정했을 때, 프레임이 시작되고 종료된다는 것을 알려야 하기 때문에 Flag같은 Delimiter가 필요하다\n\n\nCharacter-oriented Protocol, Bit-oriented Protocol에 대해 설명해보아라\n\nCharacter-oriented Protocol은 데이터들이 8비트의 문자들로 구성되는 것을 의미하고, Bit-oriented Protocol은 데이터들이 문자들로 구성되는게 아닌 이미지나 음향 등이어서 하나의 bit묶음으로 구성되는 것을 의미한다.\n\n\nBit-Stuffing과 Bit-Unstuffing에 대해서도 설명해보아라\n\nBit-Stuffing은 Flag처럼 용도가 정해져있는 문자나 비트가 데이터에도 등장할 때 그것의 의미대로 해석하지 않고 데이터로써 해석하도록 하는 방법이다. 이것을 위해 Character-oriented Protocol은 “ESC”라는 문자를 사용하는데, 가령 데이터에 “Flag”라는 문자열이 등장하면 이 앞에 “ESC”를 붙여 “ESCFlag”형태가 되도록 해 이것을 Flag로 인식되지 않도록 한다.\nBit-Unstuffing의 경우에는 수신 후 Bit-Stuffing에 의해 추가된 문자나 비트를 다시 제거하여 원래의 데이터로 복원하는 방법이다.\n\n\nSimplest Protocol에서 발생할 수 있는 문제점인 Flow Error에 대해 설명해보아라\n\nSimplest Protocol의 경우 프레임을 연속하여 보내는 방법인데, 수신자의 수신버퍼가 비워지기 전에 프레임이 도착하면 기존의 데이터를 덮어쓰므로 프레임이 누락되는 상황이 일어난다. 이러한 문제를 Flow Error라고 한다.\n\n\nStop &amp; Wait Protocol에 대해 설명해보아라\n\nFlow Error를 막기 위해, 하나의 프레임을 수신한 후에는 ACK를 보내어 수신 완료되었다는 신호를 송신자에게 보내 다음 프레임을 받을 수 있도록 하는 프로토콜이다.\n\n\nStop &amp; Wait ARQ Protocol에 대해 설명해보아라\n\n기존의 Stop &amp; Wait Protocol은 노이즈가 없는 매체에서의 통신이기 때문에 프레임이나 ACK가 유실될 염려가 없었지만, 노이즈가 있는 환경에서는 유실될 가능성이 있기 때문에 해당 경우에 대한 대응책을 마련한 것이 Stop &amp; Wait ARQ Protocol이다.\nStop &amp; Wait ARQ Protocol의 경우에는 프레임이 유실될 경우 수신자는 정상적으로 수신하지 못하였기 때문에 ACK를 보내지 않는다. 이때 송신자는 일정시간 ACK가 오기를 기다렸다가, 오지 않으면 프레임이 유실되었다고 판단해 해당 프레임을 재전송하게 된다\n만일 ACK가 유실된 경우라면 송신자는 수신실패라고 판단해 재전송하게 된다. 하지만 수신자는 정상적으로 수신하였기 때문에 중복된 프레임을 받게 된다. 이것을 막기 위한 장치가 Sequence Number이다. 각 프레임에 번호를 매겨 전송했을시에 수신자가 이미 수신한 프레임인지 아닌지를 Sequence Number를 통해 확인하게 되고, 수신하지 않은 프레임이라면 수신하지만 이미 수신한 프레임이라면 폐기하게 된다\n그리고 이 Sequence Number는 ACK에도 포함되어 전송되게 된다. Sequence Number를 ACK에 포함시켜 전송함으로 이전까지는 전부 정상적으로 수신했고 이제는 이 프레임이 필요하다는 것을 프레임 송신자에게 알리는 것이다.\n\n\nStop &amp; Wait ARQ Protocol의 단점에 대해 설명해보고, 이것을 해결하기 위한 Protocol중 하나인 Go-back-N ARQ Protocol에 대해 설명해보거라\n\nStop &amp; Wait ARQ Protocol의 단점은 수신자가 프레임을 수신한 후에 ACK를 전송하고 그 다음 프레임을 수신하기 전까지 아무것도 안한다는 비효율성에 있다.\n따라서 이것을 해결하기 위한 Protocol인 Go-back-N ARQ는 수신버퍼가 비워질 정도의 시간간격만 주고 프레임을 연속하여 전송한다. 만일 송신한 모든 프레임에 대해 정상적으로 수신하면 모든 프레임에 대해 ACK를 전송한다. 하지만 프레임 하나가 수신실패할 경우 그 이후 수신되는 모든 프레임을 폐기하고 ACK도 이후로 보내지 않는다. 그렇다면 송신자는 받은 ACK중에 Sequence Number가 가장 큰 프레임부터 재전송하기 시작한다. Sequence Number중 가장 큰값부터 재전송하기 시작하는 이유는 ACK의 의미가 “이전까지는 전부 정상적으로 받았고 이 번호부터 전송해달라”는 뜻이므로 이전의 프레임에 대해서는 정상적으로 수신된 것이 검증되기 때문이다.\n송신측은 프레임의 재전송을 위해 Slide Window라는 버퍼를 이용한다. 프레임을 전송하고 난 후에 이 버퍼에 저장해 두었다가, ACK를 받아 수신까지 완료됨이 확인되면 이 버퍼에서 삭제하는 방식으로 작동한다.\n\n\nSelective ARQ Protocol 에 대해 설명하고 Go-back-N ARQ와의 차이점에 대해 설명해보아라\n\n이 프로토콜과 Go-back-N ARQ 프로토콜의 차이점은 프레임의 유실이 발생했을 때 이후에 수신되는 프레임들을 폐기하지 않고 수신자의 버퍼인 Receive Window에 저장해두었다가, 수신받지 못한 프레임을 재전송받는데에 있다. 수신받지 못한 프레임을 재전송해달라는 의미로 ACK가 아닌 NAK를 사용하는데, 수신자는 수신받은 프레임이 중간에 하나 비는것을 Sequence Number를 이용해 판단하고, 수신받지 못한 프레임이 있을 경우 ACK를 보내지 않고 NAK를 전송한다. NAK를 받은 송신자는 해당하는 프레임만 재전송한 뒤, 수신자가 수신하고 전부 정상적으로 수신되었다면 ACK를 보내어 다음 프레임들을 받게 된다.\n\n\nPiggybacking에 대해 설명해보아라\n\nPiggybacking은 양방향으로 데이터 통신을 하는 경우, ACK를 데이터와 함께 프레임에 넣어 송신하는 방법이다. 이렇게 함으로 자기가 송신해야 하는 데이터와 함께, 수신받은 데이터에 대한 ACK를 동시에 송신할 수 있게 된다.\n\n\nGo-back-N ARQ와 Selective ARQ에서 Slide Window의 사이즈와 Sequence Number를 어떻게 설정하면 수신 에러가 나는지와 그 이유에 대해 지껄여보거라\n\nGo-back-N ARQ에서는 Slide window의 사이즈와 Sequence Number의 크기가 동일할 경우에 수신 오류가 난다. 만약 Slide Window의 사이즈가 4이고 Sequence Number가 03일때 송신자가 03의 프레임을 모두 전송했다고 하자. 이때 수신자는 이 프레임들을 전부 수신받고 그 다음 프레임인 0번을 기다리는 상황에서 전송한 ACK가 전부 유실되면 송신자는 ACK가 전부 들어오지 않으므로 Slide Window에 있는 프레임을 전부 재전송하게 된다. 그럼 수신자에게는 재전송한 0번 프레임부터 수신되지만 수신자 입장에서는 이것이 재전송된 프레임이 아닌 내가 그 다음으로 받아야 할 0번 프레임으로 판단해 폐기하지 않고 수신하게 된다. 따라서 프레임의 중복수신이 일어나므로 수신 오류가 난다.\nSelective ARQ에서는 Slide 혹은 Receive Window의 크기가 Sequence Number 크기의 절반보다 크면 수신 오류가 생긴다. 만일 Window의 사이즈가 3이고 Sequence Number가 03이라고 가정해보자. Window의 사이즈가 3이기 때문에 송신자는 02의 프레임을 송신할 것이고, 수신자는 이 프레임을 전부 정상수신했지만 ACK가 전부 누락된 상황이라고 해보자. 수신자는 0~2프레임을 정상수신했으므로 Receive Window에 3번, 0번, 1번의 프레임이 수신되기를 기다리고 있는데 송신자 입장에서는 ACK가 전부 들어오지 않았으므로 Slide Window에 있는 프레임을 전부 재전송한다. 그럼 수신자에게는 재전송한 프레임 0번, 1번, 2번이 수신되지만 수신자는 이것이 재전송한 프레임이라는 것을 인지하지 못하고 0번과 1번을 Receive Window에 삽입하게 된다. 따라서 프레임 중복수신이 일어나므로 수신 오류가 난다.\n\n\nNormal Response Mode의 개념에 대해 설명하고 이때의 Point-to-Point와 Multipoint의 개념에 대해 설명해보아라. 그리고 Asynchronous Balanced Mode의 개념에 대해서도 설명해보아라\n\nNormal Response Mode는 통신에 참여한 station중 하나의 station에서만 통신을 시작하는 것이 가능한 방법이다. Point-to-Point는 station과 station이 1:1로 통신하는 경우이고, Multipoint는 1:n으로 통신하는 경우를 의미한다. Asynchronous Balanced Mode의 경우에는 통신에 참여한 station이 모두 통신을 먼저 시작할 수 있는 것을 의미한다.\n\n\nHDLC 프로토콜의 S-frame, I-frame, U-frame의 개념에 대해 설명하고, 각각의 frame header의 Control bit에 대해 구조와 의미를 설명해보아라\n\nS-frame은 데이터를 송신하기 위한 프레임이며, I-frame은 ACK나 NAK를 송신하기 위한 프레임, U-frame은 통신 모드 변경등의 통신을 위한 프레임이다.\nS-frame의 경우는 Control bit가 0으로 시작하며 수신자의 Sequence Number인 N(R)와 송신자의 Sequence Number인 N(S)로 구성된다. N(R)은 자신이 받은 프레임에 대해 정상적으로 수신하였고, 다음 프레임을 요청하는 용도로 사용되므로 ACK의 Sequence Number와 동일한 기능을 한다. N(S)는 자신이 보내는 데이터에 대한 Sequence Number를 명시하는 용도이다. S-frame에 N(R)과 N(S)이 모두 존재하는 이유는 Piggybacking을 지원하기 위한 용도이며, 데이터를 수신하지 않고 송신만 하는 경우에는 N(R)은 사용하지 않고 N(S)만 사용게 된다.\nI-frame의 경우에는 Control bit가 10으로 시작하며 프레임의 용도를 구체적으로 구분하기 위한 Code와 N(R)로 구성된다. Code부분을 이용해 현재 통신속도가 양호한지, 아니면 너무 빠른지 등을 알릴 수 있고, 해당 프레임이 ACK가 아닌 NAK로 기능한다는 것도 알릴 수 있다. I-frame은 기본적으로 ACK로 작동하므로, 상대방에게 ACK Sequence Number를 알리기 위해 N(R)을 시용한다.\nU-frame의 경우에는 Control Bit가 11로 시작하여 통신 모드를 Normal Responce Mode나 Asynchronous Balanced Mode로 설정하는 등의 통신 관리를 위한 bit인 Code Bit들을 사용한다.\n\n\n\nMedia Access Control §\n\nMedia Access Control의 개념에 대해 설명해보시오\n\nMedia Access Control이라는 것은 하나의 통신 회선을 여러 station이 공유할때, 프레임을 동시에 보내게 되면 충돌이 일어나 프레임이 제대로 수신되지 않는 것을 막기 위해 통신을 제어하는 방법을 의미한다.\n\n\nMedia Access Control을 크게 세개의 분류로 나누고, 각각에 대해 설명해보아라\n\nMedia Access Control은 크게 Random Access, Controlled Access, Channelization으로 분류할 수 있다.\nRamdom Access는 회선을 사용할 수 있는 권한을 랜덤한 경쟁을 통해 얻어내는 방법을 의미한다.\nControlled Access는 통신 중앙 제어장치가 존재해 이것의 관리 하에 충돌이 일어나지 않도록 통신하는 방법을 의미한다.\nChannelization은 Multiplexing을 이용해 모두가 통신 회선을 이용하지만, 충돌이 일어나지 않게 하는 방법이다.\n\n\nALOHA 알고리즘의 작동 원리에 대해 씨부려보시오\n\nALOHA 알고리즘은 우선 상위 걔층으로부터 데이터를 전달받으면 랜덤한 시간동안 대기한 후에 프레임을 전송하는 구조이다. 이렇게 하는 이유는 충돌이 일어났을 경우 ACK를 수신받지 못하게 되는데, 모든 station이 같은시간동안 대기하고 재전송할 경우 다시 충돌이 일어나기 때문이다. 따라서 랜덤한 시간동안 대기하는 방법을 통해 재충돌을막는 방법을 사용한다.\nALOHA 알고리즘은 다음과 같이 작동한다. 우선 시도횟수를 0으로 하여 시작하게 되는데, 프레임 전송 후에 타임아웃이 걸릴때까지 ACK가 오지 않는다면. 시도횟수를 1 증가시킨 후 (0 ~ 2^시도횟수 - 1)중 하나의 숫자를 랜덤으로 뽑는 Binary Back-off의 방법을 통해 난수를 하나 생성한다. 이후 난수에 프레임이 송신지까지 도달하는데까지 걸리는 시간을 곱해 대기시간을 설정한다. 그리고 대기시간 이후 다시 프레임을 전송해보고, ACK가 오지 않을 경우 시도횟수를 하나 증가시키고 다시 난수를 생성하여 대기하는 과정을 반복하며, 시도횟수가 15를 넘을 경우에는 Abort하는 방법으로 작동한다.\n\n\nALOHA 알고리즘의 단점에 대해 설명하고, 이것을 해결하기 위한 Slotted ALOHA 알고리즘에 대해 설명하시오\n\nALOHA 알고리즘의 단점은 랜덤하게 결정된 대기시간이 어떤 값이든 될 수 있기 때문에 다른 station에서 프레임을 송신하고있는 와중에 프레임을 전송하여 충돌이 날 수 있다는 것이다.\n따라서 Slotted ALOHA알고리즘에서는 일정시간단위로 시간을 나눈 Slot의 개념을 이용한다. 하나의 프레임은 하나의 Slot에서 송신 완료되도록 하고, 난수를 이용해 대기시간을 설정할때 Slot단위로 대기시간이 설정되게 해 중간에 겹치는 일이 없도록 하는 것이 이 알고리즘의 특징이다. 따라서 프레임이 준비되면 바로 전송하는것이 아닌, 새로운 Slot이 시작되는 시점에 전송되며, 충돌이 일어날 경우 난수를 통해 Slot단위의 대기시간을 생성한 후 대기해 대기시간이 종료되면 해당 Slot이 시작되는 시점에 송신하게 된다.\n\n\nCSMA 프로토콜의 핵심적인 기능을 CSMA의 말뜻과 함께 설명하시오\n\nCSMA는 Carrier Sensing Multiple Access의 약자로, 통신매체를 사용하고있는 station이 있는지를 수시로 확인하는 Carrier Sensing기법을 사용한다.\n\n\nCSMA에서 발생할 수 있는 충돌 중 한가지를 1-persistant를 이용해서 설명해보이소. 그리고 충돌이 일어날 수 있는 나머지 한가지 경우에 대해서도 설명해보이소\n\n1-persistant의 경우 회선이 비었는지 아닌지를 수시로 체크하고 회선이 빌 경우 바로 프레임을 송신한다. 하지만 송신하고자 하는 station이 여러개일 경우 회선이 비는 것을 동시에 감지하고 프레임을 전송하기 때문에 충돌이 발생할 수 있다\n충돌이 발생하는 나머지 하나의 경우는 한 station이 프레임을 송신했지만 다른 station의 위치까지 도달하지 않아 회선이 비었다고 판단해 프레임을 송신하는 것이다\n\n\nNon-persistant와 p-persistant에 대해서 설명해보이소.\n\nNon-persistant는 회선이 사용중인지 아닌지를 확인하는 것을 랜덤하게 하는 것을 말한다. 즉, 회선을 검사한 후에 회선이 사용중이라면 랜덤한 시간을 대기한 후, 대기시간이 종료되면 그때 다시 검사하는 방법이다. 만일 검사했을때 회선이 비었다면 바로 프레임을 송신하게 된다.\nP-persistant는 time slot개념을 이용하는 방법이다. 회선을 계속 검사하다 회선이 비면 난수를 하나 뽑아 지정된 상수보다 작은지 아닌지를 판단한다. 만일 작으면 해당 slot에서 전송하게 되고, 크다면 다음 slot이 오기만을 기다리다 slot이 오면 회선이 비었는지를 판단하고, 비었다면 다시 난수를 뽑는 과정을 반복한다. 회선이 비지 않았다면 다시 회선이 빌때까지 계속 확인하는 과정으로 돌아간다.\n\n\nCSMA / CD에서 CD의 말뜻과 이것의 작동원리를 설명하시오\n\nCSMA / CD에서 CD는 Collision Detection을 의미한다. 이것은 파동의 중첩원리를 이용하는데, 신호 두개가 충돌하면 파동의 세기가 두배가 되기 때문에 수신된 신호의 세기가 비정상적으로 크다면 충돌이 일어났다고 판단하는 것이다. 충돌이 감지되면 그 즉시 송신을 중단하기 때문에, 더 효율적이라는 장점이 있다.\nCSMA / CD은 우선 시도횟수를 0으로 두고 Persistant중 하나를 이용해 프레임을 전송할 시점을 정한 후, 프레임을 전송한다. 프레임이 전송되다 멈추면, 멈춘 이유가 충돌이 감지돼서인지 송신이 완료돼서인지 판단하고 충돌이 감지된 경우라면 시도횟수를 1 증가시키고 Binary Backoff를 이용해 랜덤한 시간을 대기한 후 다시 Persistant를 이용해 프레임을 전송할 시점을 정하는 것으로 돌아간다.\n\n\nCSMA / CD에서 충돌이 감지되는 Best Case와 Worst Case에 대해 설명하고, Worst Case를 이용해 CSMA / CD를 사용할 수 있는 조건에 대해 한번 설명해보이소\n\n충돌이 감지되는 Best Case는 다른 Station에서 송신한 프레임이 자신에게 거의 다 도달해서 프레임을 송신한 직후 충돌이 일어나 그것을 감지하는 경우이다.\nWorst Case는 자신이 전송한 프레임이 다른 Station에 도달하기 바로 직전 해당 station이 프레임을 송신해 충돌이 일어나는 경우이다. 이 경우에는 자신으로부터 다른 station에게 프레임이 전송되기까지 걸리는 시간과 충돌이 일어난, 다른 station이 송신한 프레임이 자신에게 전송되기까지의 시간을 합친 만큼의 시간 뒤에 충돌이 일어나므로 충돌이 일어났다는 사실을 매우 늦게 알게 된다.\n근데 충돌이 일어난, 다른 station이 보낸 프레임이 자신에게 도달하기 전에 프레임의 송신이 완료된다면 CSMA / CD가 가지는 이점을 활용할 수 없을 것이다. 따라서 프레임을 송신하는데 걸리는 시간이 프레임이 목적지까지 가는데 걸리는 시간의 두배보다 커야 CSMA / CD를 사용할 수 있다.\n\n\nCSMA / CD를 무선환경에서 사용하지 못하는 이유와 CSMA / CA의 개념에 대해 설명하시오.\n\nCSMA / CD는 신호 세기의 증폭을 이용해서 충돌여부를 가리지만 무선환경에서는 충돌이 일어나도 증폭률이 크지 않아 충돌을 감지하기 어렵다\n따라서 CSMA / CA에서는 충돌을 감지하기 않는대신 ACK같은 프레임 송신 후에 연달아 전송되는 프레임이 송신되는 것을 보장해주기 위해 IFS라는 시간을 대기한다.\n우선 시도횟수를 0으로 시작하여 회선이 비워질때까지 대기한다. 회선이 비워진 뒤에는 IFS 시간동안 대기한 뒤 Binary Backoff를 이용해 프레임을 보낼 시점을 정하고, 회선이 아직도 비워져 있는지를 확인한 뒤 프레임을 송신한다. 회선이 비워져있지 않다면 다시 비워질때까지 대기하게 되고, 프레임을 송신한 뒤에는 ACK가 수신되는 것을 기다렸다가 수신되지 않으면 시도횟수를 1 증가시키고 다시 회선이 비워져있는지 확인하는 과정을 반복한다.\n\n\nPolling의 작동방식을 Poll, SEL, ACK, NAK의 개념을 이용해 설명해보아라\n\nPolling은 Primary라는 통신 중앙 제어 장치가 존재해 이것의 관리 하에 Contention Free한 통신이 이루어진다.\n먼저 Station에서 Primary로 데이터를 보내는 방식은 다음과 같다. Primary는 Station각각에 대해 보낼 데이터가 있는지 물어보는 프레임인 Poll을 하나씩 보내게 된다. 만일 Station이 보낼 데이터 없다면, NAK을 보내게 되고 보낼 프레임이 있다면 Data를 보내게 된다. 그럼 Primary는 ACK를 전송하는 것으로 통신이 마무리된다.\nPrimary에서 Station으로 데이터를 보내는 방법은 다음과 같다. Primary는 우선 보내고자 하는 Station에게 받을 준비가 되었냐는 것을 의미하는 프레임인 SEL을 전송하게 된다. 만일 준비가 되었다면 Station은 ACK를 보내게 되고 그럼 Primary는 데이터를 해당 Station에게 보내게 된다. 그럼 Station이 ACK를 보내는 것으로 통신이 종료된다\nStation에서 Station으로 데이터를 보내는 방법은 다음과 같다. Polling은 Primary에서만 통신을 먼저 시작할 수 있으므로 Station과 Station간의 통신은 중간에 Primary를 거치는 방식으로 진행된다. 우선 Primary가 자신에게 Poll을 보낼때까지 기다린다. 그럼 보낼 데이터를 Primary로 먼저 보내게 되고, 그것을 수신한 Primary는 이것이 다른 Station에게 가야되는 프레임이라는 것을 깨닫고 해당 Station에게 SEL을 보내 데이터를 전송하게 된다.\n\n\nToken Passing의 작동방식을 간단맨하게 설명해보아라\n\nToken Passing은 통신에 참여한 Station이 번갈아 Token이라는 이름의 통신 제어권을 얻게되는 구조이다. 한 Station에게 Token이 있다면, 자신이 보낼 데이터들을 전부 보낸 후, 다음 순번의 Station에게 Token을 넘기게 되고 그럼 그 Station이 자신이 보낼 데이터를 전부 송신하는 구조인 것이다.\n\n\nCDMA의 개념과 작동원리에 대해 설명해보아라\n\nCode-Division Media Access 프로토콜은 DSSS와 유사한 방식으로 작동한다. 즉, 각 Station들은 Walsh Table을 이용해 생성된 Spread Code를 하나씩 갖고 있고, 자신의 데이터의 각 비트들을 자신의 Spreading Code에 곱해 데이터를 변환한다. 그리고 모든 Station들은 그것을 회선의 사용여부와 무관하게 송신하게 된다. 그럼 수신자 입장에서는 충돌이 일어난 데이터를 받게 되는데, 여기서 특정 송신자가 송신한 데이터를 받고 싶으면 그 송신자의 Spreading Code를 데이터에 곱해주게 되면 원본의 데이터로 변환되게 된다.\n\n\n\nEthernet §\n\nIEEE 802의 개념에 대해 어떤 환경에서 사용하도록 만들어진 표준인지를 포함하여 적으시오. 그리고 여기서는 어떤 프로토콜을 Logical Link Control에서 사용하는지 적으시오.\n\nIEEE 802는 LAN환경에서 작동하는 물리계층과 데이터 링크 계층들의 여러 함수(모듈)등을 표준화한 것이다.\n그리고 여기서는 HDLC 프로토콜을 Logical Link Control에서 사용한다\nHDLC 프로토콜이 담긴 LLC의 헤더를 LLC PDU라고 부른다\n\n\nStandard Ethernet이 사용하는 Bus Topology에 대해 설명해보아라\n\nBus Topology는 하나의 통신 회선에 별다른 장치 없이 여러 Station들이 병렬적으로 연결된 구조를 의미한다\nBus Topology를 사용하는 Ethernet을 Bridged Ethernet이라고 한다\n\n\nStandard Ethernet의 최대 / 최소 전송 바이트를 적고 이것이 필요한 이유에 대해 설명하시오\n\nStandard Ethernet의 최대 전송 byte는 헤더를 제외하고 1500byte이고, 최소 전송 바이트는 헤더를 제외하고 46byte이다.\n전송 최대 크기가 필요한 이유는 너무 많은 바이트를 보내게 되면 Redundancy Bit가 너무 커지기 때문이고, 전송 최소 크기가 필요한 이유는 Standard Ethernet이 CSMA / CD를 사용하기 때문이다.\n\n\nStandard Ethernet이 사용하는 물리계층의 프로토콜과 MAC 프로토콜을 적어보아라\n\nStandard Ethernet은 물리계층에서는 Manchester Scheme 프로토콜을 이용하고, 사용하는 MAC프로토콜로는 CSMA / CD를 사용한다.\n\n\nFast Ethernet과 Gigabit Ethernet 에서는 이전버전과의 호환성을 위해 BusCSMA / CD, Bus Topology등을 사용하는 함수들을 전부 삭제시켰다 (O / X)\n\n아니쥬?(X)\n\n\nFast Ethernet과 Gigabit Ethernet에서 사용하는 Star Topology에 대해 설명해보시오\n\nStar Topology는 하나의 회선에 Station들이 연결하는 구조가 아닌 중앙 Switch에 Station들이 붙게 되고 이것이 통신의 전반을 제어함으로써 Contention Free한 통신을 하게 되는 것을 의미한다.\nStar Topology의 Switched Ethernet은 Half-Duplex Switched Ethernet으로, 중앙 Switch에 하나의 회선으로 연결해 이것으로 데이터의 송수신을 모두 하는 것을 의미한다\nFull-Duplex Switched Ethernet은 중앙 Switch에 송신용 회선과 수신용 회선을 연결해 송수신 회선을 두개로 분리하여 송수신 하는 것을 의미한다\n두개의 Station만 직접적으로 연결한 Point-to-Point, 하나의 Switch를 사용하는 Star, 여러개의 Switch를 이용하는 Multiple Stars, Switch들을 또 하나의 Switch로 묶은 Hierarchy of Stars로 분류한다\n\n\nFast Ethernet과 Gigabit Ethernet의 물리계층에서는 하나로 통일된 encoding방식을 사용한다(O / X)\n\n아니쥬?(X)\nFast Ethernet과 Gigabit Ethernet에서는 통신 매체의 종류에 따라 다른 encoding 방식을 사용한다\n\n\n\nWifi §\n\nPCF와 DCF, AP의 개념에 대해 설명해보아라. 그리고 PCF와 DCF에서 사용하는 MAC 프로토콜이 무엇인지 적어라\n\nPCF는 중앙 통신 제어 장치를 이용해 Contention Free한 통신을 하는 경우를 일컫는다. 그리고 이때의 중앙 통신 제어 장치를 AP라고 부르며 Polling 방식으로 통신하게 된다.\nDCF는 AP를 이용하지 않고 직접 통신하는 경우를 말한다. 당연히 Contention의 가능성이 있으며, 이것을 줄이기 위해 CSMA / CA를 사용한다.\n\n\nBSS와 ESS의 개념에 대해 설명해보아라\n\nBSS는 Station들이 직접 통신하거나 AP하나를 두고 통신할 수 있을 만큼 가까운 거리에서의 통신을 의미한다.\nESS는 Station들간의 거리가 멀어 AP와 유선통신을 거쳐 통신하게되는 구조를 말한다.\n\n\nSIFS, PIFS, DIFS의 개념을 설명해보아라. 그리고 각각의 길이를 대소비교하고 그 이유에 대해 적어라\n\nSIFS는 프레임을 수신한 후, 이것에 대한 답장을 준비하여 전송하기까지의 최소한의 시간이다.\nPIFS는 통신회선이 idle해진 이후 AP가 기다리는 시간이다.\nDIFS는 통신회선이 idle해진 이후 통신에 참여하지 않았던 Station이 기다리는 시간이다.\nSIFS &lt; PIFS &lt; DIFS순으로 시간이 길다. 왜냐하면 SIFS는 지금까지 통신에 직접적으로 참여하고 있었던 Station이 기다리는 시간이므로 제일 우선순위가 높기 때문이다. DIFS는 지금까지의 통신에 참여하고 있지 않았던 Station들이므로 가장 낮은 우선순위를 가진다. AP는 통신을 제어해야되기 때문에 기존의 통신에 참여하고있지는 않았어도 다른 Station들보다 더 높은 우선순위를 가지게 하기 위해 SIFS보다는 길지만 DIFS보다는 짧은 시간을 PIFS가 가지게 된다.\n\n\nWifi에서의 CSMA / CA에 등장하는 Virtual Carrier Sensing의 개념에 대해 NAV의 개념과 함께 설명하고, 작동 과정에 대해서도 설명하되 RTS, CTS의 개념과 각 프레임이 수신되었을 때 기다리는 IFS의 종류를 포함하여 설명하라\n\nVirtual Carrier Sensing은 통신 우선권을 가진 Station들이 특별한 프레임을 송신해 다른 Station들에게 “지금 우리가 통신할 것이니 앞으로 언제까지는 Carrier Sensing을 하지 말아라”라고 통보하는 것이다. 이렇게 함으로써 다른 Station들은 Carrier Sensing을 하는데 들어가는 전력소모를 줄일 수 있고, 통신에 참여하는 Station들은 해당기간 내에는 충돌을 완벽하게 배제할 수 있게 된다는 장점이 있다. 그리고 이렇게 해서 Carrier Sensing을 하지 않는 기간을 NAV라고 한다.\n작동과정은 일단 Persistant를 이용해 프레임의 전송 시점을 정한다. 그리고 그 시점이 오면 DIFS를 기다린다. DIFS를 기다리는 것은 이전의 통신에는 참여하고있지 않았기 때문이다. 그리고 먼저 RTS를 보낸다. RTS는 Ready To Send를 의미하는 프레임으로 상대방에게 수신할 준비가 되었냐고 물어보는 동시에 통신에 참여하지 않는 Station들에게 이제부터 통신을 할것이니 언제까지 NAV로 설정하여라 라고 통지하는 용도이다. 또한 이 프레임은 크기가 아주 작아 Error Detection과 Correction이 아주 손쉬우므로 이것을 먼저 보내봐 충돌이 일어나는지 안일어나는지 확인해 DIFS이후에 회선을 사용하고 있는 Station이 존재하는지 알아내는 용도이기도 하다. 그리고 RTS가 정상적으로 수신되었다면 SIFS를 기다린 다음 CTS를 송신한다. 이것은 Clear To Send라는 의미의 프레임으로 상대방에게 통신을 시작하여도 된다고 알려줌과 동시에 자신의 주변에 있는 통신에 참여하지 않는 Station들에게도 NAV를 설정하게 하는 역할을 한다. RTS가 정상적으로 수신되었다면 아무도 회선을 사용하고있지 않았다는 소리이므로 다른 Station들은 NAV가 설정되었을 테니 충돌의 여지가 없어 SIFS만을 기다리게 된다. 그리고 CTS를 받은 송신자는 SIFS를 기다린 후 데이터 프레임을 송신하게 되는 식으로 통신이 이루어진다. SIFS를 기다리는 이유도 마찬가지로 이미 다른 Station들은 NAV가 설정되어 충돌의 여지가 없기 때문이다.\n\n\nWifi의 통신 전 과정에 대해 Super frame, Beacon, CFP, CP의 개념들도 같이 설명하며 서술해보거라 그리고 각각의 경우 사용되는 IFS도 같이 서술하여라\n\nWifi의 통신 과정은 일단 Super frame의 반복으로 이루어진다. 즉, Super frame은 Wifi 통신의 기본 단위인 것이다.\n하나의 Super frame은 일단 AP가 PIFS를 기다리고 Beacon Frame을 송신하는 것으로 시작한다. AP가 통신을 하는것이기 때문에 DIFS가 아닌 PIFS만을 기다리고 송신한다.\nBeacon Frame에는 PCF로 통신할 기간과 DCF로 통신할 기간, 다음 Beacon을 보내는 시간이 명시되어 있다. 이것은 Wifi가 Polling을 이용한 통신과 CSMA / CA를 이용한 통신을 둘 다 활용하기 때문이다. 또한 PCF로 통신할 기간을 명시함으로써 이 기간동안에는 Station들이 전부 Carrier Sensing을 하지 않는다. Virtual Carrier Sensing이 이루어지는 셈인 것이다. Beacon을 송신하고 PCF로 통신하는 기간 동안은 AP의 제어 하에 이루어지기 때문에 충돌의 위험이 없어 CFP, 즉, Contention Free Period라고 부르고 이후 DCF로 통신하는 기간 동안은 충돌의 위험이 있기 때문에 CP, 즉, Contention Period라고 부른다. 따라서 하나의 Super frame은 CFP와 CP로 구성되는 셈이다.\nPCF 통신 구간에는 AP의 지휘 아래 Polling방식으로 통신한다. 그리고 이때에는 충돌의 위험이 없으니까 SIFS만의 시간만을 기다리고 송신하게 된다\nPCF가 종료되면 AP가 CF-End의 프레임을 전송한다. 그럼 이때부터 DCF방식으로 통신하므로 Station들이 CSMA / CA의 방식으로 DIFS를 기다리고 프레임을 전송하게 된다.\nDCP가 종료되면 AP가 우선권을 가지므로 PIFS를 기다리고 Beacon을 전송한다. 이렇게 새로운 Super frame이 시작되는 것이다.\n\n\nWifi의 Frame에서 Type을 통해 어떤 종류의 프레임을 구분하는지 서술해보거라\n\nType의 비트에 따라 Beacon등으로 작동하는 Management type인지, RTS, CTS, ACK, NAK등으로 작동하는 Control type인지, 아니면 데이터를 송신하기 위한 Data type인지 구분한다.\nType 00 Subtype 1000이면 Beacon으로 기능하고\nType 01 Subtye 1011이면 RTS, 1100이면 CTS, 1101이면 ACK로 기능하며\nType 10이면 데이터 송신용 프레임으로 사용된다\n\n\nIntra-BSS와 Inter-BSS의 개념에 대해 서술해보거라\n\nIntra-BSS는 BSS내부에서의 통신으로 AP를 이용하거나 직접 통신하는 방법으로 가시적인 가까운 거리 내에서 통신하는 것을 의미한다\nInter-BSS는 BSS간의 통신으로 BSS의 AP들을 유선통신으로 연결해 유선통신을 거쳐 비교적 먼 거리를 통신하는 것을 의미한다\n\n\nIntra-BSS환경에서 두 Station이 직접 통신하는 경우와 Inter-BSS의 경우에 대해 통신 과정을 서술해보거라. 이때 프레임 헤더의 To-DS bit와 From-DS bit가 어떻게 설정되는지, 그리고 각각의 경우 Address 1, 2, 3, 4에 어떤 값이 들어가는지를 보여라\n\nIntra-BSS의 환경에서 두 Station이 직접 통신하는 경우에는 프레임을 직접 주고받으므로 To-DS와 From-DS가 00으로 설정된다. 그리고 Address 1에는 송신지의 주소, Address 2에는 수신지의 주소가 설정되게 된다.\nInter-BSS의 환경에서 Station A이 StationB에게 송신한다고 하고 A와 가까운 AP를 AP1, B와 가까운 AP를 AP2라고 해보자. 우선 A는 AP1으로 프레임을 전송하게 된다. 이때 To-DS는 1, From-DS는 0으로 설정되고 Address1에는 AP1, Address2에는 A, Address3에는 B가 설정된다.\nAP1으로 온 프레임은 유선통신을 이용해 AP2로 이동한다. 이때 To-DS는 1, From-DS는 1, Address1은 AP1, Address2는 AP2, Address3은 A, Address4는 B로 설정된다\nAP2로 온 프레임은 B에게 전달된다. 이때 To-DS는 0, From-DS는 1, Address1은 AP2, Address2는 B, Address3은 A로 설정된다.\n\n\n\nBluetooth §\n\nBluetooth가 사용하는 ISM band에 대해 간략하게 말해보거라\n\nISM band는 Industrial, Scientific, Medical의 약자로 이것을 위한 공익 목적의 대역폭을 의미한다.\n\n\nPiconet, Scatternet에 대해 간략히 설명해보거라\n\nPiconet은 하나의 Primary와 여러개의 Secondary로 이루어진 환경을 의미하고\nScatternet은 하나의 Primary와 여러개의 Secondary, 그리고 여러개의 Secondary / Primary 로 구성된 환경을 의미한다. 여기서 Secondary / Primary는 하나의 Primary에 지배를 받는 Secondary이긴 하지만 그와 동시에 다른 여러개의 Secondary들을 거느릴 수 있는 단말을 의미한다.\n\n\nBluetooth의 개발 목적을 간략하게 설명해보거라\n\nBluetooth는 Secondary의 칩을 아주 작고 값싸게 만들어 다양한 단말에 이식해 단말간 근거리 무선 통신을 하기 위해 개발되었다\n\n\nBluethooth의 계층구조를 Bluetooth Protocol Profile, L2CAP, Audio, Upper Stack Layer, Baseband, Bluetooth Radio, Lower Stack Layer, Host Controller Interface의 용어를 설명해가며 서술해보거라 한번\n\n일단 Bluetooth로 전송할 수 있는 데이터 중 음향이 아닌 모든 데이터는 여러개의Bluetooth Protocol Profile들에 의해 만들어진다. 그리고 이것은 데이터 링크 계층의 LLC sublayer에 해당하는 L2CAP이라는 모듈로 모인 후 데이터 링크 계층에 해당하는 하위계층인 Baseband계층으로 내려간다. 음향의 경우 Audio라는 모듈을 통해 만들어진 후 L2CAP을 거치치 않고 바로 Baseband로 내려가게 된다. 그리고 Baseband에서는 물리계층에 해당하는 Bluetooth Radio로 내려보내게 된다. Baseband 의 상위 계층들은 소프트웨어적으로 구현되어 있어 Upper Stack Layer라고 하며, Baseband를 포함한 하위계층은 하드웨어적으로 구현되어 있어 Lower Stack Layer라고 한다. 그리고 이 둘을 Host Controller Interface가 연결하게 된다.\n\n\nBaseband가 사용하는 TDMA 프로토콜에 대해 Hop을 이용해 설명해보거라.\n\nTDMA는 기본적으로 Slot을 이용한다. 그리고 짝수번쨰의 Slot에는 Primary만 Hop의 형태로 데이터를 전송하고 홀수번쨰의 Slot에는 Secondary만 Hop의 형태로 데이터를 전송한다.\n\n\nBaseband의 SCO, ACO모듈에 대해 각각의 경우 Hop의 길이는 어떻게 되는지, 어느 상위 모듈에서 데이터가 들어왔을때 해당 모듈을 사용하는지 구분하여 서술하여라\n\nSCO모듈은 송수신의 정확성보다는 그 속도에 중점이 맞춰져 있는 통신방식이다. 음향의 전송의 경우에는 지연이 없어야 하므로 Audio 모듈에서 SCO방식의 데이터를 생성하며, Primary와 Secondary가 빠르게 데이터를 주고받아야 하기 때문에 하나의 Slot에 하나의 Hop을 전송하게 된다\nACO모듈은 송수신의 속도보다는 정확성에 중점이 맞춰져 있는 통신방식이다. 음향이 아닌 모든 데이터에 대해 필요하므로 L2CAP에서 ACO방식의 데이터를 생산한다. Redundancy Bit등을 늘리거나 한번에 많은 양의 데이터를 전송하기 때문에 프레임의 크기가 커 1, 3, 5개의 Slot에 걸쳐 하나의 Hop을 보내는 방식으로 통신한다.\n\n\n블루투스를 이용한 전화를 걸고 받는 과정에 대해 설명해보거라\n\n일단 상대방의 전화번호 등의 데이터와 전화가 걸려왔다는 신호 등을 보낸다. 이것은 음향신호가 아니므로 L2CAP에서 SCO방식으로 데이터가 생성된다.\n그리고 전화를 받으면 그때부터는 음향신호이므로 Audio모듈로 변경되어 ACO방식으로 데이터가 생성된다\n\n\n\nLayer Architecture §\n\nProtocol, Standard의 차이와 Protocol을 Algorithm으로 부르는 이유에 대해 서술해보거라\n\nProtocol은 통신을 위해 통신에 참여한 단말들 간 약속을 한 것을 의미하고\nStandard는 Protocol중 하나를 정해 표준으로 설정함으로써 대부분의 단말들이 지키도록 한 것이다.\nProtocol은 통신을 효율적으로 하기 위해 문제를 해결한 것이라고 볼 수 있으므로 Algorithm의 일종이라고 볼 수 있다.\n\n\n프로토콜의 구성요소 세가지에 대해 설명해보거라\n\n프로토콜은 Syntax, Semantics, Timing으로 구성된다\nSyntax는 프레임을 구성하는 형식(Format)을 의미한다\nSemantics는 각 Syntax마다 그것이 어떤 의미를 가지는 지 이다.\nTiming은 통신이 혼자서 하는 것이 아니고 상대방과 같이 하는 것이기 때문에 시간을 통일시키는 것을 의미한다.\n\n\nLayer Architecture의 개념과 이유를 설명하여라. 그리고 Module, Interface, Peer-2-Peer의 개념에 대해 말해보고 Interface를 이용하는 것의 장점에 대해 말해보거라\n\nLayer Architecture은 통신을 위한 시스템을 계층적으로 구성한 것을 의미한다. 여기서 계층적이라는 것은 상위 계층에서 하위 계층의 서비스를 아용할 수는 있지만, 하위계층에서 상위계층의 서비스를 이용할 수는 없는 것을 의미한다. 이렇게 하는 이유는 통신 시스템을 구축하는 것이 아주 방대하기 때문에 기능별로 계층으로 나눠 각각의 계층을 개발한 후, 이어붙이는 식으로 개발하기 위해서이다.\nModule은 각각의 계층을 구현한 것을 의미한다. 그리고 Interface는 계층간 연결해주는 다리같은 역할을 한다. Peer-2-Peer은 계층간 통신을 의미한다. 이것은 어느 한 Station의 한 계층에서 보낸 패킷은 다른 Station의 해당 계층으로 정확히 동일하게 전달되므로 계층을 오르내리며 통신하는 것이 아닌 계층간 통신을 하는 것으로 단순화해서 생각할 수 있다는 의미를 가진다. 이것은 두 Station간의 통신이라는 아주 어려운 문제를 계층간 통신이라는 비교적 단순한 문제로 나누어서 생각할 수 있다는 장점이 있다\nInterface를 이용하는 것의 장점은 만일 Module이 변경되었을 경우 인접한 계층의 모듈또한 변경해야 되는 번거로움을 막기 위한 것이다. Module이 변경되어도 Interface가 변경되지 않으면 다른계층의 Module또한 변경하지 않아도 된다는 장점이 있다.\n\n\nData Link Layer의 역할 다섯가지에 대해 말해보거라\n\nFlow Control : Flow Error를 막기 위해 통신의 흐름을 제어하는 것\nError Control : Error Detection, Error Correction을 위해 통신의 흐름을 제어하는 것\nAccess Control : 프레임들 간의 충돌을 막기 위해 통신의 흐름을 제어하는 것\nFraming : 데이터 크기가 너무 크거나 작아 통신에 문제가 생기는 걸 막기 위해 프레임 단위로 나누는 것\nAddressing : 프레임이 정확한 위치에 도달할 수 있도록 주소를 설정하는 것\n\n\nOSI 7 Layer의 각각의 계층의 역할에 대해 설명해보아라\n\nPhysical Layer : 데이터의 인코딩을 통해 최대한 적은 bit가 오송신되도록 하고, 그리고 수신된 bit를 디코딩 하는 작업을 하는 계층\nData Link Layer : Hop-to-Hop통신의 완전무결한 통신을 보장하기 위한 계층\nNetwork Layer : Hop-to-Hop통신에서 더 나아가 Source-to-Destination의 통신을 위한 계층 - Source-to-Destination의 중간 경로 설정의 역할을 한다\nTransport Layer : Hop-to-Hop통신의 완전무결한 통신은 Data Link Layer에서 보장되지만 이러한 완전무결한 Hop-to-Hop통신들이 모인다고 해서 완전무결한 Source-to-Destination의 통신이 이루어지는 것은 아니다 - 여기는 신뢰성 있는 Source-to-Destination 통신을 위한 기능들이 모여있는 계층이다\nSession Layer는 Station내에서 정확한 프로세스를 찾아 수신되게 해주는 것을 위한 계층이다.\nPresentation Layer : 여기서는 UTF-8, ASCII등의 문자열 인코딩이나 암호화 등의 작업을 하게 된다\nApplication Layer : 여기서는 사용자와 직접 소통하는 것을 지원하기 위한 계층이다\n\n\n\nNetwork Layer §\n\nPhysical Address와 Logical Address의 주 목적과 사용되는 계층에 대해 설명해보아라\n\nPhysical Address는 Hop-to-Hop 프레임 전송을 위한 주소로 데이터 링크 계층에서 사용된다.\nLogical Address는 Source-to-Destination 패킷 전송을 위한 주소로 네트워크 계층에서 사용된다.\n\n\nRouter(Intermediate Node, Gateway, Next Hop)의 역할과 이것이 사용하는 계층, 작동원리를 설명하리오. 작동 원리는 2-Level Hierarchy의 필요성, netid, routing table을 이용해 설명하거라\n\nRouter는 패킷이 전송될 때 거치게 되는 중간다리역할을 한다. 또한 다음에는 어느 Router로 가야할지를 알려주는 역할도 하게 된다.\nRouter는 Physical, Data Link, Network 세 계층만을 사용한다.\nRouter에는 Logical Address를 이용해 해당 주소로 가려면 어디로 가야되는지를 나타내는 테이블이 저장되어 있는데, 모든 Logical Address에 대해 Port Number를 저장하면 테이블의 크기가 너무 커지므로 2-Level Hierarchy구조를 가지게 된다. 이것은 Logical Address의 몇개의 비트를 netid로 설정한 뒤, 같은 netid를 가지는 Logical Address들은 하나의 Port로 나가게 하는 방식이다. 따라서 어떤 Logical Address를 가지고 어느 port로 나가야 하는지 알기 위해서는, Logical Address의 netid를 이용해 Routing table에서 Port Number를 알아내는 방식으로 작동한다.\n\n\nLogical Address의 대표적인 세 Class와 이들 각각에 대해 netid와 hostid를 구분하는 방법에 대해 서술해보거라\n\nLogical Address의 Class로는 대표적으로 Class A, Class B, Class C가 있으며\nClass A는 첫번째 비트에 0이 들어가고 그 이후 7개의 비트에 netid가 저장돼있으며 나머지 24개의 비트에 hostid가 저장되게 된다. 십진수로 표현된 Logical Address에서는 뒤의 24 비트가 hostid이므로 A.B.C.D에서 A가 netid이고 B, C, D가 hostid가 되는 셈이다.\nClass B는 첫번째와 두번째 비트가 10이 되고 그후 14개의 비트에 netid가 저장되며 나머지 16개의 비트에 hostid가 저장된다. 십진수로 표현된 Logical Address에서는 뒤의 16비트가 hostid이므로 A.B.C.D에서 A, B가 netid이고 C, D가 hostid가 된다\nClass C의 경우 세번째 비트까지가 110으로 구성되고 그후 21개의 비트에 netid가 저장되며 나머지 8개의 비트에 hostid가 저장된다. 십진수로 표현된 Logical Address에서는 뒤의 8비트가 hostid이므로 A.B.C.D에서 A, B, C가 netid이고 D가 hostid가 된다.\n\n\nnetid와 hostid를 할당받는 방법에 대해 서술하고 각 Class당 하나의 netid에 몇개의 hostid가 대응되는지를 이용해 어떤 기준으로 netid를 할당하는지 적어보거라\n\nnetid는 NIC에서 기관에게 할당해주는 값이다. 해당 기관은 netid를 할당받은 후에, hostid를 독자적으로 할당함으로써 netid와 hostid가 할당된다. Class A의 경우에는 하나의 netid에 2^24개의 hostid가 대응되므로 그정도로 규모가 큰 기관에게 할당해주고, Class B의 경우에는 하나의 netid에 2^16개의 hostid가 대응되므로 그정도의 규모를 가지는 기관에게 할당해주며, Class C의 경우에는 하나의 netid에 2^8개의 hostid가 대응되므로 이정도의 규모를 가지는 작은 기관에게 할당해준다.\n\n\nAS의 개념과 AS는 어떤것을 이용해 통신하는지 적어보거라\n\n라우터와 라우터간의 통신을 위한 라우터를 AS라고 부르고 이때에는 netid만을 가지고 Routing table을 이용해 다음에 이동해야 할 AS를 정하게 된다\n\n\nSubnet의 개념과 장점, 작동과정에 대해 설명하시오. 이때 Destination, Subnet Mask, Port Number, Default의 용어를 활용하시오.\n\nSubnet은 라우터간의 통신이 아니고 라우터에서 특정 Station으로 가야할때 사용하는 방법이다. 라우터의 하나의 포트에 모든 Station들을 병렬적으로 연결할 수도 있지만 Subnet을 이용해 하나의 포트를 여러개의 포트로 나눠준 뒤, 각각의 포트에 Station들을 병렬적으로 연결하는 방식으로 구성된다. 이렇게 하는것의 장점은 물리적으로 인접한 위치에 있는 Station들에 대해 하나의 포트를 할당하여 네트워크의 전체 구조를 계층적으로 형성하여 한눈에 보기 쉽다는 것이다.\nSubnet의 작동과정은 일단 Subnet Router를 설치할 때 Routing Table을 생성한다. Routing table에는 Destination, Subnet Mask, Port Number가 있는데 Logical Address가 하나 들어오면 이 테이블의 첫번째 행의 Subnet Mask와 AND연산을 한다. 그리고 그 결과가 Destination과 일치하는지 확인한다. 그리고 일치할 경우에는 해당 Port Number로 빠져나가고, 아니라면 다음 행에 대해 동일한 작업을 반복한다. 그리고 만약 어떠한 Destination과도 일치하지 않는다면, 해당 Subnet에 속하지 않는 Logical Address인 것이므로 Subnet Mask를 0.0.0.0으로 하고 이때의 Destination은 Default인 0.0.0.0으로 하며 Port Number로는 Subnet의 외부로 빠져나가게 하는 Port Number를 주어서 빠져나가게 한다.\n\n\nLogical Address 192.168.188.67이 192.168.188.0/26에 해당하는 Port로 빠져나가는지 판단해봐라 그리고 해당 Port에 몇개의 Station이 연결되어 있는지 판단하여라\n\n192.168.188.0이 Destination이고, /26이면 Subnet Mask가 255.255.255.192이므로 192.168.188.67과 Subnet Mask를 AND연산하면 그 결과는 192.168.188.64가 되어 Destination과 일치하지 않으므로 해당 Port로 빠져나가지 않는다.\n32 - 26 = 6이므로 2^6개인 64개의 Station이 해당 포트에 연결되어 있다.\n\n\nStation에 내장되어 있는 Routing Table을 생성하는 방법에 대해 설명해보거라\n\nStation에 내장되어 있는 Routing Table을 생성하는 방법은 일단 자신이 속한 서브넷의 Subnet Mask를 Routing Table의 Subnet Mask에 적어준다. 그리고 자신의 논리주소와 이 Subnet Mask를 AND연산해 Destination을 알아낸다. 그리고 해당 Destination에 매핑되는 주소는 같은 서브넷에 존재하는 것 이므로 Gateway의 값을 connected로 해준다.\n그리고 Destination에 매칭되지 않는 논리주소는 라우터를 찾아가게 해야되므로 두번째 행에는 Subnet Mask를 0.0.0.0, Destination은 Default, Gateway는 라우터의 논리주소를 적어준다. 그리고 이 행의 Flag값으로 G를 적어서 해당 논리주소가 유효한 값임을 명시한다.\n\n\nARP 프로토콜에 대해 설명하고, Logical Address를 알때 ARP Request를 보내고 받는 과정에 대해 설명하여라\n\nARP는 Routing Table을 이용해 보내야 할 곳의 Logical Address를 알아낸 후 이것을 가지고 Physical Address를 알아내기 위한 프로토콜이다.\nARP Request는 수신지의 물리주소를 broadcast로, 논리주소는 routing table로 알아낸 논리주소로 하여 패킷을 전송한다. 그럼 같은 서브넷에 있는 모든 Station이 수신하고 Network Layer로 올려보내 논리주소를 비교한다. 논리주소가 일치하는 Station은 수신지의 물리주소를 ARP의 송신지 물리주소로, 논리주소는 ARP의 송신지 논리주소로 하여 답장을 하게 되고, 따라서 ARP Request를 보낸 Station은 상대방의 물리주소를 알게 된다.\n\n\n같은 서브넷에 있는 Station에게, 다른 서브넷에 있는 Station에게, 외부망에 있는 Station에게 프레임을 전송하는 전 과정을 서술하거라\n\n같은 서브넷에 있는 Station에게 패킷을 전송하는 과정은 일단 자신의 Routing table을 통해 해당 Station이 같은 서브넷에 존재하는지 알아낸다. 같은 서브넷에 존재한다는 것을 알아챈 뒤에는 자신의 Subnet에 대해 ARP Request를 날려 물리주소를 얻고, 패킷을 전송한다.\n다른 서브넷에 있는 Station에게 패킷을 전송하는 과정은 마찬가지로 자신의 Routing table을 이용해 자신의 서브넷에 존재하는지 먼저 확인한다. 자신이 속한 서브넷에 존재하지 않으므로 라우터로 가야된다는 것을 알게 되고, Routing table을 이용해 알아낸 라우터의 논리주소를 이용해 ARP Request를 날리게 된다. 라우터의 물리주소를 알아낸 다음에는 라우터로 패킷을 보낸다. 패킷을 받은 라우터는 이 패킷의 논리주소로 가려면 어디로 가야되는지 Routing Table을 사용하여 찾게 된다. 이 논리주소에 해당하는 Station이 존재하는 서브넷을 찾았다면, 해당 서브넷에서 패킷의 논리주소를 이용해 ARP Request를 보내어 해당 Station의 물리주소를 알아낸다. 그리고 이것을 이용해 패킷을 송신하는 것으로 통신이 완료된다\n외부망의 Station으로 패킷을 전송하는 경우에도 마찬가지로 자신의 Routing table을 통해 자신의 서브넷에 존재하는지 확인한다. 자신의 서브넷에 없으므로 결과로 라우터의 논리주소를 받게될 것이고, 그 논리주소에 대해 ARP Request를 보내 라우터의 물리주소를 알아낸 후 패킷을 라우터로 전송한다. 라우터에 도착한 패킷을 보고 라우터는 이것이 어느 서브넷에 존재하는지를 Routing Table을 이용해 찾는다. 하지만 서브넷 어디에도 없으므로 Default에 걸려 외부의 라우터로 빠져나가게 된다. 이후 동일한 과정을 거치며 Station을 찾게 된다.\n\n\n192.168.40.0/24 서브넷에 속하는 Station의 Routing table에서 Subnet Mask를 255.255.255.0에서 255.255.0.0으로 변경했을 경우 동일 서브넷의 Station으로 패킷을 송신했을 때, 다른 서브넷의 Station으로 패킷을 송신했을 때, 외부망의 Station으로 패킷을 송신했을 때 송신이 성공하는지 아닌지 그 이유와 함께 서술하그라\n\n192.168.40.30에서 같은 서브넷에 속하는 192.168.40.50으로 패킷을 전송하려고 한다면 자신의 Routing Table에서 Destination이 192.168.0.0이므로 192.168.40.50과 Subnet Mask를 AND연산해보면 192.168.0.0가 나와 같은 서브넷이라고 판단한다. 따라서 이 경우에 ARP 요청을 하고 패킷을 전송하면 정상적으로 수신된다\n192.168.40.30에서 다른 서브넷에 속하는 192.168.45.30으로 패킷을 보내려고 할 때 자신의 Routing Table에서 Destination이 192.168.0.0이므로 192.168.45.30과 Subnet Mask를 AND연산해보면 Destination과 같아 같은 서브넷에 존재하는 것으로 판단한다. 따라서 해당 서브넷에서 ARP Request를 날려도 같은 서브넷에 존재하지 않기 때문에 응답이 오지 않고 따라서 통신은 실패하게 된다\n192.168.40.30에서 외부망에 속하는 188.28.50.30으로 패킷을 보내려고 할 때 자신의 Routing Table에서 Destination이 192.168.0.0으로 설정된다. 따라서 188.28.50.30이랑 Subnet Mask를 AND연산했을 때 188.28.0.0이 나와 Destination과 다르므로 라우터로 가게 되고, 라우터부터는 Subnet Mask가 제대로 설정되어 있으므로 수신에 성공하게 된다.\n\n\n192.168.40.0/24 서브넷에 속하는 Station의 Routing Table에서 Subnet Mask를 255.255.255.0에서 255.255.255.192로 변경했다고 가정하자. 이때 192.168.40.20에서 같은 서브넷에 속하는 Station인 192.168.40.67로 패킷을 전송하는 과정에 대해 서술해보거라\n\nSubnet Mask를 255.255.255.192로 변경하면 Destination은 192.168.40.0이다. 이때 192.168.40.67과 Subnet Mask를 AND연산하면 192.168.40.64가 나오므로 라우터로 패킷이 이동한다. 라우터에서 해당 패킷이 어느 서브넷에 속하는지를 알기 위해 Routing Table을 사용해보면 해당 패킷이 왔던 서브넷에 존재한다는 것을 알게 되고 따라서 ARP를 날려 수신지로 보내게 된다.\n\n\n"},"originals/datacommunication.spring.2021.cse.cnu.ac.kr/부록---시험대비)-싱하형배-데이터통신-모의고사":{"title":"부록 - 시험대비) 싱하형배 데이터통신 모의고사","links":[],"tags":[],"content":"\nPhysical Layer §\n\nBitrate, Baud rate, Signal Element, Signal Level, Bandwidth의 개념을 설명해보라\nShannon Capacity와 Nyquist Bitrate가 각각 어떤 Channel에 적용되는 공식이냐\nShannon Capacity와 Nyquist Bitrate를 이용해 Signal Level을 구하는 방법을 서술하라\nDigital Data를 Digital Signal로 변환할때 Synchronization이 중요한 이유를 설명해보라\nLine Coding의 한 종류인 Manchester Scheme에 대해 설명해보아라. 그리고 이 방식의 단점도 적어라\nBlock Coding의 개념에 대해 사용하는 경우, 작동방식을 간단히 지껄여보아라\nPCM Encoder에 대해 어떤 신호에 대해 사용하여 어떤 신호를 생성해내는 과정인지, 그리고 작동 과정을 설명해보아라\nASK, FSK, PSK, Constellation Diagram 각각의 개념을 말해보아라\nMultiplex의 개념과 사용하는 이유를 말해보아라\nFDM의 작동 원리에 대해 말해보아라\nTDM의 작동 원리에 대해 말해보아라\nSpread Spectrum의 개념과 장단점에 대해 말해보아라\nFHSS의 개념에 대해 설명해보아라. 그리고 이것의 단점을 상쇄할 수 있는 방법도 설명해보아라\nDSSS의 작동원리와 장점에 대해 설명해 보아라\n\nData Link Layer §\nData Link Control(Logical Link Control) §\n\nError Detection과 Correction의 차이에 대해 설명해보아라\nFixed-size Framing과 Variable-size Framing의 차이와 Delimiter에 대해 설명해보아라\nCharacter-oriented Protocol, Bit-oriented Protocol에 대해 설명해보아라\nBit-Stuffing과 Bit-Unstuffing에 대해서도 설명해보아라\nSimplest Protocol에서 발생할 수 있는 문제점인 Flow Error에 대해 설명해보아라\nStop &amp; Wait Protocol에 대해 설명해보아라\nStop &amp; Wait ARQ Protocol에 대해 설명해보아라\nStop &amp; Wait ARQ Protocol의 단점에 대해 설명해보고, 이것을 해결하기 위한 Protocol중 하나인 Go-back-N ARQ Protocol에 대해 설명해보거라\nSelective ARQ Protocol 에 대해 설명하고 Go-back-N ARQ와의 차이점에 대해 설명해보아라\nPiggybacking에 대해 설명해보아라\nGo-back-N ARQ와 Selective ARQ에서 Slide Window의 사이즈와 Sequence Number를 어떻게 설정하면 수신 에러가 나는지와 그 이유에 대해 지껄여보거라\nNormal Response Mode의 개념에 대해 설명하고 이때의 Point-to-Point와 Multipoint의 개념에 대해 설명해보아라. 그리고 Asynchronous Balanced Mode의 개념에 대해서도 설명해보아라\nS-frame, I-frame, U-frame의 개념에 대해 설명하고, 각각의 frame header의 Control bit에 대해 구조와 의미를 설명해보아라\n\nMedia Access Control §\n\nMedia Access Control의 개념에 대해 설명해보시오\nMedia Access Control을 크게 세개의 분류로 나누고, 각각에 대해 설명해보아라\nALOHA 알고리즘의 작동 원리에 대해 씨부려보시오\nALOHA 알고리즘의 단점에 대해 설명하고, 이것을 해결하기 위한 Slotted ALOHA 알고리즘에 대해 설명하시오\nCSMA 프로토콜의 핵심적인 기능을 CSMA의 말뜻과 함께 설명하시오\nCSMA에서 발생할 수 있는 충돌 중 한가지를 1-persistant를 이용해서 설명해보이소. 그리고 충돌이 일어날 수 있는 나머지 한가지 경우에 대해서도 설명해보이소\nNon-persistant와 p-persistant에 대해서 설명해보이소.\nCSMA / CD에서 CD의 말뜻과 이것의 작동원리, 장점을 설명하시오. 또한 CSMA / CD의 전체적인 작동과정도 설명해보시오\nCSMA / CD에서 충돌이 감지되는 Best Case와 Worst Case에 대해 설명하고, Worst Case를 이용해 CSMA / CD를 사용할 수 있는 조건에 대해 한번 설명해보이소\nCSMA / CD를 무선환경에서 사용하지 못하는 이유와 CSMA / CA의 개념에 대해 설명하시오.\nPolling의 작동방식을 Poll, SEL, ACK, NAK의 개념을 이용해 설명해보아라\nToken Passing의 작동방식을 간단맨하게 설명해보아라\nCDMA의 개념과 작동원리에 대해 설명해보아라. 그리고 Spreading Code를 생성할때 사용되는 Table의 이름을 어디 한번 말해보시오\n\nEthernet §\n\nIEEE 802의 개념에 대해 어떤 환경에서 사용하도록 만들어진 표준인지를 포함하여 적으시오. 그리고 여기서는 어떤 프로토콜을 Logical Link Control에서 사용하는지 적으시오.\nStandard Ethernet이 사용하는 Bus Topology에 대해 설명해 보아라\nStandard Ethernet의 최대 / 최소 전송 바이트를 적고 이것이 필요한 이유에 대해 설명하시오\nStandard Ethernet이 사용하는 물리계층의 프로토콜과 MAC 프로토콜을 적어보아라\nFast Ethernet과 Gigabit Ethernet 에서는 이전버전과의 호환성을 위해 BusCSMA / CD, Bus Topology등을 사용하는 함수들을 전부 삭제시켰다 (O / X)\nFast Ethernet과 Gigabit Ethernet에서 사용하는 Star Topology에 대해 설명해보시오\nFast Ethernet과 Gigabit Ethernet의 물리계층에서는 하나로 통일된 encoding방식을 사용한다(O / X)\n\nWifi §\n\nPCF와 DCF, AP의 개념에 대해 설명해보아라. 그리고 PCF와 DCF에서 사용하는 MAC 프로토콜이 무엇인지 적어라\nBSS와 ESS의 개념에 대해 설명해보아라\nSIFS, PIFS, DIFS의 개념을 설명해보아라. 그리고 각각의 길이를 대소비교하고 그 이유에 대해 적어라\nWifi에서의 CSMA / CA에 등장하는 Virtual Carrier Sensing의 개념에 대해 NAV의 개념과 함께 설명하고, 작동 과정에 대해서도 설명하되 RTS, CTS의 개념과 각 프레임이 수신되었을 때 기다리는 IFS의 종류를 포함하여 설명하라\nWifi의 통신 전 과정에 대해 Super frame, Beacon, CFP, CP의 개념들도 같이 설명하며 서술해보거라. 그리고 각각의 경우 사용되는 IFS도 같이 서술하여라\nWifi의 Frame에서 Type을 통해 어떤 종류의 프레임을 구분하는지 서술해보거라\nIntra-BSS와 Inter-BSS의 개념에 대해 서술해보거라\nIntra-BSS환경에서 두 Station이 직접 통신하는 경우와 Inter-BSS의 경우에 대해 통신 과정을 서술해보거라. 이때 프레임 헤더의 To-DS bit와 From-DS bit가 어떻게 설정되는지, 그리고 각각의 경우 Address 1, 2, 3, 4에 어떤 값이 들어가는지를 보여라\n\nBluetooth §\n\nBluetooth가 사용하는 ISM band에 대해 간략하게 말해보거라\nPiconet, Scatternet에 대해 간략히 설명해보거라\nBluetooth의 개발 목적을 간략하게 설명해보거라\nBluethooth의 계층구조를 Bluetooth Protocol Profile, L2CAP, Audio, Upper Stack Layer, Baseband, Bluetooth Radio, Lower Stack Layer, Host Controller Interface의 용어를 설명해가며 서술해보거라 한번\nBaseband가 사용하는 TDMA 프로토콜에 대해 Hop을 이용해 설명해보거라.\nBaseband의 SCO, ACO모듈에 대해 각각의 경우 Hop의 길이는 어떻게 되는지, 어느 상위 모듈에서 데이터가 들어왔을때 해당 모듈을 사용하는지 구분하여 서술하여라\n블루투스를 이용한 전화를 걸고 받는 과정에 대해 설명해보거라\n\nLayer Architecture §\n\nProtocol, Standard의 차이와 Protocol을 Algorithm으로 부르는 이유에 대해 서술해보거라\n프로토콜의 구성요소 세가지에 대해 설명해보거라\nLayer Architecture의 개념과 이유를 설명하여라. 그리고 Module, Interface, Peer-2-Peer의 개념에 대해 말해보고 Interface를 이용하는 것의 장점에 대해 말해보거라\nData Link Layer의 역할 다섯가지에 대해 말해보거라\nOSI 7 Layer의 각각의 계층의 역할에 대해 설명해보아라\n\nNetwork Layer §\n\nPhysical Address와 Logical Address의 주 목적과 사용되는 계층에 대해 설명해보아라\nRouter(Intermediate Node, Gateway, Next Hop)의 역할과 이것이 사용하는 계층, 작동원리를 설명하리오. 작동 원리는 2-Level Hierarchy의 필요성, netid, routing table을 이용해 설명하거라\nLogical Address의 대표적인 세 Class와 이들 각각에 대해 netid와 hostid를 구분하는 방법에 대해 서술해보거라.\nnetid와 hostid를 할당받는 방법에 대해 서술하고 각 Class당 하나의 netid에 몇개의 hostid가 대응되는지를 이용해 어떤 기준으로 netid를 할당하는지 적어보거라\nAS의 개념과 AS는 어떤것을 이용해 경로를 정하는지 적어보거라\nSubnet의 개념과 장점, 작동과정에 대해 설명하시오. 이때 Destination, Subnet Mask, Port Number, Default의 용어를 활용하시오.\nLogical Address 192.168.188.67이 192.168.188.0/26에 해당하는 Port로 빠져나가는지 판단해봐라. 그리고 해당 Port에 몇개의 Station이 연결되어 있는지 판단하여라\nStation에 내장되어 있는 Routing Table을 생성하는 방법에 대해 설명해보거라\nARP 프로토콜에 대해 설명하고, Logical Address를 알때 ARP Request를 보내고 받는 과정에 대해 설명하여라\n같은 서브넷에 있는 Station에게, 다른 서브넷에 있는 Station에게, 외부망에 있는 Station에게 프레임을 전송하는 전 과정을 서술하거라\n192.168.40.0/24 서브넷에 속하는 Station의 Routing table에서 Subnet Mask를 255.255.255.0에서 255.255.0.0으로 변경했을 경우 동일 서브넷의 Station으로 패킷을 송신했을 때, 다른 서브넷의 Station으로 패킷을 송신했을 때, 외부망의 Station으로 패킷을 송신했을 때 송신이 성공하는지 아닌지 그 이유와 함께 서술하그라\n192.168.40.0/24 서브넷에 속하는 Station의 Routing Table에서 Subnet Mask를 255.255.255.0에서 255.255.255.192로 변경했다고 가정하자. 이때 192.168.40.20에서 같은 서브넷에 속하는 Station인 192.168.40.67로 패킷을 전송하는 과정에 대해 서술해보거라\n"},"originals/datacommunication.spring.2021.cse.cnu.ac.kr/부록---실습자료-1)-MAC,-ARQ":{"title":"부록 - 실습자료 1) MAC, ARQ","links":[],"tags":[],"content":"\n\n                  \n                  충남대학교 컴퓨터공학과 김상하 교수님의 &quot;데이터 통신&quot; 강의를 필기한 내용입니다. \n                  \n                \n\n\n\n                  \n                  다소 잘못된 내용과 구어적 표현 이 포함되어 있을 수 있습니다. \n                  \n                \n\nMedia Access Control(MAC) §\n\n두개 이상의 디바이스가 하나의 링클르 공유할 때, 충돌이 발생하지 않도록 하는 것?\n\nFlow, Error Control §\n\nFlow Control은 noiseless에서 ACK를 이용해 수신증을 날리는 개념이고\nError Control은 이제 여기에 노이즈가 있는 환경까지 고려해 수신증을 날리는 거 뿐 아니라 프레임/ACK의 전송과정에서 오류가 날 수 있는것을 해결하기 위해 ARQ를 도입하는것을 말한다\n\nGo Back N ARQ 프로토콜 §\n\n얘는 이제 프레임을 연속적으로 보내다가 ACK가 들어오면 거기로 돌아가서 거기서부터 보내기 시작하는 방식으로 진행된다\n프레임은 이제 윈도우라는 배열 비스무리한것에 저장이 되어 있다가 슬라이딩 단위로 0번부터 쭉쭉 송신하게 되는데 - 이때 슬라이딩은 한번에 몇개의 프레임을 보내냐 하는 것이라고 생각하면 된다. 즉, 슬라이드에 3개의 프레임을 할당하면 한번에 3개의 프레임이 날라가는 것\n수신측에서 아직 다음 프레임이 안들어왔다거나 아니면 중간에 빼먹은 프레임이 있을 경우(1번 이후 3번이 들어와 2번 프레임이 없는 경우 등) 해당 번째의 프레임을 요청하는 ACK을 날리게 된다\n그럼 이제 송신측에서는 그걸 보고 해당 번째의 프레임부터 다시 전송을 시작하게 된다 - 빼먹은놈만 전송하는게 아니고 ACK에 명시되어있는 프레임부터 전송을 시작하게 되는 것\n다만 수신측에서는 중간에 빼먹은게 있을 때 그 뒤에 들어온 프레임은 전부 discard한다 - 즉, 1번 이후에 3번이 들어오면 ACK2를 날리고 3번은 폐기하게 되는 것\n\nSelective Repeat ARQ §\n\n얘도 윈도우 슬라이딩방식으로 보내긴 하는데\ngoBack이랑의 차이점은 얘는 중간에 송신 못한 프레임이 있을때 NAK이라는 것을 날리게 된다 - 다음꺼를 요청할때는 ACK, 못받은놈이 있을 때에는 NAK\n그럼 이제 송신측에서는 거기서부터 송신을 시작하는게 아니라 누락된 프레임을 보내고, 그 다음에 아까 보내던거부터 이어서 보내게 되는 것\n다만 이렇게 되면 수신측에서는 순서대로 수신받는게 아니기 때문에 프레임들을 순서에 따라 정렬하는 작업을 필수적으로 해줘야 한다\n하지만 저렇게 폐기하고 다시받는거보다 이렇게 뒤죽받죽으로 받고 정렬하는 것이 더 효율적이도 시간도 더 적게 걸린댄다\n"},"originals/datacommunication.spring.2021.cse.cnu.ac.kr/부록---실습자료-2)-Peer-2-Peer-process":{"title":"부록 - 실습자료 2) Peer 2 Peer process","links":[],"tags":[],"content":"\n\n                  \n                  충남대학교 컴퓨터공학과 김상하 교수님의 &quot;데이터 통신&quot; 강의를 필기한 내용입니다. \n                  \n                \n\n\n\n                  \n                  다소 잘못된 내용과 구어적 표현 이 포함되어 있을 수 있습니다. \n                  \n                \n\nPeer 2 Peer(P2P) §\n\n토렌트 생각하면 된다 - 컴퓨터끼리 대등하게 동작한다 즉, 하나의 컴퓨터가 서버 혹은 클라이언트의 지위를 가지는 기존의 네트워크 체계와는 다르게 p2p에서는 컴퓨터 한대가 클라이언트 이자 서버인 두가지 역할을 하게 되는 것\n클라이언트-서버 네트워크와 대비되는 또하나의 네트워크 체계인 것\n\nData layer §\n\nPhysical layer로부터 받은 전기적 신호의 오류를 검출하고 그 오류를 수정하는 기능적/절차적인 수단을 제공해주는 계층\n\n부계층 - MAC §\n\n디바이스의 물리적인 주소값을 말한다?\n전송받은 데이터에 저장되어있는 MAC주소를 보고 올바르게 수신되었는지 판별하여 상위계층으로 보내는 등의 역할을 한다\n\n부계층 - LLC §\n\n얘네는 디바이스 들 간에 존재할 수 있는 프로토콜 간의 차이를 보완해 주는 역할을 한다\n\n데이터 전송방식 §\n\nUNICAST : 1:1 통신을 일컬음 → Point 2 Point communication → 여러명한테 보내고 싶으면 여러번 보내야 된다 → 또한 제한된 회선을 나눠써야 하기 때문에 불편하다\nBROADCAST : 연결된 모든 디바이스한테 데이터를 뿌리는 방식 → Ethernel layer에서는 주소의 모든 자릿수가 F인 주소를 사용한댄다\nMULTICAST : 연결된 모든 디바이스들 중 특정한 디바이스들한테만 데이터를 전송하는 방식 → 개인이 아니라 그룹한테 데이터를 보내는 것\n\nEthernel Protocol §\n\n근거리 유선망인 Ethernel에서 주로 사용하는 규격\n물리계층의 신호와 배선, 데이터링크 계층에서의 MAC규격 등을 정의한다\n상위계층에서 데아터 링크 계층으로 데이터를 보내면 데이터 링크 계층에서는 이것을 프레임이라는 전송 단위로 변환한다 - 이 프레임의 크기는 최대 1500바이트이랜다\n그리고 여기에 송수신 이더넷 주소를 헤더로 붙여 하위계층인 물리계층으로 보내게 되는 것\n수신할때는 물리계층으로부터 데이터 링크 계층으로 프레임 데이터를 받으면 이더넷 주소의 모든 숫자가 F이거나 자신의 이더넷 주소와 같을 경우 상위계층으로 보내고 아닐 경우에는 폐기하게 된다\n그리고 프레임 헤더 중 16비트 프로토콜 타입 필드란 곳이 있는데 이곳에 상위 어떤 계층으로 이 데이터를 보내야 하는지에 대한 정보가 담겨 있다\n\n랜카드, 네트워크 어댑터 §\n\n네트워크 연결 및 데이터 전송을 담당\n\n실습에서 사용할 프로그램들 §\nWinsock §\n\nnetwork layer까지 접근 가능한 internet program 개발용 api다\n\nPacket driver §\n\ndata link layer까지 접근 가능하다\n다만 직접 구현해야 될 부분이 많기 때문에 winsock보다 사용하기 불편하댄다\n\njNetPcap §\n\n실습에서는 자바 기반의 패킷 프로그램인 jNetPcap을 사용한다\nWinPcap이라는 프로그램을 기반으로 하기때문에 이게 반드시 깔려 있어야 한다\n\nByte Ordering §\n\n컴퓨터 종류에 따라 데이터를 메모리에 어떻게 저장하는지를 결정하는 것\n컴퓨터마다 데이터를 쪼개어서 저장할때 어떻게 저장하는지가 다 다른데 이것을 자기 컴퓨터에 맞게 변환하지 않으면 에러가 날 수 있다\n따라서 플랫폼에 구애받지 않는 표준 규격 을 만들어 낸 것이 Byte Ordering이다\n\nBig Endian §\n\n매킨토시 pc의 계열에서 쓰인다\n바이트의 높은 자릿수에 위치하는 데이터부터 메모리에 적재되는 방식 - Network Byte Order라고 한다\n예를들어 0x12345678을 저장할때 얘는 메모리에 12, 34, 56, 78이렇게 저장한다\n\nLittle Endian §\n\n인텔계열의 pc에서 쓰인다\n바이트의 낮은 자릿수에 위치하는 데이터부터 메모리에 적재되는 방식 - Host Byte Order라고 한다\n예를들어 0x12345678을 저장할때 얘는 메모리에 78, 56, 34, 12이렇게 저장한다\n이 두 방식을 이용해 네트워크로부터 받은 데이터를 자기 컴퓨터에 맞게 새로 재구성하는 작업을 거친다\n"},"originals/datacommunication.spring.2021.cse.cnu.ac.kr/부록---실습자료-3)-단편화":{"title":"부록 - 실습자료 3) 단편화","links":[],"tags":[],"content":"\n\n                  \n                  충남대학교 컴퓨터공학과 김상하 교수님의 &quot;데이터 통신&quot; 강의를 필기한 내용입니다. \n                  \n                \n\n\n\n                  \n                  다소 잘못된 내용과 구어적 표현 이 포함되어 있을 수 있습니다. \n                  \n                \n\nData Fragmentation Concept §\n\n헤더를 제외한(TCP / IP 헤더는 포함함) 데이터의 최대크기는 1500byte이고 이것을 최대 전송 단위(MTU) 라고 한다\n그리고 얘보다 더 큰 데이터를 보내기 위해서는 데이터를 여러개의 패킷으로 쪼개는 데이터 단편화(Data Fragmentation) 이 필요하다\n그리고 하나의 내용이라 할 지라도 크기가 크면 여러개의 패킷으로 전송되기 때문에 단편화된 패킷 하나하나마다 ACK가 필요하다\n"},"originals/datacommunication.spring.2021.cse.cnu.ac.kr/부록---실습자료-4)-프로토콜":{"title":"부록 - 실습자료 4) 프로토콜","links":[],"tags":[],"content":"\n\n                  \n                  충남대학교 컴퓨터공학과 김상하 교수님의 &quot;데이터 통신&quot; 강의를 필기한 내용입니다. \n                  \n                \n\n\n\n                  \n                  다소 잘못된 내용과 구어적 표현 이 포함되어 있을 수 있습니다. \n                  \n                \n\n용어정리 §\n\n네트워크 : 유무선의 매체를 통해 서로 연결된 장치들의 모임\n프로토콜 : 통신의 원활함을 위해 송, 수신자 간의 약속 - 통신 규약\n\n프로토콜 스택 §\n\n서로 다른 장치들 간의 원활한 통신을 위해 등장하게 된 모델이다\n여러개의 프로토콜이 계층적인 형태로 모여있다\n같은 통신을 사용한다면 같은 구조의 계층화된 모델을 사용한다\n대표적으로 OSI 7 layer, TCP/IP등의 모델이 존재한다\n그니까 이렇게 생각하면 편하네 - 우리가 전달하려고 하는 메세지를 프로토콜이라는 포장지로 여러번 감싸서 안전하고 정확하고 빠르게 원하는 대상에게 전송하게 하는 것\n\nTCP/IP 간략하게 §\n\n그니까 우리가 누군가에게 이메일로(Application) 뭔가를 보내려고 해\n그럼 그게 TCP 프로토콜에 의해 변환이 되어서(Transport)\nIP를 통해 상대방의 컴퓨터가 어디 있는지 알아내서(Network)\n너의 랜카드를 통해 그 데이터가 빠져나가는거제(Data link, Physical)\n보다시피 “계층”을 이루고 있다고 할 수 있기 때문에 계층화 모델이라 하는거임\n\n“패키지” 단위로의 데이터 전송 §\n\nTCP/IP에서를 예로 들면 너가 이메일을 보내면 이걸 하나 보내는게 아니고 이걸 여러개로 쪼개서(어떻게 쪼개는지는 제일 효율적으로 전송될 수 있는 크기로 쪼갠다) 하나의 경로뿐 아니라 여러 경로를 사용해서 송신함\n수신하는 입장에서는 이 분할된 패키지들을 다시 재조립해서 화면에 띄우게 된다\n\nEncapsulation - 송신자 입장 §\n\n포장지를 하나하나 싸는 것으로 비유할 수 있을듯\n데이터에다가 현재 계층의 프로토콜 제어정보를 헤더에 붙여서 하위 계층으로 넘겨주는 것\n프로토콜 제어정보가 뭔지는 아직 잘 모르겠고\n그니까 일단 데이터가 계층을 내리갈때 그냥 내리가는게 아니고 추가적인 정보가 헤더에 덧붙여져서 계층을 내리간다는 거네\n캡슐화 과정이 매우 중요하댄다\n\nDemultiplex - 수신자 입장 §\n\n포장지를 하나하나 벗기는 것으로 생각해 볼 수 있음\n수신한 놈에서 헤더를 검사해서 상위계층에 넘겨줄때는 헤더를 하나 떼어내고 넘겨주게 된다는 거다\n헤더에는 어느 계층에서 이 헤더를 씌웠다는 식별자가 다 들어있어서 어느 계층에서 최종적으로 데이터가 소비되어야 할 지 알아낼 수 있단다\n캡슐화의 반대공정인것이야\n\nIPC §\n\nInter-Process Communication\n기기 간의 통신이 아니라 한 기기 내에서의 프로세스들끼리의 통신을 의미\n프로세스들 간의 메모리 공간을 침범하게 되면 예상치 않은 정보 변경이 일어나 오류가 날 수도 있지만 경우에 따라 데이터를 공유해야 할 필요도 있다\n또한 이러한 필요성에 따라 공유를 한다 해도 동기화 문제가 생길 수도 있다 - 다른 프로세스한테 정보전달이 제대로 되지 않을 수도 있다는 것 - 약간 깃에서 merge할때 충돌하는 경우랑 비슷한거 아닐까\n이렇듯 프로세스들간에 교신을 안전하고 효율적으로 하기 위해 나온 개념이 IPC이다\n이 프로세스들간의 통신은 메인 커널에서 메세지를 뿌려주는 message passing과 프로세스들이 물리적 메모리를 공유하는 shared memory방식이 있다\n\nsocket §\n\nIPC에서의 통신의 출입구 역할을 한댄다 - 통신 라인의 양 끝단\n약간 ㅈㄴ 뜬구름잡는목소리와 뜬구름잡는 설명방식으로 뜬구름잡는 소리나 해대고 있네\n통신에 필요한 리소스를 시스템적으로 할당하는 것?\n그냥 뭐 서버 소켓과 클라이언트 소켓이 있댄다\n"},"originals/jan.daejeon.k-devcon.com":{"title":"2024-01-27) K-DevCon 대전 강연 기록","links":[],"tags":["conference"],"content":"\n\n                  \n                  2024-01-27 에 대전에서 열린 &quot;K-DevCon&quot; 기록입니다. \n                  \n                \n\n\n\n                  \n                  강연 들으면서 기록하느라 다소 이상한 내용이 있을 수 있습니다. \n                  \n                \n\nSession 1) Coding test §\n\n못들음..\n\nSession 2) Testing §\n\n테스트 피라미드\n\nunit test: 빠르고 비용이 적음\nintegration test: 느리고 비용이 큼\n\n\n테스트 트로피\n\ne2e test: 20\nintegration test: 60\nunit test: 20\n정도의 비중으로 가져가는 것\nmsa 구조의 유행으로 unit test 보다는 microservice 들의 integration 의 중요성이 늘어남\n\n\n테스트 대역\n\n테스트 하고자 하는 부분의 종속성을 가진 부분에 대해서는 대역 (스턴트맨 등) 을 두어서 테스트 과정에서의 종속성을 제거하는 것\nDummy: 가짜 데이터?\nStub: 종속성을 가진 함수 호출에 대해 “미리 정해진”, “일관된” 답변을 응답하는 놈\nFake: Stub 이랑 비슷하지만 일관된 답변이 아닌 실제 구현본의 shortcut? 을 이용해 유사하게 동작하게 하는 것\nMock (모의 객체): 예상된 입력에 대해 정해진 답변을 제공? Stub 이랑 뭔차이 인지는 모르겠음\n\nMock 이 실제 구현과 비슷해지면 프로덕션 환경과 비슷해져서 유지보수가 어려워진다\n그래서 내가 핸들링하지 못하는, SMTP, 결제, 알람 모듈 등 써드파티를 사용할 때 이용하면 좋다는 듯\n\n\n\n\n테스트 코드도 코드이기 때문에 유지보수가 필요하고, 따라서 유지보수의 필요성이 적어지게 작성하는 것이 좋다\n\n깨지기 쉬운 테스트를 지양해라\n테스트 코드 간의 종속성이 너무 얽혀 있어서 A 를 테스트하기 위한 테스트코드가 변경되었을 때 B 테스트가 실패하는 경우\nTip1) 공개 API 를 활용해 테스트 진행\n상태를 테스트해라? 함수의 구현보다는 함수의 입출력 상태에 기반해서 테스트 코드 작성?\n\n\nFixure / Setup / Teardown\n\nFixture: 일관된 테스트를 진행하기 위한 환경\nSetup: 테스트하기 위한 데이터들을 설정\nTeardown: 다음 테스트를 진행하기 위해 Setup 에서 설정한 데이터를 다시 원복\n\n\nJSON 을 활용해서 테스트 데이터를 정의해 놓자\n테스트 제목을 잘 지어서 어떤 테스트를 하는 코드인지 한번에 파악 가능하도록 해라\nBDD Pattern\n\nDCI\n\nDescribe: 누가\nContext: 어떤 상황에서\nIt: 어떻게 작동\n\n\n\n\n테스트 코드를 디버깅해야 하는 상황은 피해라\n\n조건, 반복문을 피해라\n논리를 넣지 말고 하드코딩을 활용해라\n\n\n특수 케이스를 잘 잡아라\n\n엣지 케이스\n코너 케이스: 특수한 조건들이 겹쳐서 발생하는 이슈\n\n\n순수 함수 활용\n\n동일한 입력에 대한 동일한 출력을 반환하는 함수\n를 활용하라\n변할 수 있는 값 (뭐 현재시간 등) 은 함수 내에 포함하지 않고 입력을 받도록 해라\n\n\n\nSession 3: 링크드인 활용하기 §\n\n시작하기\n\n프로필 업데이트\n인맥 늘리기\n인맥의 글 들에 추천 / 좋아요 누르기\n인맥들의 글들을 짧은 글과 함께 repost 하여 내 관심사를 퍼트리기\n\n\n적극적인 PR 을 위해서는 프로필 노출 항목 을 전체 공개로 설정하는 것이 좋음\n인맥 관리하기\n\n1촌의 수를 늘리는 것이 좋음\n\n1촌의 주변 인물들에게 1촌 추천으로 우선 노출되기 때문\n작성한 글들도 1촌들에게 우선적으로 노출되어 퍼져나가기 때문\n\n\n1촌은 페이스북 팔로우와는 달리, 질 좋은 인맥만을 선별하여 connect 하기 위한 개념\n\n따라서 1촌 신청/수락은 3만번 정도로 횟수가 제한 되어 있고, 500명 정도의 1촌을 유지하는 것이 권장됨\n누군가에게 1촌 신청할때나, 혹은 그 분이 수락했을 시에 간단한 감사인사를 남기는 것이 좋음\n\n\n\n\n퍼스널 브랜딩 전략\n\n정체성\n\n나는 어떠한 사람인가?\n\n\n방향성\n\n그 정체성과 관련있는 활동을 하였는가?\n\n\n꾸준한 활동\n\n이러한 활동을 얼마나 오랫동안 지속해 왔는가?\n\n\n\n\n한줄프로필 (헤드라인) 작성법\n\n직무전문성 - 정체성을 드러낼 수 있는 최대 5개 정도의 키워드 작성\n어떻게 적어야 할 지 모르겠다면, 동종 업계의 인원을 검색해서 키워드 참고하기\n현재의 직무 외에도 미래에는 어떤 것을 해보고 싶다 등의 미래 지향적인 키워드 들을 넣어놓는 것도 좋음\n\n\n간단프로필 작성법\n\n포트폴리오 + 간단 소개\n혹은, 커버레터 (직무 전문성을 나타내는 간단한 자기소개 문구) 를 넣어도 좋음\n\n업무 분야 및 역할\n관심 분야\n\n\n\n\n경력 및 학력 작성법\n\n회사 간략 소개\n나의 역할 / 업무\n주요 기술\n최신순으로 나열, 그리고 경력 내의 직책이 여러개일 경우 중요도 순대로\n\n\n보유 기술\n\n직무를 대표하는 기술이 먼저 보이게 작성하는 것이 좋음\n기술 평가 혹은 동료에게 추천 기능 활용\n\n\n모든 항목을 되도록이면 영어로 작성 (국내에서도 키워드 검색 등에서 영문을 많이 활용)\n깔끔한 프로필 사진, Full name 기재\n글 올리기\n\n최근 글들을 보면서 트랜드 및 작성법 파악\n\n\n\nSession 4: 연봉협상 §\n\n연봉 협상과 통보?\n\n통보: 평가 후 “일방적으로 통보”\n협의: 평가 후 “제시 후 협의”\n\n\n정성적 / 정량적 평가?\n\n인사 평가 제도를 숙지?\n\n\n셀프 리뷰\n\n그간의 실적을 회고\n실적들을 수치화\n추가적인 자기개발 등의 열정 어필?\n\n\n협상에 성공하기\n\n준비가 부족\n\n스스로에 대한 평가를 철저히 하지 못함\n어차피 안될 것 같으니까 지래짐작하여 포기\n\n\n통보를 받았을 때 그냥 accept 하지 말자 -&gt; 이때부터가 협상의 시작이다\n기준점 수치화 필요\n\n이런식으로\n\n첫 제안 금액 (최선)\n만족 금액 (차선)\n결렬 금액 (최악)\n\n\n이러한 수치를 정해두지 않으면 협상 내내 휘둘리다가 별 소득 없이 끝난다\n그리고 이러한 기준점에 대한 데이터에 기반한 근거가 있어야 한다\n\n정당한, 객관적인 이유\n\n\n또한 이러한 기준점에 대한 제스처도 생각을 해야 한다\n\n\n감정 컨트롤을 해야 한다\n\n싸우러 가는 것이 아니다 -&gt; 이 협상에 나온 사람도 결정권자가 아닌 중개인의 입장으로 온 것이다\n설득력이 없는 개인 사정 등의 근거를 대지 말것\n다른 회사랑 비교하지 말 것 -&gt; 회사마다 업무와 사정이 다르기 때문\n까내려도 문제의 본질 (희망 연봉의 간격을 줄이는 것) 을 잊지 말고 감정에 휘둘리지 말어라\n공통의 적 만들기? 협상자와의 공통의 적을 생각해 내서 서로를 악으로 만드는 것이 아닌 제 3의 악에 대응하는 식\n\n\n연봉과 성과급을 혼동하지 마라\n\n연봉은 미래의 가치이고\n성과급은 과거의 가치이다\n따라서 협상 중에 과거의 실적만을 어필할 것이 아니고 이것을 기준으로 미래에는 어떠한 가치를 회사에 안겨줄 것인지를 어필할 것이다\n\n\n\b자신감이 반이다\n침묵 전략: 먼저 제시하지 마라\n\n얼마 받고 싶냐고 물어보면 얼마 생각하셨냐고 역질문 해보기\n\n\n시간 끌기: 모호한 워딩? 으로 질질 끌기?\n내 이야기는 줄이고 사측의 상황을 들으면서 상황 파악\n\n듣다가 나중에 다시 얘기하자고 미루기 등\n\n\n\n\n결정권자도 통보한 연봉에 상향 버퍼가 있다\n판례를 만들기 싫어서 안된다라고 하면, 대신 보너스로 달라는 식 혹은 복지 향상 등의 협상사례\n"},"originals/jumptopython.books.wikidocs.net/(책)-점프-투-파이썬-정리록":{"title":"(책) 점프 투 파이썬 정리록","links":["originals/jumptopython.books.wikidocs.net/01.-화면입출력","originals/jumptopython.books.wikidocs.net/02.-파이썬-자료형-개요","originals/jumptopython.books.wikidocs.net/03.-문자열","originals/jumptopython.books.wikidocs.net/04.-리스트","originals/jumptopython.books.wikidocs.net/05.-튜플","originals/jumptopython.books.wikidocs.net/06.-집합","originals/jumptopython.books.wikidocs.net/07.-데크","originals/jumptopython.books.wikidocs.net/08.-딕셔너리","originals/jumptopython.books.wikidocs.net/09.-반복,-조건문","originals/jumptopython.books.wikidocs.net/10.-함수-선언-문법","originals/jumptopython.books.wikidocs.net/11.-함수-타입-힌트,-제네레이터","originals/jumptopython.books.wikidocs.net/12.-클래스","originals/jumptopython.books.wikidocs.net/13.-클래스-문법","originals/jumptopython.books.wikidocs.net/14.-파일입출력","originals/jumptopython.books.wikidocs.net/15.-예외처리","originals/jumptopython.books.wikidocs.net/16.-모듈","originals/jumptopython.books.wikidocs.net/17.-패키지","originals/jumptopython.books.wikidocs.net/18.-내장함수-정리","originals/jumptopython.books.wikidocs.net/19.-내장라이브러리-정리","originals/jumptopython.books.wikidocs.net/20.-클린코드-가이드","originals/jumptopython.books.wikidocs.net/21.-정규표현식-이용","originals/jumptopython.books.wikidocs.net/부록---정규표현식"],"tags":[],"content":"개요 §\n책 정보 §\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n출판저자링크위키북스박응용위키북스\n목차 §\n\n01. 화면입출력\n02. 파이썬 자료형 개요\n03. 문자열\n04. 리스트\n05. 튜플\n06. 집합\n07. 데크\n08. 딕셔너리\n09. 반복, 조건문\n10. 함수 선언 문법\n11. 함수 타입 힌트, 제네레이터\n12. 클래스\n13. 클래스 문법\n14. 파일입출력\n15. 예외처리\n16. 모듈\n17. 패키지\n18. 내장함수 정리\n19. 내장라이브러리 정리\n20. 클린코드 가이드\n21. 정규표현식 이용\n부록 - 정규표현식\n"},"originals/jumptopython.books.wikidocs.net/01.-화면입출력":{"title":"01. 화면입출력","links":[],"tags":[],"content":"\n\n                  \n                  위키북스 박응용 저 &quot;점프 투 파이썬&quot; 책을 읽고 정리한 내용입니다. \n                  \n                \n\n\n\n                  \n                  다소 잘못된 내용과 구어적 표현 이 포함되어 있을 수 있습니다. \n                  \n                \n\n띄어쓰기 연결 §\nprint(&quot;abc&quot; &quot;def&quot;)\n\n띄어쓰기로 연결하면 그냥 붙어서 나온다\n화면에 abcdef 가 출력된다\n\n콤마 연결 §\nprint(&quot;abc&quot;, &quot;def&quot;)\n\n콤마로 연결하면 띄어쓰기 후 붙어서 나온다\n화면에 abc def 가 출력된다\n\nprint(&quot;abc&quot;, &quot;def&quot;, sep=&quot;$&quot;)\n\nprint함수의 생략가능한 매개변수인 sep 은 띄어쓰기연결시에 어떤 문자로 연결할지를 결정한다\n화면에 abc$def 가 출력된다\n디폴트값은 ’ ’ 이다(한칸 띄어쓰기)\n\n줄바꿈 안하기 §\nprint(&quot;abcdef&quot;, end=&#039;&#039;)\n\nprint함수의 생략가능한 매개변수인 end 는 출력 이후 처리를 담당한다\n이것을 ’’ 로 바꿔주면 버퍼가 줄 바꿈을 하지 않고 출력이 완료된 그 자리에서 다음 출력을 기다리고 있을 것이다\n디폴트는 \\n이다(한칸 줄바꿈)\n\n사용자로부터 입력받기 §\na = input(&quot;input value : &quot;)\n\ninput함수는 입력버퍼와 함께 띄울 문구 (예시에서는 “input value :”) 를 인자로 줄 수 있고 입력버퍼에 입력한 값을 반환한다\n\n파일실행시에 입력받기 §\n# In terminal: python file_name.py a b c d\nsys.argv[1:]\n\nsys 모듈에는 파이썬 파일을 인터프리트할때 파이썬 파일과 함께 입력한 값들을 저장하는 argv 라는 리스트가 있다\n터미널에서 저렇게 파이썬 파일 이름 옆에 몇가지를 적어주면\nsys.argv 에는 [“file_name.py”, ‘a’, ‘b’, ‘c’, ‘d’] 이렇게 저장되게 된다\n그럼 이것을 [1:] 로 슬라이싱하면 옆에 적어준 애들만 가져와서 사용할 수가 있는 것이다\n당연한거지만 import sys로 sys모듈을 가져와야 사용할 수 있다\n"},"originals/jumptopython.books.wikidocs.net/02.-파이썬-자료형-개요":{"title":"02. 파이썬 자료형 개요","links":[],"tags":[],"content":"\n\n                  \n                  위키북스 박응용 저 &quot;점프 투 파이썬&quot; 책을 읽고 정리한 내용입니다. \n                  \n                \n\n\n\n                  \n                  다소 잘못된 내용과 구어적 표현 이 포함되어 있을 수 있습니다. \n                  \n                \n\nOverview §\n\nNone\n숫자형\n\n정수형 : int, bool (불리언도 0,1의 정수로 분류)\n실수형 : float\n\n\n순서가 존재하는 자료형\n\n불변형 : str, tuple, bytes\n가변형 : list\n\n\n순서가 없는 자료형\n\n집합형 : set\n매핑형 : dict\n\n\n\n자료구조, 자료형, 추상자료형 §\n\n자료구조 : 데이터를 효과적으로 저장하고 접근 하기 위한 이론\n자료형 : 데이터를 컴퓨터가 읽어들이는 방식 을 선언하는 것\n추상 자료형 : 자료형의 연산 동작을 명기 한 것(실제 구현은 하지 않는다)\n\n객체복사 §\n\na = copy.copy(b)\n= 는 객체복사가 아니고 참조할당이므로 가변객체의 동기화를 막는 복사를 하고 싶으면 copy 모듈의 copy() 메소드를 쓰면 된다\n불변객체는 어차피 변경될일이 없으니 copy 를 써도 참조할당이 된다\n\n깊은복사 §\n\na = copy.deepcopy(b)\n가변객체 내부에 가변객체가 있는경우, 즉, 이중 리스트같은 경우에는 copy() 를 해도 외부 리스트는 복사되지만 내부는 여전히 참조할당되어 내부의 가변객체가 변경되면 복사본도 같이 동기화되어 변경되게 된다\n이를 막고 내부까지 객체복사를 하는 방법이 바로 deepcopy() 이다.\n\n가변객체와 불변객체 §\n\n가변객체 : list, set, dict\n\n얘네들은 가변객체이다. 따라서 얘네들은 구성요소를 변경할 수 있고 변경하더라고 주소값이 달라지지 않는다\n변수를 가변객체 자료형으로 선언하면 그 변수도 가변성을 지닌다. 즉, 주소가 같다면 변경사항도 공유한다.\n따라서 두 변수를 = 연산을 하면 둘 다 같은 값과 주소를 가지게 되어 하나의 변경이 나머지 하나에도 영향을 미치게 된다\n\n\n불변객체 : 나머지 전부\n\n불변객체는 말 그대로 변경이 불가능하다. 구성요소를 변경할 수 없거나 변경하면 주소값을 새로 할당받는다\n변수를 불변객체 자료형으로 선언하면 그 변수도 불변이 된다.\n즉, 주소가 같아도 변경사항을 공유하지 않고 변경과 즉시에 주소값도 바뀐다.\n따라서, 두 변수를 = 연산으로 같은 값을 넣어주면 같은 주소값을 가지지만 하나의 값이 바뀌게 되면 나머지 하나도 바뀌는게 아니고 값이 바뀐 변수의 주소값을 새로 할당해주고 나머지 하나의 주소와 값은 그대로이다\n\n\n\n파이썬 숫자의 특징 §\n\n파이썬의 숫자는 임의 정밀도(Arbitary-Precision) 를 가진다\n\nc나 자바는 자료형당 크기가 정해져있는 고정 정밀도(Fixed-Precision)을 가진다. 즉, 이 범위를 넘어서면 오버플로우가 발생한다\n파이썬은 임의 정밀도를 가진다. 따라서 숫자의 크기에 따라 메모리 사용량이 달라진다. 따라서 오버플로우가 발생하지 않는다\n\n\n파이썬은 숫자도 객체로 선언된다\n\nc언어는 객체가 아닌 원시타입(Primitive Type)은 할당된 공간에 숫자만 저장한다. 따라서 사칙연산은 되지만 그 이상의 다양한 기능은 제공하지 않는다. 대신 빠르다는 장점이 있다\n자바는 원시타입과 객체타입을 모두 지원한다. 객체타입은 숫자이외에도 헤더에 다양한 정보를 갖고 있어 다양한 연산을 제공 한다. 대신 원시타입보다는 용량도 크고 느리다는 단점 이 있다\n파이썬은 숫자를 포함한 모든것이 객체로 선언된다 성능보다는 편의성을 중시하는 파이썬의 성향이 나타난다\n다만, 빠른 연산을 위해 NumPy라는 파이썬 라이브러리는 c로 작성되어 원시타입과 빠른 연산속도를 이용할 수 있다\n\n\n"},"originals/jumptopython.books.wikidocs.net/03.-문자열":{"title":"03. 문자열","links":[],"tags":[],"content":"\n\n                  \n                  위키북스 박응용 저 &quot;점프 투 파이썬&quot; 책을 읽고 정리한 내용입니다. \n                  \n                \n\n\n\n                  \n                  다소 잘못된 내용과 구어적 표현 이 포함되어 있을 수 있습니다. \n                  \n                \n\n파이썬에서의 문자열을 불변객체다 §\n\n문자열의 문자 하나를 인덱스로 접근해 수정한다던가 등의 행위는 금지된다\n= 로 참조복사를 해도 불변객체이기 때문에 두 변수의 동기화는 안된다\n참조복사가 아닌 값 복사를 하고싶을때는 [:] 슬라이싱을 이용하면 된다\n\n기본적인 표현법 §\n&#039;str&#039;\n&quot;str&quot;\n&#039;&#039;&#039;str&#039;&#039;&#039;\n&quot;&quot;&quot;str&quot;&quot;&quot;\n줄바꿈 §\n&#039;\\n&#039;\n&#039;&#039;&#039;&lt;ENTER&gt;&#039;&#039;&#039;\n&quot;&quot;&quot;&lt;ENTER&gt;&quot;&quot;&quot;\n인덱스참조 §\nstr[int]\n\n음수를 넣으면 뒤에서부터 온다\n\n슬라이싱 §\nstr[a:b:c]\n\na = 첫인덱스 : 생략하면 0\nb = 끝인덱스 : 생략하면 문자열 맨끝\nc = 인덱스이동 : 디폴트는 1, 0주면 에러남, 음수는 역이동(문자열 뒤집기에 이용)\n파이썬의 문자열 슬라이싱은 연산속도가 아주 빠르다. 문자열을 처리할 일이 있으면 리스트로 바꾸거나 하지 말고 문자열 자체에서 슬라이싱 등을 이용하는게 좋다\n\n포매팅 §\n퍼센트 포매팅 §\n(&quot;%10s&quot; % 123)\n(&quot;%0.2f&quot; % 1.23456)\n\n10 : 포매팅되는 부분 총길이가 10이 되고 123은 오른쪽 정렬 후 남는부분은 스페이스바로 채움. 숫자가 음수이면 왼쪽정렬. 이딴거 필요없으면 숫자는 안써도됨\ns : 포매팅되는놈의 자료형. s는 문자열이기때문에 아무거나 넣어도 된다\n% 123 : 123을 포매팅시키겟다는 뜻\n0.2 : 소숫점 뒤 2자리까지 표시하겠다는 뜻\nf : 소숫점 자리수를 지정할때는 f로 자료형을 지정해 줘야 한다\n\n인덱스 포매팅 §\n&quot;{0} {1} {2}&quot;.format(123, 456, 789)\n&quot;{a} {b} {c}&quot;.format(a = 1, b = 2, c = 3)\n\n{} 안의 숫자가 인덱스, 뒤에 123 456 789가 인덱스 순대로 들어감\n문자 인덱스를 사용할때는 format() 안에 직접 명기해야함\n\n변수 포매팅 §\nf&quot;{변수1} {변수2}&quot;\n\n변수를 직접 안에 포매팅하고싶을때\n\n변형해서 포매팅하기 §\n&quot;{a:$^10}&quot;.format(a = 123)\nf.&quot;{a:$^10}&quot;\n&quot;{a:0.2f}&quot;.format(a = 1.234)\nf.&quot;{a:0.2f}&quot;\n\na : format 에서는 인덱스(숫자가능), f 에서는 변수명\n$ : 총 길이중 포매팅하고 남은 공백을 $ 로 채운다는 뜻 (다른 문자도 가능)\n^ : 포매팅되는 123이 가운데 정렬된다는 뜻. &gt; 는 오른쪽, &lt; 는 왼쪽이다\n10 : 총 길이가 10이라는 뜻.\n0.2 : 소숫점 뒤 2자리까지만 표시\nf : 실수형. 소숫점 자리수 표현시에는 f반드시 써줘야된디\n\n문자열 함수들 §\n문자 개수 세기 §\na.count(&#039;b&#039;)\n\n’b’ 의 갯수를 a 에서 세어서 알려줌\n\n문자의 최소인덱스 찾기 §\na.find(&#039;b&#039;)\na.index(&#039;b&#039;)\n\n문자열 a 에서 ’b’ 가 나온 첫 인덱스를 반환한다\nfind 함수는 문자열이 없을때 -1 반환하고 index 는 오류를 발생시킨다\n\n문자 사이사이에 원하는 문자 넣기 §\n&#039;$&#039;.join(&quot;abcd&quot;)\n\n결과는 “a*b*c$d” 이다\n\n대소문자화 §\na.upper() # 대문자화\na.lower() #소문자화\n공백지우기 §\na.lstrip()\na.rstrip()\na.strip()\n\nlstrip() : 문자열a의 왼쪽 공백이 전부 사라진다\nrstrip() : 문자열a의 오른쪽 여백이 전부 사라진다\nstrip() : 문자열a의 양쪽 여백이 전부 사라진다\n\n문자열 바꾸기 §\na.replace(&quot;이걸로&quot;, &quot;이것을&quot;)\n\n문자열 a 의 뒤엣놈을 앞에놈으로 바꾼다\n\n문자열 리스트화 §\na.split(&quot;기준&quot;)\n\n문자열을 “기준” 으로 나눠서 리스트로 반환한다\n“기준” 을 안쓰면 스페이스바를 기준으로 나눈다\n"},"originals/jumptopython.books.wikidocs.net/04.-리스트":{"title":"04. 리스트","links":[],"tags":[],"content":"\n\n                  \n                  위키북스 박응용 저 &quot;점프 투 파이썬&quot; 책을 읽고 정리한 내용입니다. \n                  \n                \n\n\n\n                  \n                  다소 잘못된 내용과 구어적 표현 이 포함되어 있을 수 있습니다. \n                  \n                \n\n파이썬의 리스트는 다른 리스트들과 다르게 구현되어 있다 §\n\nc나 자바의 경우에는 리스트에 요소로 들어갈 자료형의 정수배를 하여 리스트의 메모리를 할당한다\n\n이 경우에는 연속된 메모리 공간에 인덱스 순서대로 리스트의 요소가 저장되므로 인덱스를 지정하면 간단한 연산만으로 메모리 주소를 알 수 있어 매우 빠르다\n하지만 이 경우에는 리스트에 같은 자료형의 요소만 저장할 수 있고 선언된 리스트의 크기를 넘어서면 에러가 발생하는 등 불편한 점이 있다\n\n\n하지만 파이썬은 속도를 양보하고 편의성을 가져왔다. 즉, 파이썬의 경우 연속된 메모리 공간에 리스트의 요소를 저장하지 않는다\n\n파이썬에서는 요소들의 주소를 하나의 배열로 관리하는 형식을 취하며, 요소가 추가되면 리스트의 다음 공간에 추가하는 방식이 아닌 추가된 요소의 주소를 주소배열에 넣어주는 방식이다\n이 방식은 새로 요소가 추가되면 요소를 메모리 어딘가에 할당하고 이것의 주소를 주소배열에 연결해주고, 요소가 삭제되면 주소배열과 요소와의 연결을 끊어주는 방식으로 요소 추가와 삭제가 이루어진다\n\n\n이 방식의 장점은 기술한대로 편리함에 있다.\n\n실제로 요소들이 차지하는 메모리 공간은 단순한 특정 자료형의 정수배가 아니기 떄문에, 리스트에 다양한 자료형을 추가해도 문제가 되지 않는다\n또한 리스트의 크기가 제한적이지 않으며 언제든 리스트의 크기를 늘리거나 줄일 수 있다 는 장점이 있다\n\n\n하지만 단점은 기술한 대로 속도 이다.\n\n주소배열이 저장하고 있는 주소들은 반드시 인덱스 순서대로라고 할 수 없다.\n요소가 추가되면 주소배열의 빈공간에 그냥 넣어주고 삭제되면 그 요소가 차지하던 주소배열의 자리를 그냥 비워주면 되기 때문이다\n따라서 간단한 인덱스를 통한 값 조회의 경우에도 모든 주소배열의 주소로 들어가 값과 데이터타입, 요소들이 저장하고 있는 인덱스 값을 비교해야 되므로 단순한 연산으로 끝나지 않게 된다\n\n\n\n생성자 §\na = list()\na = list(iterable)\n\n인자를 아무것도 안주면 빈 리스트를 생성해서 반환한다\n반복가능한 객체를 인자로 주면 그 객체의 내용을 리스트화해서 반환한다\n\n요소 추가 §\na.append(b)\na += [b]\na.extend([b])\na.insert(i, b)\n\n리스트 a 의 맨 뒤에 요소 b 를 추가하거나 인덱스 i 에 요소 b 를 추가하는 메소드들\n+= 연산이랑 extend() 는 같은 기능을 한다\n이미 선언된 리스트에만 요소 추가가 가능하다. - [1, 2].append(3) 같은 연산은 불가능하다\n\n요소 삭제 §\ndel a[i]\na.remove(b)\na.pop()\na.pop(0)\n\ndel : 인덱스로 접근해 삭제\nremove() : 입력값과 같은 값을 가지는 첫 요소를 삭제\npop() : 맨 뒷 요소를 삭제\npop(0) : 맨 앞 요소를 삭제\npop() 이 O(1)로 제일 빠르고 다른애들은 선형비교를 해야하기 때문에 O(n)이다\n\n문자열로 만들기 §\n&#039;a&#039;.join(a)\n\n리스트a의 요소 사이사이에 ’a’ 를 넣어서 하나의 문자열로 만든다\n\n대소비교 §\n[3, 4] &gt; [1, 2] # True\n[3, 4] &gt;= [1, 2] # True\n[1, 2] == [1, 2] # True\n\n리스트도 문자열마냥 앞의 인덱스부터 차례대로 대소비교해 전체 리스트의 대소를 판별한다\n\n리스트 반복 §\n[1, 2, 3]*3\n\n결과는 [1, 2, 3, 1, 2, 3, 1, 2, 3] 이다\n\n파이썬에서 제공하는 강력한 정렬함수 : sort, sorted §\na.sort()\nsorted(a)\n\nsort() : a를 내부적으로 정렬한다\nsorted() : a를 정렬한 결과를 반환한다\n그냥 sort() 메소드는 리턴값이 없다는것에 주의해야한다\n생략가능한 매개변수 key=func 를 통해 정렬의 기준을 정할 수 있다\n\n내가 이 기능을 다시 이용할지는 모르겠지만, key로 전달하는 함수의 리턴값이 튜플이라면, 인덱스가 우선인 것을 기준으로 정렬하고 이것으로 정렬이 불가능하면 그때 뒤의 인덱스로 기준을 옮겨가며 정렬한다\n\n\n팀소트의 O(nlogn) 의 아주 빠른 함수이다\n\n순서 뒤집기 §\na.reverse()\na[:]\n\n리스트 a 의 순서를 뒤집은 결과를 반환한다\n\n인덱스 반환 §\na.index(123)\n\n123 의 위치를 a 에서 찾아서 반환한다\n\n요소 갯수 세기 §\na.count(123)\n\n123 의 갯수를 a 에서 세어서 반환한다\n\n요소인지 아닌지 §\n${OBJ} in ${LIST}\n${OBJ} not in ${LIST}\n\nin : 객체가 리스트의 요소이면 True, 요소가 아니면 False 를 반환\nnot in : 그 반대\n\n인덱스와 값을 같이 갖고오기 §\nenumerate(lst)\n\n리스트를 받아 (인덱스, 값) 의 튜플을 요소로 하는 반복가능객체로 반환한다\n\n최대/최소 §\nmax(lst)\nmin(lst)\n\nmax 는 요소의 최대값을, min 은 요소의 최소값을 리턴한다\n생략가능한 매개변수 key=func 를 통해 최대/최소의 기준을 정할 수 있다\n"},"originals/jumptopython.books.wikidocs.net/05.-튜플":{"title":"05. 튜플","links":[],"tags":[],"content":"\n\n                  \n                  위키북스 박응용 저 &quot;점프 투 파이썬&quot; 책을 읽고 정리한 내용입니다. \n                  \n                \n\n\n\n                  \n                  다소 잘못된 내용과 구어적 표현 이 포함되어 있을 수 있습니다. \n                  \n                \n\n튜플은 리스트의 불변객체 버전이다 §\n\n선언 이후에는 요소 변경 및 삭제가 안된다\n\na[0] = 2 나 del a[0] 등의 연산은 안된다 이말이다\n\n\n어차피 불변객체이므로 참조복사밖에 안된다\n\n= 연산을 하든 copy() 를 쓰든 tuple() 로 새로 만들든 내용이 같기때문에 참조복사밖에 안된다.\n\n\n+ 나 += 연산은 요소 추가를 하는것 같지만 사실 새로 만드는거다\n\n리스트의 경우에는 +, += 연산을 해도 주소값이 바뀌지 않지만 튜플은 새로 객체를 하나 반들어서 반환하기 때문에 주소값이 달라진다.\n\n\n\n선언 §\n(1, 2, 3)\n(1, )\n1, 2, 3\n\n튜플은 () 로 선언하며 괄호가 없어도 튜플로 선언된다\n튜플은 요소가 한개여도 콤마를 찍어줘야 한다\na, b = 1, 2 : 여러개의 변수를 선언 및 초기화할때 이렇게 튜플을 이용해주면 편하다\na, b = b, a : 변수 두개의 값을 맞교환할때 제3의 변수를 안쓰고 이렇게 단순하게 하는것이 가능하다\n\n생성자 §\na = tuple()\na = tuple(iterable)\n\n인자를 안주면 빈 튜플을 반환하고\n반복 가능한 객체를 인자로 주면 해당 객체의 내용을 튜플로 변환하여 반환한다\n\n인덱스 접근 §\ntpl[int]\n덧셈 §\n(1, 2, 3) + (4, 5, 6)\n\n결과는 (1, 2, 3, 4, 5, 6) 이다\n튜플은 불변객체이기 때문에 덧셈의 결과는 새로운 객체로 생성된다.\n\n슬라이싱 §\ntpl[1:20:2]\n\n인덱스 1부터 19까지 인덱스 2씩 증가하며 슬라이싱\n\n곱셈 §\n(1, 2, 3) * 3\n\n결과는 (1, 2, 3, 1, 2, 3, 1, 2, 3) 이다\n\n길이구하기 §\nlen(tpl)"},"originals/jumptopython.books.wikidocs.net/06.-집합":{"title":"06. 집합","links":[],"tags":[],"content":"\n\n                  \n                  위키북스 박응용 저 &quot;점프 투 파이썬&quot; 책을 읽고 정리한 내용입니다. \n                  \n                \n\n\n\n                  \n                  다소 잘못된 내용과 구어적 표현 이 포함되어 있을 수 있습니다. \n                  \n                \n\n집합은 키 없는 딕셔너리와 같다 §\n\n이것이 딕셔너리와 동일하게 {} 로 표현되는 이유이다.\n따라서 딕셔너리처럼 인덱스로 접근하지도 못하고 딕셔너리와는 다르게 키도 없기 때문에 키로 접근하지도 못한다.\n즉, 집합은 개별 요소에 접근할 수 있는 방법이 전혀 없다\n각각의 요소에 접근하지 못하기 때문에 요소들이 불변객체로 선언 되어야만 하는 것이다\n개별요소에 접근하기 위해서는 집합의 상태에서는 안되고 리스트나 튜플로 변환해서 접근 해야 한다\n\n집합은 중복되는 요소를 가질 수 없다 §\n\n수학에서의 집합과 마찬가지이다\n따라서 리스트/튜플을 집합으로 변경하면 중복된 요소들이 하나로 정리 된다. 이것은 중복된 요소를 제거하는 메커니즘 으로도 이용된다\n\n선언 §\na = {1, 2, 3, 4}\n\n키:벨류 쌍이 아닌 요소만 중괄호에 묶으면 집합이 된다\n집합의 요소도 불변객체여야 한다. 리스트를 요소로 가질 수 없다 이말이다\n\n생성자 §\na = set()\na = set(iterable)\n\n인자를 안넣으면 빈 집합이 만들어진다\n반복가능한 객체를 넣으면 그 객체의 내용이 집합화되어 반환된다\n\n교집합 §\na &amp; b\na.intersection(b)\n\n두 잡합의 교집합을 구하는 연산이다\n\n합집합 §\na | b\na.union(b)\n\n두 집합의 합집합을 구하는 연산이다\n\n차집합 §\na - b\na.difference(b)\n\n두 집합의 차집합을 구하는 연산이다\n교집합과 합집합과는 다르게 차집합은 순서에 신경써야된다 (a - b, b - a는 다르다)\n"},"originals/jumptopython.books.wikidocs.net/07.-데크":{"title":"07. 데크","links":[],"tags":[],"content":"\n\n                  \n                  위키북스 박응용 저 &quot;점프 투 파이썬&quot; 책을 읽고 정리한 내용입니다. \n                  \n                \n\n\n\n                  \n                  다소 잘못된 내용과 구어적 표현 이 포함되어 있을 수 있습니다. \n                  \n                \n\n데크는 양방향 큐이다 §\n\ndeq : double-ended queue의 약자이다\n즉, 양쪽으로 append하고 pop하는 연산에 특화 되어있는 자료형이다\n리스트의 경우에는 오른쯕에 넣고 빼는 append() 와 pop() 은 O(1)로 빠르지만, 왼쪽에 넣고 빼는 insert(0, x) 와 pop(0) 은 리스트 요소를 한칸씩 전부 밀고 당겨야 되므로 O(n)의 시간복잡도를 가진다\n하지만 데크의 경우에는 양쪽에 넣고 빼는 연산이 전부 O(1)로 매우 빠르다.\n따라서 양쪽으로 넣고 빼는 일이 많은 경우에는 리스트보다 데크를 사용하는 것이 더 좋다.\n\n생성자 §\na = collections.deque()\na = collections.deque(iterable)\n\n인자를 아무것도 넣지 않으면 빈 데크가 만들어진다\n반복 가능한 객체를 넣으면 그 객체의 내용이 데크로 만들어진다\nmaxlen=숫자 : 생략가능한 매개변수로 maxlen 이 있다. 이놈은 데크의 최대길이를 선언하는놈이며 데크가 찼을 경우에 새로 요소를 추가하면 왼쪽에서부터 차례로 지워진다\n\n요소 추가 §\ndeq.append(object)\ndeq.appendleft(object)\n\nappend() 은 오른쪽에 요소 추가\nappendleft() 은 왼쪽에 요소 추가\n\n데크 확장 §\ndeq.extend(iterable)\ndeq.extendleft(iterable)\n\nextend() 는 오른쪽에 확장\nextendleft() 는 왼쪽에 확장\n\n요소 삭제 §\ndeq.pop()\ndeq.popleft()\n\npop() 은 오른쪽에서 하나 꺼냄\npopleft() 은 왼쪽에서 하나 꺼냄\n\n인덱스 찾기 §\ndeq.index(object)\n\nobject가 처음으로 등장하는 인덱스를 deq에서 찾아서 알려줌\n\n회전하기 §\ndeq.rotate(n=1)\ndeq.rotate(n=-1)\n\nn=1 : 오른쪽으로 하나 회전. 즉, deq.appendleft(deq.pop()) 와 같음\nn=-1 : 왼쪽으로 하나 회전. 즉, deq.append(deq.popleft()) 와 같음\n숫자는 얼마큼 회전할지, 부호는 방향을 의미한다\n"},"originals/jumptopython.books.wikidocs.net/08.-딕셔너리":{"title":"08. 딕셔너리","links":[],"tags":[],"content":"\n\n                  \n                  위키북스 박응용 저 &quot;점프 투 파이썬&quot; 책을 읽고 정리한 내용입니다. \n                  \n                \n\n\n\n                  \n                  다소 잘못된 내용과 구어적 표현 이 포함되어 있을 수 있습니다. \n                  \n                \n\n딕셔너리는 해시 테이블을 이용하는 자료형이다 §\n\n숫자 뿐만 아니라 문자열, 튜플 등의 다양한 불변 객체를 키로 받을 수 있다. 이 과정을 해싱 이라고 한다.\n그리고 이런 키마다 각각의 벨류를 연결하는 해시 테이블의 형태로 구성된다. 이 벨류들은 키를 통해서만 접근이 가능하다\n해시 테이블의 장점은 다양한 자료형을 지원하면서도 연산의 속도가 아주 빠르다는 장점 이 있다. 파이썬 딕셔너리의 대부분 연산은 O(1)의 짧은 연산속도를 가진다\n\n선언 §\ndct = {&quot;key1&quot;:&quot;value1&quot;, &quot;key2&quot;:&quot;value2&quot;}\n\n키:벨류 쌍들이 {} 속에 담겨있는 형태이다.\n딕셔너리의 키값은 변하면 안되기 때문에 불변객체로 선언해줘야 한다.\n\n리스트를 키로 주면 안된다 이말이다\n\n\n딕셔너리는 하나의 키에 하나의 벨류를 갖는다.\n\n따라서 동일한 키를 갖는 두 벨류를 넣게되면 하나는 사라지게 된다.\n\n\n그럼 여러개를 하나의 키로 묶고싶으면 리스트나 튜플을 이용하면 된다.\n\n생성자 §\na = dict([(a, 1), (b, 2), (c, 3)])\na = dict(a=1, b=2, c=3)\n\n[(), ()] 형태의 튜플 리스트를 인자로 받아 딕셔너리로 만들거나\n키=벨류 쌍을 여러개 입력해서 딕셔너리로 만들 수도 있다\n\n접근 §\ndct[&quot;key1&quot;]\ndct.get(&quot;key1&quot;)\n\n인덱스로 접근하는게 아닌 키를 이용해 벨류를 접근한다. 따라서 인덱스 대신 키값을 대괄호 [] 에 넣어주면 벨류값에 접근할 수 있다.\nget 함수는 [] 접근과 동일하나 키값이 존재하지 않는 경우 오류가 아닌 None 객체를 반환한다\nO(1)이다\n\n키:벨류 쌍 추가하기 §\ndct[&quot;key&quot;] = &quot;value&quot;\n\n이미 존재하는 key라면 해당하는 value가 바뀌겠지만 존재하지 않는다면 저 키:벨류 쌍을 새로 추가한다\nO(1)이다\n\n키:벨류 쌍 삭제 §\ndel dct[&quot;key&quot;]\n\n딕셔너리는 del 말고는 다른 삭제방법이 없다\n\n키들만 모아서 리스트로 §\ndct.keys()\n\n딕셔너리의 키들만 모아서 리스트로 반환한다\n정확히는 리스트가 아닌 제네레이터로 반환한다\n\n리스트로 쓰고싶으면 list() 를 이용하자\n\n\n\n벨류만 모아서 리스트로 §\ndct.values()\n\n딕셔너리의 벨류들만 모아서 리스트로 반환한다\n정확히는 리스트가 아닌 제네레이터로 반환한다\n\n리스트로 쓰고싶으면 list() 를 이용하자\n\n\n\n(키, 벨류)튜플 리스트로 바꾸기 §\ndct.items()\n\n딕셔너리의 키와 벨류를 튜플로 묶어서 리스트로 반환한다\n정확히는 리스트가 아닌 제네레이터로 반환한다\n\n리스트로 쓰고싶으면 list() 를 이용하자\n\n\n\n키:벨류 쌍의 갯수 구하기 §\nlen(dct)\n\n딕셔너리의 키:벨류 쌍의 갯수를 리턴한다\nO(1)이다\n\n키가 존재하는지 알아내기 §\n&quot;key&quot; in dct\n\n키가 딕셔너리에 이미 존재하는지를 boolean 객체로 반환한다\n이것도 O(1)이다\n\n키:벨류 쌍 모두 지우기 §\ndct.clear()\n\n딕셔너리 내의 모든 키:벨류 쌍이 삭제된다\n\n입력순서가 유지되는 딕셔너리 §\na = collections.ordereddict()\n\n딕셔너리는 원래 입력 순서가 유지 안되다가 최근 파이썬 업데이트로 인해 입력순서가 유지되는것으로 바뀌었다\n하지만 이전버전과의 호환성을 위해 입력순서 유지가 필요하면 collections 모듈의 ordereddict() 클래스를 활용하자\n\ntype 이 dict 는 아니다. ordereddict 라는 wrapping된 딕셔너리 객체이다\n\n\n\n초기화를 자동으로 해주는 딕셔너리 §\na = collections.defaultdict(type)\n\n“abc” 라는 키가 존재하지 않을 때 dct[“abc”] + 2 연산을 하면 존재하지 않는 키에 접근하므로 오류가 난다\n하지만 이렇게 키가 존재하지 않을 때 자동으로 키:벨류 를 생성하고 초기화해 연산을 가능하게 해주는게 collections 모듈의 defaultdict 객체이다\ndct = defaultdict(int) 로 선언하고 위의 연산을 해주면 “abc” 의 벨류로 자동으로 0 이 초기화되고 2가 더해져 “abc”:2 의 쌍이 추가된다\n괄호 안에 자료형을 꼭 명시해야 된다. 어떤 자료형으로 초기화할껀지 알아야 하기 때문이다\n이것도 순수한 딕셔너리는 아닌 wrapping된 딕셔너리 객체로 나오게 된다\n\n리스트나 튜플의 중복인자 세기 §\na = collections.counter(list/tuple)\na.most_common(3)\n\n[1, 1, 3, 3, 3, 3, 5, 5, 5, 5, 5, 5] 라는 리스트를 counter 객체로 만들면\n{1:2, 3:4, 5:6} 로 바꿔준다\n즉, 동일한 인자가 몇개있는지를 세어서 인자를 키로, 갯수를 벨류로 하는 딕셔너리로 반환한다\nmost_common(숫자) 은 가장 자주 등장하는 인자를 ’숫자’ 순위까지만 튜플 리스트로 반환한다\n이것도 순수한 딕셔너리는 아닌 wrapping된 딕셔너리 객체로 나오게 된다\n"},"originals/jumptopython.books.wikidocs.net/09.-반복,-조건문":{"title":"09. 반복, 조건문","links":[],"tags":[],"content":"\n\n                  \n                  위키북스 박응용 저 &quot;점프 투 파이썬&quot; 책을 읽고 정리한 내용입니다. \n                  \n                \n\n\n\n                  \n                  다소 잘못된 내용과 구어적 표현 이 포함되어 있을 수 있습니다. \n                  \n                \n\n기본구조 §\nif 조건 :\n\t# ...\nelif 조건 :\n\t# ...\nelse :\n\t# ...\n\nelse if 가 아니고 elif 이다\n: 이후에 줄바꿈 및 인덴테이션 꼭해야된다\n해당조건에 암것도 안하고싶으면 pass 를 쓰면 된다\n\n조건부 표현식 §\na = 3 if 조건 else 4\n\n조건이 참이면 변수 a 에 3을 넣고 거짓이면 4를 넣는다\n= 대신 +=, -= 를 써도 된다\n\nfor문 §\nfor i in lst :\n\t# ...\nfor a, b in tuplelist :\n\t# ...\n\nfor문에서 in 은 반복가능객체에서 요소를 하나씩 꺼내 앞의 변수에 넣어주는 연산이다\n튜플 리스트의 경우 in 앞을 튜플로 받아 여러개의 값을 하나의 for 문으로 받아올 수 있다.\n\n연속된 자연수 for문으로 받아오기 §\nfor i in range(1, 10) :\n\t# ...\n\nrange 함수는 입력한 범위의 연속된 정수를 반복가능객체로 반환하는 함수이다.\nrange(1, 10)은 1~9를 제공한다\n\n인덱스와 값 같이 for문으로 받아오기 §\nfor a, b in enumerate(lst) :\n\t# ...\n\nenumerte 의 반환값을 튜플로 받아 리스트의 인덱스와 값을 같이 가져올 수도 있다\n\n리스트 컴프리헨션 §\na = [i + 10 for i in lst]\n\n리스트 내에 for문을 넣어서 한줄로 for문과 리스트 생성을 끝낼 수 있다\n[ {{ 수식 }} for {{ 변수 }} in {{ 반복가능객체 }} ]\n위의 코드 결과는 리스트의 모든 요소에 10을 더해서 리스트 a의 구성요소로 만들어준다\n"},"originals/jumptopython.books.wikidocs.net/10.-함수-선언-문법":{"title":"10. 함수 선언 문법","links":[],"tags":[],"content":"\n\n                  \n                  위키북스 박응용 저 &quot;점프 투 파이썬&quot; 책을 읽고 정리한 내용입니다. \n                  \n                \n\n\n\n                  \n                  다소 잘못된 내용과 구어적 표현 이 포함되어 있을 수 있습니다. \n                  \n                \n\n함수선언 §\ndef func_name(arg1, arg2) :\n\treturn 반환할거\n\ndef : 함수 선언 명령어\narg : 매개변수\n인덴테이션 꼭 해줘야 한다\n구현 안하고싶으면 pass를 이용하자\n여러개의 값을 ’,’ 로 연결하면 튜플이므로 문제없이 return 할 수 있다.\n\n반환값을 받을때는 a, b, c … = func_name() 이렇게 받아주면 편리하다\n\n\n\n튜플로 인자 입력 §\ndef func_name(*arg) : # 선언\nfunc_name(&#039;a&#039;, 123, &quot;abc&quot;, ... ) # 호출\narg[1] == 123 # 접근\n\n* 는 입력한 인자들을 전부 튜플로 묶어 변수(arg)로 접근할 수 있게 해준다\n입력한 인자들은 순서대로 arg[i] 로 접근 가능하다\n인자를 몇개를 받을지 모를때 이용해주면 된다\n\n딕셔너리로 인자 입력 §\ndef func_name(**kwarg) : # 선언\nfunc_name(ab=12, cd=34, ... ) # 호출\nkwarg[ab] == 12 # 접근\n\n**는 입력한 인자들을 전부 딕셔너리로 묶어 변수(kwarg)로 접근할 수 있게 해준다\n=를 기준으로 왼쪽을 문자열로 키에 집어넣고, 오른쪽을 벨류에 집어넣는다.\n=왼쪽이 문자열 형식으로 키에 할당된다는거에 유의할것\n통상적으로 keyword argument의 줄임말인 kwarg 를 변수명으로 쓴다\n\n생략가능한 매개변수 §\ndef func_name(arg1, arg2, arg3 = 123):\n\t# ...\n\narg1과 arg2는 그냥 변수지만 arg3처럼 선언시에 바로 초깃값을 넣어주면 호출시에 인자를 안넣어줘도 되는 생략가능한 매개변수가 된다\n따로 인자를 넣어주지 않는 한 arg3은 123으로 기능한다\n123으로 사용하고싶지 않은 경우에는 호출시에 func_name(1, 2, arg3 = 345) 이렇게 해주면 arg3은 345로 기능한다\n내장함수 중 이것을 이용하는 예는 sort나 min/max 에서의 key나 print에서의 end같은애들이 있다\n\n한줄짜리 함수 = 람다 §\nfunc_name = lambda 매개변수 : 반환할거\n\n람다는 ’:’ 전후를 이용해 함수객체를 즉석에서 만들어서 반환한다\n한줄로 구현할 수 있는 단순한 함수의 경우 사용하면 좋다\n변수(func_name)에 넣어서 사용할 수도 있지만 map이나 filter등 함수형 기능을 제공하는 메소드들의 함수객체 매개변수에 인자로 줄 수도 있다\n"},"originals/jumptopython.books.wikidocs.net/11.-함수-타입-힌트,-제네레이터":{"title":"11. 함수 타입 힌트, 제네레이터","links":[],"tags":[],"content":"\n\n                  \n                  위키북스 박응용 저 &quot;점프 투 파이썬&quot; 책을 읽고 정리한 내용입니다. \n                  \n                \n\n\n\n                  \n                  다소 잘못된 내용과 구어적 표현 이 포함되어 있을 수 있습니다. \n                  \n                \n\n타입 힌트 §\n\n파이썬에서는 자료형의 종류를 동적으로 할당한다\n하지만 이렇게 할 경우 편리하기는 하지만 가독성도 떨어지고 연산중 자료형이 안맞아 오류가 날 수 있다\n그래서 파이썬에서는 이 타입 힌트라는 기능을 제공한다\n변수의 경우 변수: 자료형 으로 타입 힌트를 줄 수 있고\n반환값의 경우 -&gt; 자료형 으로 타입 힌트를 줄 수 있다\n다만 말 그대로 타입 힌트이므로 이것을 따르지 않았을 경우 경고만 할 뿐 따로 에러처리를 하지는 않는다\n\n즉, 타입힌트를 써줘도 얼마든지 동적으로 할당될 수 있으므로 조심해야한다\n\n\n파이썬에서 pip install mypy 를 해주면 mypy 가 깔리게 되는데, 요놈을 이용하면 타입 힌트랑 자료형이랑 안맞을때 오류처리를 해 손쉽게 고칠 수 있도록 도와준다\n\n타입 힌트를 활용한 함수선언 §\ndef func_name(arg1: type, arg2: type) -&gt; type :\n\treturn 반환할거\n\narg: type : 매개변수와 매개변수의 타입\n-&gt; type : 리턴값의 타입\n\n제네레이터 §\n\n제네레이터는 어떤 많은 값들을 생성해서 사용해야할때 전부 다 만들어놓고 사용하는게 아닌 만드는 방법만 저장했다가 호출시에 바로바로 만들어 쓰는 개념 이다\n대표적인예로 range() 함수를 알아보자\n\n5조5억개의 숫자를 생성해야한다고 가정해보자\n이때 l1 = [n+1 for n in range(0, 오조오억)] 으로 그냥 리스트를 생성하고\nl2 = range(0, 오조오억) 이렇게 해줬을때 두가지는 인덱스로 접근도 가능하고, iterate도 사용할 수 있으니 같은 기능을 제공한다고 할 수 있다\n심지어 len() 으로 요소의 갯수를 구해도 같은 값을 출력한다\n하지만 이 둘의 메모리 소모를 보면 확연히 차이가 난다 - l2가 현저히 적은 양의 데이터를 먹는다\n이것은 l1는 오조오억개의 숫자를 미리 만들어서 저장하고 있지만, l2의 경우에는 숫자를 생성하는 방법만 저장하고 실질적으로 만든 숫자는 가지고 있지 않기 때문\n따라서 제네레이터는 같은 기능을 제공하지만 현저히 적은 메모리를 먹는다는 장점이 있다\n\n\n일반 함수에서 제네레이터 기능 사용하기 : yield\n\nreturn 같은 경우에는 반환하면 바로 함수가 종료되지만 yield 의 경우에는 종료되지 않는다\nreturn 같은 경우에는 반환값이 그대로 반환되지만 yield는 제네레이터 객체가 반환된다*\nnext(반환된 제네레이터 객체) 를 이용해 다음으로 함수가 반환할 값을 그때그때 받아서 쓸 수가 있다\n이것도 return 의 경우에는 값을 다 만들어서 반환하지만 yield 의 경우에는 값을 만드는 방법을 저장했다가 next() 로 호출할때마다 그때그때 값을 만들기 때문임\n\n\n\n제네레이터 함수 §\nyield 반환할거 # 함수 return문 대신\nnext(제네레이터 객체) # 제네레이터 호출\n\n함수를 제네레이터형으로 선언하고싶으면 return 대신 yield 를 사용하면 된다\n대신 함수의 반환값이 제네레이터 객체이므로 다음 값을 받고싶을때는 next() 를 이용하면 된다\n함수의 반환값이 제네레이터 객체이고 다음값을 받을떄는 next() 를 써야된다는 점을 꼭 기억할 것\n"},"originals/jumptopython.books.wikidocs.net/12.-클래스":{"title":"12. 클래스","links":[],"tags":[],"content":"\n\n                  \n                  위키북스 박응용 저 &quot;점프 투 파이썬&quot; 책을 읽고 정리한 내용입니다. \n                  \n                \n\n\n\n                  \n                  다소 잘못된 내용과 구어적 표현 이 포함되어 있을 수 있습니다. \n                  \n                \n\n객체와 인스턴스 §\n\n클래스A를 가지고 B를 만들었을때\n\nB는 객체이다. 즉, 객체는 이놈의 특성 이다\nB는 A의 인스턴스이다. 즉, 인스턴스는 해당 객체가 어떤 클래스를 가지고 만들어진건지 나타내는 관계 이다\n\n\n\n객체변수와 클래스 변수 §\n\n객체변수는 객체 내부에서 독립적으로 사용하며 다른 객체에는 영향을 주지않는 용도로 쓰인다\n클래스 변수는 클래스의 모든 인스턴스에 범용적으로 작용하며 값이 변경되면 모든 객체에서 값이 동기화되어 변경 된다. 이것을 정적인 특성 을 가진다 라고 표현한다\n객체변수는 클래스 내부의 어느 곳에서나 self.변수 를 통해 선언해줄 수 있지만 해당 클래스에 어떤 객체변수가 존재하는지 한눈에 보기 위해 보통 생성자에서 선언하고 초기화 해준다\n클래스 변수는 클래스 내부의 최상위 인덴트에 선언 해 주면 된다\n주의할 점은 클래스 변수의 경우 객체에서 값을 변경해주면 정적인 특성이 작용하지 않고 해당 객체 내부에서만 값이 변경 된다\n따라서 클래스 변수의 값을 변경하고자 할 때는 클래스.변수 이런식으로 클래스로 접근하여 값을 변경해야 된다\n클래스는 객체를 만드는 틀이므로 모든 객체에 동일하게 작용하는 클래스 변수의 값을 변경하기 위해서는 틀로 만든 객체에서 값을 변경할게 아니라 틀인 클래스에서 변경하라는 의미 라고 생각하면 된다\n\n메소드의 첫번째 매개변수, self §\n\n함수와는 다르게 메소드의 경우 해당 메소드를 호출하는 객체가 존재한다\n파이썬에서는 메소드의 첫번째 매개변수로 해당 메소드를 호출하는 객체가 들어가게 된다\n근데 보통 객체 자기자신이 메소드를 호출하므로 관례적으로 객체변수 이름을 self 로 해준다. 자바에서의 this 와 동일한 의미이다\n객체를 이용해 메소드 호출시에 객체.메소드() 를 하면 해당 객체가 자동으로 self 에 들어가므로 객체로 메소드를 호출할때는 따로 self 에 값을 넣어주지 않아도 된다\n하지만 클래스로 메소드를 호출하게 되면 어떤 객체에서 호출하는지 알 수 없기 때문에 클래스.메소드(객체) 이렇게 어떤 객체에서 호출할지 명시 해줘야 한다\n"},"originals/jumptopython.books.wikidocs.net/13.-클래스-문법":{"title":"13. 클래스 문법","links":[],"tags":[],"content":"\n\n                  \n                  위키북스 박응용 저 &quot;점프 투 파이썬&quot; 책을 읽고 정리한 내용입니다. \n                  \n                \n\n\n\n                  \n                  다소 잘못된 내용과 구어적 표현 이 포함되어 있을 수 있습니다. \n                  \n                \n\n선언 §\nclass Class_name(Parent_class) :\n\n괄호 안에 상속받을 부모 클래스 이름을 적는다. 상속받을 클래스가 없으면 안적어도 된다\n괄호안에 부모클래스가 들어간다는 것에 유의할 것\n\n메소드 선언 §\ndef method_name(self, arg1, arg2, ... ) :\n\n메소드 선언 명령어는 def이다\n첫번째 매개변수는 관례적으로 self 를 써준다\n함수가 아닌 메소드 선언시에는 self 를 잊지 말자\n\n생성자/객체변수 선언 §\ndef __init__(self, arg1, arg2, ...) :\n\tself.arg = 123\n\n메소드 이름을 __init__ 으로 해줘야 생성자로 인식을 한다\n관례적으로 객체변수는 생성자에서 self.변수 = 값 형식으로 선언을 해서 사용한다\n생성자 이름이 클래스명이 아닌것에 유의할 것\n\n정적 클래스 변수 선언 §\narg = 123\nClass_name.arg = 456\n\n클래스 내부 최상위 인덴트에 변수를 선언해주면 클래스 변수로 선언된다\n값을 변경할때는 객체로 접근해서 변경하는게 아닌 클래스로 접근하여 변경해야 한다\n클래스가 아닌 객체에서 값을 변경하면 정적인 특성을 잃는다는 것에 유의할 것\n\n오버라이딩 §\ndef parent_method(self, arg1, arg2, ... ) :\n\n따로 @override 같은거 할 필요 없이 부모클래스의 메소드를 그대로 가져와서 구현만 새로 해주면 된다\n"},"originals/jumptopython.books.wikidocs.net/14.-파일입출력":{"title":"14. 파일입출력","links":[],"tags":[],"content":"\n\n                  \n                  위키북스 박응용 저 &quot;점프 투 파이썬&quot; 책을 읽고 정리한 내용입니다. \n                  \n                \n\n\n\n                  \n                  다소 잘못된 내용과 구어적 표현 이 포함되어 있을 수 있습니다. \n                  \n                \n\n파일 열기 §\nfile_object = open(&quot;./file.txt&quot;, &#039;r&#039;)\nfile_object = open(&quot;./file.txt&quot;, &#039;w&#039;)\nfile_object = open(&quot;./file.txt&quot;, &#039;a&#039;)\n\nopen 함수는 인자로 받은 경로에의 파일을 열어서 파일객체로 반환한다\n’r’ 은 읽기 전용, ’w’ 는 파일 새로 만들기(+기존파일 덮어쓰기), ’a’ 는 파일 맨마지막줄에서부터 내용 추가하기\n\n파일 닫기 §\nfile_object.close()\n\n메모리 최적화와 오류 방지를 위해 안쓰는 파일은 꼭 닫아줘야 한다\n\n열고닫는걸 한번에 §\nwith open(&quot;./file.txt&quot;, &#039;r&#039;) as file_object :\n\t# ...\n\n콜론(:)과 인덴트를 이용해 인덴트를 벗어나면 자동으로 파일이 닫히게 된다\n파일을 잠깐 사용할때 사용하면 좋다\n\n파일 쓰기 §\nfile_object.write(&quot;abcdef&quot;)\n\n열어놓은 파일에 “abcdef” 를 읽기방식에 의거하여 추가한다\n\n파일 읽어오기 §\nfile_object.readline()\nfile_object.readlines()\nfile_object.read()\n\nreadline() : 파일의 한 줄을 읽어온다. 호출할때마다 다음줄을 읽어오는 구조이다\nreadlines() : 파일의 한줄한줄을 리스트로 만들어 반환한다. 인덱스로 각 줄에 접근할 수 있다\nread() : 파일 전체를 하나의 문자열로 반환한다\n"},"originals/jumptopython.books.wikidocs.net/15.-예외처리":{"title":"15. 예외처리","links":[],"tags":[],"content":"\n\n                  \n                  위키북스 박응용 저 &quot;점프 투 파이썬&quot; 책을 읽고 정리한 내용입니다. \n                  \n                \n\n\n\n                  \n                  다소 잘못된 내용과 구어적 표현 이 포함되어 있을 수 있습니다. \n                  \n                \n\n기본구조 §\ntry :\n\t# code ...\nexcept ErrorClass1, ErrorClass2, ... :\n\t# action ...\n\ntry문을 우선 실행하고 에러가 날 경우 해당 에러의 except문이 실행된다\ntry 이후 code에 에러의 가능성이 있는 내용을 넣는다\nexcept 이후의 ErrorClass는 에러클래스이다. 해당 에러클래스에 대한 대응을 action에 적으면 된다\n에러클래스를 여러개 명시하면 적어준 여러개의 에러에 대해 동일하게 대응할 수 있다\n에러클래스를 안적으면 모든 에러에 대해 단일한 대응을 할 수 있다\nexcept문을 에러마다 적어서 에러마다 다른 대응을 하는것도 가능하다\n대응하기 싫으면 pass를 이용하자\n에러클래스는 암거나 적어도 되는게 아니다. 파이썬에서 제공하는 에러클래스를 이용하던가, 에러클래스를 만들어야 가능하다\n\n기본제공하는 몇가지 오류클래스 §\n\nIndexError : 리스트/튜플 등에서 존재하지 않는 인덱스를 접근했을때\nZeroDivisionError : 0으로 나눴을 때\nFileNotFoundError : 존재하지 않는 파일을 open() 하려 할때\nKeyError : 존재하지 않는 딕셔너리의 키에 접근하려 할 때\n\n오류 메세지 가져오기 §\nexcept ErrorClass as a :\n\tprint(a)\n\n에러가 발생할 경우 화면에 출력하기 좋은 에러 메세지를 문자열 형태로 기본 제공한다. 이것을 as a 로 변수 a 에 받아서 출력할 수 있다\n에러를 잡는다고 무조건 화면에 에러메세지가 뜨지는 않는다. 화면에 에러메세지를 띄우려면 print() 로 원하는 문구를 출력해야 한다\n\n오류가 발생하든말든 반드시 실행시키기 §\nfinally :\n\t# code ...\n\nfinally 문의 내용은 에러가 발생하든 말든 무조건 실행된다\n대표적으로 파일닫기에 주로 사용된다. 에러가 나도 열어놓은 파일은 반드시 닫아야 되기 때문에 finally 문에 close() 를 넣어놓으면 에러가 나더라도 파일을 안전하게 닫을 수 있다\n\n에러 일부러 발생시키기 §\nraise ErrorClass\n\n오류를 일부러 발생시켜야 할 때도 있다. 다음은 그 용례이다\n\n자식클래스가 반드시 오버라이딩했으면 하는 메소드가 부모클래스에 있다고 하자\n이럴때 부모클래스의 메소드에 오류를 발생시키면 자식클래스는 이것을 오버라이딩하지 않으면 오류가 나므로 무조건 오버라이딩할 수 밖에 없다\n\n\n\n나만의 오류 만들기 §\nclass ErrorName(Exception) :\n\tpass\n\nException 클래스를 상속받아 클래스를 만들면 나만의 에러클래스를 만들 수 있다\n에러클래스로 선언돼있지도 않고 기본제공하는 에러클래스도 아닌경우에는 except문에 사용할 수 없다\n\n예외처리문의 필요성 §\n\n예외처리를 if문으로 할 수도 있다. 어차피 try-except문도 조건문처럼 작동하기 때문이다.\n하지만 조건문을 사용했을 때 같은 오류가 여러군데에서 발생하면 그 부분마다 조건문을 달아줘야하기 때문에 코드가 길고 복잡해진다\ntry-except문을 이용하면 이런 오류들을 한꺼번에 처리할 수 있으므로 훨씬 간편하다는 이점 이 있다\n"},"originals/jumptopython.books.wikidocs.net/16.-모듈":{"title":"16. 모듈","links":[],"tags":[],"content":"\n\n                  \n                  위키북스 박응용 저 &quot;점프 투 파이썬&quot; 책을 읽고 정리한 내용입니다. \n                  \n                \n\n\n\n                  \n                  다소 잘못된 내용과 구어적 표현 이 포함되어 있을 수 있습니다. \n                  \n                \n\n모듈이란 §\n\n원하는 기능이 다른 파이썬 파일에 구현되어 있다면, 그 파일을 가져와서 내 파일에서 동작하도록 할 수 있다. 이때의 가져온 파이썬 파일을 모듈이라고 한다\n따라서 모든 파이썬 파일은 그 자체로 실행될수도 있지만 다른 파일에 사용될 수도 있다. 그 자체로 실행될때 메인으로 실행됐다고 하고 다른 파일에 사용되면 모듈로 사용됐다고 한다\n\n모듈 가져오기 §\nimport A.B # 전부 다 가져오기\nA.B.C() # 사용할때\nfrom A.B import C # 일부만 객체만 가져오기\nC() # 사용할때\nfrom A import B # 일부 모듈만 가져오기\nB.C() # 사용할때\n\n디렉토리 A 에 모듈 B 가 있고 함수 C() 를 사용하려 할때의 모듈 가져오는 방법, 사용법 이다\n그냥 import 의 경우 경로의 최종점은 모듈이어야 한다\n파이썬 파일이 위치한 디렉토리의 하위 디렉토리의 모듈만 접근할 수 있다\n\n외부 디렉토리의 모듈 가져오기 §\nsys.path.append(경로) # 파이썬 파일에서\nPYTHONPATH=경로 # 터미널에서\n\n모듈이 현재 디렉토리의 하위 디렉토리에 위치해있지 않을 때 경로를 추가해주는 작업이다\nsys.path : 모듈을 검색할 경로들이 들어있는 리스트. append() 를 통해 추가 가능하다\nPYTHONPATH : 터미널에서 환경변수로 sys.path 에 경로를 추가시켜줄 수 있는 기능이다\n위의 방법으로 경로설정을 하지 않고 외부 디렉토리의 모듈을 가져오면 모듈을 찾지 못하고 에러가 난다\n\n상대경로 §\n\n현재 디렉토리 : ./\n부모 디렉토리 : ../\n파이썬 파일이 위치한 디렉토리가 부모 디렉토리가 아니라 현재 디렉토리라는 것에 주의\n\n닉네임 이용하기 §\nimport A.B.C.D as E :\n\n경로가 길고 복잡할때 as 로 닉네임을 붙여주면 경로 대신 사용할 수 있다\n\n모듈과 메인 분리하기 §\nif __name__ == __main__ :\n\t# ...\n\n모듈의 내부에 메인으로 실행됐을 경우에만 동작하길 원하는 부분이 있으면 이 조건문 아래 적어주면 된다\n__name__ : 해당 파일의 실행 모드를 담는 변수. 메인으로 실행되면 __main__ 이 저장되고 모듈로 실행되면 모듈명이 들어간다\n"},"originals/jumptopython.books.wikidocs.net/17.-패키지":{"title":"17. 패키지","links":[],"tags":[],"content":"\n\n                  \n                  위키북스 박응용 저 &quot;점프 투 파이썬&quot; 책을 읽고 정리한 내용입니다. \n                  \n                \n\n\n\n                  \n                  다소 잘못된 내용과 구어적 표현 이 포함되어 있을 수 있습니다. \n                  \n                \n\n패키지의 필요성 §\n\n프로젝트가 커지면 코드가 길어지게 되는데 이때 가독성이 안좋아지기 때문에 기능별로 모듈로 쪼개 는 것이 좋다\n이 모듈들을 폴더별로 정리 하면 깔끔하고 헷갈리지 않게 프로젝트를 관리할 수 있는데 이 폴더 계층 구조를 패키지라고 한다\n\n패키지 만들기 §\n\n파일들을 폴더로 정리해준 다음 폴더마다 __init__.py 파일을 추가\n\n__init__.py파일은 파이썬3부터는 필요없지만 호환성을 위해 넣어주자\n\n\n폴더의 최상단에 main.py 를 만들어주고 import 로 필요한 모듈을 가져다쓰면 된다\n\nmain.py 는 메인으로 프로그램이 돌아갈 파일이며 관례적으로 main 이라고 이름지어준다\nmain.py 파일이 최상단에 있지 않은 경우 다른 디렉토리의 모듈을 사용할때는 경로설정을 꼭 해줘야 한다\n\n\n\n__init__.py 파일의 __all__ 리스트 §\n__all__ = [&quot;module1.py&quot;, &quot;module2.py&quot;, ... ]\n\nfrom-import *로 디렉토리의 모듈들을 한꺼번에 가져올 수 있는데 이때 __init__.py의 __all__ 리스트에 포함된 모듈만 가져온다\n__all__ 을 작성하지 않고 from-import *을 하면 오류가 난다\n"},"originals/jumptopython.books.wikidocs.net/18.-내장함수-정리":{"title":"18. 내장함수 정리","links":[],"tags":[],"content":"\n\n                  \n                  위키북스 박응용 저 &quot;점프 투 파이썬&quot; 책을 읽고 정리한 내용입니다. \n                  \n                \n\n\n\n                  \n                  다소 잘못된 내용과 구어적 표현 이 포함되어 있을 수 있습니다. \n                  \n                \n\n절대값 §\nabs(-3) == 3\n반복가능한객체의 요소들이 전부 참인지 §\nall([1, 2, 3]) == True\nall([0, 1, 2]) == False\n반복가능한객체의 요소들이 하나라도 참인지 §\nany([0, 0, 3]) == True\nany([0, 0, 0]) == False\n아스키코드 -&gt; 문자 §\nchr(97) == &#039;a&#039;\n(몫, 나머지)튜플 반환 §\ndivmod(7, 3) == (2, 1)\n실행가능한 문자열 실행하기 §\neval(&quot;abs(-3)&quot;) == 3\n함수객체를 받아 반복가능객체의 요소를 넣어 참인것만 걸러내기 §\nfilter(_func, _iterable)\n\nfilter 라는 반복 가능한 객체로 반환된다\n\n정수 -&gt; 16진수 §\nhex(234) == 0xea\n객체의 주소 알아내기 §\nid(object)\n비정수의 정수화 §\nint(&#039;3&#039;) == 3\nint(3.4) == 3\n인스턴스관계 여부 §\ninstance(_object, _Class)\n반복가능객체의 요소들을 후처리해 새로 묶기 §\nmap(_func, _iterable)\n\nmap 이라는 반복가능객체로 반환된다\nfilter 와의 차이점은 filter 는 참인값만 걸러내지만 map 은 거르지 않고 함수실행결과를 그대로 담는다\n\n정수 -&gt; 8진수 §\noct(34) == 0o42\n문자 -&gt; 아스키코드 §\nord(&#039;a&#039;) == 97\nx의 y승 §\npow(x, y)\n반올림 §\nround(3.5) == 4\nround(1.2345, 2) == 1.23\n비문자열의 문자열화 §\nstr(3) == &#039;3&#039;\n반복가능객체의 요소 합 §\nsum([1, 2, 3]) == 6\n자료형 알고싶다 §\ntype(object)\n같은인덱스끼리 묶기 §\nlist(zip([1, 2], [3, 4])) == [(1, 3), (2, 4)]\n\n리스트 뿐 아니라 튜플, 문자열도 된다\n당연히 두 인자의 길이는 같아야 한다\n"},"originals/jumptopython.books.wikidocs.net/19.-내장라이브러리-정리":{"title":"19. 내장라이브러리 정리","links":[],"tags":[],"content":"\n\n                  \n                  위키북스 박응용 저 &quot;점프 투 파이썬&quot; 책을 읽고 정리한 내용입니다. \n                  \n                \n\n\n\n                  \n                  다소 잘못된 내용과 구어적 표현 이 포함되어 있을 수 있습니다. \n                  \n                \n\n프로그램 강제종료 §\nsys.exit()\n파일에 객체 그대로 담기 §\npickle.dump(_object, _file_object)\npickle.load(_file_object)\n\ndump() : 객체를 파일에 저장\nload() : 파일에 있는 객체 갖고오기\n\n현재 디렉토리 조회/변경하기 §\nos.getcwd()\nos.chdir(&quot;new_path&quot;)\n\ngetcwd() : 현재 디렉토리 조회\nchdir() : 현재 디렉토리 변경\n\n시스템 명령어 실행하기 §\nos.system(&quot;command&quot;)\nos.popen(&quot;command&quot;)\n\nsystem() : 명령어를 실행. 반환값은 없다\npopen() : 명령어를 실행하고 결과를 읽기전용 파일객체로 반환받음\n\n디렉토리 생성/삭제 §\nos.mkdir(&quot;directory&quot;)\nos.rmdir(&quot;directory&quot;)\n\nmkdir() : 디렉토리 생성\nrmdir() : 디렉토리 삭제\n\n파일 삭제/이름바꾸기 §\nos.unlink(&quot;file&quot;)\nos.rename(old, new)\n\nunlink() : 파일 삭제\nrename() : 이름바꾸기\n\n파일 복사하기 §\nshutil.copy(&quot;old.txt&quot;, &quot;new.txt&quot;)\nshutil.copy(&quot;old.txt&quot;, &quot;new&quot;)\n\nold.txt의 내용을 new.txt에 그대로 복사해넣는다.\n만약 new가 디렉토리 이름이면 해당 디렉토리에 복사하고 동일한 이름의 파일이 있으면 덮어쓰기한다\n\n디렉토리 안의 파일/폴더 목록 §\nglob.glob(&quot;path&quot;)\n\n디렉토리 안의 파일/폴더 목록을 리스트로 반환한다\n정규식을 써서 원하는 놈만 조회할 수도 있다\n\n임시 파일 §\ntempfile.mkstemp()\ntempfile.TemporaryFile()\n\nmkstemp() : 임시파일의 이름으로 쓸 수 있는 문자열을 반환한다\nTemporaryFile() : 임시파일의 파일객체를 만들어서 반환한다\n\n웹페이지 열기 §\nwebbrowser.open(&quot;web&quot;)\nwebbrowser.open_new(&quot;web&quot;)\n\nopen() : 이미 브라우져가 열려있으면 새 탭으로 띄워주고 안열려있으면 새 창으로 띄워준다\nopen_new() : 브라우져가 열려있든 말든 새 창으로 띄워준다\n"},"originals/jumptopython.books.wikidocs.net/20.-클린코드-가이드":{"title":"20. 클린코드 가이드","links":[],"tags":[],"content":"\n\n                  \n                  위키북스 박응용 저 &quot;점프 투 파이썬&quot; 책을 읽고 정리한 내용입니다. \n                  \n                \n\n\n\n                  \n                  다소 잘못된 내용과 구어적 표현 이 포함되어 있을 수 있습니다. \n                  \n                \n\nDOCSTRING 적기 §\n&quot;&quot;&quot;함수설명\nArgs:\n\t변수1(자료형):설명\n\t변수2(자료형):설명\n \nReturns:\n\t자료형: 반환값 설명\n&quot;&quot;&quot;\n\n함수/메소드를 작성할때는 매개변수와 리턴값, 그리고 기능을 설명하는 주석인 DOCSTRING 을 적어주는게 좋다\n\nPEP8/구글 파이썬 스타일 가이드 정리 §\n\n함수에 필요한 변수를 초기화할때 가변객체말고 불변객체 를 사용해라\n\n예를들어 매개변수로 리스트를 받으려고 할때 a=[] 이렇게 주지 말고 a=None 이렇게 주는것이 안전하다\n함수가 동작하는 중에 저 변수를 사용하면 기본값이 변경되기 때문\n솔직히 뭔말인지 잘 모르겠다\n\n\n불리언 연산식을 적을때는 암시적인 표현법 을 사용하는 것이 더 안전하고 가독성이 높다\n\n리스트가 비어있다는걸 len(리스트) == 0 으로 표현하는것보다는 not 리스트 이렇게 표현한다\n리스트가 비면 당연히 False 값을 갖는데 굳이 길이가 0이라고 명시적으로 적어주면 가독성이 떨어진다 이말이다\n\n\n특정대상(예를들면 정수)이랑 비교하는 불리언 연산식의 경우 비교대상이랑 직접적으로 비교하는 연산식 으로 적어주는게 좋다\n\n변수 is not None and not 변수 이렇게 적지 말고 변수 == 0 이렇게 직접 적어주는 것이 좋다\n마찬가지로 not 변수 % 2 이렇게 말고 변수 % 2 != 0 이게 직접비교가 더 좋다더라\n\n\n한 문장의 길이는 80자를 넘지 않도록 해야된다\n\n모니터를 큰거를 써도 한문장이 80자를 넘어가게 되면 가독성이 떨어지더라\n\n\n"},"originals/jumptopython.books.wikidocs.net/21.-정규표현식-이용":{"title":"21. 정규표현식 이용","links":[],"tags":[],"content":"\n\n                  \n                  위키북스 박응용 저 &quot;점프 투 파이썬&quot; 책을 읽고 정리한 내용입니다. \n                  \n                \n\n\n\n                  \n                  다소 잘못된 내용과 구어적 표현 이 포함되어 있을 수 있습니다. \n                  \n                \n\n정규식 컴파일 §\nptrn = re.compile(&quot;정규식&quot;)\n\nre 모듈의 compile() 메소드는 정규식을 컴파일해 패턴객체로 반환한다\n당연히 import re 로 모듈을 가져와야 한다\n\n매칭된부분 문자열 리스트로 받기 §\nstr_list = ptrn.findall(&quot;문자열&quot;)\n\n문자열을 정규식으로 조사해 매칭되는 모든 부분을 문자열 리스트로 반환한다\n\n컴파일 옵션 §\nre.compile(&quot;정규식&quot;, 옵션)\n\n정규식 뒤에 컴파일 옵션을 같이 넣어줄 수 있다\n\nre.DOTALL, re.S : .기호가 대체할 수 있도록 한다\nre.IGNORECASE, re.I : 대소문자를 구분하지 않는다\nre.MULTILINE, re.M : match()나 ^는 문자열의 맨 앞을 조사하는데, 이 옵션을 넣으면 줄 바꿈한 부분도 조사한다\nre.VERBOSE. re.X : 정규식에 whitespace와 주석을 달 수 있게 해준다.\n\n정규식이 길어지면 읽기가 힘든데, 이때 re.VERBOSE 옵션을 주어 주석으로 설명을 달면 훨씬 보기 편하다\n\n\n\n\n\n매칭된부분 문자열 바꾸기 §\nstr = ptrn.sub(&quot;replace&quot;, &quot;target&quot;)\nstr = ptrn.sub(&quot;replace&quot;, &quot;target&quot;, count = 1)\nstr = ptrn.sub(func_object, &quot;target&quot;)\n\n“target”을 패턴으로 조사해 매칭되는 모든 부분을 “replace”로 바꿔치기하여 문자열로 반환한다\n생략가능한 매개변수 count를 설정하면 바꾸는 횟수를 정할 수 있다.\n\ncount = 1이면 제일 먼저 매칭된 부분만 바꾸고, count = 2이면 첫번째와 두번째로 매칭된 부분을 바꾸는 식이다\n\n\n“replace”대신 함수각체를 넣을 수도 있다. 그럼 매칭된 부분이 함수 처리 결과로 바뀌게 된다\nsub대신 subn을 이용하면 (“결과 문자열”, 바꾼 횟수:int) 이렇게 튜플로 반환한다\n\nsub 메소드 참조구문 §\n\nsub의 “replace”에 사용하면 그룹을 참조할 수 있다\n\nptrn = re.compile(&quot;(?P\\w+)\\s+(?P\\w+)&quot;)\nptrn.sub(&quot;\\g \\g&quot;, &quot;abc def&quot;)\n\n이렇게 해주면 “def abc”가 반환된다\n\n패턴객체 -&gt; 매치객체 §\nmtch = ptrn.match(&quot;문자열&quot;)\nmtch = ptrn.search(&quot;문자열&quot;)\nmtch_gen = ptrn.finditer(&quot;문자열&quot;)\n\n패턴으로 문자열을 조사해 매칭되는부분을 매치객체로 반환한다\nmatch() : 문자열의 맨 앞만 조사해 매치된다면 반환한다\nsearch() : 문자열 전체를 조사해 제일 먼저 매칭되는 놈을 반환한다\nfinditer() : 문자열 전체를 조사해 매칭되는 모든놈을 매치객체 제네레이터로 반환한다\n\n컴파일 안하고 패턴객체 메소드 사용하기 §\nre.ptrn_method(&quot;정규식&quot;, &quot;문자열&quot;)\n\n저렇게 re모듈에서 패턴객체 안거치고 match, search같은 패턴객체의 메소드를 사용할 수 있다\n여러번 사용할 정규식이라면 패턴객체를 만들어놓고 사용하는게 편리하지만 한번만 사용할 정규식이라면 re모듈선에서 바로 처리해 주는 것이 깔끔하다\n\n매칭된놈 매치객체에서 문자열로 받기 §\nmtch.group()\nmtch.group(숫자)\n\n인자를 안넣거나 0을 넣으면 매치된놈을 문자열로 반환한다\n숫자를 인자로 넣으면 그 숫자에 해당하는 번째의 그룹을 문자열로 반환한\n\n매칭된 부분 인덱스 매치객체에서 가져오기 §\nmtch.start()\nmtch.end()\nmtch.span()\n\nstart() : 매칭된부분 첫 인덱스를 반환한다\nend() : 매칭된부분 끝 인덱스+1를 반환한다\nspan() : 매칭된부분 (첫 인덱스, 끝 인덱스+1) 를 튜플로 반환한다\n\n백슬레시 (\\) 매칭법 §\n\n파이썬은 \\ 를 자동으로 변환한다. 따라서 메타기호가 아닌 문자로써의 매칭하기 위해 정규식에 \\ 이렇게 써봤자 바뀌어서 메타기호로 인식하게 된다\n그렇다고 \\ 를 표현하기 위해 \\\\\\\\이렇게 4개를 쓸 수도 없는 일이다. 이때 Raw String 이라는 것을 이용한다\n문자열 앞에 r 을 붙여주면 Raw String이 된다. r“\\”를 쓰면 얘가 하나로 자동변환하지 않고 그냥 냅두기 때문에 문자로써의 \\ 을 사용할 수 있다\n"},"originals/jumptopython.books.wikidocs.net/부록---정규표현식":{"title":"부록 - 정규표현식","links":[],"tags":[],"content":"\n\n                  \n                  위키북스 박응용 저 &quot;점프 투 파이썬&quot; 책을 읽고 정리한 내용입니다. \n                  \n                \n\n\n\n                  \n                  다소 잘못된 내용과 구어적 표현 이 포함되어 있을 수 있습니다. \n                  \n                \n\n문자 클래스 §\n\n[abc] : a, b, c중 하나라도 있으면 매치\n[a-e] : a부터 e까지(a, b, c, d, e)중 하나라도 있으면 매치(from-to)\n[^abc] : a, b, c중 하나라도 있으면 매치되지 않음(not)\n어떤 메타기호던지 ^와 -를 제외하면 []안에 검색조건으로 넣을 수 있다\n[] : 특정 문자를 찾거나 특정 문자를 배제할 때 주로 사용된다\n\n\\ 정규식 §\n\n여기 있는것들은 대문자로 쓰면 not 의 의미가 된다\n\\d : digit = 숫자와 매치. [0-9]와 같음\n\\s : space = 스페이스처럼 눈에 안보이는 문자들과 매치\n\\w : word = 숫자/알파벳과 매치\n\\b : 단어경계(알파벳과 숫자가 아닌 부분)을 조사함\n\n\\babc : abc로 시작하는 단어를 매칭\n\n\n\n\\ 정규식 (심화) §\n\n\\A : re.MULTILINE 와 상관없이 문자열의 맨 처음만 조사함\n\n\\Aabc : 문자열이 abc 로 시작하면 매칭\n\n\n\\Z : re.MULTILINE 와 상관없이 문자열의 맨 끝만 조사함\n\nabc\\Z : 문자열이 abc 로 끝나면 매칭\n\n\n\\W 는 숫자,알파벳이 아닌 부분을 찾아 매치해 소비하고 결과로 반환하지만 \\b 는 그 부분을 조사할 뿐 숫자,알파벳이 아닌 부분을 소비해 결과로 반환하지는 않는다\n\\A, \\Z 도 마찬가지로 조사에는 반영되지만 소비되어 결과로 반환되지는 않는다\n\\A와 ^, \\Z와 $ 의 차이점은 re.MULTILINE 의 영향을 받냐 안받냐 이다. ^와 $의 경우 옵션을 주면 줄마다 처음이나 끝을 조사하지만, \\A와 \\Z는 옵션을 줘도 문자열의 맨 처음/끝만 조사한다\n\n문자열의 맨 처음과 끝 조사하기 §\n\n^ : 문자열의 맨 처음을 조사함. re.MULTILINE 옵션을 주면 줄바꿈된 모든 줄의 시작점을 조사한다\n\n^abc : 문자열이 abc 로 시작하면 매칭\n\n\n$ : 문자열의 맨 끝을 조사함. re.MULTILINE 옵션을 주면 줄바꿈된 모든 줄의 끝점을 조사한다\n\nabc$ : 문자열이 abc로 끝나면 매칭\n\n\n\nDOT 메타기호 §\n\n.: 모든 문자와 매칭\n\na.b: acb, adb, a b 등 a와 b사이에 \\n이 아닌 어떠한 문자가 와도 매칭된다\n\\n도 넣고싶다면 컴파일 옵션으로 re.DOTALL 을 넣으면 된다\n\n\n\n반복 §\n\nab*c : ac, abc, abbc 등 b가 0번 이상 반복되면 매치\nab+c : abc, abbc, abbbc등 b가 1번이상 반복되면 매치\nab{2,4}c : abbc, abbbc, abbbbc처럼 b가 2~4번 반복되면 매치\nab?c : ac, abc처럼 b가 0번이나 1번 등장하면 매치\n{,}처럼 인자를 생략할 수도 있다. 앞을 생략하면 0, 뒤를 생략하면 무한대이다\n\nOR연산 §\n\nabc|def: abc나 def가 등장하는 부분과 매치\n\n그루핑 §\n\n(abc): 그루핑 - 여러 정규식들을 소괄호로 묶는 것\n(abc)+ : abcabcabc같이 abc가 반복되는 부분을 매치\n\n그룹 인덱스 §\n(그룹1)(그룹2(그룹3))\n\n\n왼쪽에서 오른쪽으로, 밖에서 안으로 그룹 인덱스가 매겨진다\n\n([a-z]+)\\s+(\\w+)에서\n\n([a-z]+) : 1번 그룹\n(\\w+) : 2번 그룹\n\n\n\n\n매치객체의 group() 매소드에 인자로 그룹 번호를 넣어주면 해당하는 그룹에 매치된 결과만 소비할 수 있다\n\n그룹 재참조 §\n\n\\숫자: “숫자”에 해당하는 번째의 그룹을 재참조한다\n\n&quot;abc def ghi ghi&quot;를 &quot;(\\w+)\\s+\\1&quot; 정규식으로 매치해보면 &quot;ghi ghi&quot;가 매치된다.\n즉, 어떤 그룹에 매치된 문자열과 동일한 문자열이 또 등장하면 그룹 재참조로 매치할 수 있다\n\n\n\n그룹 네이밍 §\n\n(?P정규식) 을 통해 그룹을 인덱스로 접근하지 않고 키를 통해 접근할 수도 있다\n이때에는 group(&quot;그룹명&quot;) 이렇게 메소드의 인자로 키를 넣어주면 된다\n재참조할때는 (?P=그룹명) 이렇게 해주면 된다\n\n전방 긍정/부정 탐색 §\n\n(?=정규식) : 정규식과 부합하는 부분을 검거\n(?!정규식) : 정규식과 부합하지 않는 부분을 검거\n전방 긍정/부정 탐색의 경우 기본적으로 소비되지 않는다. 즉, 검색조건에는 들어가지만 검색결과에 안나오고 다음검색시 제외되지도 않는다는 말이다\n\n헷갈리지 말자 §\n\n^\n\n^정규식 :문자열의 맨 처음부터 조사\n[^문자] : 해당 문자가 없는지 조사\n\n\n?\n\nab? : b가 0번이나 1번 등장하는지 조사\n(?) : 그루핑 확장기호/전방탐색\nab*? : non-greedy로 작동하게 함\n\n\n\nGreedy 한 메타기호란? §\n\n어떤 메타기호가 Greedy하다는 것은 이놈이 최대한 많은 문자들을 소비하려고 한다는 것 이다\nGreedy한 메타기호는 *와 +가 있다.\n\n정규식 &quot;a.*c&quot;을 &quot;abcabcabc&quot;의 문자열에 대입하면 &quot;abc&quot;도 있지만 제일 많은양을 소비할 수 있는 &quot;abcabcabc&quot; 를 소비하게 된다\n\n\n이것을 막으려면 * 와 +뒤에 ?를 붙여주는 것이다. 이것을 붙여주면 최대소비가 아닌 최소소비가 되어 제일 적은양을 소비하는 선택지를 검거 할 것이다\n\n위의 정규식을 &quot;a.*?c&quot;로 바꿔주면 &quot;abcabcabc&quot;의 문자열에 대입했을 때 &quot;abc&quot;가 매치되게 된다\n\n\n\n매칭? 소비? §\n\n매칭 : 문자열의 특정 부분이 정규식의 조건에 부합하여 검거 하는 것\n소비 : 문자열의 특정 부분이 매칭되면 그부분은 없다고 생각하고 다음 매치를 찾는다\n\n예를들어 “abcdef”중에서 조건에 부합하여 검거의 대상이 되는 곳이 abc와 bcd라고 해보자\n그러면 먼저 abc를 먼저 매칭할 것이다\n그다음에 다시 매치를 시도해보면 bcd가 매치될거라고 생각하겠지만 bcd는 매치되지 않는다\n왜냐하면 이미 abc가 매치되어서 소비되었기 때문에 남은 def중에서 조건에 부합하는 부분이 있는지 검토하게 되는 것이다\n\n\n"},"originals/kubernetes.jan.2023.si-analytics.ai/01.-쿠버네티스와-친해지기":{"title":"01. 쿠버네티스와 친해지기","links":[],"tags":[],"content":"Kubernetes 맛보기 §\n\n처음부터 쿠버네티스의 구조 및 작동원리 등을 배우는 것은 쿠버네티스를 처음에 배우는 사람에게는 자칫 지루해질 수도 있고 클러스터 관리자가 아닌 사용자 입장에서는 불필요할 수도 있다… 먼저 쿠버네티스에 등장하는 핵심 개념부터 몇개 살펴보자.\n\n스토리텔링: NGINX 가 돌아가는 홈서버를 구축해보자. §\n\nA씨는 설 명절에 집에서 할 것이 없어 간단하게 NGINX 가 돌아가는 홈서버를 구축보려 한다. 먼저 A씨는 감자마켓에서 서버로 사용할 컴퓨터를 하나 구입하고, 거기에 NGINX 를 설치한다.\n\n\n\n설치를 완료한 후 localhost 로 접속해보니 잘 작동한다. 하지만 A씨는 조금 더 욕심을 내어 자신의 사이트를 외부에서도 접속이 되게 하고 싶다. 이를 위해 라우터를 설치하고 외부 접속을 위한 설정을 한다.\n\n\n\nA씨가 자신의 홈서버를 주변에 열심히 소문낸 결과, 접속자 수가 폭증하기 시작했다. A씨는 이에 대응하기 위해 동일한 서버를 한대 더 구비해 부하를 분산하고자 한다. 하지만 시간이 부족한 A씨는 친구 B씨를 데려와 서버 관리를 부탁한다. B씨는 한대가 고장나면 곧바로 다른 서버를 설치하는 등 항상 두개의 서버가 작동하고 있게 노력한다.\n\n\n\n서버들을 사용하던 중, A씨는 서버들의 데이터를 외부에 보관하면 좋겠다는 생각을 하게 된다. 따라서 A씨는 외부 스토리지서버를 한대 구입한 후, 각 서버들이 사용할 수 있게 설정하였다.\n\n\n위의 이야기를 그대로 쿠버네티스로… §\n\n\nPod: 파드는 A씨가 설치한 서버에 비유될 수 있는 개념으로, 쿠버네티스에서 가장 작은 컴퓨팅 유닛 오브젝트이다.\n\n서버에 여러개의 프로세스가 돌아갈 수 있는 것처럼, 파드에도 여러개의 프로세스가 작동할 수 있으며 이때 프로세스들은 컨테이너 형태로 구성된다.\n\n\nService: 파드를 클러스터 내외부에 노출시켜 네트워크를 통해 접근할 수 있게 하는 오브젝트이다.\nDeployment: 파드를 관리하는 관리자로 비유될 수 있는 개념으로, 지정해준 개수의 파드가 항상 작동할 수 있도록 보장해주는 역할을 한다.\n\n엄밀히 말하면, 파드의 개수를 일정하게 유지시키는 것은 ReplicaSet 의 역할로, Deployment 는 ReplicaSet 를 관리하며 롤링 업데이트 등의 추가적인 기능을 제공한다.\n즉, Pod -&gt; ReplicaSet -&gt; Deployment 로 소속관계를 표현할 수 있다.\n\n\nVolume: 파드의 컨테이너가 사용할 수 있는 볼륨이다.\n\nNGINX 배포 실습 §\n\nVolume 관련 부분은 실습이 어렵기 때문에 일단은 제외하였습니다.\n\nPod 생성하기 §\n\n파드 생성\n\nkubectl run nginx --image=nginx:stable\n\n생성된 파드 확인\n\nkubectl get pod nginx\nNAME    READY   STATUS    RESTARTS   AGE\nnginx   1/1     Running   0          7m26s\n\nDeployment 생성하기 §\n\n하지만, 파드를 단독으로 생성하는 경우는 거의 없고, Deployment 등의 다른 오브젝트를 생성하여 파드가 생성되도록 하는 것이 일반적이다.\n디플로이먼트 생성하기\n\nkubectl create deployment nginx --image nginx:stable\n\n생성된 디플로이먼트 확인\n\nkubectl get deployment nginx\nNAME    READY   UP-TO-DATE   AVAILABLE   AGE\nnginx   1/1     1            1           3m42s\n\n\n디플로이먼트의 가장 중요한 역할은 파드를 여러개로 복제하고 항상 일정한 개수가 유지되도록 하는 것이다. 다음의 명령어를 통해 파드의 개수를 증가시켜보자.\n\nkubectl scale deployment nginx --replicas 3\n\n디플로이먼트 확인\n\nkubectl get deployment nginx\nNAME    READY   UP-TO-DATE   AVAILABLE   AGE\nnginx   3/3     3            3           5m21s\n\nService 생성하기 §\n\n본 실습에서는 LoadBalancer 타입의 서비스를 생성하는데, 이에 대한 자세한 내용은 이후에 배운다.\n\n\n다음의 명령어를 통해 Service 를 생성할 수 있다.\n\nkubectl expose deployment nginx --type LoadBalancer --name nginx --port 80\n\n생성된 Service 확인\n\nkubectl get service nginx\nNAME    TYPE           CLUSTER-IP       EXTERNAL-IP   PORT(S)        AGE\nnginx   LoadBalancer   10.103.178.141   localhost     80:32560/TCP   53s\n\n\n브라우저를 통해 localhost 로 접속해보면 다음과 같은 화면을 볼 수 있다.\n\n\n리소스 삭제하기 §\n\n이후의 실습을 위해 생성했던 리소스들을 삭제한다.\n생성한 리소스는 kubectl delete $RESOURCE $NAME 을 통해 삭제할 수 있다.\n\nkubectl delete pod nginx\nkubectl delete deployment nginx\nkubectl delete service nginx\nYAML 을 이용해 배포하기 §\n\nkubectl create deployment ... 등의 명령어를 통해 리소스들을 생성하는 것 이외에도, 리소스를 정의하는 YAML 파일을 통해 생성하는 것도 가능하다.\nYAML 파일을 이용할 때에는 create 혹은 apply 명령어에 -f 옵션을 이용하여 파일을 명시해 주면 된다.\n\n\n\n                  \n                  기본적으로 create 는 생성 명령어이고 apply 는 변경 명령어이나 생성에도 사용할 수 있습니다. 하지만, create 로 생성한 리소스에 apply 를 하게 되면 경고 문구가 출력되니 변경의 가능성이 적은 리소스는 create 를 사용하고 그렇지 않은 리소스는 apply 를 이용할 것을 권장합니다.\n                  \n                \n\nkubectl create -f $YAML_FILE\nkubectl apply -f $YAML_FILE\n\n그럼 이제 위에서 배포한 것을 동일하게 YAML 파일로 배포하는 것을 실습해 보자.\n\nNGINX 를 YAML 을 이용해 배포하기 §\n\n아래의 두 YAML 파일을 배포하면, 위 실습에서 생성했던 Deployment 와 Service 를 동일하게 배포할 수 있다.\n\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: nginx\nspec:\n  selector:\n    matchLabels:\n      app: nginx\n  template:\n    metadata:\n      labels:\n        app: nginx\n    spec:\n      containers:\n        - name: nginx\n          image: nginx:stable\napiVersion: v1\nkind: Service\nmetadata:\n  name: nginx\nspec:\n  ports:\n    - name: http\n      port: 80\n      protocol: TCP\n      targetPort: 80\n  selector:\n    app: nginx\n  type: LoadBalancer\nYAML 을 이용하는 이유: 리소스의 코드화 (Infrastructure as Code, IaC) §\n\nYAML 파일을 이용하면 쿠버네티스 클러스터에 생성된 리소스들을 코드로써 관리할 수 있으며, 여기에는 다음과 같은 장점이 있다.\n\n리소스 생성과 편집, 삭제가 간편해진다.\n\nYAML 파일을 이용해 리소스를 생성하고, YAML 파일을 편집해 리소스를 변경하며, YAML 파일을 이용해 리소스를 삭제할 수 있다.\n\n\ngit 과 같은 버전 관리 툴을 이용하여 변경 이력 추적을 간편하게 할 수 있다.\n\n\n코드로 관리하는 것 이외에도, YAML 파일을 이용하면 cli 툴에서 제공하지 않는 다양한 설정들이 가능하다.\n\n추가적인 Kubectl 명령어 §\nKubectl get -o 옵션 §\n\n-o wide: 기본 제공되는 정보 이외의 추가적인 정보들을 같이 출력한다.\n\nkubectl get $RESOURCE $NAME -o wide\nkubectl get deployment nginx -o wide\n\n-o yaml: 배포된 리소스의 상태를 YAML 포맷으로 조회한다.\n\nkubectl get $RESOURCE $NAME -o yaml\nkubectl get deployment nginx -o yaml\nKubectl describe 명령어 §\n\ndescribe 명령어는 배포된 리소스의 자세한 정보를 출력해준다.\n\nkubectl describe $RESOURCE $NAME\nkubectl describe deployment nginx"},"originals/kubernetes.jan.2023.si-analytics.ai/02.-기본-개념":{"title":"02. 기본 개념","links":[],"tags":[],"content":"Kubernetes 등장 배경 §\n배포 환경의 변천사 §\n\n\n출처: https://kubernetes.io/docs/concepts/overview/\n\n\n기존의 배포환경: 물리 서버 한대에 여러 App 들을 설치하여 배포하였다.\n\n한계점: 각 App 들을 격리시키지 못해 하나의 App 이 너무나 많은 리소스를 점유하는 등의 문제가 발생한다.\n\n\n가상화 배포환경: 물리서버 한대에 여러 가상머신 (Virtual Machine, VM) 을 생성해 각 App 들을 격리시켰다.\n\n한계점: 가상머신은 가상화를 위한 Hypervisor 가 필요하고 가상머신 내에도 OS 가 설치되기에 다소 무겁고 리소스 사용량이 많다는 문제가 있다.\n\n\n컨테이너 배포환경: 물리서버 한대에 여러 컨테이너를 생성해 각 App 들을 격리시켰다.\n\n컨테이너는 호스트 머신과 커널을 공유하기 때문에, 추가적인 OS 가 필요 없어 가상화 배포환경보다 가벼운 격리 배포환경을 구축할 수 있다.\n\n\n\nKubernetes 배포 환경 §\n\n\nKubernetes 에서는 이러한 컨테이너 배포환경에 더 높은 추상화를 제공해 컨테이너 형태의 App 들을 훨씬 쉽고 효율적으로 관리할 수 있게 해준다.\n\nKubernetes 구성요소 §\n\n\n출처: https://kubernetes.io/docs/concepts/overview/components/\n\n\nAPI Server\n\n클러스터를 관리하는 ReST API 를 제공하는 컨테이너이다.\n\n\nCloud-controller manager\n\n쿠버네티스가 클라우드 상에서 작동한다면, 해당 클라우드 프로바이더의 API 와 연동하여 클라우드의 리소스를 제어하는 컨테이너이다.\n\nEKS 를 예시로 들자면, 쿠버네티스에 LB type service 가 생성되면 AWS ALB 를 자동으로 생성 &amp; 설정해주는 등\n\n\n클라우드상에서 작동하지 않는다면, 설치하지 않아도 되는 구성요소이다.\n\n\nController manager\n\n생성된 리소스가 바람직한 상태를 유지하도록 하는 컨테이너이다.\n\n\nETCD\n\n클러스터의 모든 정보가 저장되는 키-벨류 기반의 데이터베이스 컨테이너이다.\n클러스터의 모든 정보가 저장되기에, ETCD 의 데이터가 깨지게 되면 클러스터 전체가 망가지게 된다.\n\n\nKubelet\n\n쿠버네티스 클러스터를 구성하는 물리 머신에 설치되는 시스템 데몬(Systemd service)으로, API Server 와 컨테이너 런타임과 통신하며 컨테이너들을 관리한다.\n\n\nKube-proxy\n\n노드 내외부의 통신을 담당하는 컨테이너이다.\n\n\nScheduler\n\n새로운 파드가 생성되었을때, 해당 파드를 어느 노드에 실행시킬지 선택하는 컨테이너이다.\n\n\n\nKubernetes 의 기본적인 작동 원리 §\n“상태” §\n\n바람직한 상태: 사용자가 kubectl 등을 통해 지정해준 사용자가 원하는 리소스의 형태\n현재 상태: 실제 쿠버네티스 클러스터에의 리소스의 형태\n상태를 일치시키기 위해 노력하는 것: 컨트롤러\n이렇게 사용자는 원하는 상태를 클러스터에 알려주는 형식으로 리소스를 생성한다 → 선언적 (Declarative) 아키텍처\n\nSpec, Status §\n\n바람직한 상태와 현재 상태는 모두 리소스의 YAML 에 저장된다.\n\n바람직한 상태는 spec 에 명시\n현재 상태는 status 에 명시\n\n\nkubectl get deployment ... -o yaml 로 spec 과 status 를 확인해보자.\n\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  annotations:\n    deployment.kubernetes.io/revision: &quot;1&quot;\n  creationTimestamp: &quot;2023-01-25T06:17:49Z&quot;\n  generation: 1\n  labels:\n    app: nginx\n  name: nginx\n  namespace: default\n  resourceVersion: &quot;66785&quot;\n  uid: e6fbe72b-9198-4928-8ead-0cd515449835\nspec:\n  progressDeadlineSeconds: 600\n  replicas: 1\n  revisionHistoryLimit: 10\n  selector:\n    matchLabels:\n      app: nginx\n  strategy:\n    rollingUpdate:\n      maxSurge: 25%\n      maxUnavailable: 25%\n    type: RollingUpdate\n  template:\n    metadata:\n      creationTimestamp: null\n      labels:\n        app: nginx\n    spec:\n      containers:\n      - image: nginx:stable\n        imagePullPolicy: IfNotPresent\n        name: nginx\n        resources: {}\n        terminationMessagePath: /dev/termination-log\n        terminationMessagePolicy: File\n      dnsPolicy: ClusterFirst\n      restartPolicy: Always\n      schedulerName: default-scheduler\n      securityContext: {}\n      terminationGracePeriodSeconds: 30\nstatus:\n  availableReplicas: 1\n  conditions:\n  - lastTransitionTime: &quot;2023-01-25T06:17:50Z&quot;\n    lastUpdateTime: &quot;2023-01-25T06:17:50Z&quot;\n    message: Deployment has minimum availability.\n    reason: MinimumReplicasAvailable\n    status: &quot;True&quot;\n    type: Available\n  - lastTransitionTime: &quot;2023-01-25T06:17:49Z&quot;\n    lastUpdateTime: &quot;2023-01-25T06:17:50Z&quot;\n    message: ReplicaSet &quot;nginx-76769d88f7&quot; has successfully progressed.\n    reason: NewReplicaSetAvailable\n    status: &quot;True&quot;\n    type: Progressing\n  observedGeneration: 1\n  readyReplicas: 1\n  replicas: 1\n  updatedReplicas: 1"},"originals/kubernetes.jan.2023.si-analytics.ai/03.-다양한-리소스들":{"title":"03. 다양한 리소스들","links":[],"tags":[],"content":"Workload Resource §\nStatefulSet §\nPain point §\n\nDeployment 의 Pod 는 “일용직” 과 유사한 측면이 있다.\n\n일용직 노동자는 일을 그만두어도 다른 인력을 쉽게 구해 대체할 수 있듯이,\nPod 는 삭제되어도 아무런 영향을 주지 않고 Deployment 에 의해 재생성된다.\n하지만 회사의 중요한 업무를 맡는 직책 (예를 들면 대표이사) 라면?\n\n\nDeployment 의 Pod 는 이름을 예측할 수 없다.\n\nDeployment 를 생성하여 Pod 를 생성하면 nginx-76769d88f7-gsmjb 와 같이 deployment 이름 뒤에 replicaset 과 pod 를 구분짓는 임의의 문자열이 생성되어 작명된다.\n하지만 이름을 예측해야 할 필요성이 있다면?\n\n\n\nStatefulSet 이란? §\n\nPain point 1 번의 설명처럼, Deployment 의 Pod 는 언제든지 삭제되고 재생성되어도 문제가 없는 애플리케이션을 위한 것이다.\n\n이것을 Stateless 라고 표현한다.\n\n\n하지만 어떤 애플리케이션의 경우 삭제되거나 재생성되는 것이 영향력을 가질 수 있고, 이러한 애플리케이션을 위한 것이 StatefulSet 이다.\n\nStatefulSet 의 파드를 이전에는 “Pet” 이라고 표현했다. 다른 것으로 대체될 수 없는 소중한 것이라는 의미를 전달하기 위해서이다.\n\n\nStatefulSet 은 대표적으로 다음과 같은 특징을 갖는다.\n\nStatefulSet 이 생성한 파드에는 임의의 문자열이 아닌 0부터 시작하는 숫자가 부여된다. 즉, foo 라는 이름의 StatefulSet 을 생성하면 foo-0, foo-1 … 등의 이름이 부여된다.\n\n이것은 StatefulSet 이 생성하는 Pod 가 소중한 것이라는 개념을 뒷받침해준다. 자신이 기르는 애완동물 이름을 랜덤하게 지어주는 사람은 없다.\n\n\nStatefulSet 의 Pod 들은 소중하기 때문에 일반적으로 데이터가 안전하게 보관되어야 할 필요가 있다. 따라서 StatefulSet 은 PVC (쿠버네티스의 볼륨 요청 방식, 뒤에서 다룬다) 를 자동으로 생성해주는 기능을 제공한다.\n\n\n\nUsecase §\n\nDatabase\n\n대다수의 DBMS 들은 고가용성 설계를 할 때 단순히 데이터 복제를 하진 않는다.\n다양한 방식으로 고가용성 DBMS 가 운영되지만 하나의 사례는 여러개의 DB 인스턴스 중 하나를 Master (혹은 Active), 나머지를 Slave (혹은 Standby) 로 선정하고 Master 가 모든 요청을 처리하되, 데이터 저장 / 변경의 경우 일정 부분의 Slave 에도 반영이 되어야 요청이 처리된 것으로 간주하는 방식이다.\n\n이렇게 하면 모든 DB 인스턴스에 정보를 복제하는 것보다 빠르게 요청을 처리할 수 있고, 데이터 이중화라는 본래의 목적도 달성할 수 있기 때문이다.\n\n\n하지만 이때에는 DB 인스턴스가 삭제되는 것이 가볍게 지나칠 일이 아니기에 함부로 삭제되거나 재생성되어서는 안된다.\n또한, DB 의 사용자(클라이언트) 입장에서는 Master 에게 요청을 보내야 하기 때문에 어떤 인스턴스가 Master 인지 알아야 한다. 즉, DB 인스턴스의 이름을 사전에 알고 있어야 된다는 이야기이다.\n\n\n\nDaemonSet §\nPain point §\n\n어떤 애플리케이션은 모든 노드에서 작동해야 할 필요가 있다.\n\n만일 Deployment 를 이용해 파드를 모든 노드에서 작동하게 하려면, 추가적인 설정이 필요할 뿐더러 클러스터에 노드가 추가되었을 경우 파드의 개수를 수동으로 증가시켜줘야 한다.\n\n\n\nDaemonSet 이란? §\n\nDaemonSet 은 모든 노드 각각에 반드시 한개의 Pod 가 작동하도록 보장하는 리소스이다.\n\nUsecase §\n\n노드를 관리하는 애플리케이션\n\n노드의 Networking 을 담당하는 파드\n\n쿠버네티스 시스템 컴포넌트 중 노드 내외부의 통신을 담당하는 Kube-proxy 도 DaemonSet 으로 생성된다.\n\n\n노드의 로그를 수집하는 파드\n\n노드의 시스템 로그 및 파드들이 생산하는 로그를 수집하는 파드의 경우 모든 노드에 배포되게 하기 위해 DaemonSet 으로 생성된다.\n\n\n\n\n\nJob §\nPain point §\n\n파드가 생성된 후 일정한 작업을 수행하고 종료되었으면 좋겠다.\n\n하지만, Deployment 는 파드가 삭제되어도 재생성되기에 이러한 니즈를 충족시킬 수 없다.\n\n\n\nJob 이란? §\n\n파드를 생성한 후, 작업이 정상적으로 종료될때까지 파드를 유지하다가 정상 종료 이후 삭제하는 리소스이다.\n\nUsecase §\n\n일회성 작업\n\n예를 들면, \bAI/ML 모델 학습용 파드나\n시스템 성능 테스트 (벤치마크) 파드 등\n\n\n\nCronJob §\nPain point §\n\n주기적으로 어떤 작업을 수행해주기 위해, Job 이 특정한 시간 주기로 생성되었으면 좋겠다.\n\nCronJob 이란? §\n\n지정한 시간 간격 (혹은 규칙) 에 따라 Job 을 생성하여 특정한 작업을 하게 해주는 리소스이다.\n\nUsecase §\n\n주기적인 작업을 요하는 애플리케이션\n\n예를 들면, 매월 1일자에 저장된 로그를 압축하여 디스크 사용량을 줄이는 파드\n\n\n\nNetworking Resource §\n\n\n                  \n                  네트워크 관련 리소스들은 아래의 Deployment 를 활용한 실습을 통해 소개드리겠습니다. \n                  \n                \n\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: nginx\nspec:\n  selector:\n    matchLabels:\n      app: nginx\n  template:\n    metadata:\n      labels:\n        app: nginx\n    spec:\n      containers:\n      - name: nginx\n        image: nginx:stable\nService §\nPain point §\n\nDeployment 를 통해 파드를 여러개 생성했을 때, 단일 진입점이 있었으면 좋겠다.\nPod IP 와 같이 언제든 바뀔 수 있는 진입 주소가 아닌, 고정된 진입 주소가 있으면 좋겠다.\n\nService? §\n\nService 는 Pod 로 접근하는 엔드포인트를 제공하는 리소스이다.\n위의 Pain Point 는 이 Service 리소스를 통해 다음과 같이 해결된다:\n\nService 로 들어온 트래픽은 Service 와 연결된 Pod 들로 부하 분산된다.\nService 는 생성시에 Virtual IP 가 할당되기에 접근할 수 있는 고정주소로 사용할 수 있다.\n\n추가설명) Pod 는 재생성이 빈번하고 그때마다 IP 를 새로 할당받지만, Service 의 경우에는 재생성될 일이 적고, 생성시에 IP 를 할당받기는 하지만 YAML 파일에 IP 를 직접 명시해 줄 수도 있다. 또한, 쿠버네티스에는 클러스터 내부에서 사용할 용도의 DNS 가 존재하기에, Service 의 IP 주소가 아닌 도메인으로 접속하는 것도 가능하다.\n이것에 관해서는 아래의 실습에서도 확인할 수 있다.\n\n\n\n\n\nClusterIP Service §\nClusterIP 서비스란? §\n\n클러스터 내부 통신용 엔드포인트를 생성하기 위한 서비스 리소스이다.\nService 리소스를 생성할 때, type 을 지정해주지 않거나 type: ClusterIP 로 지정해주면 해당 리소스가 생성된다.\n\nCluster IP 실습 §\n\n다음의 명령어 혹은 YAML 파일을 이용해 nginx Deployment 에 ClusterIP 서비스를 연결해준다.\n\nkubectl expose deployment nginx --name nginx --port 80\napiVersion: v1\nkind: Service\nmetadata:\n  name: nginx\nspec:\n  ports:\n  - name: http\n    port: 80\n    protocol: TCP\n    targetPort: 80\n  selector:\n    app: nginx\n  type: ClusterIP\n\n생성된 ClusterIP 를 확인한다.\n\nkubectl get service nginx\nNAME\tTYPE\t\tCLUSTER-IP\t   EXTERNAL-IP   PORT(S)   AGE\nnginx   ClusterIP   10.105.103.161   &lt;none&gt;\t\t80/TCP\t4m2s\n\n\nClusterIP 를 통해 접속이 이루어지는지 확인하기 위해 간단히 curl 이 설치되어있는 파드를 생성한다.\n\napiVersion: v1\nkind: Pod\nmetadata:\n  name: curlpod\nspec:\n  containers:\n  - name: curl\n    image: docker.io/curlimages/curl:7.86.0\n    command:\n      - sleep\n      - &quot;infinity&quot;\n    imagePullPolicy: IfNotPresent\n  restartPolicy: Always\n\n다음의 명령어를 통해 curl 파드 내에서 통신을 시도해보고, NGINX 홈페이지 HTML 이 조회되는지 확인한다. (사용된 IP 는 다를 수 있다.)\n\n# kubectl exec -it curlpod -- curl ${kubectl get service nginx 명령어를 통해 확인한 Internal IP 주소}\nkubectl exec -it curlpod -- curl 10.105.103.161\n&lt;!DOCTYPE html&gt;\n&lt;html&gt;\n&lt;head&gt;\n&lt;title&gt;Welcome to nginx!&lt;/title&gt;\n&lt;style&gt;\nhtml { color-scheme: light dark; }\nbody { width: 35em; margin: 0 auto;\nfont-family: Tahoma, Verdana, Arial, sans-serif; }\n&lt;/style&gt;\n&lt;/head&gt;\n&lt;body&gt;\n&lt;h1&gt;Welcome to nginx!&lt;/h1&gt;\n&lt;p&gt;If you see this page, the nginx web server is successfully installed and\nworking. Further configuration is required.&lt;/p&gt;\n\n&lt;p&gt;For online documentation and support please refer to\n&lt;a href=&quot;http://nginx.org/&quot;&gt;nginx.org&lt;/a&gt;.&lt;br/&gt;\nCommercial support is available at\n&lt;a href=&quot;http://nginx.com/&quot;&gt;nginx.com&lt;/a&gt;.&lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;Thank you for using nginx.&lt;/em&gt;&lt;/p&gt;\n&lt;/body&gt;\n&lt;/html&gt;\n\n\n하지만 ClusterIP 의 Internal IP 는 변경 가능성이 높기 때문에 파드간 통신에서는 Internal IP 를 직접적으로 사용하기 보다는 Domain 를 활용한다.\n\n쿠버네티스에는 기본적으로 “CoreDNS” 라는 네임서버가 파드로 배포되어 있고, 클러스터 내부에서 사용되는 Domain 에 대한 처리를 담당한다.\nDomiain 은 다음과 같이 구성된다: {서비스 이름}.{네임스페이스 이름}.svc.{클러스터 이름}.local\n따라서 위에서 생성한 ClusterIP 에 대한 Domain 은 다음과 같다: nginx.default.svc.cluster.local\n\n참고) {클러스터 이름} 은 기본값이 cluster 이다. 하지만 클러스터 생성시에 다른 이름을 지정해줄 수도 있으니 정상적으로 작동하지 않는다면, kubectl exec -it 파드 -- cat /etc/resolv.conf 로 DNS 설정을 확인해보자.\n\n\n\n\n다음 명령어를 통해 Internal IP 대신 Domain 으로 NGINX 에 접속해본다.\n\n# kubectl exec -it curlpod -- curl ${ClusterIP 의 domain}\nkubectl exec -it curlpod -- curl nginx.default.svc.cluster.local\n&lt;!DOCTYPE html&gt;\n&lt;html&gt;\n&lt;head&gt;\n&lt;title&gt;Welcome to nginx!&lt;/title&gt;\n&lt;style&gt;\nhtml { color-scheme: light dark; }\nbody { width: 35em; margin: 0 auto;\nfont-family: Tahoma, Verdana, Arial, sans-serif; }\n&lt;/style&gt;\n&lt;/head&gt;\n&lt;body&gt;\n&lt;h1&gt;Welcome to nginx!&lt;/h1&gt;\n&lt;p&gt;If you see this page, the nginx web server is successfully installed and\nworking. Further configuration is required.&lt;/p&gt;\n\n&lt;p&gt;For online documentation and support please refer to\n&lt;a href=&quot;http://nginx.org/&quot;&gt;nginx.org&lt;/a&gt;.&lt;br/&gt;\nCommercial support is available at\n&lt;a href=&quot;http://nginx.com/&quot;&gt;nginx.com&lt;/a&gt;.&lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;Thank you for using nginx.&lt;/em&gt;&lt;/p&gt;\n&lt;/body&gt;\n&lt;/html&gt;\n\nNodePort Service §\nNodePort 서비스란? §\n\nNodePort 타입의 서비스는 모든 노드의 특정 30000-32767 사이의 포트를 열고, 해당 포트로 들어오는 트래픽을 파드로 전달해줄 수 있게 하는 리소스이다.\n보통 클러스터 외부에서 파드에 접근하기 위해 사용한다.\n\nNodePort 실습 §\n\n다음의 명령어 혹은 YAML 파일을 통해 NodePort 서비스를 생성한다.\n\nkubectl expose deployment nginx --name nginx-np --type NodePort --port 80\napiVersion: v1\nkind: Service\nmetadata:\n  name: nginx-np\nspec:\n  ports:\n  - name: http\n    nodePort: 31045\n    port: 80\n    protocol: TCP\n    targetPort: 80\n  selector:\n    app: nginx\n  type: NodePort\n\n생성한 NodePort 서비스를 확인한다.\n\nkubectl get service nginx-np\nNAME\t   TYPE\t   CLUSTER-IP\t   EXTERNAL-IP   PORT(S)\t\tAGE\nnginx-np   NodePort   10.110.201.171   &lt;none&gt;\t\t80:31045/TCP   118s\n\n\n참고) YAML 파일을 이용하면 개방할 30000 번대 포트를 직접 지정할 수 있지만, kubectl cli 를 이용하면 30000번대의 임의의 포트가 개방된다.\nPORT(S) 항목에 바인드되어있는 30000 번대 포트를 통해 브라우저로 접속해본다.\n\n\nLB Service §\nLB(LoadBalancer) 서비스란? §\n\n클러스터 외부의 로드밸런서와 연동하여 외부의 트래픽을 클러스터 내부의 파드로 전달하는 리소스\n\nLB 서비스 vs NodePort 서비스 §\n\nLB 서비스와 NodePort 서비스 모두 외부의 트래픽을 파드에 전달한다는 점에서는 동일하다.\n하지만, 두 서비스가 사용되는 Usecase 는 많이 다르다.\n\nLB 서비스의 경우에는 클러스터 외부의 로드밸런서 (SW 혹은 HW) 와 연동되어야 하기 때문에 온프레미스 클러스터에서는 사용하기 힘들다.\n\n쿠버네티스 클러스터가 클라우드에서 작동하는 경우에는 Cloud controller 를 이용해 AWS 의 ALB 와 같은 리소스를 자동으로 생성하고,\nDocker desktop 혹은 minikube 의 경우에는 플러그인이 있어 자동적으로 처리해주지만 온프레미스 클러스터에서 안정적으로 사용할 수 있는 솔루션은 부족하다.\n\n\n\n\n따라서 온프레미스 클러스터에서는 LB 서비스보다는 NodePort 를 이용해 외부의 트래픽을 전달받는다.\n\n참고) NodePort 의 포트 범위가 30000-32767 이기에, 만일 80 이나 443 와 같은 Known port 로 트래픽을 받을 때에는 아래와 같이 앞단에 HAProxy 같은 프록시를 구성하기도 한다.\n\n\n\n                                             +-----------------------------+\n                                 +----&gt; 32000/TCP(NodePort BE)    K8s Node |\n                                 |           +-----------------------------+\n                                 |\n        +--------------------+   |           +-----------------------------+\n--&gt; 80/TCP(FE)       HAPROXY |---+----&gt; 32000/TCP(NodePort BE)    K8s Node |\n        +--------------------+   |           +-----------------------------+\n                                 |\n                                 |           +-----------------------------+\n                                 +----&gt; 32000/TCP(NodePort BE)    K8s Node |\n                                             +-----------------------------+\n\nIngress §\nIngress 란? §\n\ningress 는 L7 라우팅 규칙을 정의하는 리소스이다.\n\nIngress? Ingress controller? §\n\n쿠버네티스의 다른 리소스들과 마찬가지로, “리소스”, “리소스-컨트롤러” 와의 관계와 같다.\n\n“리소스”는 객체이고, 해당 객체에 명시된 내용에 따라 클러스터의 상태를 관리하는 프로세스(컨테이너) 가 “리소스-컨트롤러” 이듯이,\nIngress 는 객체이고, 생성된 Ingress 에 따라 L7 라우팅 규칙을 업데이트하고 그에 따라 작동할 수 있게 하는 것이 Ingress controller 이다.\nNGINX 에 비유하자면, Ingress 는 nginx.conf 파일이고, Ingress controller 는 NGINX 프로세스이다.\n\n\n쿠버네티스 내부에는 Ingress 리소스가 정의되어 있지만, 이것을 처리하는 컨트롤러 (Ingress controller)는 구현되어있지 않고 별도의 설치가 필요하다.\n\n이것은 쿠버네티스가 직접 소프트웨어 L7 로드밸런서를 구현하기보다는 NGINX, HAProxy 같은 상용 솔루션들을 활용하고 사용자로 하여금 익숙한 솔루션을 선택할 수 있도록 한 것이다.\n다만, 컨트롤러도 디플로이먼트의 형태로 구성되기에 이것을 외부에 노출시키기 위해 LB 서비스 혹은 NodePort 서비스의 도움이 필요하다.\n\n\n\nIngress 의 사용 이유 §\n\nNGINX, HAProxy 같은 일반적인 소프트웨어 L7 로드밸런서를 사용하는 이유와 같다.\n즉, 클러스터로 진입하는 제일 앞단에서 TLS/SSL 인증서를 처리하거나, Application layer 에서의 라우팅을 이용해 클러스터 내부의 백엔드로 트래픽을 전달하는 용도로 사용한다.\n따라서 원하는 파드를 외부에 노출시키고자 할 때 LB 혹은 NodePort 를 이용해 직접 노출시키는 것이 아닌 Ingress controller 만 외부에 노출시켜놓고 이것이 전달해주는 트래픽을 받을 수 있도록 Ingress 리소스를 생성해주면 된다.\n\nIngress 의 작동 원리 §\n\n\nIngress controller 를 설치하고 외부에 노출한 뒤에는, Ingress 를 생성했을 때에 그에 맞는 L7 라우팅 규칙이 생성되어 외부의 트래픽이 파드로 전달되는 방식으로 작동한다.\n\n트래픽을 규칙에 따라 파드로 전달할때에는, Ingress controller pod → target pod 간 통신, 즉, 클러스터 내부의 통신이기에 Cluster IP 타입의 서비스를 이용한다.\n즉, L7 로드밸런서로 비유하자면, FE 는 Ingress controller 를 클러스터 외부에 노출시키는 LB type service 이고, BE 는 클러스터 내부의 파드에 연결된 Cluster IP type service 이며, 이 둘을 연결지어주는 규칙을 Ingress 리소스로 정의하게 되는 셈이다.\n\n\n\n실습 §\n\n먼저, Ingress 를 처리할 Ingress controller 를 설치한다.\n\n아래의 명령어는 Kubernetes 에서 공식적으로 지원하는 Ingress controller 인 NGINX ingress controller 를 ingress-nginx 네임스페이스에 설치한다.\n\n\n\nkubectl apply -f https://raw.githubusercontent.com/kubernetes/ingress-nginx/controller-v1.5.1/deploy/static/provider/cloud/deploy.yaml\n\ningress-nginx 네임스페이스에 인그레스 컨트롤러가 정상적으로 설치되었는지 확인한다.\n\nkubectl -n ingress-nginx get all\n\nhttps://localhost 로 접속하여 404: Not Found 화면이 보이는지 확인한다.\n\n404: Not Found 가 보이는 것은 Ingress controller 가 정상적으로 작동하고 있으나, root path 에 대한 ingress 가 생성되지 않았기에 자원을 찾을 수 없다는 문구를 보여주는 것이다.\n\n\n\n\n\n신규 Ingress 를 생성한다.\n\n본 Ingress 가 작동하기 위해서는 nginx 라는 이름의 ClusterIP 서비스와, 해당 서비스가 노출하고 있는 Deployment 등의 리소스가 필요하다. (앞선 실습에서 이미 생성되었다고 가정)\n\n\n\napiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: nginx-ing\n  annotations:\n    nginx.ingress.kubernetes.io/rewrite-target: /\nspec:\n  ingressClassName: nginx\n  rules:\n  - host: localhost\n    http:\n      paths:\n      - path: /testpath\n        pathType: Prefix\n        backend:\n          service:\n            name: nginx\n            port:\n              number: 80\n\n생성한 Ingress 에는 host 가 localhost 이고 path 가 /testpath 일때 “nginx” 라는 이름의 서비스 오브젝트로 트래픽을 전달하도록 되어 있다. 따라서 브라우저에서 https://localhost/testpath 로 접속해본다.\n\n\n생성한 리소스 정리 §\nkubectl delete deployment nginx\nkubectl delete service nginx\nkubectl delete service nginx-np\nkubectl delete pod curlutils\nkubectl delete ingress nginx-ing\nkubectl delete -f https://raw.githubusercontent.com/kubernetes/ingress-nginx/controller-v1.5.1/deploy/static/provider/cloud/deploy.yaml"},"originals/kubernetes.jan.2023.si-analytics.ai/04.-심화":{"title":"04. 심화","links":[],"tags":[],"content":"Probe §\nProbe 란? §\n\nProbe 는 파드의 health check 를 위한 기능으로, Kubelet 이 주기적으로 실행하며 해당 파드가 정상적으로 작동하는지, 혹은 트래픽을 받을 준비가 되어 있는지 확인해주는 기능이다.\nProbe 에는 다음과 같이 세가지 종류가 있다.\n\nLiveness Probe: 파드가 정상인지 확인하는 기능으로, 파드가 비정상적이라면 컨테이너를 재실행시켜주는 역할이다.\nReadiness Probe: 파드가 트래픽을 받을 준비가 되어있는지 확인하는 기능으로, 파드가 준비가 안되어 있으면 Service 를 통한 접근을 제한한다.\nStartup Probe: 파드가 초기 세팅을 온전히 마칠 수 있도록 기다려주는 역할을 한다.\n\n예를 들어, 파드 생성 후 초기 세팅을 마치는데까지 60초가 걸리는 경우 이것을 기다리지 못하고 Liveness Probe 가 작동해서 파드를 재실행시켜버린다면 파드는 영원히 정상적인 상태가 되지 못하기 때문에 필요한 기능이다.\n\n\n\n\n\n실습 - Liveness Probe §\n\n다음의 YAML 파일을 이용해 파드를 배포한다.\n\napiVersion: v1\nkind: Pod\nmetadata:\n  labels:\n    test: liveness\n  name: liveness-exec\nspec:\n  containers:\n  - name: liveness\n    image: registry.k8s.io/busybox\n    args:\n    - /bin/sh\n    - -c\n    - touch /tmp/healthy; sleep 30; rm -f /tmp/healthy; sleep 600\n    livenessProbe:\n      exec:\n        command:\n        - cat\n        - /tmp/healthy\n      initialDelaySeconds: 5\n      periodSeconds: 5\n\n위 파드의 컨테이너를 확인하면, 30초에 한번씩 /tmp/healthy 파일을 생성하고 지우는 것을 확인할 수 있다.\n또한 livenessProbe 로 /tmp/healthy 파일을 5초마다 확인하고 있는 것을 알 수 있다.\n따라서, 파드가 생성되고 30초간은 liveness probe 가 성공하며 파드가 정상적으로 작동하게 되지만, 30초가 지난 뒤에는 실패하며 파드를 재실행할 것이다.\n생성 이후 다음의 명령어로 파드의 상태를 모니터링한다.\n\n이론상으로는 30초에 한번씩 재실행되어야 하지만, 실제로는 약 77초에 한번씩 재실행되었다.\n\n\n\nwatch -n 0.2 kubectl get pod liveness-exec\nConfigMap, Secret §\nConfigMap 과 Secret 의 역할 §\n\nConfigMap 과 Secret 은 파드에 파일을 전달하는 볼륨의 일종이라고 볼 수 있다.\nConfigMap 과 Secret 에 data 를 넣어 생성한 후에 파드 내에 마운트시키면 해당 마운트 지점에 작성한 data 를 파일의 형태로 확인할 수 있다.\n다만 ConfigMap 과 Secret 의 차이점은 ConfigMap 은 plain text 로 저장되는 한편, Secret 은 Base64 인코딩이 되어 (암호화되는 것은 아니지만) 쉽게 읽을 수 없도록 변환된다.\n이에 ConfigMap 은 .conf 같은 설정파일을 파드 내부에 주입시켜주는 것에 활용되고, Secret 은 DB 접속 비밀번호 등을 저장하고 파드 내에서 사용할 수 있도록 활용된다.\n\nConfigMap 실습 §\n\nNGINX 의 index.html 파일을 주입하는 ConfigMap 생성\n\napiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: nginx-index\ndata:\n  index.html: |\n    &lt;h1&gt;Hello World!&lt;/h1&gt;\n\n생성한 ConfigMap 을 사용하는 Deployment 생성\n\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: nginx\nspec:\n  selector:\n    matchLabels:\n      app: nginx\n  template:\n    metadata:\n      labels:\n        app: nginx\n    spec:\n      containers:\n      - name: nginx\n        image: nginx:stable\n        volumeMounts:\n        - name: nginx-index-cm\n          mountPath: &quot;/usr/share/nginx/html&quot;\n          readOnly: true\n      volumes:\n      - name: nginx-index-cm\n        configMap:\n          name: nginx-index\n          items:\n          - key: &quot;index.html&quot;\n            path: &quot;index.html&quot;\n\nDeployment 를 노출하는 Service 생성\n\napiVersion: v1\nkind: Service\nmetadata:\n  name: nginx\nspec:\n  ports:\n  - name: http\n    port: 8080\n    protocol: TCP\n    targetPort: 80\n  selector:\n    app: nginx\n  type: LoadBalancer\n\n이후 브라우저를 통해 localhost:8080 으로 진입하면 ConfigMap 을 통해 주입해준 페이지를 볼 수 있다.\n\n\nNamespace, RBAC §\nNamespace 란? §\n\n네임스페이스 (Namespace)는 오브젝트들을 묶어 논리적으로 구분지을 수 있게 해주는 오브젝트이다.\n\n“논리적”으로 구분짓기 때문에 물리적인 격리와는 보안성 등의 측면에서 차이가 난다.\n\n\n쿠버네티스의 모든 리소스는 네임스페이스에 속하거나 (Namespaced object) 클러스터 전역에 속하게 (Cluster-scoped object) 된다.\n\n예를들면, Deployment, Pod 같은 오브젝트는 네임스페이스에 종속되고,\nNode 같은 리소스는 네임스페이스에 속하지 않는다.\n\n\n쿠버네티스 네임스페이스에는 대표적으로 네임스페이스를 지정하지 않으면 자동으로 부여되는 default namespace와 쿠버네티스 시스템이 사용하는 오브젝트들이 속하는 kube-system 이 있다.\n\nRBAC 이란? §\n\nRBAC 이란 Role-Based Access Control 이라는 뜻으로, “역할” 을 “사용자”에게 “부여”하여 권한을 관리하는 방법이다.\n\n역할은 “리소스”와 그에 적용할 수 있는 “행동” 을 묶어놓은 것이고, 이것을 대상이 되는 “사용자” 에게 “부여” 하는 방식이다.\n비유하자면\n\n“Cloud Engineer” 라는 역할은 “쿠버네티스 클러스터” 라는 리소스에 대해 “관리” 하는 행동을 의미하고\n역할 부여 대상인 “김해람” 에게 해당 역할을 부여해서 권한 관리를 한다.\n\n\n\n\n\n쿠버네티스에의 RBAC §\n\n쿠버네티스에서는 RBAC 을 구현하기 위해 다음과 같은 리소스들을 제공한다.\n\nRole (ClusterRole)\nRoleBinding (ClusterRoleBinding)\n\n\nRole 에는 파드, 서비스와 같은 리소스와 그에 할 수 있는 행동 (view, edit 등) 을 명시하여 역할을 생성할 수 있도록 하는 리소스이고,\n\n특정 네임스페이스에만 속하는 역할을 Role, 클러스터 전체에 속하는 역할을 ClusterRole 로 생성한다.\n\n\nRoleBinding 은 생성한 Role 과 부여 대상인 사용자 혹은 ServiceAccount 를 연결해주는 리소스이다.\n\nServiceAccount 는 로봇 계정으로 비유할 수 있다 → 일반 사용자가 클러스터에 계정을 생성하여 작업을 하는 것처럼, 파드가 클러스터 내에서 작업을 하기 위한 로봇 계정이 ServiceAccount 이다.\n마찬가지로 특정 네임스페이스에만 속하는 역할을 연결하는 리소스가 RoleBinding 이고, 클러스터 전체에 속하는 역할을 연결하는 리소스는 ClusterRoleBinding 이다.\n\n\n\nRBAC 예시 (실습 X) §\napiVersion: rbac.authorization.k8s.io/v1\nkind: Role\nmetadata:\n  namespace: default\n  name: pod-reader\nrules:\n- apiGroups: [&quot;&quot;]\n  resources: [&quot;pods&quot;]\n  verbs: [&quot;get&quot;, &quot;watch&quot;, &quot;list&quot;]\napiVersion: rbac.authorization.k8s.io/v1\nkind: RoleBinding\nmetadata:\n  name: read-pods\n  namespace: default\nsubjects:\n- kind: User\n  name: jane\n  apiGroup: rbac.authorization.k8s.io\nroleRef:\n  kind: Role\n  name: pod-reader\n  apiGroup: rbac.authorization.k8s.io\nPV, PVC §\nPV, PVC 란? §\n\n\n쿠버네티스는 클러스터 관리자와 클러스터 이용자를 구분하여 볼륨을 관리하는 방법을 제시한다.\n\n즉, 클러스터 관리자가 사용할 수 있는 볼륨을 미리 지정해 놓으면, 클러스터 이용자는 해당 볼륨을 자신의 Deployment등에 사용하게 된다.\n\n\n클러스터 관리자가 생성하는 볼륨을 PV (Persistent Volume)이라고 하고,\n클러스터 이용자가 해당 볼륨을 요청하는 것을 PVC (Persistent Volume Claim)이라고 한다.\n관리자가 직접 PV 를 생성하여 PVC 에 연결될 수 있도록 할 수도 있지만, 대부분의 경우에는 PV 를 자동으로 생성해주는 PV provisioner 를 구축하여 PVC 가 생성이 되었을 때 자동으로 PV 가 생성되도록 한다.\n"},"originals/kubernetes.jan.2023.si-analytics.ai/쿠버네티스-교육자료-(SI-Analytics,-Jan.-2023)":{"title":"쿠버네티스 교육자료 (SI Analytics, Jan. 2023)","links":["originals/kubernetes.jan.2023.si-analytics.ai/01.-쿠버네티스와-친해지기","originals/kubernetes.jan.2023.si-analytics.ai/02.-기본-개념","originals/kubernetes.jan.2023.si-analytics.ai/03.-다양한-리소스들","originals/kubernetes.jan.2023.si-analytics.ai/04.-심화"],"tags":[],"content":"\n\n                  \n                  사내에서 진행한 신규입사자 쿠버네티스 기초 교육 자료입니다. \n                  \n                \n\n개요 §\n\n2023년 1월 25~27일간 매일 1시간 정도씩 SI Analytics 에서 진행한 신규입사자 대상 쿠버네티스 기초 교육 자료입니다.\n원문에서 쿠버네티스 관련 내용만 남기고, 민감한 정보들은 전부 삭제하였습니다.\n\n목차 §\n\n01. 쿠버네티스와 친해지기\n02. 기본 개념\n03. 다양한 리소스들\n04. 심화\n"},"originals/os.bahn.ewha.kocw.net/(이화여대)-운영체제-강의록":{"title":"(이화여대) 운영체제 강의록","links":["originals/os.bahn.ewha.kocw.net/01.-운영체제란","originals/os.bahn.ewha.kocw.net/02.-System-Structure-&-Process-Execution","originals/os.bahn.ewha.kocw.net/03.-Process","originals/os.bahn.ewha.kocw.net/04.-Process-Management","originals/os.bahn.ewha.kocw.net/05.-CPU-Scheduling","originals/os.bahn.ewha.kocw.net/06.-Process-Synchronize","originals/os.bahn.ewha.kocw.net/07.-Deadlocks","originals/os.bahn.ewha.kocw.net/08-1.-Memory-Address","originals/os.bahn.ewha.kocw.net/08-2.-Physical-Memory-Allocation","originals/os.bahn.ewha.kocw.net/09.-Virtual-Memory","originals/os.bahn.ewha.kocw.net/10.-File-Systems","originals/os.bahn.ewha.kocw.net/11.-Disk-Scheduling"],"tags":[],"content":"개요 §\n강의 정보 §\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n제공강사링크KOCW 온라인 강의이화여자대학교 컴퓨터공학과 반효경 교수님KOCW\n목차 §\n\n01. 운영체제란\n02. System Structure &amp; Process Execution\n03. Process\n04. Process Management\n05. CPU Scheduling\n06. Process Synchronize\n07. Deadlocks\n08-1. Memory Address\n08-2. Physical Memory Allocation\n09. Virtual Memory\n10. File Systems\n11. Disk Scheduling\n"},"originals/os.bahn.ewha.kocw.net/01.-운영체제란":{"title":"01. 운영체제란","links":[],"tags":[],"content":"\n\n                  \n                  이화여자대학교 컴퓨터공학과 반효경 교수님의 &quot;운영체제 (KOCW)&quot; 강의를 필기한 내용입니다. \n                  \n                \n\n\n\n                  \n                  다소 잘못된 내용과 구어적 표현 이 포함되어 있을 수 있습니다. \n                  \n                \n\n운영체제 핵심 §\n\n\n운영체제의 핵심은 컴퓨터의 하드웨어 바로 위에 설치되어 아래로는 하드웨어 자원을 관리하고 위로는 사용자 혹은 사용자 애플리케이션을 위한 편의 기능을 제공하는 것이다.\n\n그래서 그 편의기능이 뭐냐\n사용자로 하여금 내가 실행시킨 프로그램만 실행되고 있게 느끼도록 해주고\n하드웨어를 제어하는 복잡한 작업을 대행하기 때문에 하드웨어에 대한 부분은 사용자가 고려하지 않아도 되게끔 해준다.\n\n\n자원 분배를 할때는 분배의 형평성과 효율성 (주어진 자원 내에서의 최고의 성능) 이 Trade-off 관계에 있게 되는데 운영체제는 이 둘을 적절하게 타협해서 분배를 한댄다\n\n뭐 예를들면 CPU 스케줄링할때 중요한 프로세스에다만 몰빵하면 중요하지 않은 프로세스는 CPU할당을 받지 못하게 되는 이러한 Trade-off\n\n\n\n운영체제, 커널 §\n\n커널은 운영체제의 핵심적인 부분으로 메모리에 항상 상주한다.\n따라서 좁은 의미의 운영체제는 커널만을 칭하고 (협의의 운영체제) 넓은의미에서는 커널 뿐 아니라 주변의 다른 시스템 유틸리티까지 포함한다 (광의의 운영체제).\n\n운영체제의 분류 §\n동시 작업 가능 여부 §\n\nSingle tasking: 한번에 하나의 작업만 처리\n\n일례로 MS-DOS 의 경우에는 한번에 하나의 작업만 처리할 수 있어 명령을 끝내기 전에 다른 명령을 실행시킬 수 없다\n\n\nMulti tasking: 한번에 여러개의 작업 처리\n\n사용자의 수 §\n\nSingle user: 머신을 한 번에 한 명의 사용자만 사용할 수 있는 운영체제\nMulti user: 머신을 한번에 여러명의 사용자가 (원격) 접속하여 사용할 수 있는 운영체제\n\n따라서 Multi user 를 위해서는 사용자 간의 격리를 위한 보안성이나 자원 할당 등의 부가적인 기능이 필요하다.\n\n\n\n작업 처리 형태 §\n\nBatch processing: 이건 작업을 바로 처리하는 것이 아니라 일정량 모아서 한번에 처리하는 형태\n\n따라서 작업을 요청하면 다른 작업이 일정량 모인 후에 실행되고 결과가 나올때 까지 기다려야 했다.\n지금은 거의 안쓰고 옛날 Punch card 같은 처리 시스템에서 많이 쓰였음\n\n\nTime sharing: CPU time을 잘게 쪼개 여러 프로세스를 돌아가며 실행시키는 형태\n\n뭐 지금의 운영체제가 다 그렇지 뭐\n다만 이건 시간상의 제약이 있지는 않다 → 시간을 쪼개 작업을 처리하지만 해당 시간 내에 끝내는 것을 목표로 하지는 않음\n\n\nReal time: 작업의 deadline이 있어 해당 deadline 전까지 작업을 끝마치도록 하는 형태\n\n시간이 중요한 시스템들 (뭐 원자력 제어 시스템이나 미사일 등) 을 위한 시스템\n시간 내에 끝나지 않았을때 진짜 ㅈ되는 것을 위한 것이 Hard realtime system 이고\n시간 내에 끝내야 하긴 하지만 ㅈ되지는 않는것 (뭐 동영상 스트리밍의 경우에는 1초에 24프레임을 불러와야 하니까) 을 위한 게 Soft realtime system 이라고 부르더라\n\n\n\nMulti-어쩌고 §\n\n프로세스를 병렬적으로 처리하는데에는 다음과같은 용어들이 있는데 어느정도는 구분할 수 있어야 한다\n\nMultitasking: 가장 범용적인 (범위가 큰) 용어 → 걍 프로세스가 여러개 작동될 수 있어 하나가 끝나기 전에 다른 하나가 실행될 수 있는 것\nMultiprogramming: 프로세스 여러개가 하나의 메모리에 적재될 수 있는 것\n\n뭐 당연히 Multitasking 을 위해서는 Multiprogramming 이 되어야 하고 어느정도는 Multitasking과 의미가 겹치지만 얘는 약간 메모리 측면을 강조한 용어라고 할 수 있다.\n\n\nTime sharing: 프로세스 여러개가 CPU time을 돌아가며 할당받는 것\n\n이것도 Multitasking 과 개념이 좀 겹치지만 얘는 CPU time을 강조한 용어라고 할 수 있다\n\n\nMultiprocess: 얘는 진짜 Multitasking과 차이가 없는거같은데\nMultiprocessor: 얘는 CPU가 여러개 달린 하드웨어적인 용어이다\n\n일반적으로 Multitasking 이라 할때는 싱글프로세서를 의미한다.\n\n\n\n\n\n운영체제의 구조 §\n\n\nCPU 스케줄링: CPU time 을 언제 누구에게 줄까?\n\n선입선출? 가장 빨리 끝나는 놈부터?\n\n\n메모리 관리: 메모리를 어떤 방식 프로세스들에게 할당해줄까?\n\n메모리를 어떻게 쪼개서 프로세스에게 할당할까?\n만일 메모리가 부족한 경우에 누군가를 디스크로 내보내야 한다면 누구를 내보낼까?\n\n\n파일 관리: 파일들을 디스크에 어떻게 저장해서 어떻게 읽을까?\n\n하나의 덩어리로 저장? 잘라서 저장?\n읽을때는 들어온 요청의 순서대로? 아니면 디스크 헤드랑 가장 자까이 있는 놈부터?\n\n\n입출력 관리: 속도도 느리고 제각각인 입출력장치랑 어떻게 상호작용할까?\n\nInterrupt 방식을 사용 → I/O 작업을 CPU가 계속 신경쓰는 게 아닌 작업이 끝났을 때 인터럽트를 걸어서 그때서야 CPU가 신경쓰도록 하는 방식\n\n\n"},"originals/os.bahn.ewha.kocw.net/02.-System-Structure-&-Process-Execution":{"title":"02. System Structure & Process Execution","links":[],"tags":[],"content":"\n\n                  \n                  이화여자대학교 컴퓨터공학과 반효경 교수님의 &quot;운영체제 (KOCW)&quot; 강의를 필기한 내용입니다. \n                  \n                \n\n\n\n                  \n                  다소 잘못된 내용과 구어적 표현 이 포함되어 있을 수 있습니다. \n                  \n                \n\nSystem Structure §\n\n\nCPU + Memory = Computer\n나머지 디스크 키보드 등은 IO Device 라 부른다.\nMemory 는 CPU 의 작업공간이라 할 수 있음 → Instruction들을 하나씩 메모리에서 읽어다 실행시키게 됨 → PC가 메모리의 주소를 가리키기 때문\n\nCPU의 유일한 업무는 PC가 가리키는 Instruction을 가져와서 실행시키는 것 밖에는 없다.\n\n\nDevice controller: 각 device들을 관리하는 작은 CPU같은놈\n\nDevice controller 는 제어정보를 위한 Control register와 Status register 도 추가적으로 가진다\n또한 정보를 임시적으로 저장하기 위한 Buffer 도 존재함 → Local buffer\n\n이 Local buffer 에는 CPU(근데 대부분 DMA Controller) 가 접근해서 IO처리가 끝난 데이터들을 가져온다.\n\n\n근데 이제 Device controller 가 실행해야 되는 Instruction은 어떤 형태로 제공되느냐\n니가 많이 들어봤던 펌웨어 가 이러한 역할을 해준다 → 펌웨어가 약간 디바이스의 OS라 할 수 있는거지\nDevice driver: 컨트롤러가 하드웨어였다면 얘는 소프트웨어다 → 각 장치별 처리 루틴을 담은 OS 의 코드 일부분\n\n펌웨어는 실제로 디바이스 컨트롤러가 실행하는 Instruction이고 Device Driver 는 CPU가 실행하는 디바이스를 관리하기 위한 Instruction 이라는 차이가 있더라\n\n\n\n\nMode bit: 현재 실행중인 Instruction이 User mode 인지 Kernel mode 인지를 저장하는 플래그\n\n일반 사용자 프로세스가 시스템적으로 중요한 작업을 직접 할 수 없도록 하드웨어적으로 막아놓음\n0: 모니터(커널, 시스템) 모드 → 보안을 해칠 수 있는 중요한 명령어(Previleged instruction)들을 수행할 때\n1: 사용자 모드 → 일반 사용자 프로세스가 사용할 수 있는 안전한 명령어\nOS로 전환되기 전에는 해당 플래그가 0으로 바뀌고 다시 사용자 모드로 가기 전에는 1로 바뀐다.\nMode bit 이 1일때는 특정 프로세스의 메모리 공간밖에 접근할 수 없고 0일때는 모든 메모리 공간에 접근할 수 있다더라\n\n\nInterrupt line: IO 등의 인터럽트들이 들어오는 통로\n\nCPU는 메모리랑만 작업하고 그 외의 것들에는 관여하지 않는다\n따라서 IO 등의 작업이 필요할 경우에는 해당 작업을 Device controller 등에게 위임한 뒤 다시 메모리에 있는 Instruction들을 실행한다.\n만일 Device controller 가 작업을 마치게 되면 그때 인터럽트를 걸게 되는데\nCPU는 Instruction 하나를 실행한 이후 매번 Instuction line 을 체크해서 들어온 인터럽트가 있는지 확인하고\n인터럽트가 있으면 해당 인터럽트를 먼저 처리하게 된다\n얘는 소프트웨어적으로 큐형식으로 작동한다기보다는 하드웨어적 버스로 구성되어 전기신호를 보냄으로써 인터럽트가 걸리게 하는거 같다 → 근데 확실하지는 않음\n\n\nTimer: 프로그램의 CPU time을 재는 타이머\n\n프로그램이 IO 등을 만나면 이거때문에 더이상 해당 프로세스에서는 작업하지 못하므로 제어권이 딴놈에게 넘어가지만\n만일 IO가 안일어나면 이놈만 CPU를 잡아먹고있는 Monopolize 가 발생한다\n따라서 Context switching 이 일어나기 전에 Timer를 설정해놓고 실행하다가 타이머가 종료되면 Timer 인터럽트를 걸어 딴놈으로 옮겨갈 수 있도록 함\n\n\nDMA(Direct Memory Access): IO 디바이스에 의한 인터럽트는 생각보다 빈번하게 발생하기 때문에 매번 CPU에 인터럽트를 걸면 경장히 비효율적이다.\n\n따라서 저 DMA라는 놈이 중간다리 역할을 하게 되는데\n이름에서부터 알 수 있듯이 얘도 CPU와 마찬가지로 메모리에 접근할 수 있다.\n따라서 인터럽트가 발생할때마다 CPU대신 이놈이 메모리에 적재를 해주고\n몇 바이트 수준이 아닌 블럭 단위의 좀 많이 데이터가 모이면 그때 한번에 인터럽트를 걸어서 CPU가 알 수 있도록 해준다.\n근데 메모리에 CPU랑 DMA가 같이 접근하게 되면 동기화 문제가 발생하기 때문에\nMemory controller 가 마치 세마포마냥 접근을 중재해주게 되는 것이다.\n\n\n\nTrap, Syscall, Exception §\n\n프로세스는 IO 등의 커널 함수가 필요하면 직접 실행하거나 OS가 먼저 해주는게 아니라 프로세스가 OS에 요청하는 식으로 작동한다.\n왜냐면 사용자 프로그램이 실행되고 있을때는 Mode bit 이 1이기 때문에 권한이 없어 메모리의 커널 영역으로 점프하지 못하기 때문\n따라서 일반적인 함수나 분기, 반복과는 다른 방식으로 작동한다.\n사용자 프로세스는 커널 함수를 요청하기 위해 일종의 인터럽트를 걸어 해당 함수가 실행될 수 있도록 하는데 → 이런 인터럽트를 거는 과정 덕분에 Mode bit 이 0으로 바뀔 수 있고 따라서 커널 영역의 Previleged Instruction들을 실행할 수 있더라.\n이렇게 사용자 프로세스가 커널 함수를 호출하는 것을 Syscall(System call) 이라고 한다.\n사용자 프로세스가 인터럽트 비스무리한걸 거는 경우가 한가지 더 있는데 바로 어떤 값을 0으로 나누려 하는 경우 등의 Exception 이 발생했을 때이다.\nSyscall하고 Exception을 합쳐서 사용자 프로세스가 거는 인터럽트 비스무리한걸 Trap 혹은 Software Interrupt 이라고 하더라\nSyscall 또한 어찌보면 사용자가 요청하는 커널 함수이기때문에 올바른 요청이냐에 대한 검증이 선행된다.\n그니까 대략 이런식으로 움직임 → IO 의 경우 예시임\n\nIO가 필요할 때 프로세스(A)는 해당 기능을 호출한다. (Syscall - Software Interrupt)\nOS가 CPU를 차지하며 해당 Device controller 에게 일을 시킨다.\n다른 프로세스(B)로 CPU가 전환\nIO 작업이 끝나면 해당 Device controller 에 의해 IO 인터럽트 발생 (Interrupt - Hardware Interrupt)\n그러면 DMA가 Device 에 있던 Buffer에서 데이터를 가져다가 메모리에 적재하고 즉당한 시점에 CPU에 인터럽트를 건다\nCPU 가 다시 OS로 전환되며 해당 인터럽트를 처리\nIO 인터럽트때문에 멈춰있던 프로세스(B)로 CPU가 넘어오며 진행 → 무조건은 아니고 일반적으로는 거렇다더라\nIO를 요청한 프로세스(A)로 CPU가 넘어오며 다시 작업 진행\n\n\n\nInterrupt Handling §\n\nInterrupt Service Routine: 얘는 특정 인터럽트가 걸렸을때 실행되는 Instruction 모음이다. = 해당 인터럽트를 처리하는 커널 함수\nInterrupt Vector Table: 얘는 위의 ISR들에 대해 인터럽트 번호-ISR 주소(위치) 를 매핑시켜놓은 테이블이다\n\n이것 덕분에 특정 인터럽트가 발생했을 때 그걸 처리하는 ISR이 어느 위치에 있는 지 알 수 있게 되고 해당 ISR 이 실행되게 되는 거다.\n\n\n\nSynchronous, Asynchronous IO §\n\n\n얘는 뭐가 좋고 뭐가 나쁘고가 아니고 걍 구현방식의 차이인데\n먼저 Synchronous IO 는 IO요청을 한 다음에 해당 IO가 끝날때까지 요청한 프로세스는 기다리다가 IO 인터럽트가 걸리면 그제서야 다시 프로세스가 재개되는 방식이고\nAsynchronous IO 는 끝날때까지 기다리지 않고 요청하는 작업을 끝내자마자 요청한 프로세스로 돌아갔다가 나중에 IO 인터럽트가 걸리면 데이터를 가져와서 계속 일하는 방식이다.\n일반적으로는 Synchronous 의 경우에는 읽기 작업에 많이 사용된다 → (보통은) 데이터를 읽어들인 다음에 그 데이터를 가지고 계속 작업하는 것이 순리이므로\n그리고 Asynchronous 는 쓰기 작업에 많이 사용된다 → (보통은) 데이터를 화면이나 디스크에 쓴 다음에는 프로세스에서 해당 데이터를 쓸 일이 많지 않기 때문\n물론 뭐 정해진건 아니다 → 읽기 요청도 Asynchronous 로 구현하거나 쓰기 요청도 Synchronous 로 할 수도 있다\n\nImplementation of Synchronous IO §\n\nSynchronous IO 는 구현방법이 2가지 인데 보통 후자의 방법으로 많이 한다.\n먼저 첫번째는 IO가 끝날때까지 Busy waiting을 하는 방법이다 → 즉, IO가 끝날때까지 CPU가 해당 프로세스와 함께 대기하는 방법\n\n하지만 당연하게도 이 방법은 비효율적이다\n비싼 자원인 CPU가 놀고 있다는 점에서도 그렇고\nIO가 하나 걸리면 딴거를 못하니까 IO 요청도 한번에 하나밖에 못하기 때문\n\n\n그래서 두번째 방법은 해당 프로세스로 CPU time 을 주지 않는 방법이다\n\n이렇게 하면 해당 프로세스가 어차피 실행되지 않기 때문에 자동으로 대기상태가 되는 효과가 있고\nCPU가 다른 프로세스로 옮겨가기 때문에 CPU time을 낭비하지도 않으며\n다른 IO syscall이 들어와도 일 시켜놓고 또 다른 프로세스로 넘어가면 되기 때문에 IO 요청도 여러개 받을 수 있다.\n\n\n\nIO Instruction Type §\n\n\nIO를 하는 방법에는 두가지가 있는데\n위 그림에서 왼쪽이 일반적인 상황으로 메모리에 접근하는 명령어와 디바이스에 접근하는 명령어(Special Instruction)가 별개로 존재하여 사용하는 방식과\n오른쪽처럼 각 디바이스들을 메모리처럼 취급해서 확장 메모리 주소를 붙인 다음 메모리 접근 명령어를 그대로 사용하는 방식이 있다 → 이 방식을 Memory Mapped IO 라고 부르더라\n\nMemory Hierarchy §\n\n\nPrimary: 레지스터, 캐시(S-Memory), 램(DRAM) → 빠르고 비싸고 (따라서 용량이 작고) 휘발성이고 바이트단위로 접근이 가능해서 CPU가 실행시킬 수 있고 (Executable)\nSecondary: 느린 대신 싸고 (용량 크고) 비휘발성이고 바이트단위가 아닌 섹터 등의 단위로 접근할 수 있어서 CPU는 실행시킬 수 없다.\n메모리에 접근하는것도 10개 정도의 Instruction이 소요되기에 이를 보완하기 위해 캐쉬 메모리를 두는거고\n재사용의 목적으로 처음에 접근할때는 물론 오래 걸리지만 한번 접근해서 캐쉬에 올려놓고 나서는 그 다음부터는 아래까지 안내려가도 되기 때문에 훨씬 빠르게 사용할 수 있음 → 이런거를 캐싱이라 한댄다.\n\nProgram Execution §\n\n\n뭐 옛날에 배운것처럼 프로그램이 메모리에 올라가서 실행가능한 상태가 되었을때는 프로세스라고 하는데\n메모리에 올라가기 전에 한 단계를 더 거친다 → Virtaul Memory 할당\n이건 다음과 같은 식으로 이루어진다\n\nVirtual Address Space 할당 → 프로세스 하나마다 주소 0부터 시작하는 가상의 메모리 공간을 할당하고\n\n이 가상 메모리 공간에는 많이 들어봤던 Code, data, heap-stack 이 드간다\n\n\nAddress translation 을 통해서 가상 메모리 공간을 실제 메모리에 할당한다.\n\n근데 가상 메모리 공간이 실제 메모리에 할당될때는 연속적인 공간에 할당되는게 아니고 쪼개서 당장 필요한것만 메모리에 올려놓고 나머지는 디스크의 Swap area 로 다시 내려놓았다가 사용할 일이 있으면 그때 가져오는 방식으로 작동함\n\n\n\n\n\nKernel §\n\n\nKernel 이 차지하는 메모리 공간도 당연히 Code, Data, Stack의 형태로 구성된다\n뭐 Code 에는 자원 관리나 인터럽트 처리하는 코드 및 편의기능이 드가있고\nData 에는 CPU, 메모리, 디스크를 관리하기 위한 자료구조들과 PCB가 적재된다\n\n다음시간에 배우겠지만 프로세스가 하나 실행되면 해당 프로세스의 상태같은 제어정보를 담기 위한 자료구조가 하나씩 생성되며 이들을 PCB(Process Control Block)이라고 부른다.\n\n\nStack에는 위 그림에서는 좀 헷갈리게 이름이 붙여져 있지만 결국에는 커널도 여러개의 함수로 구성되어있기 때문에 커널 함수가 실행될때마다 스택에 쌓이게 된다\n\n즉, 어떤 프로세스가 어떤 함수를 호출하면 그때 스택에 ~프로세스가 호출한 ~함수 의 형식으로 스택이 쌓이게 되는 거다\n따라서 커널은 프로세스별로 스택을 만들어서 특정 프로세스가 호출한 커널 함수 정보를 관리한다.\n\n\n\nFunctions §\n\n함수는 고급 언어 수준 뿐만 아니라 어셈블리어에서도 존재한다 → 어떤 언어로 코드를 작성해도 컴파일 이후에는 결국에는 걔네들이 다 함수형태로 바뀌게 된댄다\n함수에는 세가지 분류가 있다\n사용자 정의 함수: 말그대로 사용자가 정의한 함수\n라이브러리 함수: 사용자가 정의한 게 아니고 다른 사람이 라이브러리로 만들어놓은 함수\n\n라이브러리 함수도 당연히 컴파일 이후 바이너리에 함께 들어있게 되고\n따라서 프로세스가 된 이후에 일반 프로세스의 Code 공간에 존재하게 된다.\n\n\n커널 함수: 커널 프로그램의 함수\n\n이 함수를 호출하는게 결국에는 Syscall 인거고\nSyscall 이 필요한 이유를 좀 다른 관점에서 보면 Virtual memory에서 Address space 는 프로세스마다 갖고 있고 Address jump는 해당 Address space 내에서만 가능하기 때문에 다른 Address space 에 속하는 커널 함수로는 점프할 수가 없어서 Syscall 이 필요한 거라고 볼 수도 있다.\n\n\n\n\n\n그래서 프로세스 하나와 커널과의 상호작용만 보면 (Time sharing 같은거 다 빼고)\n사용자 함수나 라이브러리 함수가 실행될때는 해당 프로세스의 주소공간에서 User mode(Mode bit 1) 로 작동하다가\nSyscall이 발생하면 Kernel mode(Mode bit 0) 으로 변경되어 커널 함수가 실행되는 것이다.\n"},"originals/os.bahn.ewha.kocw.net/03.-Process":{"title":"03. Process","links":[],"tags":[],"content":"\n\n                  \n                  이화여자대학교 컴퓨터공학과 반효경 교수님의 &quot;운영체제 (KOCW)&quot; 강의를 필기한 내용입니다. \n                  \n                \n\n\n\n                  \n                  다소 잘못된 내용과 구어적 표현 이 포함되어 있을 수 있습니다. \n                  \n                \n\nProcess and Context §\n\n일단 뭐 프로세스는 Program in Execution 을 의미한다.\n여기서 이제 프로세스의 문맥(Context) 가 중요한데\n이건 특정 프로세스가 어느 한 시점에 어떤 상태인지를 나타내는 정보라고 생각하면 된다\n다음과 같이 세개로 분류해볼 수 있다\n\nCPU 상태( → 레지스터 상태): PC 나 다른 레지스터에 어떤 값이 들어와있었나\nMEM 상태: Code 부분에는 어떤 것들이 담겨있고 Data의 변수들에는 어떤 값이 들어있고 Stack에는 어떤 함수 호출이 쌓여있는지 등등\nKernel 상태: 프로세스를 제어하기 위한 정보인 PCB에 어떤 값이 들어가있는지 혹은 해당 프로세스가 어떤 Syscall 을 호출해서 어떤 커널 함수들이 Kernel stack에 쌓여있는지\n\n\n프로세스의 상태 관리가 필요한 이유는 Context switching 때문이다 → Time sharing등을 위해 실행중인 프로세스를 바꾸려면 실행중이던 프로세스의 상태를 완전히 백업하여 백업된 Context 를 다시 불러왔을 때 이전에 실행중이던 상태 그대로 재개되어야 하기 때문시\n\n5 State Process Model §\n\n\n우리 빵효경 교수님은 5 State Process Model 로 설명을 한다\n5가지 상태중에 중요한건 가운데에 3가지인 Running, Ready, Waiting(Blocked) 인데\nRunning 은 CPU를 할당받아 한창 실행이 되고 있는 상태고\n\n위 그림에서 보이는것처럼 Running 상태가 끝나는건 3가지 경우가 있다\n타이머 종료\n프로그램 종료 (Exit)\n이벤트 발생 → 자발적 CPU 반납\n\n\nReady 는 다른건 다 준비됐고 CPU만 할당받으면 다시 실행할 수 있는 상태를 의미한다\n\n얘는 위 그림에서 보이는것처럼 프로세스가 생성되어 CPU만 받으면 되는 상태까지 오거나\nRunning 상태였다가 Timer 가 끝나서 CPU를 뺏겼거나\nBlock 을 먹었다가 Event 가 종료되어 다시 준비완료\n\n\n그리고 Blocked 는 Syscall 등의 이벤트에 의해 지금 당장 CPU를 할당해주어도 실행할 수 없는 상태를 의미한다\n\n여기서 이벤트는 IO 같은 Syscall 혹은 Interrupt 일 수도 있지만\n조리퐁같은 경우에도 이벤트가 된다 → 다른 쓰레드가 이미 공유 데이터를 쓰고있어서 현재 프로세스가 접근할 수 없는 경우에도 이벤트라고 말할 수 있다\n\n\n\nPCB (Process Control Block) §\n\n\n앞에서도 누누이 말했듯 커널에 저장되어 프로세스를 제어하기 위한 정보가 PCB (Process Control Block) 이고\n4개정도의 파트로 이루어진다\nOS 관련 정보에는 (1) 프로세스의 상태 (2) PID (3) 스케줄링 정보와 (4) 우선순위 정보가 드가고\nCPU 관련 정보에는 PC를 포함한 레지스터의 값들\nMEM 관련 정보에는 해당 프로세스의 Code, Data, Stack 의 위치 (메모리 주소) 정보\nFile 관련 정보에는 이놈이 열어놓은 파일 디스크립터들이 드간다.\n\nContext Switch §\n\n\nContext Switch 는 한 프로세스에서 다른 프로세스로 CPU 를 바꿔주는 과정인데\n다음과 같은 과정을 거친다\n\nA(중고)의 문맥 (PC, Reg, MEM 등) 을 전부 A의 PCB에 때려넣는다\nB(새삥)의 PCB에서 이전 문맥을 가져다가 전부 세팅을 한다\n\n\n근디 중요헌건 Context switch는 사용자 프로세스가 교체되었을 때에만 Context switch 라고 한다는 것이다.\n아래 그림 봐봐라\n\n\n\n(1) 같은 경우에는 Interrupt 혹은 Syscall 이 일어나서 ISR 이나 Syscall func 가 싱행된 후에 다시 원래 프로세스로 돌아왔다 → 이경우에는 Context switch 라고 하지 않는다 이거야\n\n일반적으로는 굳이 프로세스 교체가 필요하지 않은 이벤트의 경우에는 Context switch가 일어나지 않고 원래놈으로 되돌아온다\n\n\n하지만 (2) 같은 경우에는 이건 못참지\n\nTimer interrupt의 경우에는 의도적으로 프로세스를 교체하기 위한 거고\nIO 의 경우에도 오래걸리기 때문에 거의 대부분 프로세스가 Block 된다\n즉, 이런 경우에는 원래의 프로세스로 되돌아갈 수 없기 때문에 새로운 프로세스가 굴러들어오고, 따라서 Context switch 가 되었다고 표현한다.\n\n\n이건 사용자 → 커널 전환보다 사용자 → 사용자 전환이 훨신 오버헤드가 크기 때문이랜다\n\n예를들면 캐쉬를 비우는 Cache flush 의 경우에는 사용자 → 커널 전환에서는 완전 싹 비울 필요가 없기 때문에 이거로 인한 오버헤드가 현저히 적어진댄다\n\n\n\nProcess Queues §\n\n\n프로세스의 상태를 관리하기 위해 위처럼 Process Queue 가 소프트웨어적으로 구성되어있다\n하지만 프로세스는 선입선출로 관리되지 않기 때문에 아마 우선순위큐로 구현이 되어있지 않을까 싶은데\n어쨋든 대기 상태 큐인 Ready Queue하고\nBlock 먹은 이후 각 디바이스에서의 처리를 기다리는 Device Queues 가 있댄다\n마지막으로 모든 프로세스를 담는 Job Queue 가 존재한다\n그리고 큐에 들어가는 각각의 원소들은 PCB로\n아까 PCB의 그림에서 보면 PCB에 Pointer field 가 존재하는데 이걸 통해 각각의 PCB 들이 큐의 형태로 연결되어있게 된댄다\n\nScheduler §\n\nShort term scheduler(→ CPU Scheduler): 어떤 프로세스에게 CPU를 줄지 말지 결정하는 스케줄러\n\n즉, Ready queue 에 있는 프로세스들 중 어떤넘을 Running 으로 바꿀지 결정한다\n프로세스는 아주 찰나의 순간만 CPU를 잡고 있다가 쫒겨나므로 매우 빈번하게 Scheduling 이 발생한다 → 따라서 이름이 Short term 인 것임\n\n\nLong term scheduler(→ Job Scheduler): 어떤 프로세스에게 메모리를 줄지 말지 결정하는 스케줄러\n\n즉, New 상태에 있는 프로세스들 중 어떤놈을 Ready로 바꿀지 결정한다\n이건 Multiprogramming level 을 결정하는데에 아주 중요한 역할을 한다\n\n메모리에 너무 적은 프로세스가 올라가면 CPU가 비효율적이고 반대로 너무 많은 프로세스가 올라가있어도 중요한 부분이 메모리에 올라가지 못하기 때문에 IO가 너무 많이 일어나 CPU가 비효율적으로 작동한다\n따라서 Degree of Multiprogramming 을 제어할 필요가 있고 이것 제어하는게 Long term scheduler 인 것\n\n\n하지만 요즘의 Time sharing system에서는 사용하지 않고 일단 전부 Ready 로 박는다 → 이유는 바로 다음의 스케줄러가 존재하기 때문\n\n\nMedium term scheduler(→ Swapper): 어떤 프로세스를 스왑할지 결정하는 스케줄러\n\nLong term scheduler 가 사용되지 않는 대신 이놈이 Degree of Multiprogramming을 관장한다.\n즉, 프로세스 몇개가 메모리에 올라갈지 결정하는 것을 메모리에 적재될 시점부터 정하는게 아니고 적재한 다음에 결정하겠다는 소리임\n얘를 이용해 일단 프로세스가 생성되면 무적권 Ready 박고 Multiprogramming level 이 너무 높아지면 이 스케줄러를 이용해 프로세스 몇개를 디스크로 방출시켜서 낮추는 방식으로 작동한다더라\n\n\n\n7 State Process Model §\n\n\n일단 먼저 주의할점은 맨 위에 Running 두개는 사실 하나의 상태라는 점이다\n\n프로세스의 상태를 논할때는 무적권 사용자 프로세스를 말하지 커널 프로세스의 경우에는 상태의 개념이 없다\n그래서 만일 사용자 프로세스가 작동하다가 이벤트가 발생해 커널 함수가 실행되는 경우에도 여전히 Running 상태라고 말하며 위의 그림에서는 그걸 Monitor mode 라고 구분지어준 것 뿐임\n\n\n그래서 Medium term scheduler 가 등장하면서 새로운 상태인 Suspended ~ 가 등장하게 됐는데\n이건 Blocked 랑은 완전히 다른 개념이다 → Blocked 의 경우에는 IO 등의 이벤트가 완전히 해결되고 난 뒤에는 다시 Ready 로 돌아오지만\nSuspended 의 경우에는 메모리에서 아주 퇴출된 상태를 의미하며 이놈이 메모리로 다시 올라오기 위해서는 Medium term scheduler 에 의해 다시 머리채가 잡혀 올라와야 한다는 것\n그래서 메모리에 올라와있을 때를 Active 라고 하고 스왑되어 나갔을때는 Inactive 라고 한다\n\nThread §\n\n\n쓰레드 별거 없다\n만약 동일한 코드를 이용해 여러개의 프로세스를 실행시키면 각 프로세스마다 주소공간하고 PCB가 생성되게 될텐데\n이렇게 하면 Data 나 Code 등의 부분은 중복해서 메모리에 올라가므로 아주 비효율적이다 이말이야\n그래서 Thread 라는 것을 생각해내게 됐는데\n이건 Lightweight process 로 하나의 프로세스 내에서 별개의 작업을 하려고 할 때 공유할 수 있는 부분은 최대한 공유하고 분리해야만 하는 것만 분리시키자는 개념이다\n\n전통적인 프로세스를 Heavyweight process 라고도 하며 이것은 쓰레드를 한개만 갖고 있는 프로세스와 동일하다\n\n\n그래서 일단 분리해야 되는 부분은 다음과 같다\n\nPC: 당연히 쓰레드들마다 코드의 다른 부분을 실행시키고 있을 것이기 때문에 PC는 각 쓰레드마다 하나씩 있어야 할 것이다\nReg set: 마찬가지로 레지스터의 값들도 쓰레드마다 다를게 분명하다\nStack: 쓰레드들마다 코드의 다른 부분을 실행할 것이기 때문에 호출된 함수들도 다를것이고, 따라서 Stack 도 별도로 관리되어야 할 것이다\n\n\n즉, PCB 의 구조에서 프로세스의 실행과 관련된 부분인 CPU 관련 필드, 그리고 주소 공간에서 스택이 쓰레드마다 갖고 있게 되는 것이다.\n\n\n공통적인 부분은 프로세스 내에서 위의 세개를 뺀 나머지 (Data, Code 등등) 이며 이 부분을 Task 라고 하더라\n쓰레드의 장점은 크게 네가지가 있다\n\nResponsiveness: 하나의 프로세스 내에서 하나의 쓰레드가 블락먹어도 다른 쓰레드가 계속 일을 할 수 있기 때문에 사용자에게 더 빠른 응답을 제공해 줄 수 있다.\nResource Sharing: 쓰레드는 최소한만 생성하고 대부분 공유하기 때문에 메모리를 덜먹는다\nEconomy: 이건 위의 장점에 의해 산출되는 장점인데 대부분 공유하기 때문에 Creating 혹은 Context Switching 을 할 때 일반적인 프로세스를 생성하거나 갈아치울때보다 현저리 적은 오버헤드를 가진다\nUtilization of MP(Multi Processor) Architectures: 프로세서가 여러개인 경우 쓰레드를 여러 프로세서에서 실행시켜 병렬작업이 가능해진다.\n\n\n쓰레드 종류는 Kernel Thread 와 User Thread 가 있댄다\n\nKernel Thread 는 쓰레드의 존재를 커널도 알고 따라서 Context switch 도 커널에 의해 이루어지지만\nPOSIX 같은 User Thread 는 쓰레드의 존재를 커널은 모르고 라이브러리 형태로 제공된다 → 따라서 Context switch 등도 프로세스 딴에서 관리된다.\n\n\n"},"originals/os.bahn.ewha.kocw.net/04.-Process-Management":{"title":"04. Process Management","links":[],"tags":[],"content":"\n\n                  \n                  이화여자대학교 컴퓨터공학과 반효경 교수님의 &quot;운영체제 (KOCW)&quot; 강의를 필기한 내용입니다. \n                  \n                \n\n\n\n                  \n                  다소 잘못된 내용과 구어적 표현 이 포함되어 있을 수 있습니다. \n                  \n                \n\nProcess Lifecycle §\nProcess Creation §\n\n프로세스는 (Init process 가 아니라면)부모프로세스가 반드시 존재하고, 부모 프로세스를 복제하는 방식으로 자식 프로세스가 생성된다\n\n뭐 init process 는 알다시피 sysvinit 이나 systemd 등이 있겠제\n따라서 프로세스는 init process 를 루트로 하는 트리형식의 계층 구조를 형성하게 된다\n이렇게 자식을 복제하는 것은 fork() 시스템 콜을 이용해 수행할 수 있다\n프로세스 생성이 시스템 콜인 이유는 사용자 프로세스가 직접 하기에는 어려운 작업이고 아마 보안상의 문제도 껴있을거다\n\n\n자식 프로세스도 당연히 프로세스니까 자원을 할당받을텐데 여기에는 몇가지 정책(모델) 이 존재한다\n\n자원을 부모와 공유하여 운영체제로부터 받지 않는 모델\n자원을 부모와 일부만 공유하고 나머지는 운영체제로부터 할당받는 모델\n부모와 공유하지 않고 전부 운영체제로부터 할당받는 모델\n\n\n생각해보면 자식 프로세스는 부모 프로세스와 독립적인 프로세스이기 때문에 자원을 공유하지 않고 운영체제로부터 할당받는게 맞는 거 같지만\nUNIX 같은 경우에는 효율성을 위해 일단 부모와 공유하는 방식을 사용한다\n\n뭔소리냐면\nfork() 과정에서 부모꺼를 복제한다고 했자네\n근데 자원을 복제하면 결국에는 똑같은게 두개가 생길거 아님 → 뭐 프로세스의 Data, Code, Stack 같은게 똑같은게 두개가 생기게 될거아님\n이게 좀 낭비같은거야\n그래서 UNIX 에서는 일단 자원을 복사하지 않고 공유하고 있다가 부모랑 달라지면 그때 복사를 하는 방식을 이용한다\n즉 Lazy copy 라고 말할 수 있는거임 → 이걸 Copy-On-Write (COW) 라고 표현한다\n\n\n\n\n복제하는 과정을 좀 더 자세히 살펴보면\n\n일단 fork() 가 불려지면 운영체제는 PID 를 제외한 부모의 모든 것(뭐 PCB나 바이너리 같은것들 → 앞에서 배운 Process context 에서 PID 만 뺀거라고 생각해도 된다)을 복사한다\n그리고 자식 프로세스에게 새로운 주속 공간을 할당한다\n\n\n하지만 fork() 만 존재한다면 모든 프로세스가 부모랑 같은 작업만 할거 아니냐 → 그래서 (일반적으로는) fork() 이후에 exec() 이라는 시스템 콜이 사용된다\n\nexec() 은 기존에 존재하던 프로세스에 새로운 프로그램을 덮어 씌우는 시스템 콜인데\n일반적으로 fork() 이후에 exec() 시스템 콜이 호출되는 식으로 프로그램이 프로세스로 변환된다\n따라서 프로세스의 생성은 fork → exec 이 두가지 단계를 거친다고 할 수 있다\n물론 저 두 단계는 독립적이어서 fork() 만 해서 부모를 복사하기만 할 수도 있다\n\n\n\nProcess Execution §\n\n자식 프로세스가 생성되었을 때 부모가 취할 수 있는 동작은 두가지가 있는데\n\n그냥 별개의 프로세스로써 자식이랑 같이 공존하며 실행되거나\n자식 프로세스가 종료되어야 진행이 가능한 경우에는 block 을 먹어서 자식이 종료될때까지 기다릴 수도 있다 (wait() 시스템 콜)\n\n\n\nProcess Termination §\n\n프로세스가 자발적으로 종료될 때에는 일단 exit() 시스템 콜을 이용한다\n\n프로그래밍 언어에서 지원하는 라이브러리(뭐 예를 들면 go 의 os 같은 거) 를 통해 exit() 시스템 콜을 호출할 수도 있고\n아니면 프로그램 코드가 종료되면 (뭐 마지막 중괄호가 닫히는 등의 main() 함수가 리턴되는 시점) exit() 시스템 콜이 작동되도록 컴파일러가 넣어주는 등의 방법 등\n여러가지의 방법이 있지만 어쨋든 자발적으로 프로세스가 종료될때는 exit() 시스템 콜이 무조건 호출된다\nexit() 이 호출된 다음에는 자식이 부모에게 output data 를 보내게 되고\n프로세스의 각종 자원들이 운영체제한테 반납된다\n\n\n그럼 자발적이지 않은 경우는 무엇이냐 → 부모 프로세스가 자식의 수행을 종료시키는 경우가 존재한다\n\n뭐 자식이 너무 많은 자원을 먹어서 한계치를 넘어선 경우랄지\n자식이 하고 있는 작업이 불필요해진 경우랄지\n부모가 종료된 경우랄지\n\n운영체제는 (init process 가 아닌 이상) 부모가 없는 프로세스가 존재하도록 하지 않는다\n따라서 부모가 종료될때는 자식을 전부 종료시킨 후에 종료되도록 하는데\n자식한테 또 자식이 있을 경우에는 또 그 자식이 종료되는 절차를 밟을 거 아님\n그래서 부모가 종료될때는 자식을도 단계적으로 종료되게 된다\n\n\n\n\n\nProcess Syscall §\nFork §\n\n\n이제 이건 fork() 시스템 콜에 대한 C 언어 코드 예제인데\n일단 흔히 나올 수 있는 질문 중 하나는 부모 코드에 fork() 가 있는데 부모 코드를 그대로 복제하면 자식 코드에도 fork() 가 있을 것이고 그럼 자식도 fork() 를 해서 자식이 무한대로 생성되는거 아니냐 인데\n\n아니다\n앞서 fork() 를 할 때에는 Process context 전체를 복사한다고 했자네\n따라서 PC 값도 복사가 되기 때문에 자식 프로세스는 프로그램의 맨 처음부터 실행하는 것이 아니라 fork() 가 호출된 바로 다음 시점부터 실행된다\n\n\n그럼 PC 값이 복사된다면 부모와 자식은 같은 Physical memory address 의 instruction 을 실행하게 될까\n\n그것도 아니다\n왜냐면 PC 에 들어가는 값은 Virtual memory address 이기 때문에 PC 값이 같긴 하지만 실제로 참조하는 Address space 는 다르고 따라서 다른 Physical memory address 를 참조하게 된다\nPhysical memory address 에 대해서 CPU 는 알지 못한다 → CPU 가 사용하는 주소는 전부 Logical (뭐 Virtual address랑 거의 같다고 재철소장님이 그랬으니까) 이고 이걸 Physical address 로 바꾸는 건 CPU 가 아니라 Memory Management Module 이 BASE 랑 LIMIT 레지스터 값을 이용해 수행한다\n참고\n\nDifference between program counter in the executable and program counter in the main memory\nDoes the program counter generate the virtual address or a physical address in a cpu?\n\n\n\n\n부모와 자식이 코드가 동일하다면 어떻게 다른 작업을 하도록 할 수 있을 까?\n\nC 언어에 구현되어 있는 fork() 함수는 호출했을 때에 PID 값을 반환하도록 되어 있는데\n생각해보면 호출된 이후에는 부모와 자식 이렇게 프로세스가 두개가 생기므로 fork() 함수는 각 프로세스에게 두번 PID 값을 반환한다고 생각할 수 있다\n근데 이때 부모 프로세스에게는 양수 정수값을 반환하는 방식으로 생성된 자식 프로세스의 PID 값을 반환해주고\n자식 프로세스에게는 0을 반환해준다\n이걸 이용해서 하나의 코드로 부모와 자식에게 다른 일을 시킬 수 있다\n\n\n\nExec §\n\n\nexec() 시스템 콜은 위에서 말한 것처럼 새로운 프로그램으로 현재 프로세스를 덮어씌우는 것을 수행한다\n그래서 C 언어에서는 이 시스템 콜을 위해 execlp() 라는 함수를 제공해주는데\n뭐 문법은 위에 사진 보던가 너가 찾아봐라\n\n3번째 인자부터 해당 프로그램의 Args 들이 들어가는데\n마지막 인자는 null string 을 넣어서 닫아줘야 한다네\n\n\n중요한건 exec() 시스템 콜을 호출하고 나면 새로운 프로그램이기 때문에 main() 함수의 맨 첫번째 줄부터 실행하게 된다\n\n어찌보면 당연한 얘기지 → 프로그램이 새로 프로세스가 됐는데 당연히 Process context 는 없는게 맞지\n\n\n다음은 exec() 을 실행하고 난 뒤에는 원래의 프로그램으로 되돌아오지는 못한다는 거다\n\n이것도 당연한 얘기다 → 기존의 프로세스가 새로운 프로그램으로 덮어씌워졌으니까 원래꺼는 없어지고 되돌아오지도 못하는게 인지상정\n\n\n마지막으로는 fork() 와 exec() 은 별개의 시스템 콜이기 때문에 fork() 없이도 exec() 을 호출하는게 가능하다는 거다\n\n따라서 이때에는 자식이 생기는 방식이 아니라 그냥 나 자신이 새로 태어나게 된다\n\n\n\nWait §\n\n\nwait() 은 별거 없다\n그냥 부모가 자식 끝날때까지 block 되어 기다리게 하는 시스템 콜이 wait() 이다\n\n그래서 wait() 이 호출되면 커널은 해당 프로세스를 block 시켰다가\n해당 프로세스의 자식 프로세스가 모두 종료되면 다시 ready 로 바꾼다\n\n\n위 그림은 그냥 예제고 → 읽어보면 걍 별거 없다\nwait() 을 이용한다고 할 수 있는 프로그램이 Shell 프로그램이다\n\n결국에는 쉘의 경우에도 입력한 프로그램을 시키는 것이기 때문에 해당 프로그램을 자식 프로세스호 실행시키고 wait 하다가 끝나면 다시 커서를 깜빡이게 하는 방식으로 활용한다.\n\n\n\nInter Process Conmunication (IPC) §\n\nIndependent Process: 프로세스는 기본적으로 각자 독립적으로 작동하고 다른 프로세스에 영향을 끼지지 않는다 (뭐 부모 - 자식 관계는 예외)\nCooperating Process: IPC 를 이용하면 다른 프로세스의 수행에 영향을 끼칠 수 있다\n\nMessage Passing §\n\n\nIPC 의 분류중에 Message Passing 은 일단 커널을 브로커로 해서 메시지를 전달하는 방법 (Message System)이다\n\n따라서 공유 메모리나 공유 변수 등을 사용하지 않는다\n\n\n뭐 인터페이스가 두가지 종류가 있다네\n\nDirect Communication\n\n\n얘는 수신 프로세스를 명확하게 명시하는 방식이랜다\n\n\nIndirect Communication\n\n\n그리고 얘는 수신 프로세스를 명시하지 않고 메일박스(?) 나 포트번호 등을 이용해서 메시지를 간접적으로 전달하는 방식이라네\n\n\n\n\n\nShared Memory §\n\n\n얘는 말 그대로 공유 메모리를 커널로부터 할당받아서 두 프로세스가 메모리에 존재하는 데이터를 공유하는 방법이다\n얘도 당연히 커널의 힘을 빌려야 하긴 하지만 Message Passing 의 경우에는 매번 커널에 의존하지만 얘는 공유 메모리를 처음 매핑할때만 커널에 의존한다는 차이점 정도가 존재한다\n\nThread §\n\n뭐 쓰레드는 프로세스가 아니기 때문에 IPC 라고 하기에는 좀 뭐하지만\nThread 끼리는 메모리를 공유하기 때문에 통신이 아주 간편맨하댄다\n"},"originals/os.bahn.ewha.kocw.net/05.-CPU-Scheduling":{"title":"05. CPU Scheduling","links":[],"tags":[],"content":"\n\n                  \n                  이화여자대학교 컴퓨터공학과 반효경 교수님의 &quot;운영체제 (KOCW)&quot; 강의를 필기한 내용입니다. \n                  \n                \n\n\n\n                  \n                  다소 잘못된 내용과 구어적 표현 이 포함되어 있을 수 있습니다. \n                  \n                \n\n\n\n                  \n                  문서를 이전하는 과정에서, 이미지 데이터가 유실되어 문서상에 보이지 않습니다. \n                  \n                \n\nCPU, IO Burst §\n(사진 사라짐)\n\n프로세스가 실행되는 것은 (일반적으로) CPU 를 연속적으로 사용하다가 IO 때문에 Block 되있거나 하는 것의 반복이라고 할 수 있는데 이때\nCPU 를 연속적을 사용하는 구간을 CPU Burst 라고 하고\nIO 때문에 Block 먹어있는 구간을 IO Burst 라고 한다\n\nCPU, IO Bound Job §\n(사진 사라짐)\n\n이 그래프는 한 CPU Burst 의 실행시간과 CPU Burst 의 빈도를 나타낸 그래프인데\n보면 왼쪽은 CPU Burst 의 기간이 아주 짧고 빠르게 반복된다\n\n이것은 잦은 IO 에 의해 CPU Burst 와 IO Burst 가 빈번하게 반복되는경우인데\n이러한 Job (== Process) 들을 IO Bound Job 이라고 한다\n일반적으로 IO 는 표준 입출력 등의 사람과 Interaction 하기 위한 것이 많기 때문에 사람과의 interaction 이 잦은 경우에 IO Bound Job 이 된다\n\n\n그리고 오른쪽의 Job 들은 한번 CPU 가 잡으면 오랫동안 사용하여 CPU Burst 의 기간이 길고 따라서 빈도는 낮아지는데 (당연히 한번 잡았을때 길게 쓰니까 빈도는 작아질 수 밖에 없다)\n\n이러한 Job 들을 CPU Bound Job 이라고 부르고 일반적으로 연구 등의 목적을 위해 복잡한 계산을 오랫동안 진행하는 Job 들인 경우가 많다\n\n\n뭐 그래서 IO Bound Job 이 사람과의 상호작용이 잦기 때문에 CPU Bound Job 이 너무 CPU 를 오래 잡고 있어 사용자 Response 가 늦어지는 일이 벌어지지 않게 하기 위해 CPU Scheduling 을 한다네\n\nScheduler, Dispatcher §\n\nCPU Scheduler: Ready 인 프로세스 중에 Running 상태가 될 프로세스를 고르는 커널 프로세스\n\nCPU Scheduling 이 발생하는 경우는 대표적으로 다음과 같다\n\n프로세스가 CPU Time 을 _자진 반납_하는 경우 (Non-preemptive)\n\nIO 등의 사유로 CPU Time 을 반납 (Running → Blocked)\nProcess Terminate 로 CPU 반납 (Running → Exit)\n\n\n프로세스가 CPU Time 을 빼앗기는 경우 (Preemptive)\n\nTimer interrupt (Running → Ready)\nIO 가 완료된 프로세스의 우선순위가 현재 프로세스보다 높을 때 (Blocked → Ready)\n\n\n\n\n\n\nDispatcher: 현재의 프로세스에서 CPU Scheduler 가 고른 프로세스로 Context switch 를 진행하는 커널 프로세스\n\nCPU Scheduling §\n고려사항들 §\n\nReady 상태인 (CPU Burst 에 진입한) 프로세스 중 누구한테 CPU 를 줄 것인가?\n한번 CPU 를 받았으면 끝날때까지 계속 쓰게 할 것인가 아니면 중간에 뺏을 것인가?\n\nPerformance Index (Measure, Criteria) §\n\nPerformance Index 는 성능을 측정하는 척도를 의미하는데 아래와 같이 두개로 나눌 수 있다\nSystem Performance: 얼마나 시스템의 자원을 효율적으로 굴리느냐\n\nCPU Utilization: 얘는 CPU 이용률을 의미한다\n\n“률” 이기 때문에 당연히 전체에서 부분이 차지하는 비율을 의미하는데\nCPU Utilization 에서는 “시간” 을 기준으로 측정한다 → 즉, 시스템이 작동하고 있는 전체 시간 중에서 CPU 가 일을 하고 있는 비율이 얼마냐\n\n\nThroughput: 얘는 처리량을 의미하는데\n\nCPU Utilization 이 시간에 대한 값이었다면 얘는 양을 나타내는 값이다\n즉, 단위시간동안 처리한 작업의 양을 의미하는 것\n\n\n\n\nProgram Performance: 사용자가 느끼는 프로세스의 빠릿빠릿함\n\nTurnaround Time: 한번의 CPU Burst 동안 걸린 시간의 총합\nWaiting Time: 한번의 CPU Burst 동안 CPU 가 할당되지 않고 기다린 시간의 총합\nResponse Time: 한번의 CPU Burst 동안 CPU 가 처음으로 할당되기까지 걸린 시간\n그냥 이렇게만 보면 멍게소리인가 싶을텐데 한번의 CPU Burst 에 어떤 일들이 일어나는지를 생각해보면 알기 쉽다\n\n먼저 IO Burst 가 끝나고 CPU Burst 에 들어온 시간이 0초라고 해보라\n그러고 바로 CPU 를 할당받을 수 있으면 기모찌하겠지만 인생이란게 그렇게 녹록하지 않아서 4초에 CPU 를 할당받아서 작업을 했다라고 치면\n첫 4초가 Response Time 이 되는 것\n\n즉, CPU Burst 가 시작된 이래로 얼마나 빨리 CPU 가 할당되었느냐 이다\n\n\n그리고 만일 Preemptive 로 스케줄링되어 6초에 CPU 를 빼앗겼다가 7초에 다시 받고 10초에 IO 가 생겨서 IO Burst 로 빠져나갔다고 치면\n일단 기다린 시간을 다 합쳐보면 맨 처음 4초에 중간에 1초 기다렸으니까 5초 → 이게 Waiting Time 이 된다.\n\n즉, Waiting Time 은 처음의 Response Time에다가 CPU Burst 중간중간에 쉬는시간까지 다 합친 값이다\n\n\n그리고 전체적으로는 10초가 걸렸으므로 이게 Turnaround Time 이 된다\n\n즉, Turnaround Time 은 IO Burst 사이의 시간 간격이라고 생각할 수도 있고\nWaiting Time 에다가 CPU Time 까지 합친 시간이라고 생각할 수도 있다\n\n\n\n\n\n\n\n스케줄링 알고리즘 분류 §\n\nPreemptive: 하나의 프로세스가 너무 오래 CPU 를 차지하지 못하도록 중간에 뺏는 알고리즘\nNon-preemptive: 하나의 프로세스가 CPU 를 먹으면 IO 등의 이슈가 없는 한 계속 들고 있게 하는 알고리즘\n\nPriority Scheduling §\n\n그냥 단순하게 생각해서 우선순위에 따라 다음 프로세스를 선택하는 방식인데\nPreemptive 의 경우에는 당연히 우선순위가 높은 놈이 들어오면 빼앗고 Non-preemptive 의 경우에는 높은놈이 들어와도 빼앗지 않았다가 그놈이 끝나면 그 다음 우선순위 높은놈에게 주는 방식\n주의할 점은 일반적으로 UNIX(Linux) 계열에서는 숫자가 낮을수록 우선순위가 높은 거다\n\nSyslog 생각해봐도 emerg 가 0 이잖여\n\n\n\nStarvation, Aging §\n\n이후에 등장하는 스케줄링 알고리즘에서 Starvation 이라는 말이 나오는데 이건 알고리즘의 부작용으로 특정 프로세스가 CPU 를 할당받지 못하는 상황을 의미한다\n\n만일 우선순위가 낮은 프로세스의 경우 해당 프로세스보다 우선순위가 높은 프로세스가 항상 존재한하면 해당 프로세스는 영원히 CPU 를 받지 못한다.\n\n\n이를 해결하기 위한 방법으로 Aging 이 있는데 이건 우선순위가 낮은 프로세스가 오랫동안 CPU 를 할당받지 못하면 자연스럽게 우선순위가 높아지게 하는 방법을 의미한다\n\nScheduling Algorithms §\nFCFS (First Come First Serve) §\n\n\n뭐 별거 없다 → 선입선출\n\n당연히 무지성 선입선출이기 때문에 Non-preemptive 이다\n\n\n\n얘의 문제점은 예상하시는 바와 같이 앞에 오래걸리는 놈이 하나 버티고 있으면 그 뒤에 있는 놈들은 다 지연된다는 거다\n\n\n예를 들어 아래의 두개 상황을 비교해봐라\n(사진 사라짐)\n\n첫번째의 경우는 앞에 오래걸리는 애가 있어서 평균 Waiting Time 이 17이나 되지만\n만일 앞에 짧은 애가 오면 평균 Waiting Time 은 3으로 거의 1/6 이 줄어든다\n이렇듯 FCFS 에서 앞에 오래걸리는 한놈때문에 나머지가 전부 지연되는 것을 Convoy effect 라고 하더라\n\n\n\nSJF (Shortest Job First) 혹은 SPN (Shortest Process Next) §\n\n\nFCFS 를 보면서 ‘그럼 제일 적게걸리는 놈한테 먼저 주면 되는거 아닌가’ 라고 생각했으면 이게 그거다\n\n\n즉, CPU Time 이 제일 적은 놈에게 우선적으로 CPU 를 주는 것\n\n\n얘는 이제 Non-preemptive 하고 Preemptive 두가지 버전이 있는데\n\n\nNon-preemptive SJF 은 일단 CPU 를 CPU Time 이 적은놈한테 주되 이걸 빼앗을 수는 없으므로 더 짧은 놈이 들어와도 일단은 현상유지하는 것이고\n\n\nPreemptive SJF 는 CPU Time 이 더 짧은 놈이 오면 CPU 를 빼앗아서 이놈한테 주는거다\n\n그런데 이때 CPU Time 은 지금 실행중인 놈의 남은 시간과 새로운 놈의 시간을 비교하기 때문에 SRTF (Shortest Remaining Time First 혹은 그냥 SRT) 라고도 부른다\n또한 이 경우는 평균 Waiting Time 이 최소가 되는 것으로 알려저 있다 (Waiting Time Optimal)\n\n똑똑이들이 증명해놨다네\n\n\n\n\n\n뭐 아주 좋아보이지만 아쉽게도 얘도 문제가 있다\n\nStarvation: 눈치챘겠지만 앞에 짧은 애들만 오면 긴놈은 절대로 CPU 를 받을 수 없다.\n그리고 CPU Time 는 사전에 알지 못하는 값이다\n\n\n\nCPU Time 을 예측하는 방법으로 Exponential Averaging 이라는게 있는데 다른 분야에도 등장하는 개념이라니까 간단하게 짚고 넘어가면\n\nt(n) 은 n 번째의 CPU Time 이고\n따우(n) 은 n 번째의 CPU Time 예측값일때\nExponential Averaging 의 공식은 다음과 같다\n\n(사진 사라짐)\n\n이 식을 전개해보면\n\n(사진 사라짐)\n\n가 되는데 상수 a 가 0 &lt; a &amp;&amp; a &lt; 1 이기 때문에 제곱할수록 작아진다\n즉, 제일 최근의 값은 1에 그나마 가까우므로 가중치가 높아지고 옛것으로 갈수록 0에 가까워지니까 가중치가 낮아지는 것으로도 생각할 수 있는 것\n찾아보니까 이 개념은 머신러닝에서도 사용되는듯\n\n\n\nRR (Round Robin) §\n\n지겹다 지겨워 그냥\n알다시피 무지성 돌라돌라골림판이다\n\n즉, 일정한 Time Quantum 으로 CPU Time 을 난도질해서 해당 시간이 끝나면 다른 프로세스에게 또 Time Quantum 만큼의 CPU Time 만 주는 방법이다\n\n\n얘는 다양한 CPU Time 을 가지는 프로세스들이 섞여있을 때 맛집이 된다\n\n스케줄링 할 때 CPU Time 을 예측할 필요도 없고\nCPU Time 크든 작든 돌아가며 CPU 가 할당되므로 Starvation 에 빠질 우려도 없다\n심지어 CPU Time 길수록 Waiting Time 도 늘어나는 합리성까지 보여준다\n\n\n하지만 CPU Time 이 전부 똑같을때는 똥된다\n\n단순히 FCFS 를 생각해도 100 짜리 4개가 들어오면 100, 200, 300, 400 의 시간에 프로세스가 종료되지만\nRR 로 돌리면 다같이 돌다가 전부 400에 프로세스가 종료되기 때문\n이렇듯 CPU Time 이 같은 경우에는 비효율적이나 일반적인 상황이 아니기 때문에 대부분 효율적이다\n\n\nTime Quantum 이 극단적이 되면 어찌되는가\n\nq 가 너무 커지면 FSFC 와 다를바가 없어서 비효율적이고\nq 가 너무 작아지면 Context Switching 의 오버헤드가 너무 커져 비효율적이 된다\n\n\n\nMulti-level Process Queueing §\n\n위에 소개된 알고리즘들은 전부 프로세스를 큐 하나에 때려박고 적당히 꺼내서 CPU 를 할당해주는 방식이었다면\n지금부터 소개되는 알고리즘들은 프로세스를 우선순위에 따라 여러 큐에 넣어서 관리하는 방법들이다\n이러한 방식은 일반적으로 큐마다 다른 스케줄링 알고리즘을 사용하고\n상위 우선순위의 큐가 비지 않아 Starvation 이 발생할 것을 방지하기 위해 CPU 를 차등 분배한다\n\n즉, 상위 우선순위의 큐가 비어야만 하위 큐로 가는게 아니고\n우선순위가 높은 큐에는 CPU 를 더 많이 할당해주고 낮은 큐에는 적게 할당하는 식으로 유도리있게\n\n\n\nMulti-level Queue §\n(사진 사라짐)\n\n얘는 프로세스의 특성에 따라 우선순위를 두고 우선순위에 따른 큐를 여러개 만들어 상위 우선순위의 큐가 비어야 그 아래 큐에 있는 프로세스에게 CPU 가 할당될 수 있도록 하는 Preemptive 한 방식이다\n\n위 그림은 그렇게 여러개의 큐를 나누어놓은 예시 그림임\n\n\n하지만 이러한 방식은 우선순위 변동의 유연함이 없어 문제가 있더라\n\nMulti-level Feedback Queue (Feedback Scheduling) §\n(사진 사라짐)\n\n얘는 RR 방식의 큐를 여러개 준비해놓고 아래로 내려갈수록 Quantum 값이 증가하게 해놓은 다음\n처음 들어온 프로세스는 제일 우선순위가 높은 큐에 넣고\nQuantum 내에 끝내지 못하면 그 아래 큐로 내려보내는 방식이다\n이 방식은 SJF 알고리즘에서 CPU Time 을 알 수 없다는 단점을 해결했다고 볼 수 있는데 왜냐면\n일단 처음에는 CPU Time 을 알 수 없으니까 Quantum 을 짧게 하는 대신 우선순위를 높여주고\n해당 Quantum 내에 끝내지 못했다면 Quantum 을 좀 더 오래 가져가는 대신 우선순위가 낮아지게 함으로써\n자연스럽게 빨리 끝나는 프로세스는 우선순위가 높아지고 오래걸리는 프로세스는 우선순위가 낮아지는 효과를 볼 수 있다\n\n그 외의 여러가지 CPU Scheduling 방식들 §\nMulti-processor Scheduling §\n\n프로세스들이 고만고만한 경우 (Homogeneous): 하나의 큐에 다 때려넣고 여러개의 CPU 들이 나눠먹거나\n\n반드시 특정 CPU 에서만 실행되어야 하는 경우에는 걔를 위해 CPU 하나를 할당해주고 나머지를 나눠먹거나\n\n\nCPU 부하 분산 (Load Sharing): 놀고 있는 CPU 가 없도록 하기 위해 공동 큐를 두거나 CPU 마다 큐를 구성\nSymmetric Multiprocessing: CPU 들이 동등한 자격으로 스스로 스케줄링 하는 방식\nAsymmetric Multiprocessing: 얘는 마스터를 선출하는거마냥 스케줄링 작업을 전담하는 CPU 를 하나 선출해서 나머지는 이놈이 스케줄링한거에 그냥 따르는 방식\n\nReal Time Scheduling §\n\n일반적으로 Real Time 이라고 하면 주어진 시간 내로 반드시 종료되야 하는 것을 의미하는데\nHard Real Time: 말 그대로 → 시간 내에 반드시 끝나야 함\nSoft Real Time: 얘는 시간 내에 끝나야 하긴 하지만 그렇지 못한다고 해서 큰 문제가 생기지 않는 경우를 의미하는데\n\n그냥 일반적인 스케줄링에서 우선순위를 좀 높여주는 방식으로 해결 가능하고\n동영상 재생이 대표적인 예시다 → 1초에 24프레임 이상을 로드해야되지만 그렇지 못했다고 해서 지구멸망은 아닌\n\n\n\nThread Scheduling §\n\nUser Thread 의 경우: Local Scheduling 이라고 부르는데 OS 는 이 쓰레드의 존재를 모르기 때문에 POSIX Thread 같은 라이브러리들이 직접 해준다\nKernel Thread 의 경우: Global Scheduling 이라고 부르는데 Short-term scheduler 가 프로세스 스케줄링하는것과 동일하게 해준다\n\nAlgorithm Evaluation §\n\n\nQueueing Model: 아래 그림처럼 입력 데이터(Arrival Rate) 를 확률분포로 주고 이때의 출력(Service Rate) 를 이용해 성능을 측정\n\n다분히 이론적이어서 많이는 사용하지 않는댄다\n\n(사진 사라짐)\n\n\nImplementation &amp; Measurement: 실제로 코드를 작성해 커널을 빌드하여 성능 측정\n\n\nSimulation: 커널 전체가 아닌 해당 알고리즘만 코드로 작성해 실제 OS에서의 작동 방식을 분석해 만든 입력 데이터 (Trace) 를 이용한 방법\n\n"},"originals/os.bahn.ewha.kocw.net/06.-Process-Synchronize":{"title":"06. Process Synchronize","links":[],"tags":[],"content":"\n\n                  \n                  이화여자대학교 컴퓨터공학과 반효경 교수님의 &quot;운영체제 (KOCW)&quot; 강의를 필기한 내용입니다. \n                  \n                \n\n\n\n                  \n                  다소 잘못된 내용과 구어적 표현 이 포함되어 있을 수 있습니다. \n                  \n                \n\n\n\n                  \n                  문서를 이전하는 과정에서, 이미지 데이터가 유실되어 문서상에 보이지 않습니다. \n                  \n                \n\nConcurrency, Race Condition §\n(사진 사라짐)\n\n일반적으로는 위 그림처럼 데이터를 저장하는 곳하고 연산하는 곳하고는 분리되어 있으며\n연산하는 곳에서 데이터를 읽어들여 연산한 다음 저장하는 방식으로 작동되는데\n\n(사진 사라짐)\n\n위 그림처럼 동일한 데이터에 여러 연산이 접근하게 되면 문제가 생길 수 있다\n이렇게 여러 연산이 하나의 데이터에 동시에 접근하는 문제를 Concurrency Problem, 동시성 문제 라 부르고\n동시성 문제가 발생하게 되는 상황을 연산간 경쟁한다는 의미로 Race Condition 이라고 부르더라\n이를 해결하기 위해서는 데이터의 접근 순서를 제어하는 로직이 필요하고 이런걸 Process Synchronization (프로세스 동기화) 라고 한다.\n\nCommon Race Condition Situations §\n\n커널 데이터\n\n\n일반 프로세스의 경우에는 자신만의 메모리 공간이 있기 때문에 동시성 문제 잘 발생하지 않지만\n\n\n커널의 경우에는 여러 프로세스가 Syscall 등을 이용해 공유할 수 있고\n(사진 사라짐)\n\n위 처럼 프로세스가 Syscall 을 해 커널모드에서 실행되다가 타임아웃이 난 후에 다른 프로세스로 넘어갔다가 여기서도 Syscall 을 걸어 커널 데이터를 변경하는 경우에 동시성 문제가 생길 수 있다\n이때는 커널모드일때는 CPU 를 Preempt 하지 못하게 하고 커널모드가 끝나야 빼앗을 수 있게 함으로써 해결할 수 있다\n\n\n\n커널모드에서 작업을 하다가 인터럽트가 걸리면 하던걸 멈추고 또 다른 커널 작업인 인터럽트 핸들링을 하게 되므로 이런 경우에도 문제가 생긴다\n(사진 사라짐)\n\n위 그림이 그 예시인데\n이러한 경우는 커널 모드 실행중일때는 인터럽트가 걸리지 않게 하는 방식으로 해결할 수 있다\n\n\n\n\n공유 메모리, 쓰레드\n\n일반 프로세스에서 동시성 문제가 발생하는 경우 중 제일 흔한거는\n프로세스 간 공유 메모리를 할당받았거나\n멀티쓰레드 프로그래밍을 할 때이다\n\n멀티쓰레드의 경우에는 쓰레드 간 메모리가 공유되기 때문에 동시성 문제가 생길 수 있다\n\n\n\n\n\nHandling Concurrency §\nCritical Section §\n(사진 사라짐)\n\n코드 상에서 공유 데이터 공간에 접근하는 부분을 Critical Section 이라고 한다.\n그리고 Entry / Exit Section 에서 Critical Section 에 들어가는 프로세스들을 Lock 을 거는것처럼 관리하게 된다.\n별로 중요한건 아니지만 공유데이터에 접근하지 않는 부분을 Remainder Section 이라고 한다\n\n충족해야 할 조건들 §\n\nMutual Exclusion: 상호 배제 → 하나의 프로세스가 Critical section 에 들어가 있으면 다른 프로세스는 들어가서는 안된다\nProgress: 현재 Critical section 에 들어가있는 프로세스가 없다면 Critical section 에 들어가고자 하는 프로세스는 거기 에 들어갈 수 있어야 한다.\nBounded Waiting: 다른 프로세스가 Critical section 에 들어가 있어서 나머지 프로세스가 대기해야 한다면, 대기 시간이 유한해야 한다.\n\n즉, 하나의 프로세스가 들어가서 빠져나오지 않는 상황이 발생하거나\n특정한 몇개의 프로세스만이 Critical section 에 접근하여 나머지 프로세스들은 들어갈 수 없는 상황 (뭐 예를 들면 두개의 프로세스가 번갈아가며 들어가 다른 프로세스가 접근할 수 없는 상황) 이 되면 안된다.\n\n\n\nAlgorithm 1 §\n\n프로세스 0 번의 코드가 다음과 같고\n\n// global variable: int turn = 0;\ndo {\n\twhile (turn != 0);\n\tcritical_section();\n\tturn = 1;\n\tremainder_section();\n} while (1);\n\n프로세스 1 번의 코드가 다음과 같다면\n\n// global variable: int turn = 0;\ndo {\n\twhile (turn != 1);\n\tcritical_section();\n\tturn = 0;\n\tremainder_section();\n} while (1);\n\n일단 Mutual Exclusion 은 달성할 수 있다\n\n0번 프로세스는 turn 이 0이 될 때까지 기다리고\n1번 프로세스는 turn 이 1이 될 때까지 기다리기 때문에\n두놈이 같이 들어가는 상황은 막을 수 있음\n\n\n하지만 Progess 는 안된다\n\n왜냐면 한놈이 Critical section 에 들어가는 것이 다른놈에게만 의존하기 때문에 한놈이 안드가게 되면 다른놈도 들어가지 못한다\n가령 1번이 들어가려면 turn 값이 1이어야 되는데 0번이 들어가지 않은 경우에는 turn 값이 0으로 남아있어 1번이 절대 들어가지 못하게 된다\n\n\n\nAlgorithm 2 §\n\n이번에는 프로세스 0 번의 코드가 다음과 같고\n\n// global variable: boolean flag[2] = {false, false};\ndo {\n\tflag[0] = true;\n\twhile (flag[1]);\n\tcritical_section();\n\tflag[0] = false;\n\tremainder_section();\n} while (true);\n\n프로세스 1 번의 코드가 다음과 같다면\n\n// global variable: boolean flag[2] = {0, 0};\ndo {\n\tflag[1] = true;\n\twhile (flag[0]);\n\tcritical_section();\n\tflag[1] = false;\n\tremainder_section();\n} while (true);\n\n이번에도 Mutual Exclusion 은 달성할 수 있다\n\n서로의 flag 가 올라가있는지 체크하면서 대기하기 때문에\ncritical_section() 에는 한번에 한놈만 드갈 수 있다.\n\n\n그리고 Algorithm 1 에서의 문제점도 해결할 수 있다\n\n프로세스가 연속해서 들어가고싶어할 경우에도 상대방의 flag 는 계속 false 이기 때문에 문제되지 않는다\n\n\n하지만 이 경우에도 Progress 가 해결되지는 않는다\n\n그건 Context switch 때문인데\n프로세스 0번이 flag[0] 을 true 로 바꾼 다음에 Contect switching 이 일어나서\n프로세스 1번이 flag[1] 을 true 로 바꾼다면\n지금 아무도 드가있지 않지만 둘 다 true 로 되어 있어 아무도 들어가지 못하는 상황이 됨\n\n\n\nAlgorithm 3 (Peterson’s algorithm) §\n\n이번에는 프로세스 0 번의 코드가 다음과 같고\n\n// global variable: int turn = 0;\n// global variable: boolean flag[2] = {false, false};\ndo {\n\tflag[0] = true;\n\tturn = 1;\n\twhile (flag[1] &amp;&amp; turn == 1);\n\tcritical_section();\n\tflag[0] = false;\n\tremainder_section();\n} while (true);\n\n프로세스 1 번의 코드가 다음과 같다면\n\n// global variable: int turn = 0;\n// global variable: boolean flag[2] = {0, 0};\ndo {\n\tflag[1] = true;\n\tturn = 0;\n\twhile (flag[0] &amp;&amp; turn == 0);\n\tcritical_section();\n\tflag[1] = false;\nremainder_section();\n} while (true);\n\n보면 Algorithm 1 과 Algorithm 2 를 합쳐놓은 느낌인데 이 경우에는 모든 경우의 수를 만족할 수 있다\n하나하나 따져보는 건 나중에 시간 많을때 해보고 그냥 느낌만 잡자면\nwhile 문에서 상대방의 flag 를 검사하기 때문에 일단 두명이 같이 드가는 것은 불가능하고\n만일 Algorithm 2 에서처럼 둘 다 flag 가 올라가있는 경우에는 turn 값을 이용해 한놈은 드갈 수 있게 해주는 방식이다\n하지만 이 방식은 작동은 하지만 다소 비효율적이다 → Busy Waiting 이기 때문\n\n어쨋든 while 문을 통해 계속 CPU 와 메모리를 먹으면서 기다리기 때문에\n불필요한 자원소모라고 할 수 있기 때문\nSpin lock 이라는 용어도 알아두라\n\n\n\nHardware approach (Atomic solution) §\n\n값을 읽는 작업과 쓰는 작업을 하나의 instruction 에서 처리할 수 있다면 동시성 문제가 좀 쉽게 해결될 수 있다\n간단하게 생각해서 아래와 같은 코드로 두 프로세스가 돌아간다고 할 때\n\n// global variable: boolean is_lock = false;\ndo {\n\twhile (is_lock);\n\tis_lock = true;\n\tcritical_section();\n\tis_lock = false;\n\tremainder_section();\n} while (1);\n\n\n두번째 줄에서 is_lock 값을 확인해서 false 가 나와 세번째 줄을 수행하려 할 때\n\nContext switch 가 일어나 다른 프로세스가 is_lock 값을 바꾸고 Critical section 으로 들어간다면\n다시 돌아왔을 때 is_lock 을 확인하지 않고 Critical section 으로 들어가기 때문에 두 프로세스가 모두 Critical section 에 진입하게 된다\n\n\n\n하지만 값을 읽는것과 쓰는 작업을 한번에 해주는 instruction 가 있다면 위와 같은 상황은 해결이 된다\n\n아래의 코드에서 test_and_set() 함수는 변수의 값을 읽는 것과 값을 true 로 바꾸는 작업을 한번에 한다고 가정하면\n\n(사진 사라짐)\n\n즉, test_and_set() 함수가 변수의 값을 읽고 false 라면 true 로 바꾸고 true 여도 true 로 바꾸는 작업을 한다면\n\n\n\n// global variable: boolean is_lock = false;\ndo {\n\twhile (test_and_set(is_lock));\n\tcritical_section();\n\tis_lock = false;\n\tremainder_section();\n} while (1);\n\n그럼 2번째 줄을 수행한 다음 Context switch 가 일어나도 is_lock 값이 이미 바뀌어있기 때문에 다른 프로세스는 Critical section 으로 드가지 못한다\n\nSemapore §\n\nSemapore 은 동시성 처리를 위한 추상 자료형이다\n\n즉, Semapore 는 Property 와 Method 만 정의되고 구현방식은 정의되지 않는다\n\n\nSemapore 의 Property 는 다음의 특징을 가져야 한다\n\nInteger: 셀 수 있는 정수값을 가진다\nSemapore 의 정수값은 자원에 접근할 수 있는 프로세스의 개수를 나타낸다\n즉, 0보다 클 경우에는 해당 프로세스가 자원에 접근할 수 있다는 것을 나타내고 그렇지 않다면 대기해야 한다는 것을 의미한다\n\n\n그리고 Method 는 다음과 같으며 해당 Method 들은 Atomic 하게 작동한다\n\nP: Semapore 의 값이 0보다 클 경우에는 1을 감소시키고 그렇지 않을 경우에는 대기한다.\n\nP 연산의 경우에는 Lock 을 거는 작업을 담당한다\n1을 감소시키기 때문에 접근할 수 있는 프로세스의 개수를 하나 감소시켜 한 자리를 차지하는 셈인 거고\n0 이하일 경우에는 대기하기 때문에 자리가 없을 경우 대기하는 것으로 해석할 수 있다\n\n\nV: Semapore 의 값을 1 증가시킨다\n\nV 연산의 경우에는 Lock 을 해제하는 작업을 담당한다\n즉, 1을 증가시키기 때문에 Lock 을 풀고 한 자리를 내어놓는 것으로 해석할 수 있다\n\n\n\n\n\nImplementation 1: Busy waiting (Spin lock) §\n\nGo 로 대충 수도코드 적어보자고\n일단 struct\n\ntype Semapore struct {\n\tcount int\n}\n\n그리고 method 두개\n\nfunc (s *Semapore) P() {\n\tfor s.count &lt;= 0 {}\n\ts.count--\n}\nfunc (s *Semapore) V() {\n\ts.count++\n}\n\n뭐 간단하죠?\n근데 위에서 언급한것처럼 이 경우에는 반복문이 돌면서 기다리기 때문에 CPU와 메모리의 낭비이다\n\nImplementation 2: Block wakeup (Sleep lock) §\n\n\n이번에는 대기할때 반복문을 도는게 아니고 아예 프로세스의 상태를 Blocked 상태로 바꿔버리는 방법이다\n(사진 사라짐)\n\n\n즉, 위 그림과 같이 IO 큐 등의 여러 큐들에 추가적으로 공유데이터에 접근하는 것을 기다리는 큐를 하나 더 둬서 대기시킨다\n\n\n그래서 보통 아래처럼 구현한다\n(사진 사라짐)\n\nPCB 큐를 둬서 하나의 세마포에 대기하도록 함\n\n\n\n간단히 수도코드 적어보자고\n\n\n세마포는 다음처럼 생각할 수 있음\n\n\ntype Semapore {\n\tvalue int\n\twait  []int\n}\n\n그리고 다음처럼 메소드들을 구현할 수 있을 것이다\n\nfunc (s *Semapore) P() {\n\tif s.value--; s.value &lt; 0 {\n\t\ts.wait = append(s.wait, os.Getpid())\n\t\tos.Block() // Pseudo method `Block()`\n\t}\n}\nfunc (s *Semapore) V() {\n\tif s.value++; s.value &lt;= 0 {\n\t\tos.WakeUp(s.wait[0]) // Pseudo method `WakeUp(pid int)`\n\t\ts.wait = s.wait[1:]\n\t}\n}\n\ns.value++; s.value &lt;= 0 의 이유: 일단 1을 더해줬는데도 0과 같거나 작다는 것은 1을 더해주기 전에는 0보다 작았었기 때문에 대기하던 프로세스가 있음을 의미\n\nBusy-wait vs Block-wakeup §\n\n일반적으로는 Block-wakeup 방식이 더 좋기는 하지만\nBlock-wakeup 방식의 Context switch 에 오버헤드가 존재하기 때문에 Critical section 이 아주 짧은 경우에는 Busy-wait 방식이 오히려 더 좋을 수 있다\n\nSemapore 종류 §\n\nCountable semapore: 값이 2 이상이 될 수 있는 세마포\n\n보통 자원의 수를 세는 용도로 사용됨\n\n\nBinary semapore(Mutex): 값이 0또는 1만이 되는 세마포\n\n프로세스의 Mutual exclusion 을 위해 사용됨\n\n\n\nDeadlock, Starvation §\n\nDeadlock 은 둘 이상의 프로세스가 서로의 이벤트 종료를 기다리고 있는 상황이라고 할 수 있다\n\n그니까 쉽게 말하면 내가 끝나려면 너가 끝나야되는데 너가 끝나려면 내가 끝나야되는 상황\n\n\nStarvation 은 둘 이상의 프로세스가 자기네들끼리만 우선권을 획득해서 일부 프로세스가 우선권을 영원히 획득할 수 없는 상태를 말한다\n이 둘은 그 다음에 나오는 굶주린 소크라테스 보면 딱 이해됨\n\nBounded-Buffer Problem §\n(사진 사라짐)\n\n이 문제는 다음과 같다:\n\n공유 메모리에 있는 버퍼에는 값을 넣을 수 있는 칸이 n 개가 있다 → Bounded-buffer, 유한 버퍼\n여러 Producer 가 값을 생산하여 버퍼의 한 칸에 채워넣는다\n여러 Consumer 는 Producer 가 생산하여 버퍼에 채워넣은 값을 가져가 비운다\n\n\n이 문제에는 다음과 같은 동시성 관리가 필요하다:\n\nProducer 혹은 Consumer 프로세스는 한번에 한놈만 공유 버퍼에 접근해야 한다\n\n만일 그렇지 않은 경우에는 두 Producer 가 한번에 같은 칸에 접근해서 하나의 값이 덮어씌워지거나\n두 Consumer 가 한번에 같은 칸에 접근해서 문제가 되거나 (뭐 같은 값을 두번 가져가거나 null 을 가져가거나 등등)\n\n\nProducer 는 비어있는 칸이 있어야 값을 쓸 수 있고 Consumer 는 채워져있는 칸이 있어야 값을 가져올 수 있다\n\n\n그래서 이 문제에는 세개의 세마포가 사용된다\n\n공유 버퍼에의 접근을 제어할 Mutex\nProducer 입장에서의 자원 관리\n\n즉, 비어있는 칸이 Producer 입장에서의 자원이므로 이것을 관리할 empty_sem 이 하나 필요하다\n\n\nConsumer 입장에서의 자원 관리\n\n즉, 채워져있는 칸이 Consumer 입장에서의 자원이므로 이것을 관리할 full_sem 이 하나 필요하다\n\n\n\n\n따라서 Producer 와 Consumer 는 다음의 과정을 거쳐 작업을 수행한다\n\nProducer\n\n비어있는 칸이 있는지 확인하고 없으면 기다림\n공유데이터에 Lock 을 걺\n데이터 입력\nLock 을 풂\n채워져 있는 칸의 개수를 1 증가시킴\n\n\nConsumer\n\n채워져 있는 칸이 있는지 확인하고 없으면 기다림\n공유데이터에 Lock 을 걺\n데이터를 가져감\nLock 을 풂\n비어있는 칸의 개수를 1 증가시킴\n\n\n\n\n이를 바탕으로 수도코드를 적어보면 다음과 같다\nProducer\n\n/**\n * Shared memory\n * var buf *bufio.ReadWriter\n *\n * Semapores\n * var mutex semapore_t = 1\n * var empty_sem semapore_t = n\n * var full_sem semapore_t = 0\n */\nfunc produce() []byte { /** DO SOMETHING */ }\n \nfunc main() {\n\tfor {\n\t\tvalue := produce()\n\t\tP(empty_sem)\n\t\tP(mutex)\n\t\tbuf.Write(value)\n\t\tV(mutex)\n\t\tV(full_sem)\n\t}\n}\n\nConsumer\n\n/**\n * Shared memory\n * var buf *bufio.ReadWriter\n *\n * Semapores\n * var mutex semapore_t = 1\n * var empty_sem semapore_t = n\n * var full_sem semapore_t = 0\n */\n \nfunc consume(value []byte) { /** DO SOMETHING */ }\n \nfunc main() {\n\tfor {\n\t\tP(full_sem)\n\t\tP(mutex)\n\t\tvar value []byte\n\t\tbuf.Read(value)\n\t\tV(mutex)\n\t\tV(empty_sem)\n\t\tconsume(value)\n\t}\n}\n\n세마포 값은 다음과 같은 이유이다\n\nmutex 의 경우에는 상보배제해야되므로 값이 1이고\nempty_sem 의 경우에는 처음에는 모두 비어있으니까 값이 n 이고\nfull_sem 의 경우에는 처음에는 채워져있는게 하나도 없으니까 값이 0이다\n\n\n그리고 과정을 차근차근 보면\n\n일단 Producer 는 empty_sem 을 하나 먹고 값을 쓰되\n릴리즈 과정에서 empty_sem 을 릴리즈하는게 아니고 full_sem 을 릴리즈해서 1을 증가시킨다\n그럼 Consumer 는 full_sem 을 먹고싶은데 일단은 full_sem 이 0이니까 기다리다가\nProducer 가 full_sem 을 1 증가시키면 그걸 낼름 먹어서 값을 가져온다\n그리고 이번에는 full_sem 을 릴리즈하는게 아니고 empty_sem 을 릴리즈해서 1을 증가시키는 방식\n\n\n\nReaders-Writers Problem §\n\n이 문제는 DB 에서의 동시성 문제에 대한 간략한 예시이다:\n\nDB 에서 값을 읽는 것은 여러개가 접근해도 된다\nDB 에 값을 쓰는 것은 한놈만 접근해야 된다\n\n\n이 문제에서는 다음의 세마포를 사용해 동시성을 관리할 수 있다:\n\nDB 에 배타적으로 값을 write 하기 위한 세마포\nReader 의 개수를 세어서 Reader 가 있는 경우에는 Writer 가 접근하지 못하도록 해야 하는데 이때 Reader 들의 개수를 세기 위한 공유 변수에의 세마포\n\n\n따라서 다음과 같이 수도코드를 작성할 수 있다\nWriter\n\n/**\n * Shared memory\n * var db *bufio.ReadWriter\n * var readCount int = 0\n *\n * Semapores\n * var db_sem semapore_t = 1\n * var rc_sem semapore_t = 1\n */\n \nfunc getValue() []byte { /** DO SOMETHING */ }\n \nfunc main() {\n\tfor {\n\t\tvalue := getValue()\n\t\tP(db_sem)\n\t\tdb.Write(value)\n\t\tV(db_sem)\n\t}\n}\n\nReader\n\n/**\n * Shared memory\n * var db *bufio.ReadWriter\n * var rc int = 0\n *\n * Semapores\n * var db_sem semapore_t = 1\n * var rc_sem semapore_t = 1\n */\n \nfunc useValue(value []byte) { /** DO SOMETHING */ }\n \nfunc main() {\n\tfor {\n\t\tP(rc_sem)\n\t\tif rc++; rc == 1 {\n\t\t\tP(db_sem)\n\t\t}\n\t\tV(rc_sem)\n \n\t\tvar value []byte\n\t\tdb.Read(value)\n \n\t\tP(rc_sem)\n\t\tif rc--; rc == 0 {\n\t\t\tV(db_sem)\n\t\t}\n\t\tV(rc_sem)\n \n\t\tuseValue(value)\n\t}\n}\n\n차근차근 보면\ndb_sem 하고 rc_sem 은 어차피 상호배제를 위한거니까 값이 1이고\n\nWriter 의 경우에는 db_sem 을 잠그는 것 밖에 할게 없다\n하지만 Reader 의 경우에는 rc 를 건들기 위해 아래위로 rc_sem 을 이용하여 한번에 한놈만 접근할 수 있게 하고\n첫 Reader 의 경우에만 db_sem 을 잠그고 마지막 Reader 만 db_sem 을 풀어 이것에 대한 상호배제를 하게 한다\n\n\n하지만 위의 코드는 Starvation 이 일어날 수 있다\n\n왜냐면 Reader 가 다 빠져나간 경우에만 db_sem 이 풀리기 때문에 Reader 가 계속 들어오면 Writer 가 들어올 수 없기 때문\n\n\n\nDining-Philosophers Problem §\n(사진 사라짐)\n\n이건 배부른 돼지보다는 나은 배고픈 소크라테스의 고분분투기를 다룬 문제다\n일단 상황은\n\n소크라테스들이 자리에 앉아 생각을 하다가\n배고프면 자신의 양쪽에 있는 젓가락을 둘 다 잡아 식사를 하고\n이후에 다시 내려놓고 생각을 하는 고달픈 인생이다\n\n\n이 상황을 타개할 수 있는 가장 간단한 해결법은 다음과 같다\n\n왼쪽에 Lock 을 걸고 오른쪽에 Lock 을 걸어서 식사를 하고 차례대로 Lock 을 푸는 것\n\n\n하지만 이것은 다음과 같은 문제가 생긴다\n\nDeadlock: 만약 모든 소크라테스가 왼쪽의 젓가락을 잡으면 아무도 식사하지 못한다\nStarvation: 만약 자신의 양옆에 있는애들이 번갈아서 식사하면 나는 굶어 죽어 배부른 돼지보다도 못하게 된다\n\n\n이것을 해결할 수 있는 방법은 대표적으로\n\n한번에 4명의 소크라테스만 앉게 한다\n옆의 소크라테스를 유심히 보다가 젓가락을 모두 잡을 수 있을 때에만 식사를 한다\n비대칭 → 짝수번째 소크라테스는 오른쪽부터, 홀수번째 소크라테스는 왼쪽부터\n\n\n\nMonitor §\n\n동시성문제는 실행시에 무조건 발생하는 것이 아니라 코드를 잘못 작성했을 때 특정 조건이 맞을때에만 발생하기 때문에\n세마포를 잘못 사용했을 때에 이것을 감지해내기 어렵다\n따라서 개발자 입장에서 실수를 줄일 수 있는 더 상위 추상화가 여러 프로그래밍 언어들에서 지원되는데 이것이 Monitor 이다\n\n(사진 사라짐)\n\n\n그래서 위처럼 구성됨\n\n\n모니터에서는 공유 데이터와 그것에 접근할 수 있는 유일한 방법인 메소드를 묶어 하나의 class 로 구현하게끔한다\n\n\n구현한 뒤에는 Monitor 에는 한번에 하나의 프로세스만이 접근할 수 있도록 알아서 제어되기 때문에 Mutex 의 사용이 불필요하다\n\n즉, 명시적으로 공유데이터를 잠그거나 푸는 로직을 작성하지 않아도 된다는 소리임\n모니터에 접근한 프로세스가 종료되거나\n뒤에 나오는 Condition 에 의해 Block 되는 등의 방식으로 모니터 사용이 끝나면 다른 프로세스가 모니터에 들어와서 사용하게 된다\n\n\n\n그리고 모니터에는 Condition 기능도 제공되는데 이것은 Countable semapore 를 대체하는 기능이다\n\nBinary semapore(Mutex) 의 경우에는 모니터에서 알아서 해주니까 별다른 로직이 필요 없었지만\n상호배제가 아닌 자원 개수 관리를 위한 Countable semapore 를 위해서 Condition 이 제공된다는 것이다\n\n\n\nCondition 은 다음과 같은 두가지 기능을 가진다\n\nCondition.wait(): 얘는 현재의 프로세스를 Block 시키고 해당 Condition의 큐에 추가한다\nCondition.signal(): 얘는 해당 Condition의 큐에서 프로세스 하나를 꺼내 Ready 로 바꾼다\n\n자고 있는 프로세스가 없을 경우에는 아무 작업도 하지 않는 로직도 signal() 에 내부적으로 구현되어 있다\n\n\n즉, 하나의 Condition 변수는 하나의 줄을 의미하고 두가지 기능으로 프로세스를 줄세우거나 줄에서 꺼내는 작업을 할 수 있는 것이라 생각하면 된다\n다만 세마포의 P와 V는 자원의 개수를 값으로 가지고 필요한 자원이 있는지 없는지는 내부적으로 확인하는 대신\nCondition 을 사용할 때에는 필요한 자원이 있는지 없는지에 대한 로직은 개발자가 알아서 작성하고 재우거나 깨우는 것만 Condition 변수를 이용한다는 차이점이 있다\n\n\n\n즉, Condition 을 통해 자원이 존재하지 않을 때 프로세스를 재우고 자원이 생기면 깨우는 로직을 손쉽게 구현할 수 있다\n(사진 사라짐)\n\n그래서 위에서 살펴본 Bounded-Buffer 문제를 Monitor 를 이용해 살펴보면 위처럼 됨\nBounded-Buffer 가 Property 로 드가있고\n여기에 접근할 수 있는 produce 와 consume 이 Method 로 드가있으며\nMonitor 자체에서 Mutex 가 지원되므로 Mutex 에 관련한 로직은 삭제되었고\n자원 개수 관리에 대한 부분만 Condition 으로 대체된 것을 확인할 수 있다\n\n그리고 Condition 으로 full 과 empty 두개의 줄을 생성하고\n조건에 따라 적절하게 프로세스를 해당 줄에서 대기하게 하거나 줄에서 꺼내는 등의 작업을 하게 됨\n\n\n\n\n\nMonitor vs Semapore §\n\n모니터와 세마포는 다음과 같은 방식으로 (거의) 1:1 변환된다\n\n모니터 하나당 Mutex 를 위한 세마포를 선언한다\n모니터의 Condition 하나당 Countable semapore 를 선언한다\n모니터 메소드의 로직 중 자원 체크 &amp; wait 혹은 signal 부분을 P 혹은 V 로 대체한다\n\n\n"},"originals/os.bahn.ewha.kocw.net/07.-Deadlocks":{"title":"07. Deadlocks","links":[],"tags":[],"content":"\n\n                  \n                  문서를 이전하는 과정에서, 문서가 유실되어 보이지 않습니다. \n                  \n                \n"},"originals/os.bahn.ewha.kocw.net/08-1.-Memory-Address":{"title":"08-1. Memory Address","links":[],"tags":[],"content":"\n\n                  \n                  이화여자대학교 컴퓨터공학과 반효경 교수님의 &quot;운영체제 (KOCW)&quot; 강의를 필기한 내용입니다. \n                  \n                \n\n\n\n                  \n                  다소 잘못된 내용과 구어적 표현 이 포함되어 있을 수 있습니다. \n                  \n                \n\nLogical, Physical, Symbolic Address §\n\n\nLogical Address (Virtual Address): 프로세스 각각이 가지는 가상 주소 공간 속의 주소\n\n즉 메모리 전체에 이 프로세스 하나만 올라가있다고 상상했을 때의 주소를 의미한다\n따라서 메모리 주소는 0번부터 시작\n이제부터는 별다줄로다가 LA라 표현해보자고\n\n\nPhysical Address: 실제 메모리의 주소\n\n실제 메모리의 주소이기 때문에 하위 주소에는 커널이 들어가고 상위 주소에 유저 프로세스들이 올라가게 된다\n얘는 PA 라 표현해보자고\n\n\nSymbolic Address 라는 것은 코드 작성시에의 변수를 의미하는 것\n\n즉, 코드에는 메모리 주소가 아닌 사람이 읽을 수 있는 형태의 문자열인 변수를 사용하게 되는데 이것을 Symbolic Address 라고 하는 것\n\n\n\nAddress Binding §\n\nAddress Binding: LA 를 PA 로 바꾸는 과정\n\n메모리에 접근하기 위해서는 LA 가 아니라 PA 가 필요한데 이를 위해 주소 변환 과정이 필요하게 된다\n\n\n\nBinding 시점에 따른 분류 §\n\nBinding 시점에 따라 종류를 세 가지로 나눠볼 수 있다\n\n\n\nCompile Time Binding: 컴파일 시점에 PA 까지 결정되는 것\n\n컴파일 시점에는 SA 가 LA 로 바뀌기 때문에 이때의 주소를 PA로 사용한다는 것은\n항상 LA와 PA 가 같고\n프로세스는 항상 (별도의 조치가 없는 한) PA 0번부터 적재되게 된다\n뭐 당연히 현대의 컴퓨터에서는 사용되지 않았지만 옛날에 컴퓨터에서 하나의 프로세스만 작동되던 시절에는 이런 방식의 바인딩을 사용했다더라\nLA 와 PA 가 같기 때문에 이러한 코드를 Absolute Code(절대 코드) 라고 부르고 컴파일러는 이것을 생성하게 된다\n\n\nLoad Time Binding: 프로그램이 프로세스가 되어 메모리에 적재되는 시점에 PA 를 결정하는 것\n\n얘는 위에놈보다 좀 더 합리적이제\n메모리 사용 현황은 계속해서 바뀌어서 컴파일 시점에는 메모리의 어느 부분에 적재할지 알기 힘들기 때문에 메모리에 적재할때 LA 와 PA 를 바인딩하자는 개념\n이때에는 컴파일러가 Relocatable Code (재배치 가능 코드) 를 생성한다\n\n\nRuntime Binding: Load Time Binding 과 유사하나 최초에 메모리에 적재된 이후에도 새롭게 바인딩이 될 수 있는 방법\n\n이것은 이제 프로세스의 Swapping 을 지원하기 위해 나온 것이다\n왜냐면 프로세스가 Swap out 되면 디스크로 쫒겨나게 되는데 이후에 다시 Swap in 할 때 기존의 PA 가 아닌 새로운 PA 에 바인딩될 수 있도록 해야 하기 때문\n당연히 요즘의 운영체제에서는 이 방법을 사용한다\n프로세스가 시작되고 종료되기 전까지 PA 가 계속 바뀔 수 있으므로 주소 변환 과정을 CPU 가 아닌 MMU 라는 별도의 하드웨어를 이용해 처리한다\n\n\n\nCPU 입장에서 §\n\n위 그림을 자세히 보면\n코드가 적재되는 위치만 바뀌고 코드에 작성되어 있는 주소는 바뀌지 않잖어\n따라서 CPU가 사용하는 (바라보는) 주소는 LA 이다\n왜냐하면 코드에 작성되어 있는 주소를 바꾸기 위해서는 컴파일을 새로 해야 되는데 Compile Time Binding 이 아닌 이상 불가능 하기 때문에 코드에 작성되어 있는 주소는 LA 로 놔두고 적재 위치만 바꾸게 되는 것\n\nMemory Management Unit (MMU) §\n\n\nMMU 는 주소 변환을 해주는 하드웨어 유닛인데\n다음과 같은 방식으로 작동한다\n\n일단 CPU 가 LA 를 이용해 주소를 달라고 요청\nLA 는 무적권 0번부터 시작하기 때문에 LA 가 곧 프로세스 주소 공간의 시작점으로부터의 Offset 을 나타냄 → 프로세스가 적재되어 있는 실제 메모리 상의 시작점의 주소만 알면 여기에 LA 를 더함으로써 PA 를 구할 수 있다\n\n이 시작점의 주소는 MMU 내의 Base Register (BA) 혹은 Relocation Register 에 저장된다\n\n\nPA 를 알아낸 이후에는 여기에 저장되어 있던 것을 읽어 CPU 로 전달\n\n\n\n\n\n위의 그림이 MMU 의 작동 과정을 나타내는 그림인데\nMMU가 주소 변환을 할 때에는 LA 가 유효한지를 먼저 검사하게 된다\n왜냐면 만약 프로세스의 주소 공간의 크기가 3000일 때 이것보다 큰 LA 요청이 들어오게 된다면 프로세스 바깥의 주소 공간을 참조하게 되는 것 이므로 다른 프로세스의 주소공간에 무단 침입하는 셈이기 때문이다\n따라서 MMU 에서는 Limit Register 라는 또 다른 레지스터를 이용해서 프로세스 주소 공간의 크기를 저장해 놓고 이것보다 큰 LA 요청이 들어오면 트랩을 걸어 기각시키게 된다\n\nDynamic Loading, Overlay §\n\n일단 Dynamic Loading 이라는 것은 프로세스의 전체가 메모리에 올라가는 것이 아닌 필요한 부분만 올라가는 기법을 의미한다\n이렇게 하는 이유는 당연히 메모리 효율을 올리기 위함 → 프로그램에는 자주 사용되지 않는 오류 처리 루틴이 많이 포함되어 있기 때문에 프로세스 전체를 올리는 것은 자주 사용하지 않는 부분까지 모두 올리는 것이어서 비효율적이다\nDynamic Loading 의 정확한 정의는 OS의 힘을 빌리지 않고 메모리에 동적으로 적재되는 것을 뜻한다\n\n현대의 OS 에서는 뒤에 나올 페이징 기법을 이용해서 프로세스를 동적으로 메모리에 올리게 되는데 이것은 Dynamic Loading 이 아님\n하지만 이 용어를 딱히 구별해서 사용하지는 않는다 → 정확한 정의와는 무관하게 페이징 기법을 사용하는 것도 Dynamic Loading 이라고 부르긴 한다\n\n\nOverlay 라는 것은 Dynamic Loading 과 유사하지만 용어가 등장한 배경이 좀 다르다\n\n일단 Overlay 도 프로세스를 쪼개서 메모리에 올리는 방법이지만\nOverlay 는 메모리의 크기가 너무 작아 프로세스 하나조차 올릴 수 없는 시절에 프로그램을 작성할 때 어느부분을 올릴지 수작업으로 프로그래밍하는 방법을 의미한다\n하지만 Dynamic Loading 의 경우에는 메모리의 크기는 넉넉하지만 사용율을 높이기 위해 라이브러리의 힘을 빌려서 동적으로 적재하는 것을 일컫는다\n\n\n\nSwapping §\n\n\n일단 Swapping 이라는 것은 프로세스 전체를 디스크 등의 Backing store 로 쫒아내는 것을 말한다\n앞선 강의에서 잠깐 언급되었던 것 처럼 Swapping 은 중기 스케줄러 (Mid-term Scheduler, Swapper) 에 의해 어떤 놈이 방출될지 결정된다\n\n당연히 우선순위가 높은 놈 보다는 낮은 놈을 방출시키는게 좋겠제 → 이것을 Swapper 가 결정하게 되는 것\n\n\n이 Swapping 은 Runtime Binding 이 필수적이다\n\nCompile Time Binding 이나 Load Time Binding 의 경우에는 Swap out 되었어도 원래 위치로 되돌아 와야 하기 때문에 비효율적\nRuntime Binding 이 되어야 Swap in 될 때 비어있는 공간으로 쓱 드갈 수 있기 때문에 필수적이다\n\n\nSwapping 에서는 읽어들여야 할 데이터의 양이 많기 때문에 대부분 Transfer Time 이 차지한다고 한다\n\n이놈은 뒤에 디스크 부분에서 배울거라는데\n디스크가 데이터를 읽어들일 때는 디스크 헤드가 움직이는 Search Time 하고\n데이터를 읽어서 보내는 Transfer Time 이 있는데\n\n파일입출력같은 경우에는 Transfer Time 보다는 Search Time 이 더 오래 걸리는 반면\nSwapping 의 경우에는 보내야 할 데이터의 양이 많아 Transfer Time 이 더 오래걸린다고 하더라\n\n\n\n\n이놈도 페이징 기법과 연루되면서 용어가 좀 모호하게 쓰인다\n\n원래는 프로세스 전체가 디스크로 쫒겨나는 것을 의미하지만\n정확한 정의와 다르게 페이징 기법에 따라 페이지가 쫒겨나는 것도 Swapping 이라고들 하더라\n\n\n\nDynamic Linking §\n\n일단 Static Linking 이라는 용어부터 알 필요가 있다\n\ngcc 로 컴파일 할때 보면 라이브러리들을 오브젝트 파일로 만들어서 링크시켜주는 과정을 통해 라이브러리 내에 있던 코드가 내 코드에 포함되도록 하자네\n이렇게 라이브러리에 있던 코드를 내 코드에 포함시키는 것을 Static Linking 이라고 한다\n\n\n반면에 Dynamic Linking 은 라이브러리 코드를 내 코드에 포함시키지 않고 필요에 따라 불러오는 것을 의미한다\n\nDynamic Linking 을 하면 라이브러리 코드는 별도의 코드로 존재하고\n내가 해당 코드를 사용할 때에는 코드 전체를 가져오는 것이 아니라 해당 코드를 참조할 수 있는 작은 코드 조각 (해당 코드를 가리키는 포인터라고 생각하면 됨 → Stub 이라고 부르더라)을 코드에 넣어서 실행시점에 링크시켜 주는 것을 의미한다\n리눅스에서 .so 파일 본적 있제? 이것이 Dynamic Linking 을 위한 코드이다 → Shared Object 의 약자임\n윈도우에서는 .dll 파일 본 적 있을텐데 이것이 Dynamic Linking Library 의 약자이다\n\n\n"},"originals/os.bahn.ewha.kocw.net/08-2.-Physical-Memory-Allocation":{"title":"08-2. Physical Memory Allocation","links":[],"tags":[],"content":"\n\n                  \n                  이화여자대학교 컴퓨터공학과 반효경 교수님의 &quot;운영체제 (KOCW)&quot; 강의를 필기한 내용입니다. \n                  \n                \n\n\n\n                  \n                  다소 잘못된 내용과 구어적 표현 이 포함되어 있을 수 있습니다. \n                  \n                \n\nMemory Section §\n\n앞서 배운것 처럼\n메모리의 하위 주소는 OS 영역으로 커널 코드가 드가게 되고\n상위 주소는 사용자 프로세스 영역으로 사용자 프로세스들이 적재된다\n\nContiguous Allocation §\n\nContiguous Allocation 은 프로세스 전체를 그냥 메모리에 때려박는 것을 의미한다\n\nFixed Partition (고정 분할 방식) §\n\n\n_고정 분할 방식_은 메모리 공간을 사이즈별로 미리 분할해놓고 프로세스를 나눠놓은 공간에 집어넣는 것을 의미한다\n사이즈가 작은 것부터 시작해서 나눠 놓은 공간에 프로세스가 드갈 수 있으면 거기 넣고 아차 싶으면 다음 공간 따라서 찾은 다음에 드갈 수 있는 데에다가 넣는 방식\n이때 프로세스들 사이사이에 사용되지 않은 부분을 External Fragmentation (외부 조각) 이라 하고\n하나의 분할 내에서 사용되지 않은 부분을 Internal Fragmentation (내부 조각) 이라 한다\n\nVariable Partition (가변 분할 방식) §\n\n\n솔직히 분할을 미리 나눠놓고 넣는 방식은 너무 비효율적이자네\n그래서 공간을 분할하지 않고 일단 프로세스를 차례차례 넣어놓는 방식을 _가변 분할 방식_이라 한다\n이때에는 External Fragmentation 만 발생한다 → 분할이 따로 존재하지 않기 때문에 프로세스가 종료되면 사이사이에 빈공간이 남게 되는 것\n가변 분할 방식에서 External Fragmentation 을 Hole 이라고도 한다\n\n\n\n운영체제는 프로세스가 할당되어 있는 공간과 비어있는 공간인 Hole 들에 대한 정보를 관리하고 프로세스를 적재할 때 활용하게 된다\n\n즉, 프로세스가 종료되면 Hole 에 포함시키고 프로세스가 적재될 때에는 드갈 수 있는 Hole 을 하나 골라서 적재하게 되는 것\n\n\n\nDynamic Storage Allocation Problem §\n\n이건 Hole 들 중에서 어떤 Hole 에 프로세스를 적재시킬지 결정하는 알고리즘들을 일컫는다\n\n\nFirst Fit: Hole 들을 순차탐색하다가 프로세스가 드갈 수 있는 첫번째 Hole 에다가 넣음\n\n장점: Hole 을 탐색하는 시간이 적게 걸림\n단점: 해당 Hole 이 최선의 선택이 아닐 수 있음\n\n\nBest Fit: 프로세스가 드갈 수 있는 Hole 들 중에 가장 작은 Hole 에 넣음\n\n가장 작은 Hole 에 넣기 때문에 더 작은 Hole 이 생길 수 있으므로 작은 Hole 들이 많이 생긴다\n장점: 최적의 Hole 에 넣을 수 있음\n단점: Hole 을 탐색하는 시간이 오래걸림\n\n\nWorst Fit: 프로세스가 드갈 수 있는 Hole 들 중에 가장 큰 Hole 에 넣음\n\n가장 큰 Hole 에 넣기 때문에 큰 Hole 들이 많이 생긴다\n얘는 단점이 많다\n\nHole 을 탐색하는 시간이 오래 걸림\n큰 Hole 에는 더 큰 프로세스가 들어갈 수 있지만 굳이 여기 넣어서 더 작은 Hole 로 만들어버림\n\n\n\n\n\n\n실험 결과 First Fit 과 Best Fit 에 비해 Worst Fit 의 효율성이 더 안좋은 것으로 알려져 있다\n\nCompaction §\n\nCompaction 은 External Fragmentation 을 없애기 위해 프로세스의 위치를 이동시켜 Hole 들을 하나로 모으는 것을 의미한다\n당연하게도 바인딩을 체크하는 등의 아주 많은 작업이 필요하기 때문에 오버헤드가 크다\n따라서 이것을 효율적으로 하기 위해 모든 프로세스를 옮기는 것이 아닌 최소한의 프로세스만을 움직여서 Hole 들을 모으는 방법이 필요한데 이것도 만만치 않다더라\n\nNon-contiguous Allocation §\n\n얘는 프로세스를 잘라 메모리에 적재하는 방식인데\n동일한 크기로 자르는 방식인 Paging 기법과\n코드의 의미 단위 (뭐 Code, Data, Stack 이랄지 함수별로 나누던지) 에 따라 가변크기로 자르는 방법인 Segmentation 기법\n이 둘을 합친 Paged segmentaion 기법이 있더라\n"},"originals/os.bahn.ewha.kocw.net/09.-Virtual-Memory":{"title":"09. Virtual Memory","links":[],"tags":[],"content":"\n\n                  \n                  이화여자대학교 컴퓨터공학과 반효경 교수님의 &quot;운영체제 (KOCW)&quot; 강의를 필기한 내용입니다. \n                  \n                \n\n\n\n                  \n                  다소 잘못된 내용과 구어적 표현 이 포함되어 있을 수 있습니다. \n                  \n                \n\n\n\n                  \n                  문서를 이전하는 과정에서, 이미지 데이터가 유실되어 문서상에 보이지 않습니다. \n                  \n                \n\nDemand Paging §\n\n\n얘는 페이지를 모두 메모리에 올리는 것이 페이지가 필요한 시점에 메모리에 올리는 방법을 의미한다\n\n\n장점은\n\nIO 감소\n\n한번 올릴때 페이지 단위로 올리니까\n\n\nMemory 사용량 감소\n\n필요한 페이지만 올리니까 예외처리코드같은 자주 실행되지 않는 코드들이 메모리에 불필요하게 올라가지 않음\n\n\n빠른 응답시간\n\n여러개의 프로세스가 작동하는 경우에 하나의 프로세스 전체가 메모리에 올라가고 나머지는 아주 일부분만 올라간다면 모두 올라와있는 놈은 빠르지만 나머지는 IO 가 많아져 느림\n하지만 Demand Paging 을 사용하면 각 프로세스의 필요한 부분만 올라와있기 때문에 프로세스 전체가 메모리에 올라와있는 것보다는 느릴 수 있겠지만 전체적인 응답시간은 빨라진다\n\n\n더 많은 사용자 수용\n\n프로세스당 실시간으로 사용하는 메모리의 양이 적으므로\n\n\n\n\n\n그래서 프로세스가 메모리에 올라가게 되는 전체적인 모습을 보면 아래와 같다\n(사진 사라짐)\n\n제일 왼쪽은 가상 메모리 공간을 할당받고 프로세스가 페이지별로 나뉘어진 모습이다\n\nA ~ F 까지는 가상 메모리 공간에서 프로세스가 실제로 차지하는 페이지들이고\nG ~ H 는 프로세스가 차지하지 않는 빈 페이지임\n\n\n그리고 오른쪽의 두 그림처럼 메모리에 적재되었다고 한다면\n\n페이지 A, C, F 만 Demand Paging 에 의해 실제 메모리에 적재되었고\n나머지 페이지들은 디스크에 스왑되어있는 상황\n\n\n그때 Page Table 은 왼쪽 두번째와 같다\n\n실제 메모리에 적재되어있는 페이지는 프레임 번호가 적히고 Valid 로 표시된다\n그리고 적재되어있지 않는 페이지는 Invalid 로 표시된다\n가상 메모리 공간에서 프로세스가 차지하지 않는 빈 페이지도 Invalid 로 표시됨\n\n\n당연한 이야기지만 프로세스가 처음 생성되었을때에는 Page Table 이 전부 Invalid 로 표시되어 있고 프로세스가 실행됨에 따라 필요한 페이지가 차츰 올라가며 Valid 로 바뀌게 된다\n\n\n\nPage Fault §\n\n\n근데 Demand Paging 을 하려면 어떤 페이지가 필요해서 OS 에 올려달라고 요청할 수 있어야 되는데 이를 위한 것이 바로 Page Fault 이다\n\n\n간단히 말하면 MMU 가 주소를 바꿀때 해당 주소가 Invalid 한 페이지에 있다면 트랩을 걸어 OS 로 하여금 해당 페이지를 적재할 수 있도록 하는 것\n\n\nPage Fault 의 처리 과정은 다음과 같다\n(사진 사라짐)\n\nInvalid 페이지를 참조\n\nMMU 는 이때 유효한 주소인지, Protection Violation 등이 없는지 추가적으로 체크한다\n\n\n(MMU 에 의해) Page Fault Trap 이 걸려서 OS 로 CPU가 넘어감\n\n\n\n실제 메모리에서 비어있는 프레임 (Free Frame) 을 할당함 → 이미 모든 프레임이 하나 사용중이면 하나를 디스크로 스왑시켜서 빈 프레임을 만들어낸다\n\n디스크에서 해당 페이지를 가져오고\n빈 프레임에다가 페이지를 채움\n\n3, 4번 과정은 Disk IO 과정이기 때문에 당연히 해당 프로세스는 Block 되어 다른 프로세스로 CPU 가 넘어간다\n\n\nPage Table 에다가 Frame 번호 및 Valid/Invalid 를 업데이트함\nReady 상태로 있다가 CPU 를 받으면 멈췄던 Instruction 부터 다시 실행\n\n\n\nPage Fault Rate §\n(사진 사라짐)\n\nPage Fault Rate p 를 위와 같이 정의한다면\n\n즉, 0이면 Page Fault 가 절대 나지 않음\n1이면 모든 참조에서 Page Fault 가 발생\n\n\np 는 실제 시스템에서 0.01 정도로 아주 낮게 나온다 → Page Fault 가 앵간하면 일어나지 않는다는 의미\n\nPage Replacement §\n\n위에서 Page Fault 루틴 설명할 때 빈 프레임이 없으면 기존의 프레임에 있는 페이지를 swap out 시켜서 빈 프레임을 만들어낸다고 했는데 그것을 Page Replacement 라고 한다\n\n(사진 사라짐)\n\n위 그림이 Page Replacement 의 과정인데\n\n희생양을 정하고 Swap out 한다\n\n이때는 페이지에 변화가 없을 때에는 그냥 냅둬서 Overwrite 되게 할 수 있지만\n만일 페이지 내용에 변화가 있을 때에는 변화된 내용을 디스크에 반영해주는 IO 가 필요하다\n\n\nPage Table 에서 Swap out 한 페이지의 Validity 를 업데이트한다\n요청된 페이지를 Swap in 한다\nPage Table 에서 Swap in 한 페이지의 Validity 를 업데이트한다\n\n\n당연히 Page Replacement 를 할 때에는 Page Fault Rate 가 최소화되도록 프레임을 선택해야 되는데\n이것을 위한 알고리즘이 Replacement Algorithm 이다\n\nOptimal Algorithm (Belady’s Algorithm) §\n\n\n다시는 참조되지 않거나 가장 먼 미래에 참조될 페이지를 Replace 하자는 생각\n\n\n하지만 미래의 일은 알 수 없기 때문에 비현실적이다 → 이에 따라 Optimal Offline Algorithm 이라고도 불림\n\n\n다만, 이 알고리즘이 Page Fault 를 최소화한다는 것이 증명되어 있으므로 다른 알고리즘들의 성능에 대한 척도를 제공해주는 역할을 한다\n\n\n아래의 예제를 보면\n(사진 사라짐)\n\n위 시나리오에서 일단 첫 4번은 어쩔 수 없다 → 페이지가 없으니 어쩔 수 없이 Page Fault 가 발생\n5번째 Page Fault 에서는 4번 페이지가 가장 나중에 사용되므로 4번이 5번으로 Replace\n6번째 Page Fault 에서는 5번만 나중에 사용되므로 사용되지 않는 페이지 아무거나 Replace\n\n\n\nFIFO (First In First Out) Algorithm §\n\n\n선입선출이다\n\n\n얘는 FIFO (혹은 Belady’s) Anomaly 라는게 있는데 이게 뭐냐면\n\n일반적으로 Frame 수가 늘어나면 Page Fault 는 줄어드는 것이 일반적인데\nFIFO 방식을 사용하면 Frame 수가 늘어났을 때 Page Fault 가 늘어날 수도 있다는 것이다\n아래 예시 보면 됨\n\n(사진 사라짐)\n\n\nLRU, LFU Algorithm §\nLRU (Least Recently Used) Algorithm §\n\n\n가장 오래전에 참조된 것을 지우는 것\n\n\n최근에 참조된 것이 다시 참조될 가능성이 높다는 성질을 이용\n\n\nFIFO 와의 차이점은 FIFO 의 경우 가장 오래전에 입장한놈을 지운다면 LRU 는 가장 오래전에 마지막으로 참조된 것을 지운다\n(사진 사라짐)\n\n\nLFU (Least Frequently Used) Algorithm §\n\n가장 덜 빈번하게 참조된 것을 지우는 것\n빈번하게 참조된 것이 다시 참조될 가능성이 높다는 성질을 이용\n\nLRU vs LFU §\n(사진 사라짐)\n\nLRU 랑 LFU 의 장단점을 극단적으로 보여주기 위한 예시인데 누가 개같이 쫒겨날지는 직접 해보면 알 수 있음\n이걸 토대로 LRU 랑 LFU 를 비교해보면\nLRU 는 제일 나중에 참조된 것을 내쫒긴 하지만 그놈이 제일 많이 참조된 놈이어서 참조 빈도에 대한 고려는 안된다는 단점이 있고\nLFU 는 제일 적게 참도된 놈을 내쫒았는데 마지막 참조 시점의 고려가 되지 않는다는 단점이 있다\n\n위의 예시에서는 하필 그놈이 제일 최근에 들어온 놈이어서 연속 참조에 장애가 걸리는 문제가 발생한다\n\n\n\n구현 §\n(사진 사라짐)\n\nLRU: 얘는 Linked List 형태로 구현한다\n\n즉, 참조되면 그놈을 제일 아래로 내려 제일 높은 우선순위를 갖게 하고\n내쫒을때는 제일 위에 있는 제일 낮은 우선순위를 내쫒음\n따라서 시간복잡도는 O(1) 이 됨\n\n\nLFU: 얘는 Heap 을 이용하여 구현한다\n\n참조 시점이 아니라 빈도가 중요하므로 다른 놈들과의 비교를 해야되는데\n비교할때는 Linked List 를 이용해 일렬로 비교하며 따라가는 것 보다는 Heap 을 이용해 Leaf 까지 따라가며 비교횟수를 줄이는 것이 좋기 때문\n\n\n\n한계 §\n\n실제로는 LRU, LFU 알고리즘을 이용해 Page Replacement 를 할 수는 없다\n왜냐하면 MMU 가 하드웨어 유닛이기 때문에 Page Reference 는 OS 의 관여 없이 기계적으로 일어나기 때문\nOS 가 관여하는 부분은 Page Fault 가 발생했을 당시이므로 어떤 페이지가 언제 혹은 얼마나 참조되었는지는 OS 가 알 수 없다\n\nClock Algorithm §\n\n\n위에서 제시한 LRU, LFU 알고리즘의 한계를 극복하기 위해 등장한 알고리즘\n\n\n다음과 같이 작동한다\n(사진 사라짐)\n\n일단 시계에서 네모는 각 페이지를 의미한다\n그리고 숫자는 Reference Bit 으로, 최근에 해당 페이지가 참조되었음을 나타낸다\n\nReference Bit 은 MMU 에 의해 1로 바뀌고 OS 에 의해 0으로 바뀐다\n\n\nPage Fault 가 발생하면 OS 는 시계방향으로 Reference Bit 가 0인 페이지를 찾는다\n\nReference Bit 가 1이라면 OS 가 0으로 바꾸고 다음 페이지로 넘어간다\n\n\nReference Bit 이 0인 페이지를 찾으면 해당 페이지를 Swap out 한다\n\n\n\n이렇게 하면 다음과 같은 효과가 난다\n\nPage Fault 가 일어나지 않는 동안은 MMU 가 Reference Bit 을 관리하며 참조되었던 페이지들을 표시한다\nPage Fault 가 일어나면 OS 가 MMU 가 표시한 Reference Bit 을 이용해 참조되지 않았던 페이지를 찾아 swap out 한다\n이때 swap out 되는 페이지는 OS 에 의해 0으로 바뀐 뒤에 시침이 한바퀴를 돌아 다시 돌아올 때 까지 한번도 참조되지 않았던 것이 보장되므로 충분히 옛날에 마지막으로 참조되었던 것으로 생각할 수 있다\n\n따라서 이것은 LRU 와 비슷하다고 할 수 있다\n즉, LRU 의 근사 (approximation) 알고리즘\n공통점 → 마지막 참조 시점을 기준으로 페이지를 고름\n차이점 → 마지막 참조 시점이 가장 오래된 놈이라고 할 수는 없음\n\n\n\n\n\n이놈은 다음과 같은 이름으로도 불린다\n\nSecond Chance Algorithm: Reference Bit 이 1이면 한번 봐주고 다음 페이지로 넘어감\nNUR(Not Used Recently) 혹은 NRU(Not Recently Used): LRU 에서 Least 가 Not 으로 바뀜\n\n\n\nReference Bit 이외에도 Modified Bit 을 이용해 더욱 개선할 수도 있다\n\nModified Bit (Dirty Bit) 을 이용해 페이지가 변경되지 않았으면 IO 없이 swap out 하여 Overwrite 되게 함\n\n\n\nPage Frame Allocation §\n\n이것은 프로세스 하나에게 몇개의 Frame 을 할당할 것이냐인데\n이것이 중요한 이유는 다음과 같다\n\n프로세스는 실행코드 말고도 데이터와 협력해야되는 경우가 많으므로 여러 페이지에 동시에 참조할 일이 빈번하다\n또한 Loop 의 경우에는 해당 코드를 담은 페이지가 전부 올라와 있어야 Page Fault 가 안난다\n\n만약 Frame Allocation 이 2개인데 Loop 의 코드가 3 frame 을 필요로 한다면 1개의 페이지가 계속해서 Page Fault 가 날 것이기 때문\n\n\n\n\n다음과 같은 방법으로 할당할 수 있다\n\nEqual Allocation: 모두 똑같은 개수 할당\nProportional Allocation: 프로세스 크기에 따라 할당\nPriority Allocation: CPU 우선순위에 따라 할당\n\n\n이렇게 할당해 놓고 Replace 를 할때에는 해당 프로세스의 페이지 내에서만 Replace 되게 하는 방법을 Local Replacement 라고 한다\n하지만 프레임의 개수를 할당하지 않고 Replace Algorithm 에 따라 프로세스간 프레임을 경쟁하도록 하여 프레임 할당을 유동적으로 관리하는 것을 Global Replacement 라고 한다\n\n이렇게 하면 자연스레 프레임을 많이 필요로 하는 프로세스는 다른 프로세스의 페이지를 방출시켜 많이 차지하게 하고 해당 프로세스가 종료되면 자연스레 방출되어 다른 프로세스가 프레임을 차지할 수 있도록 할 수 있다\n\n\n\nThrashing §\n(사진 사라짐)\n\n일반적으로 메모리에 많은 프로세스가 올라오면 (= Degree of Multiprogramming 이 증가하면) CPU Utilization 은 올라간다\n하지만 어느 수준이 되면 프로세스 하나당 충분한 프레임이 확보되지 않아 Page Fault 가 너무 빈번하게 일어나 CPU Utilization 이 떨어지게 된다 → 이 시점을 Thrashing 이라고 한다\n\n이 구간에는 CPU Utilization 이 낮아 OS 가 더 많은 프로세스를 메모리에 올리려고 하고, 그러면 Page Fault 가 더 빈번하게 일어나는 악순환이 계속됨\n\n\n따라서 이것을 막기 위해서는 Degree of Multiprogramming 을 조절할 필요가 있다\n\nWorking Set Algorithm §\n\n\n페이지를 참조할때는 특정 시점에 빈번하게 참조하는 페이지가 한정되어있다는 Locality 에 착안해서\n\n\n빈번하게 참조하는 페이지들의 집합을 Working Set 이라고 부르고 WS 의 크기가 할당된 프레임의 개수보다 크면 그냥 해당 프로세스 전체를 Swap out 시켜버리는 알고리즘이다\n(사진 사라짐)\n\n\n저 WS 를 구하기 위해 Working Set Window 라는 것을 이용하는 데 이것은 페이지 참조 시퀀스에서 특정 시점의 최근 n 개의 참조 페이지를 의미한다\n\n위 그림의 예시로는 n 이 10이라고 할 수 있는 것\n이 Working Set Window 만큼의 페이지들을 집합으로 만들어 그의 개수를 기준으로 프로세스를 방출할지 말지 결정하는 알고리즘\n\n\n\nPFF (Page-Fault Frequency) Scheme §\n(사진 사라짐)\n\n얘는 Page Fault Frequency 를 추적해서 Page Fault Rate 가 일정 수준이 유지될 수 있도록 하는 것이다\n그래서 위 그림에서 보이는 것 처럼 상한 (Upper Bound) 와 하한 (Lower Bound) 를 정해놓고 상한보다 올라가면 프레임 할당을 더 증가시키고 하한보다 내려가면 프레임 할당을 줄여주는 방식\n\nPage Size §\n\nPage 사이즈가 너무 작다면\n\n장점\n\nInternal Fragmentation 의 감소\n필요한 정보만 메모리에 올라옴\n\n\n단점\n\n페이지 테이블 크기가 증가\nDisk Transfer 의 효율성 감소 (디스크에서 데이터를 찾는 것에서의 효율성)\n\n\n\n\n요즘 트랜드는 Page 사이즈를 크게 하는 것이랜다 (현재는 4Kb 정도)\n"},"originals/os.bahn.ewha.kocw.net/10.-File-Systems":{"title":"10. File Systems","links":[],"tags":[],"content":"\n\n                  \n                  이화여자대학교 컴퓨터공학과 반효경 교수님의 &quot;운영체제 (KOCW)&quot; 강의를 필기한 내용입니다. \n                  \n                \n\n\n\n                  \n                  다소 잘못된 내용과 구어적 표현 이 포함되어 있을 수 있습니다. \n                  \n                \n\nFile 이란? §\n\n이름을 통해 접근할 수 있는 정보들의 집합 을 File 이라고 하더라\n일반적으로 너가 아는 것들 이외에도\nLinux 에서는 다양한 장치들도 File 로써 관리된다 → 표준입출력이나 디스크들도 Linux 에서는 파일로 관리된다\n그리고 당연히 디스크같은 비휘발성 저장장치에 저장된다\n\nFile Operation §\n\nCreate, Delete\nOpen, Close\n\n파일의 Metadata 를 메모리에 적재하는 것을 Open\n메모리에서 내려 다시 디스크에 저장하는 것은 Close 라고 한다.\n파일을 읽거나 쓰기 위해서는 반드시 Open 되어있어야 하고 작업이 끝난 이후에는 Close 를 해야 한다.\n\n\nRead, Write\nReposition (lseek)\n\n파일입출력할때 생각해보면 포인터 (커서) 가 있어서 어디까지 읽었는지를 기억하자네\n이 포인터 (커서) 의 위치를 딴데로 옮기는 연산을 Reposition (lseek) 이라 한다.\n\n\n\nFile Metadata (Attribute) §\n\n이름에서 유추할 수 있듯이\n파일 자체의 내용이 아니고 파일의 유형, 크기, 권한 등의 파일을 설명하는 정보들을 File Metadata 혹은 File Attribute 라고 한다\n\nFile System §\n\nFile System 은 당연히 운영체제에서 파일을 관리하는 부분을 의미한다.\n이놈은 파일, Metadata, 디렉토리 계층구조, 저장 방법이나 보안성 부분을 관리한댄다\n\nDirectory, Partition §\n\nDirectory 는 뭐 너가 아는 그 폴더가 맞는데\n\n좀 더 정확하게 정의해보면 거기에 속한 파일들의 메타데이터 전부 혹은 일부를 내용으로 갖고 있는 파일을 Directory 라고 한다\n\n\nPartition 혹은 Logical Disk 는 하드웨어 디스크가 아닌 하드웨어 디스크를 쪼개서 논리적으로 여러개의 디스크를 사용하는 것과 같은 효과를 내게 하는 것을 의미한다\n\n이렇게 파티션을 나눠서 File System 을 설치하거나 Swap area 를 마련하는 등으로 활용한다.\n\n\n\nFile Open Operation §\n\n위에서 잠깐 봤지만 좀 더 깊게 드가보자고\n\n\n\n사용자 프로세스는 /a/b 경로의 파일을 열기 위해 open 시스템 콜을 한다 → 당연히 IO 작업이니까 직접 하지는 못하고 시스템 콜을 사용해야 한다\nFile System 이 Root (/) 에서부터 재귀적으로 파일의 위치를 찾아나가기 시작한다\n\nRoot 디렉토리의 위치는 File System 이 알고 있기 때문에 일단 이놈을 open 한다\nOpen 하게 되면 그놈의 메타데이터가 메모리에 올라가게 되는데, 메모리의 커널 영역 중 Open File Table 이라는 곳에 올라가게 된다\n\nOpen File Table 은 시스템 전체에 대해 열려있는 파일의 메타데이터가 테이블 형식으로 저장되어 있는 메모리의 커널 영역 중 한 부분이다\n\n\nRoot 의 메타데이터를 통해 Root Directory 의 Content 위치를 찾아내게 되고, 여기에는 하위 파일들의 메타데이터가 저장되어 있기 때문에 a 의 메타데이터를 찾아서 마찬가지로 Open File Table 에 올린다 (Open 한다)\nOpen → Content Reference 작업을 반복적으로 수행한다.\n\n즉, a 의 메타데이터를 이용해 a 의 Content 에 접근하고, 여기에서 b 의 메타데이터를 찾아 Open File Table 로 올리며 그것을 이용해 b 의 Content 에 접근한다.\n\n\n\n\n경로의 파일에 접근했다면, 해당 파일의 Content 를 메모리의 커널 영역에 올린다\n\n이 때에는 Open File Table 에 올리는 것이 아니라 열려있는 파일의 내용을 캐싱하는 Buffered Cache 에 올리게 된다\n이렇게 함으로써 프로세스는 디스크가 아닌 메모리에 캐싱되어있는 데이터에 접근하기 때문에 더욱 빠르게 데이터를 읽어올 수 있고\n여러개의 프로세스가 해당 파일을 Open 했을 때에도 디스크 IO 작업이 여러번 일어나는 것이 아니고 캐싱되어있는 데이터가 제공된다 → 즉, 파일을 Open 할 때에는 일단 해당 파일이 Buffered Cache 에 존재하는지 먼저 확인하고 없다면 그때서야 디스크 IO 작업이 이루어진다\n\n\n커널 영역에 올라가 있는 파일 Content 를 사용자 프로세스 영역으로 복사해 그놈이 접근할 수 있게 한다.\n요청한 파일의 File Descriptor 를 반환함으로써 Open 시스템 콜이 완료된다.\n\n옛날에는 File Descriptor 개념이 쬐까 헷갈렸는데 지금 딱 정리해준다\n일단 파일을 Open 했으면 해당 파일의 메타데이터가 Open File Table 에 저장되어 있겠지\n그럼 Open File Table 에 저장되어 있는 메타데이터의 주소를 PCB 에 존재하는 배열중 하나인 File Descriptor Table 에 넣는다\n\n즉, File Descriptor Table 은 해당 프로세스가 Open 한 파일의 Open File Table 내에서의 메타데이터 주소들을 담는 배열이다\n\n\n이때, File Descriptor Table 내에서의 해당 파일에 대한 인덱스 번호를 File Descriptor 라고 하는 것이다\n뭐 옛날에 배운 것 처럼 File Descriptor 0번은 표준 입력, 1번은 표준 출력, 2번은 표준 에러이다 → 프로세스가 실행되면 저 세 파일은 자동으로 열린다는 소리이다\n\n\n\n\n등장한 Table 들을 좀 비교해보면\n\nOpen File Table: 시스템 전체에 대해 열려 있는 파일들에 대한 Table\nFile Descriptor: 프로세스 하나에 대해 그놈이 열어놓은 파일들에 대한 Table\n\n\nFile Offset Table: 이건 파일 하나를 여러 프로세스가 열었을 때 각각 어디를 읽고 있는지가 다를 것이기 때문에 각 프로세스들이 어디를 읽고 있는지를 보관하는 테이블이다\n\nFile Protection §\nAccess Control Matrix §\n\n\nAccess Control Matrix 는 단순하게 어떤 사용자가 어떤 파일에 대해 권한이 있는지를 Matrix 형태로 저장해 놓은 것이다\n하지만 이 방법은 다소 비효율적이다 → 특정 사용자가 권한을 갖고 있는 파일은 한정적이기 때문에 쓸데없는 용량을 많이 차지하기 때문\n따라서 이것을 행 혹은 열 방향으로 Linked List 형태로 관리하기도 한다\n\n특정 사용자가 접근할 수 있는 파일들을 모아놓은 것을 Capability 라고 하고\n특정 파일에 대해 접근할 수 있는 사용자들을 모아놓은 것을 ACL (Access Control List) 라고 한다\n\n\n\nGrouping §\n\n\n하지만 ACM 을 이용하는 방법도 그다지 효율적이지 않다\n따라서 Linux 같은 UNIX 기반의 시스템들은 Grouping 방식을 이용해 접근 권한을 관리한다\n즉, 파일 소유주 (Owner), 일련의 사용자 집합인 그룹 (Group), 모든 사용자 (Public)에 대한 접근 권한을 각각 3비트로 표현하게 된다\n\n뭔지 알제?\n3비트에 대해 첫 1비트는 Read 권한 유무, 두번째 1비트는 Write 권한 유무, 세번째 1비트는 Execute 권한 유무를 뜻한다\n\n\n이렇게 되면 파일의 권한을 단순히 9비트로 표현할 수 있게 되고, 파일 소유주가 아닌 사용자에 대한 권한은 해당 사용자를 그룹에 포함시키거나 Public 권한을 조정함으로써 간편하게 관리할 수 있다\n\nPassword §\n\n뭐 이건 많이 사용되는 방법은 아니고\n특정 파일이나 디렉토리에 암호를 걸어 암호를 맞춰야만 접근할 수 있게 하는 방법이다\n\nMounting §\n\n\n특정 디스크 (파티션)에 대한 접근은 Root 를 통해 할 수 있지만\n다른 디스크 (파티션)에 대한 접근은 특정 디렉토리를 해당 디스크의 루트를 가리키도록 하여 수행할 수 있다 → 이 방법을 Mounting 이라고 하더라\n\nFile Content Access Method §\nSequential Access §\n\nSequential Access (순차 접근) 은 이름에서부터 알 수 있듯이 파일의 내용을 앞에서부터만 순차적으로 읽을 수 있는 방법이다\n즉, ABC 에서 A와 C에 접근하기 위해서는 B 에 무조건 접근해야 한다\n카세트 테이프같은 경우가 이렇다 → 무적권 앞에서부터만 접근해야 되는 놈\n\nDirect Access (Random Access) §\n\nDirect Access (Random Access, 직접 접근) 은 반대로 파일의 내용을 임의의 순서로 접근할 수 있는 방법을 의미한다\n즉, ABC 에서 A에 접근한 이후에 바로 C를 접근하는 것이 가능하다\n이것은 하드웨어적 서포트가 필요하고 그러한 서포트가 있어도 데이터들을 어떻게 저장하냐 따라 순차접근을 해야 할 수도 있다네\n뭐 디스크나 CD, 플래시 메모리 등이 다 지원한다\n\nDisk Allocation Methods §\n\n일단 몇가지 개념들\n\nBlock (블럭) 혹은 Sector (섹터): 디스크에 데이터를 저장하는 단위\n\n\n\nContiguous Allocation §\n\n\n말그대로 파일 하나를 디스크에 연속적으로 저장하는 방법\n장점:\n\n디스크에서 데이터의 위치를 찾은 다음에는 쭉 읽어들이면 되기 때문에 IO 가 빠르다\n\n만약 데이터들이 산발적으로 저장되어 있다면 그들을 모두 찾아야되지만 뭉쳐져있기 때문에 한번만 찾으면 됨\n따라서 IO 속도가 중요한 Realtime File 이나 Process Swapping 등에서 사용될 수 있다\n\n\n데이터가 시작위치부터 연속적으로 존재하기 때문에 Random Access 가 가능하다\n\n시작위치에서 Offset 만 알면 바로 원하는 부분을 찾을 수 있기 때문\n\n\n\n\n단점:\n\n메모리 관리때와 마찬가지로 Hole (혹은 External Fragmentation) 이 발생할 수 있다\n\n파일의 크기와 딱 맞는 공간이 없을 수도 있으므로 남은 만큼은 외부 조각으로 남는 셈\n\n\n파일 사이즈를 키우기 힘들다\n\n파일 하나가 연속적으로 저장되어야 하는데 뒤에 다른 데이터가 존재한다면 파일 사이즈를 키우기 위해서는 뒤에 있는 놈을 재배치하거나 사이즈 키우는 것을 포기해야 한다\n늘어날 수 있는 공간만큼 미리 공간을 선점하게 할 수 있지만 그렇다 하더라고 늘어날 수 있는 파일의 크기는 한정되어 있고 선점된 공간은 Internal Fragmentation 으로 남게 된다\n\n\n\n\n\nLinked Allocation §\n\n\n말 그대로 Linked List 마냥 데이터들을 연결지어놓은 것\n장점:\n\nExternal Fragmentation 이 없다\n\n\n단점:\n\nRandom Access 가 안된다\n\n어떤 특정 섹터에 접근하기 위해서는 무적권 그놈 앞에 있는 섹터들을 모두 방문해야 한다\n\n\nReliability 문제\n\n포인터를 통해 쭉 연결되어있는데 중간에 하나의 섹터에 문제가 생겨서 (Bad Sector) 포인터가 유실되면 그놈 다음에 있는 모든 섹터에 접근할 수 없다\n\n\n공간 효율성 문제\n\n일단 하나의 섹터에 무조건 다음 섹터를 위한 포인터를 저장할 공간이 마련되어야 하고\n일반적으로 섹터 하나는 512 바이트로 구성되어 있는데 이 중 4 바이트가 포인터를 위한 공간으로 사용되어 508 바이트라는 애매한 숫자가 된다 → 알다시피 대부분의 데이터 포맷은 2의 배수 크기를 가지도록 정의되어있는 것이 많은데 512 가 아닌 508 로 하면 좀 애매하다는 얘기인듯\n\n\n\n\n단점 보완\n\n이 방식을 보완한 FAT (File Allocation Table) 파일시스템은 포인터들을 별도의 공간에 모아서 관리하기 때문에 Reliability 와 공간 효율성 문제를 해결한다\n하지만 알다시피 파일의 크기가 커지면 테이블의 크기도 너무 커지므로 FAT 으로 구성할 수 있는 파일의 크기는 한정되어 있다\n\n\n\nIndexed Allocation §\n\n\n이것은 파일이 저장되어 있는 섹터들의 번호 (인덱스) 를 모아놓은 별도의 블럭을 하나 구성하는 방법이다\nFAT 랑 솔직히 뭐가 다른지 잘 모르겠음\n장점\n\n연속적으로 저장하는 것이 아니기 때문에 External Fragmentation 이 발생하지 않는다\n인덱스 블럭을 통해 특정 섹터에 바로 접근할 수 있기 때문에 Random Access 도 가능하다\n\n\n단점\n\n파일 크기가 너무 작은 경우에는 비효율적이다\n\n파일의 크기가 512 Byte 보다 작을 경우에도 최소한 데이터 섹터 하나랑 인덱스 블럭 두개가 필요하다\n\n\n파일의 크기가 너무 커도 문제다\n\n파일의 크기가 너무 커서 하나의 인덱스 블럭에 다 안들어갈 수도 있기 때문\n이때는 인덱스 블럭의 마지막은 다음 인덱스 블럭을 가리키게 하는 방법 (Linked Scheme) 을 이용하던지\n인덱스 블럭을 계층적으로 구성하는 방법 → 인덱스 테이블이 다른 인덱스 테이블들을 가리키게 하는 방법 (Multi-level Index) 를 이용할 수 있다\n\n\n\n\n\nUNIX File System §\n\nBoot Block §\n\nBoot Block: 얘는 UNIX 만의 특징이 아니고 모든 파일 시스템이 파티션 맨 앞에 Boot Block 을 둔다\n\nBoot Loader (Bootstrap Loader) 는 말그대로 컴퓨터가 부팅될때 OS 가 디스크의 어디에 저장되어 있고 어떻게 시스템을 초기화해야할지 등을 알려주는 부분이다\n뭐 요즘 Linux 배포판에는 GRUB 가 부트로더로 내장되어있제\n\n\n\nSuper Block §\n\nSuper Block: 얘는 파티션 전체에 대한 메타데이터라고 생각하면 된다\n\n즉, 어디서부터 어디까지 어떤 정보가 저장되어 있고 (가령 여기부터 여기까지는 Inode List 이다 등)\n비어있는 섹션은 어디이고 사용중인 섹션은 어디인지 등의 정보를 저장함\n\n\n\nInode, Inode List Block §\n\nUNIX 에서 Inode 의 개념은 중요하니까 좀 자세하게 알아보자고\n일단 UNIX 에서 파일의 메타데이터를 어떻게 관리하는지 알아보면\n파일의 이름을 제외한 모든 메타데이터를 Inode 라는 단위로 저장한다\n\n\n\nInode 의 구조는 위와 같다\n\n일단 Mode 부터 Count 까지는 뭐 그냥 파일들의 메타데이터들이고 그 다음부터가 중요한데\nUNIX 는 위에 소개한 Allocation Method 중에서 Indexed Allocation 을 변형한 방법을 사용한다\n그래서 Direct Blocks 부분에 데이터 섹션들의 인덱스를 저장하게 되는데\n파일의 크기가 클 경우를 대비해 3단계까지 Multi-level Index 를 제공한다\n\n즉, Single Indirect 는 인덱스 블럭을 한번 더 거쳐야 데이터가 나오고 Double Indirect 는 두번 더 거쳐야 데이터가 나오며 Triple Indirect 는 세번 더 거쳐야 되는 식\n\n\n\n\n그러면 파일의 이름은 어디에 저장하느냐 → 디렉토리의 내용에 저장된다\n\n즉, 디렉토리는 하위 파일들에 대해 이름과 Inode 번호 두가지를 저장한다\n\n\n\n\n\n이러한 Inode 들이 모두 저장되어 있는 파티션의 한 부분을 Inode List 라고 부른다\n\n헷갈리지 마라 → 파일의 메타데이터는 파일과 함께 저장되어 있는 것이 아니고 별도의 공간에 함께 모여서 관리된다\n\n\n\n(MS) FAT File System §\n\n\n위에서도 언급했듯이 FAT 파일 시스템은 Linked Allocation 의 단점들을 개선한 것이다\nUNIX 와 대조되는 차이점들에 대해 살펴보면\n\n일단 UNIX 와는 다르게 거의 모든 메타데이터가 Directory 에 저장된다\n\nDirectory 에는 추가적으로 파일의 첫 블럭의 포인터가 적혀 있어 파일이 어디서부터 시작되는지 알 수 있게 해놓았다\n\n\nFAT 부분에는 각 파일들의 FAT 정보가 저장되어 있는데, 이 테이블에는 파일을 구성하는 각 블럭들에 대해 다음 블럭의 포인터가 저장되어 있다\n\n마지막 블럭에 대한 엔트리에는 EOF 값이 들어가 있어 더이상 블럭이 없음을 나타낸다\n\n\n\n\n그래서 FAT 파일시스템의 작동 원리에 대해 대략적으로 보면\n\nDirectory 에 적혀있는 포인터를 통해 파일을 읽어나가기 시작한다\n하나의 블럭을 다 읽었다면, FAT 을 보고 다음 블럭의 포인터가 어디를 가리키는지 확인한다.\n위의 과정을 EOF 가 등장할 때 까지 반복한다\n\n\n이렇게 하면 Linked Allocation 이 가지는 단점들을 모두 해소할 수 있다\n\nRandom Access 문제\n\n파일이 열린 다음에는 FAT 이 메모리로 올라오게 되는데\n포인터를 따라갈 때 데이터 블럭을 모두 뒤지는 것이 아니라 메모리 내에 있는 FAT 내부에서만 움직이므로 데이터 블럭에 접근할 필요가 없어 훨씬 빠른 시간에 접근이 가능하다\n\n\nReliability 문제\n\n일단 포인터가 FAT 에 저장되므로 Bad Section 이 일어나도 이후의 데이터에 접근이 가능하고\n고가용성을 위해 FAT 의 복제본을 여러개 유지하기 때문에 FAT 이 망가져도 복구가 가능하다\n\n\n공간 효율성 문제\n\n포인터가 FAT 에 저장되므로 데이터 섹션의 512 바이트 중 일부를 할애할 필요가 없다\n\n\n\n\n\nFree Space Management §\nBitmap (Bit Vector) §\n\n\n뭐 이건 간단하쥬?\n블럭의 크기만큼 비트를 마련한 다음에 해당 블럭이 비었는지 아닌지를 0과 1로 표현하는 방법\n당연히 Bitmap 을 마련해야 하기 때문에 추가적인 디스크 공간이 필요하지만\nContiguous Allocation 이 아니어도 연속적인 Free Space 에 저장하는 것이 IO 에 도움이 되므로 연속적인 Free Space 를 찾을 때 효과적인 방법이다\n\nLinked List §\n\n이건 Free Block 들에 다음 Free Block 의 포인터를 저장해서 링크드 리스트 형식으로 묶어놓은 것인데\n추가적인 디스크 공간이 필요 없다는 점에서는 좋지만\n각각의 블럭들을 모두 방문해야 하기 때문에 연속적인 Free Space 를 찾는 것은 오래걸린다\n\nGrouping §\n\n\n이건 Multi-level indexed 랑 유사한 방법인데\nFree Block 하나에 n - 1 개의 Free Block 포인터를 저장하고 마지막 에는 다음 Free Block Table 을 가리키게 하는 방법이다\n근데 특징은 Linked List 와 유사함 → 추가 공간은 필요없지만 결국 연속적인 Free Space 를 찾는 것은 쉽지 않다\n\nCounting §\n\n이건 연속적인 Free Block 을 쉽게 찾아내기 위해 고안된 방법인데\n일반적으로 Block 이 반납될때는 연속적인 블럭을 반환한다는 성질에서 착안한 방법이다\n따라서 연속적인 Free Block 에 대해 시작 Block 의 포인터와 몇개가 연속되어있는지의 개수를 저장한다\n\nDirectory Implementation §\nDirectory Contents §\n\nLinear List: 디렉토리 아래에 위치한 파일들을 리스트 형태로 저장하는 것\n\n\n\n위에서 보다시피 struct{FNAME, METADATA} 형식의 리스트로 구현한다\n\n당연히 구현이 간편하지만\n파일이 존재하는지 알기 위해서는 선형 탐색을 해야 한다는 단점이 있다\n\n\n\n\nHash Table: 이것은 List 의 인덱스를 결정할때 마지막 인덱스가 아닌 해시 함수를 통해 인덱스를 지정하는 방법이다\n\n\n\n해시 함수를 사용하기 때문에 상수시간의 탐색 시간이 걸리지만\n\n매우 한정된 범위로 해시 함수를 돌려야 하기 때문에 충돌 (Collision) 이 날 수가 있다\n\n이건 뭐 자구시간에 배운것처럼 충돌이 나는 애들만 리스트로 관리하는 방법 등을 사용할 수 있겠제\n\n\n\n\n\nMetadata §\n\n이건 파일들의 메타데이터를 어디에 보관할지에 관한 것인데\n앞에서 배운것처럼 UNIX 에서는 inode 에 따로 보관하고 FAT 에서는 파일 포인터 이외에는 디렉토리에 때려박는다\n\nFilename Support §\n\n일반적으로 struct{FNAME, METADATA} 형식으로 디렉토리 Content 의 Entry 를 저장하게 되는데 이때 각 Entry 의 크기는 고정되어 있다\n이말인 즉슨 파일의 이름의 크기는 일정 크기로 제한되어야 한다는 것인데\n파일의 이름 크기에 제한을 두지 않기 위해 아래와 같은 방법을 사용해서 이름이 긴 파일들을 관리할 수 있다:\n\n\n\n위 그림처럼 파일 이름이 너무 큰 경우에는 잘리는 만큼을 디렉토리의 맨 마지막 Entry 에 모두 때려박고\n\n해당 Entry 의 파일 이름을 저장하는 부분 마지막에 잘린 이름을 가리키도록 포인터를 두는 방법으로 해결할 수 있다\n\n\n\nVFS, NFS §\n\nVFS (Virtual File System) 은 운영체제 간의 상이한 파일시스템을 프로그래머가 고려하지 않아도 되게 하기 위해 고안된 통일된 인터페이스이다\n\n즉, 프로그래머는 이 인터페이스로 파일입출력을 이용하기만 하면 해당 파일을 관리하는 파일시스템에 따라 알아서 내부적인 조작을 해준다는 것\n\n\nNFS (Network File System) 은 알다시피 파일을 네트워크를 이용해 접근할 수 있게 해주는 파일시스템이다\n\n\n\n위 그림으로 좀 자세하게 알아보자고\n\nIO 시스템 콜이 발생하면 일단 VFS 인터페이스를 통해 해당 파일의 IO 작업이 진행되는데\n만일 해당 파일이 로컬에 없고 외부에 있다면 NFS Client 데몬을 이용해 외부에서 갖고오도록 한다\n해당 요청은 RPC → Network → RPC 를 거쳐 실제 파일이 위치한 머신 (서버) 의 NFS Server 데몬에 도달하게 된다\n그럼 NFS Server 데몬은 VFS 인터페이스를 이용해 파일을 읽어서 내용을 보내주게 되는 것\n\n이때 VFS 인터페이스가 왜 사용되는지에 살짝 의구심이 들 수도 있는데 어차피 NFS Server 도 IO 시스템 콜을 할 테니까 당연빠따로 VFS 인터페이스를 거치게 된다\n\n\n\n\n\nCaching §\nPage Cache, Buffer Cache §\n\n일단 개념적인 차이점\n\nPage Cache 는 Swap area 에서 페이지를 메모리에 올릴 때 캐싱을 해서 Swap area 까지 가지 않게 하기 위한 캐시이고\nBuffer Cache 는 파일 IO 에서 한번 읽어온 블럭들을 캐싱해서 다른 프로세스에서의 요청에 조금 더 빠르게 대응하기 위한 캐시이다\n\n\n이외에도 캐시의 크기는 작기 때문에 내용을 교체하기 위한 알고리즘 (Replacement Algorithm) 에서도 차이가 나는데\n\nPage Cache 의 경우에는 이전 강의에서 말한 것 처럼 주소변환이 MMU 에 의해 이루어지므로 페이지 참조 횟수를 알 수 없어 Clock 알고리즘을 사용하고\nBuffer Cache 의 경우에는 파일 IO 라는 것이 결국에는 시스템 콜이기 때문에 운영체제로 제어권이 넘어가 파일 참조 이력을 운영체제가 알고 있다 → 따라서 LFU, LRU 등의 알고리즘을 사용하게 됨\n\n\n\nMemory Mapped IO §\n\nMemory Mapped IO 혹은 Memory Mapped File 은 파일의 일부를 그냥 가상메모리에 매핑시켜서 메모리에의 데이터 변경이 바로 파일입출력과 연동되도록 하는 개념이랜다\n이렇게 작동한다 → 파일의 일부분이 메모리의 페이지에 올라와있어 여기에 변경이 이루어지다가 Swap out 이 되면 Swap area 가 아닌 파일에 내려가 변경부분이 반영이 되고 다시 해당 파일에 접근할때에는 Page Fault 가 발생해서 파일이 페이지로 올라오는 것\n\n따라서 페이지에 접근할때는 커널의 도움을 받지 않아도 된다\n또한 Buffer Cache 의 내용을 복사해오지 않아도 된다는 장점이 있다\n\n\n당연히 처음에는 IO 를 해야 하기 때문에 mmap 이라는 시스템 콜이 최초에 이루어진다\n\n따라서 최초에 Buffer Cache 를 한번 거치게 된다 → MMAP 의 경우에 Page Cache 만 사용하기 Buffer Cache 를 사용하지 않는다고 생각하면 오산낙지다\n\n\nMMAP 을 사용하는 대표적인 케이스는 프로세스의 코드-데이터-스택 구조에서의 코드 부분이다\n\n왜냐면 프로세스의 코드는 변경되지 않기 때문에 굳이 Swap area 로 내리지 않고 실행파일이 위치한 곳으로 내려도 되기 때문\n\n\n\nUnified Buffer Cache §\n\nUnified Buffer Cache 는 Page Cache 와 Buffer Cache 를 분리하지 않고 하나로 합쳐놓은 개념이다\n\n요즘의 운영체제는 모두 이 방법을 이용한다네\n\n\n그래서 파일 IO 를 할 때에도 페이지 단위 (4Kb) 로 캐싱해서 구지 두개를 별도의 모듈로 구성하지 않는다는 느낌인듯\n또한 메모리 영역자체도 구분을 하지 않고 올려놨다가 때에 따라서 파일 버퍼로 사용하던지 아니면 페이지 캐싱을 하는 식으로 운영한댄다\n\n\n\n위 그림이 UBC 를 이용하지 않은 경우와 이용한 경우를 비교한 사진인데\n\n일단 UBC 를 사용하지 않았을때에는\n\n일반적인 파일 IO 의 경우에는 오른쪽의 경로에 따라 Buffer Cache 에 올라갔다가 사용자 프로세스로 복사되는 과정이 이루어지고\nMMAP 을 이용할 경우에는 왼쪽의 경로에 따라 파일이 Page Cache 에 등록되지만 최초에는 파일 IO 를 위해 Buffer Cache 를 거치게 되는 것\n따라서 MMAP 을 사용하든 사용하지 않든 모두 Buffer Cache 를 거치게 된다\n\n\n하지만 UBC 를 사용했을 경우에는\n\n일반적인 파일 IO 에는 별 다를 바 없지만\nMMAP 의 경우에는 Buffer Cache 와 Page Cache 가 구분되지 않기 때문에 최초의 파일 IO 에 의한 캐싱이 마치 Page Cache 로도 사용되어 캐싱이 두번 중복되는 비효율성을 해결한다\nUBC 의 경우에는 동기화 문제를 고려해야 한다\n\nUBC 를 이용하지 않았을 경우에는 하나의 파일을 여러 프로세스가 공유해도 Buffer Cache 를 기반으로 각자의 메모리 공간에 파일이 있지만\nUBC 를 사용하게 되면 공유하는 메모리 공간에 파일이 올라와있는 것과 마찬가지이기 때문\n즉, UBC 의 경우에는 한놈이 MMAP 을 해서 사용하고 있는 파일의 공간 (Page Cache 로 기능) 과 다른 한놈이 MMAP 이 아닌 파일 IO 를 해서 올려놓은 공간 (Buffer Cache 로 기능) 이 같기 때문에 동기화 문제가 발생할 수 있다는 것\n\n\n\n\n\n\n"},"originals/os.bahn.ewha.kocw.net/11.-Disk-Scheduling":{"title":"11. Disk Scheduling","links":[],"tags":[],"content":"\n\n                  \n                  이화여자대학교 컴퓨터공학과 반효경 교수님의 &quot;운영체제 (KOCW)&quot; 강의를 필기한 내용입니다. \n                  \n                \n\n\n\n                  \n                  다소 잘못된 내용과 구어적 표현 이 포함되어 있을 수 있습니다. \n                  \n                \n\n용어정리 §\nSector, Block §\n\nSector: 디스크에서 정보가 저장되는 가장 작은 단위\n\n하나의 섹터는 Header + Data (512byte) + Trailer 이렇게 세 부분으로 구성되고\nHeader 와 Trailer 에 섹터 번호하고 ECC(Error Correcting Code) 가 저장된다\n\nHeader 와 Trailer 에 드가는 정보는 Disk Controller 가 직접 접근하고 운영하는데\n만약 실제 데이터와 ECC 가 호환되지 않는다면 Bad Sector 로 간주하고 그에 따른 대응을 하게 된다\n\n\n\n\nBlock: 디스크 외부에서 바라봤을 때의 데이터 저장 단위\n\n이게 약간 헷갈릴 수도 있는데\nBlock 들이 디스크 내의 각 Sector 에 매핑되는 식으로 저장된다고 생각하면 됨\n그리고 Block 은 1차원 배열의 형태를 띈다 → Sector 의 경우에는 몇번째 원판의 몇번째 섹터 이렇게 2차원 배열로 생각할 수 있다면 Block 은 이런 물리적인 구분 없이 그냥 쭉 이어서 1차원 배열의 형태를 띈다는 것 → 뭔가 아닌거같기도 하고 확실하지 않음\n\n\n위와 같은 차이점때문에 섹터와 블럭의 사이즈는 같지 않을 수도 있는듯\n\n디스크의 구조 §\n\n\nPlatter: 디스크를 구성하는 각 원판\nTrack: Platter 내에서 같은 반지름을 가지는 Sector 의 집합\n\nCylinder 는 원래 여러 Platter 에 걸친 Track 들을 가상의 원통으로 묶은 것을 의미하는데 뭐 Track 이랑 비슷하게 생각해도 된다\n\n\nArm: 디스크를 읽어들이기 위한 막대\nRead-write Head: Arm 에서 실제로 데이터를 읽어들이는 부분\nSpindle: 디스크를 회전시키는 축\n\nFormatting §\n\nPhysical Formatting (Low-level Formatting): 디스크에 섹터들을 나누는 과정\nLogical Formatting: FAT 같은 파일 시스템을 디스크에 구성하는 과정\n\nPartitioning, Booting §\n\nPartitioning: 하나의 물리 디스크를 여러개의 논리 디스크로 나누는 과정\nBooting: 컴퓨터를 초기화하는 과정\n\n부팅은 다음과 같은 순서대로 일어난다\n\nROM 에서 Small Bootstrap Loader 를 실행시킨다\n\n메모리는 기본적으로 휘발성이지만 비휘발성의 아주 작은 공간인 ROM 이 존재한다\nCPU 는 메모리에밖에 접근할 수 없기 때문에 ROM 에 있는 부트로더를 실행함\n이놈은 Small Bootstrap Loader 라고 불리는데 이건 부팅을 시작하기 위한 기본적인 코드인 디스크에서 부트로더 전체를 메모리에 올리도록 하는 코드가 들어있다\n\n\nSector 0 에서 Full Bootstrap Loader 를 가져와서 실행\n\n위에서 SBL 이 부트로더 전체를 메모리에 올리는 역할을 한다고 했자네\n이때의 부트로더를 Full Bootstrap Loader 라고 하고 이것은 Sector 0에 저장되어 있다\nSector 0은 디스크에서 가장 최외각 트랙의 첫번째 섹터로 무적권 FBL 가 저장되도록 예약되어 있다\n\n\n\n\n\n\n\nDisk Access Time §\n\n디스크에서 데이터를 읽어오는 과정은 아래와 같이 세 부분으로 나눌 수 있다\n\nSeek Time: 디스크의 암(헤드)을 데이터가 위치한 실린더로 움직이는데 걸리는 시간\nRotational Latency: 암이 제대로 위치한 뒤에 디스크가 회전해 원하는 섹터가 헤더 위로 회전해오는데 걸리는 시간\nTransfer Time: 실제 데이터의 전송 시간\n\n\nDisk Bandwidth: 단위 시간동안 전송된 바이트의 수\n디스크에서 데이터를 읽어올 때 가장 오래 걸리는 것은 Seek Time 이고 Disk Bandwidth 를 극대화 하기 위해 섹터를 읽는 순서를 최적화하는 작업을 Disk Scheduling 이라고 한다\n\nDisk Scheduling §\n\nDisk Bandwidth 를 최대화 하기 위해서는 Seek Time 을 최소화 해야 한다고 했으므로 요청된 섹터들의 트랙 (실린더)를 기준으로 어떤 섹터를 먼저 읽을 지 결정한다\n\nFCFS (First Come First Service) §\n\n\n딱히 뭐 설명할 것도 없다\n그냥 무지성 선입선출\n당연히 비효율적이어서 안쓴다\n\nSSTF (Shortest Seek Time First) §\n\n\n이건 현재 헤드의 위치를 기준으로 가장 가까운 놈부터 처리하는 방식인데\n예상하듯이 Starvation 문제가 발생한다 → 한곳에 요청이 몰리면 그와는 멀리 있는 요청은 계속 순위가 밀리기 때문\n\nSCAN (+ C-SCAN, N-SCAN) §\n\n\nSCAN 은 기본적으로 다음과 같이 작동한다\n\n헤드가 디스크의 끝(최외각 혹은 최내각) 트랙으로 움직인다\n헤드가 반대쪽 끝으로 움직이면서 경로 상에 있는 요청들을 처리한다\n2번 과정을 반복한다\n\n\n따라서 가장 기본이 되는 SCAN 은 아래 그림 한장으로 설명된다\n\n\n\n\n\n보면 약간 엘리베이터와 비슷하기 때문에 엘리베이터 스케줄링이라고도 부른다\n\n이 방식은 Seek Distance 로 최적화 할 수 있고 Starvation 도 안생기는 장점이 있지만\n트랙의 위치에 따라 대기시간이 고르지 않다는 문제가 있다\n\n헤드가 한번 끝에서 끝까지 움직이는데 10초의 시간이 걸린다 하면\n가운데 트랙의 경우에는 가장 오래 걸려도 헤드가 절반을 움직이고 또 절반을 되돌아오면 되기 때문에 10초가 걸리지만\n외곽에 있는 트랙의 경우에는 헤드가 한번 쭉 움직이고 또 반대방향으로 쭉 되돌아와야 하기 때문에 최대 20초가 걸릴 수 있다\n\n\n\n\n위와 같은 문제를 해결하기 위한 SCAN 의 변형이 C-SCAN 이다\n\n헤드가 디스크의 끝(최외각 혹은 최내각) 트랙으로 움직인다\n헤드가 반대쪽 끝으로 움직이면서 경로 상에 있는 요청들을 처리한다\n위 과정을 반복한다\n\n\n보면 그냥 SCAN 과의 차이점은 3번 과정인데 그냥 SCAN 의 경우에는 양방향에 대해 경로상의 요청을 처리하지만\nC-SCAN 의 경우에는 단방향에 대해 요청을 처리한다 → 즉, 한쪽 방향으로 움직일 때만 요청을 처리하고 반대방향으로 되돌아 갈 때는 요청을 처리하지 않고 그냥 움직인다는 것\n따라서 아래의 그림으로 한장 정리가 가능하다\n\n\n\n\n\n따라서 이 방법을 사용하면 기존의 SCAN 방식에 있던 대기시간 불균형을 해소할 수 있다\nSCAN 방식의 변형 중에는 N-SCAN 이라는 놈도 있는데\n\n얘는 SCAN 과 유사하지만 이동중에 들어온 요청에 대해서는 경로상에 있어도 처리하지 않는다는 차이점이 있다\n즉, 한 방향으로 이동하기 전에 들어온 요청에 대해서만 이동하면서 처리하고 이동하는 중간에 들어온 요청은 지금 처리하지 않고 다시 반대방향으로 되돌아갈 때 처리한다는 입장임\n\n\n\nLOOK (+ C-LOOK) §\n\n\n위그림은 C-LOOK 이다\nSCAN 과 LOOK 의 차이점은 헤드가 어디까지 움직이냐에 달려 있다\n\nSCAN 의 경우에는 무조건 최외각-최내각에서 방향 전환을 하는 반면\nLOOK 의 경우에는 해당 방향에 더 이상 요청이 없으면 방향 전환을 한다\n즉, 트랙이 199까지 있을 때 요청된 트랙의 가장 큰 값이 180이면 SCAN 은 (오름차순일 때) 180 을 들르고 199를 간 다음에 내려가는 반면 LOOK 의 경우에는 180 을 들른 다음에 바로 내려간다\n\n\nSCAN 과 C-SCAN 의 차이와 동일하게 LOOK 과 C-LOOK 은 양방향이냐 단방향이냐의 차이밖에 없다\n\nDisk Scheduling Algorithm 의 특징 §\n\n일단 보통 SCAN 이나 LOOK 계열의 스케줄링 방식을 사용하고\n그리고 필요한 경우 쉽게 교체될 수 있도록 OS 와 별도의 모듈로 내장된다고 한다\n실제 Disk Bandwidth 는 이러한 알고리즘적 측면 외에도 파일을 어떤 방식으로 저장할지도 큰 영향을 끼친다고 한다 (연속 할당? 분할 할당?)\n\nSwap Area Management §\n\n일단 디스크를 사용하는 이유를 보면\n\n메모리의 경우에는 휘발성이기 때문에 비휘발성의 데이터 저장 장치가 필요했고\n메모리보다 저렴하되 메모리의 역할을 보조해줄 수 있는 저장장치가 필요하기 때문이다\n\n\n위 이유 중 두번째를 위한 것이 앞에서도 계속 나온 Swap Area 인데 어떻게 관리되는지 대강 알아보면\n\n\n\n뭐 요즘 우분투는 그냥 파티션 안쓰고 파일시스템으로 스왑영역을 관리하지만 디스크를 파티션해서 Swap Area 를 지정해 주는 것이 많이 쓰였다고 하더라\n\n일반적인 파일 시스템과 Swap Area 의 차이점은\n\n일단 파일보다 훨씬 더 빈번하게 참조되고\n메모리를 대체하는 공간이기 때문에 데이터들이 임시적이다 → 잠깐 머물렀다가 프로세스가 종료되면 사라지기 때문\n따라서 공간 효율성보다는 속도 효율성이 훨씬 중요하고 일반적으로 데이터를 나눠 저장하는 것이 아닌 한 덩어리로 저장 (Sequential Allocation) 하게 되고 블럭의 크기도 512바이트가 아닌 512Kb 등의 훨씬 큰 사이즈를 갖게 된다\n\n\n\n\n\nRAID §\n\n\nRAID (Redundant Array of Independant Disks): 는 디스크 여러개를 묶어서 고가용성과 속도 등의 이점을 얻고자 하는 방법이다\nInterleaving, Striping (분산 저장): 여러개의 디스크에서 데이터를 부분적으로 병렬적으로 읽어옴으로써 속도를 향상시키는 방법\nMirroring, Shadowing (중복 저장): 여러개의 디스크에 데이터를 중복해서 저장해서 Disk Failure 등의 문제 상황을 방지하는 방법\n\n단순히 중복해서 저장하는 것만이 아니고 Parity (에러 탐지 코드) 도 추가적으로 구성하기도 한다\n\n\n"},"originals/os.spring.2021.cse.cnu.ac.kr/(충남대)-운영체제-강의록":{"title":"(충남대) 운영체제 강의록","links":["originals/os.spring.2021.cse.cnu.ac.kr/01.-인터럽트,-타임쉐어링","originals/os.spring.2021.cse.cnu.ac.kr/02.-프로세스","originals/os.spring.2021.cse.cnu.ac.kr/03.-쓰레드","originals/os.spring.2021.cse.cnu.ac.kr/04.-Concurrency","originals/os.spring.2021.cse.cnu.ac.kr/05.-Semaphore","originals/os.spring.2021.cse.cnu.ac.kr/06.-Deadlock-&-Starvation","originals/os.spring.2021.cse.cnu.ac.kr/07.-메모리-관리","originals/os.spring.2021.cse.cnu.ac.kr/08.-가상메모리","originals/os.spring.2021.cse.cnu.ac.kr/09.-Segmentation","originals/os.spring.2021.cse.cnu.ac.kr/10.-CPU-Scheduling","originals/os.spring.2021.cse.cnu.ac.kr/11.-Multicore-Scheduling","originals/os.spring.2021.cse.cnu.ac.kr/12.-IO-&-Disk-Scheduling","originals/os.spring.2021.cse.cnu.ac.kr/13.-File-Management"],"tags":[],"content":"개요 §\n강의 정보 §\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n강의 구분소속교수시기학부 수업충남대학교 공과대학 컴퓨터공학과류재철 교수님2021년 봄학기\n실습 자료 §\n\ngithub://haeramkeem/Spring2021-CNU-OS\n\n목차 §\n\n01. 인터럽트, 타임쉐어링\n02. 프로세스\n03. 쓰레드\n04. Concurrency\n05. Semaphore\n06. Deadlock &amp; Starvation\n07. 메모리 관리\n08. 가상메모리\n09. Segmentation\n10. CPU Scheduling\n11. Multicore Scheduling\n12. IO &amp; Disk Scheduling\n13. File Management\n"},"originals/os.spring.2021.cse.cnu.ac.kr/01.-인터럽트,-타임쉐어링":{"title":"01. 인터럽트, 타임쉐어링","links":[],"tags":[],"content":"\n\n                  \n                  충남대학교 컴퓨터공학과 류재철 교수님의 &quot;운영체제 및 실습&quot; 강의를 필기한 내용입니다. \n                  \n                \n\n\n\n                  \n                  다소 잘못된 내용과 구어적 표현 이 포함되어 있을 수 있습니다. \n                  \n                \n\nDMA §\n\nDirect Memory Access : IO모듈을 따로 두어서(IO 전담 프로세서) 이 과정을 책임짐 - cpu가 IO작업을 하지 않는다\nIO : 입출력받는 모든 일 - 키보드 모니터 프린터 등 - IO모듈이 하는 일은 이 중에서도 필요한 데이터를 하드디스크에서 갖고오는 일을 한다\n이전에는 원하는 데이터가 메인메모리에 없으면 cpu가 하드디스크로 갖고왔음 - cpu가 직접 갖고오는 것을 Programmed IO라고 한다)\nSystem bus : 컴퓨터 내에서 데이터들이 아동하는 통로(전선)\nIO module안에는 buffer가 있어서 하드디스크로부터 가져온 데이터를 cpu가 가져가기 전까지 임시로 보관하게 된다\n\nInterrupt §\n\nIO Interrupt : IO모듈이 제대로 된 데이터를 갖고왔는지 cpu가 확인해야하기 때문에 IO모듈이 interrupt를 거는 것 - 이러한 IO방식을 Interrupt driven IO라고 한다\nInterrupt라는 것은 어떤 중요한 이벤트가 발생해 cpu가 지금 하던일을 멈추고 새로운 이벤트에 대응해야 된다고 cpu에 알려주는 것을 의미한다\n\nMemory hierachy §\n\nMemory hierarchy : 하드디스크 → 메인메모리 → 캐쉬 → 레지스터 계층구조를 의미함\n가격, 속도, 유지 등의 요소를 고려해 적절한 메모리 계층구조를 가지게 된다\n\nProcessor §\n\nProcess : 프로그램이 OS로 오면 실행가능한 프로그램을 process라고 부름\n이 process들을 실행하는게 processor\n\nCPU, GPU, DSP §\n\nCPU 는 명령어를 빠르게 처리하지만\nGPU 는 수학적 계산을 빠르게 처리하기 위해 나온 프로세서\nDSP(Digital Signal Processor) 로 음악이나 비디오 등의 시그널 처리를 담당한다\nCCP(Crypto Co-Processor) 로 암호처리를 담당한다\n\n프로세스의 처리 과정 §\n몇가지 레지스터들 용어정리 §\n\n기억안날까봐 다시 한번 설명해준다\nPC(Program Counter) : 다음으로 실행할 instruction이 들어있는 주소를 저장하는 레지스터\nIR(Instruction Register) : PC에 담긴 주소로 가서 가져온 instruction을 저장하는 레지스터\nAC(accumulator) : 임시저장소\n\nFetch §\n\nPC에서 주소를 읽어 메모리의 해당 주소로 간다\n거기 저장되어있던 instruction을 IR에 load한다\n\nExecute §\n\nIR에 load된 instruction을 실행하고 다시 Fetch를 반복한다\n\nInterrupt의 종류 §\n\nProgram : overflow, division by zero등의 상황이 일어났을 때\nTimer : 타임쉐어링 시스템에 의해 프로세스가 할당받은 시간이 만료되었을때\nIO : IO module이 데이터를 하드디스크로부터 갖고왔을 때\nHardware : memory parity failure등의 하드웨어적 이벤트가 일어났을 떄\n\nInterrupt가 발생했을 때 §\n\n기존 프로세스는 멈춰서 기다리고 interrupt handler가 interrupt를 해결하고 그 다음 줄로 넘어와 계속 코드를 실행하게 된다\nIDT : Interrupt Descriptor Table / IVT : Interrupt Vector Table : error, interrupt를 해결할 수 있는 코드의 위치(주소)를 정리한 표가 있는데 이제 interrupt handler는 이 표에 가서 지금 일어난 interrupt를 해결할 수 있는 코드가 어디에 있는지를 알아내 실행하게 된다\nSystem Call Table : 이것은 시스템 콜을 처리하는 코드의 위치(주소)를 정리한 표인데 이 표가 저장된 주소도 IDT의 마지막에 들어있다\n따라서 하나의 instruction을 execute다음에는 &lt;반드시&gt; interrupt가 일어나는지 검토하는 작업이 이루어진다\n\nMultiple interrupt §\n\n여러개의 interrupt가 일어났을 때 처리하는 방식은 두가지가 있다\nDisable/sequential : interrupt가 일어난 순서대로 처리하는 것 - 하나의 interrupt를 다 처리하고 나서 다음것이 실행됨 - interrupt를 처리하는 중간에 또다른 interrupt가 발생해도 처리하던 interrupt를 계속 처리한다\nNested : priority를 정해서 처리하는 것 - interrupt가 처리되는 와중에 새로운 interrupt가 발생했을 때 우선순위를 따져서 높은걸 먼저 처리하고 낮은걸 나중에 처리한다 - 낮은 interrupt가 발생하면 disable처럼 하던거 계속 하고 높은게 발생하면 중단하고 높은거 처리한 다음에 넘어와서 계속 처리 하는 구조이다\n\nOS §\n\nOS : 이러한 하드웨어들이 제대로 굴러가도록 관리하는 소프트웨어\n\nOS가 제공하는 서비스들 §\n\n프로그램 개발\n프로세스 실행 - process management - 프로세서와 연관\nIO기능 을 사용할 수 있게 함 - IO managemant\n파일들에 접근 할 수 있도록 해줌 - 리눅스의 경우 file discriptor를 통해서 파일들에 접근할 수 있게 해주는거 알쥬? - file management - 하드디스크와 연관\n시스템에 접근 / 다른 프로세스의 자원 등에 함부로 접근하지 못하게 하는 등의 protection - Memory protection이라고 한다 - memory management - 메인메모리와 연관\n에러에 대한 대응\n컴퓨터의 사용자가 여러명일 경우 누가 얼마나 썼는지를 계산 - 보통 클라우드에서 중요하다\n\nKernel §\n\nKernel은 OS의 핵심부분을 일컫는 말이다\nOS는 아주 사이즈가 크기 때문에 kernel이라는 핵심만 메모리에 상주하게 된다\n요즘은 컴퓨터의 성능이 놓기 때문에 커널의 사이즈를 점차 줄여나가는 microkernel이 추세이다\n\nProcess §\n\n프로그램이 실행되기 위해서는 메모리에 공간을 할당받아야 하고 또 그자리에 load되어야 하고 cpu time도 체크해야 되고 등등의 여러 데이터 구조와 여건이 갖춰져야 한다\n이런 여건들을 갖춰 os가 관리할 수 있는 실행 가능한 상태가 된 프로그램을 process라고 한다 - program in execution\n프로그램은 그냥 자료의 단위이고, 프로세스가 되어야 실행의 단위가 된다\n\n프로세스 실행의 종류 §\n\nBatch processing : 유사한 프로그램들을 한꺼번에 처리하는 것\nMulti programming(Concurrent Programming) : IO 등의 인터럽트가 일어나서 CPU가 기다리는동안 놀지 않고 다른 프로세스를 가동하는 것 - time sharing도 인터럽트를 발생시키지만 time sharing에 의한 인터럽트는 multi programming 이라고 하지 않는다 &lt;-&gt; 반대개념으로는 uniprogramming이 있다\nMulti processing(Symmetric Multi Processing - SMP) : 여러개의 코어를 갖는 CPU를 이용해 말 그대로 프로세스를 여러개 가동시키는것 - Multi programming과 헷갈리지 말아야 한다 - Multi programming의 경우에는 코어가 한개여도 가능하다 &lt;-&gt; 반대개념은 uniprocessing이다(싱글코어인 것)\nDistributed computing : 컴퓨터 여러개를 하나로 묶어 마치 하나의 컴퓨터처럼 움직이게 하는 개념\n\nTime sharing system §\n\nIO가 안일어나서 cpu가 쉬는경우가 안일어나면 하나의 프로그램이 cpu를 계속 사용하는 일이 일어나게 된다 - monopolize라고 한다\n이것을 방지하기 위해 각각의 프로세스에 시간을 할당하는 time sharing system이 나오게 된다\n\nUser mode vs Kernel mode §\n\nuser mode : 일반적인 사용자 모드. 일반적인 instruction들을 사용하고 접근이 제한된 메모리 공간에는 접근하지 못한다\nkernel mode : 관리자 모드 같은것. 시스템의 중요한 부분을 변경하는 privileged instructions들과 제한된 메모리 공간에 접근하는 것도 가능하다\nprivileged instructions나 제한된 메모리 공간에 무분별하게 접근해 시스템이 오작동하는 것을 막기 위해 os는 프로세스의 실행 모드가 유저인지 커널인지를 확인하게 된다\n\nUNIX 시스템 작동 순서 §\n\n\nUser → (command) → Command interpreter → (system call) → OS → (instructions) → Hardware\nsystem call은 OS와 밀접한 함수를 뜻하며 privileged instruction의 바로 상위 레벨 언어라고도 할 수 있다\n"},"originals/os.spring.2021.cse.cnu.ac.kr/02.-프로세스":{"title":"02. 프로세스","links":[],"tags":[],"content":"\n\n                  \n                  충남대학교 컴퓨터공학과 류재철 교수님의 &quot;운영체제 및 실습&quot; 강의를 필기한 내용입니다. \n                  \n                \n\n\n\n                  \n                  다소 잘못된 내용과 구어적 표현 이 포함되어 있을 수 있습니다. \n                  \n                \n\n프로그램 실행에서의 OS의 역할 §\n\n자원들(메모리 등)을 여러 프로세스들에게 적절하게 분배하고 관리함\n프로세스가 계속 변경되며 실행되어 동시에 실행되는것처럼 보이게 한다\n이렇게 프로세스와 IO디바이스들을 관리하는것이 OS가 하는 일이다\n\n프로세스 §\n\n실행의 단위, OS의 관리의 단위, 실행됐지만 아직 죽지는 않은 것\n프로그램 코드 와 그 코드와 연결된 여러개의 데이터로 구성된다\n코드(text) : 내가 짠 프로그램 소스파일\n코드에 연동되는 데이터는 구체적으로 global 변수는 data에, local변수와 함수는 stack에, 동적할당을 위한 공간은 heap에(단 heap은 data와 합쳐 그냥 data로 하나로 퉁쳐서 부르기도 한다), 그리고 나머지 필요한 자료들은 PCB에 저장된다\nOS는 프로세스 단위로 메모리를 할당하고 관리한다\n\nPCB에 저장되는 정보들 §\n\nPCB = Process Control Block : 프로세스의 정보들을 담은 구역(자료구조). 프로그램이 프로세스가 되기 위해서는 이 공간을 반드시 할당받아야 한다\nidentifier : 유닉스에서 PID같은놈. 프로세스들의 고유 번호이다\nstate : 프로세스의 현재 상태. 현재 실행중인건지, 기다리는 것인지 등등의 상태들이 저당된다\npriority : 프로세스들 간의 우선순위. 시스템 프로세스 같은 중요한 것들이 먼저 구동될 있도록 우선순위가 매겨져있다. 하지만 하나의 프로세스가 cpu를 monopolize하는것을 막기 위해 우선순위는 계속 바뀌게 된다\n그리고 cpu로 들어갈때 레지스터에 쓸 값들 - program counter(다름 실행할 명령어의 주소), memory pointer(이 프로세스가 저장되어있는 메모리의 주소) 등등의 정보들이 저장되게 된다\n\nSystem, Kernel, User Process §\n\nOS도 하나의 프로그램이므로 OS의 여러 기능들도 프로세스화되어 구동되게 된다\n이 OS의 프로세스를 system process라고 하며 그 중에서도 중요한 애들인 커널이 프로세스화 된 것이 kernel process(daemon) 이다. Kernel process같은 중요한 기능들은 항상 메모리에 상주한다 &lt;-&gt; 반대로 우리가 만든 프로그램들이 프로세스화되면 user process라고 하는 것\n\nDispatch, Context switch §\n\nDispatch : ready상태인 프로세스들 중 가장 우선순위가 높은놈을 running상태로 바꿔 cpu를 할당하는 일을 말함\nContext switch : 프로세스가 전환 후 새로운 프로세스가 실행되는것을 의미함\nDispatcher : 새로운 프로세스를 Dispatch하여 Context switch하는 일을 전담하는 kernel process\n여기서 중요한점은 새로운 프로세스가 Dispatch된 이후 새 프로세스가 실행되는것을 보고 Context switch가 일어났다라고 말한다 - 새로운 프로세스로 교체하는 “과정”을 Context switch라고 하는게 아니다 이말이야 - 따라서 Dispatch이후 Context Switch가 일어나는게 맞는거다\n\nProcess 실행과정 - 2 state process model §\n\n\n프로세스가 생성되면(Enter / Creation) 먼저 **Not Running(Ready)**상태가 된다 - Dispatch를 기다리는 상태\n이제 이 프로세스가 Dispatch되면 Running상태가 된다 - 실행되는 상태\n그리고 또 이놈이 실행되다가 타임아웃 등의 인터럽트를 받으면 다시 Not Running의 상태로 간다 - pause된다\n또 Dispatch되면 Running상태로 가고 이 과정을 반복하가 종료 (Exit / Termination)된다\n따라서 프로그램이 fork()되어 프로세스로 creation이 됐다가 exit()되어 다시 프로그램의 상태로 termination될때까지 수많은 pause와 dispatch를 거친다\n하지만 system process들은 잘 terminate되지 않는다 - 중요하므로\n우리가 코딩할때도. system call을 이용해 creation, dispatch, pause, terminate를 직접적으로 명령할 수도 있다 - fork(), exec(), wait(), exit()\nNot Running중인 프로세스들은 queue로 관리된다→ dispatch되면 queue에서 빠지고 pause되면 다시 queue로 들어간다\n\nsys call : fork()함수 §\n\n프로세스가 실행되다가 fork()가 실행되면 새로 프로세스가 하나 더 만들어지는데 이때 fork()를 호출한놈이 parent 이고 만들어진 놈이 child 이다\nfork()를 호출하면 parent와 동일한 놈이 하나더 child로 만들어지게 된다\n나머지는 전부 같으나 다른점이 몇가지 있다\n\nPID(identifier) 가 다르다 - 부모자식은 구별할 수 있어야 하므로\nfork()함수의 리턴값은 부모의 경우 자식의 PID, 자식의 경우 0을 리턴한다\n\n\nchild프로세스가 끝나기 전에 parent가 끝나면 좀 골치아파진다 - 원칙적으로 child가 끝나야 parent를 끝낸다 - cascade termination 이라고 한다\n하지만 부득이하게 parent가 끝나면 parent의 parent가 child의 parent로 바뀌게 된다\n\nTermination condition §\n\nNormal completion : 정상종료\ntimeout과는 별개로 cpu를 차지하는 총 시간도 중요하다 - 무한루프에 빠졌을 가능성이 있으므로 - cpu를 차지하는 총 시간이 너무 긴 경우에도 강제로 termination하게 된다 - timeout과는 별개의 개념이다 - timeout의 경우에는 cpu를 연속적으로 사용하는 시간을 말하고 이때에는 이 cpu를 잡고있는 총 시간을 말하는거 -무한루프가 아닌 원래 시간을 많이 잡아먹는 일이면 작업관리자에 승인을 요청하는 작업을 해줘야 된다\nMemory unavailable : 더이상 가용 가능한 메모리가 없을 경우\n\nProcess 실행과정 - 5 state process model §\n\n\nNew : 새로 들어와서 프로세스로 바꾸는 과정 - 여러 resource들을 할당받는 상태 - 프로세스화가 끝나면 admit되어 다음 단계로 간다\nReady : 프로세스화가 끝난 상태 - dispatch되어 running되기만 기다리는 상태이다\nRunning : dispatch후 실행중인 상태 - 실행이 끝나면 release되어 다음 단계로 간다\n\n다만 timeout이 발생하면 다시 ready로 가게 된다 - timeout의 경우에는 어떤 이벤트가 일어나 지금 당장 실행할 수 없는 상태가 아니므로\nready 상태에 있는 놈들은 queue에서 기다리게 된다\n\n\nBlocked : 키보드 입력이라거나 그러한 이벤트로 인해 잠깐 멈춘 상태 - event wait\n\n얘네는 지금 바로 다시 실행할 수 있는 상태가 아니기 때문에 ready로는 가지 못하게 되는거다 - 따라서 이벤트가 처리되어(event occurs) 다시 running 가능해지면 running되는게 아니라 ready 단게로 가게 된다\nevent queue라는 것이 존재해서 event가 처리될때까지 queue에 머문다 - 그리고 event가 끝나면 ready queue로 옮겨져 또 기다리게 된다\n\n\nExit : 프로세스가 종료되어 new에서의 역순으로 처리되는 과정 - resource를 전부 반납하게 된다\n\nProcess Swapping - 7 state process model §\n\n\n중요한 이벤트가 발생해서 당장 실행해야 되는데 메모리에 공간이 없으면 덜 중요한 애들이 메모리를 양보하고 하드디스크로 내려간다 - swap-out\n이벤트가 종료되어 얘네들이 다시 메모리로 올라오는 것을 swap-in 이라고 한다\n이렇게 프로세스가 잠깐 하드로 내려가게 되는 것을 suspend라고 한다\n이런 suspend를 관리하기 위해 suspend state가 존재한다 - ready상태에서 swap-out를 먹으면 ready / suspend로 가고 blocked 상태에서 swap-out를 먹으면 blocked / suspend로 간다\n그리고 얘네들이 다시 swap-in을 먹으면. 원래의 상태로 돌아오게 된다 - 무조건 ready로 올라오는게 아니다!!\n당연하게도 일단 메모리에 있어야(ready 혹은 blocked여야) running 상태로 갈 수 있다 - suspend에서 바로 running으로 가지는 못한다\n하지만 running에서 suspend를 먹어서 내려갈 수는 있다\n또한 지금 메모리가 부족한 경우에는 프로세스가 만들어지자마자 ready / suspend로 갈 수도 있다\n\nFigure 3.11 §\n\n\nprocesses에 process table의 시작주소가 들어있고 그 테이블에 process들의 주소들이 들어있다\n여기서 process table이 PCB table이다 - 실제로는 프로세스를 구성하는 PCB, 데이터 등등이 어느 한곳에 같이 모여있는게 아니다 이말이야 - 그림에서의 process image에는 PCB는 안들어있고 그 나머지인 text, data, heap등이 저장되어 있는 구조이다\nprocess table은 pointer를 이용해서 가변길이로 할 수도 있지만 중간에 포인터를 잃어버리면 나가리기 때문에 불변길이로 선언하는 경우가 많다 - 다만 n이 시스템에 존재할 수 있는 process들의 총 갯수이기 때문에 n을 적당한 크기로 정하는 것이 중요하다 - n이 너무 크면 메모리를 너무 많이 먹고 n이 너무 작으면 process가 생성되기 힘들다 - 이 table의 일부가 비어있어야 process가 생성될 수 있기 때문\n뭐 나머지 memory table, io table 등등도 다 비슷하다\n그리고 이 table들의 주소를 담고 있는 structure가 존재하는 형태이다\nprocess table은 메모리에 상주하게 되는데 보통 이 n값이 굉장히 크기 때문에 메모리의 많은 부분을 차지하게 된다 - 그래서 PCB의 중요한 부분만 남기고 나머지 PCB중 덜 중요한 정보들은 하드디스크로 넘기게 되는데 이 부분이 u-area이다 - 다만 running 상태가 되면 이 u-area는 메모리로 다시 올라오게 된다 - state에 따라 어디 있을지 결정되는 것\n\nProcess creation 과정 §\n\ncreation : Id 만들기 → process를 위한 공간 할당 → PCB 생성 → 필요한 포인터들 연결 → 다른 자료구조들 생성\nterminate : 이것의 역순이다\n\nReady, Blocked Queue의 구현 §\n\n\n보면 큐라고 해서 이 프로세스들이 물리적으로 막 움직이는게 아니다 - 이렇게 linked-list형태로 구성되게 된다\n루트 노드에는 첫번째 프로세스의 PCB.state의 주소가 담기고 이 PCB.state에는 다음 프로세스의 PCB.state의 주소가 담기는 식으로 다음 프로세스를 계속 가리키는 식으로 큐가 구현되어있더라 이말이야\n\nInterrupt vs trap §\n\nInterrupt : 프로세스의 외부에서 이벤트가 발생해서 멈추는 것\n\ninterrupt가 발생하면 실행 모드가 user → kernel mode로 바뀐다\nuser의 process가 멈추고 kernel의 interrupt handler가 실행되게 된다 - 다음 실행할 instruction의 주소가 interrupt handler의 첫주소로 설정되는 것\ninterrupt가 끝나면 다시 원래의 instruction 주소로 돌아오며 실행모드도 user mode 로 바뀌게 된다\n\n\nTrap : 프로세스의 내부에서 이벤트가 일어나 멈추는 것\n\nContext switching이 일어나기까지의 과정 §\n\n중단된 시점의 레지스터 값을 전부 진행중인 프로세스의 메모리로 옮긴다(stop &amp; save)\nstate를 바꾼다(running → ready나 다른 상태들)\nqueue에 추가한다\n다음 process를 선택한다(select)\n그 process의 state를 변경한다(ready → running)\nprocess의 메모리에서 레지스터 값들을 다 가져오는 등 새 프로세스의 중단지점으로 다 restore한다(restore)\n바뀐 process를 진행한다\n"},"originals/os.spring.2021.cse.cnu.ac.kr/03.-쓰레드":{"title":"03. 쓰레드","links":[],"tags":[],"content":"\n\n                  \n                  충남대학교 컴퓨터공학과 류재철 교수님의 &quot;운영체제 및 실습&quot; 강의를 필기한 내용입니다. \n                  \n                \n\n\n\n                  \n                  다소 잘못된 내용과 구어적 표현 이 포함되어 있을 수 있습니다. \n                  \n                \n\n쓰레드가 필요한 이유 §\n\nfork()를 하면 프로세스가 pid만 다르고 그대로 복제되는데 그러면 이 resource들을 공유하면 어떨까 하는 생각에서 나옴\n왜냐하면 fork를 통해 매번 복사를 해 메모리에 할당되면 메모리도 많이 잡아먹고 복사하는데 시간이 걸리므로 오래 걸린다 이말이야\n그래서 resource는 공유하고 dispatch만 다르게 해 시간과 메모리를 절약하자는 생각이다\ntext와 data는 공유하면서 스택만 여러개로 복제되는 구조 - 이 하나하나의 스택들을 Thread라고 한다\n그래서 이제는 실행의 단위가 프로세스가 아니라 프로세스 내의 Thread가 된다\n그리고 이 thread들의 정보를 저장하는 놈이 TCB이다 - PCB와 별개로 쓰레드들마다 자신의 정보를 담고 있는 TCB가 생기게 된다\n그래서 이제는 fork를 할때 프로세스 전체에 대한 공간을 확보하는게 아니고 스택이랑 TCB로 이루어진 thread만 확보하면 된다\n이 때문에 thread를 light-weight process라고 부른다\ndispatch의 단위는 thread가 되고 resource의 단위(resource ownership이라 한다)는 process가 되는 것이다\n하지만 process는 여전히 protection의 단위가 된다 - 어차피 thread는 데이터를 공유하므로 protection할 필요가 없더라\n그래서 이제는 execution state도 thread단위로 일어나게 되고 context change가 일어나는 것도 thread단위로 일어나게 되며 실행되다가 cpu에서 물러날때 문맥저장도 쓰레드 단위로하게 된다\n쓰레드의 장접은 다음과 같다\n\n가볍기 때문에 fork, terminate, context-change가 빠르다 - context-change가 빠르기 때문에 concurrent processing에서도 이점이 있다\n그리고 같은 프로세스여도 여러 thread를 가질 수 있기 때문에 하나의 프로세스가 실행되다 block을 먹어 기다려야 되는 상황에서도 process change없이 thread change를 통해 하나의 프로세스를 계속 이어나갈 수 있다\n또한 정보를 공유하기 때문에 IPC에서도 이점이 있다\n\n\n\n예시 - 웹 서버에서의 쓰레드 §\n\n서버에서는 클라이언트의 리퀘스트가 들어오면 이 이것을 처리하는 프로세스로 처리하는게 아니라 자식 프로세스를 fork해서 처리하게 한다\n이렇게 하는 이유는 자기가 직접 처리해버리면 이것을 처리하는 동안에는 다른 클라이언트의 리퀘스트를 받지 못하기 때문\n근데 쓰레드 없이 fork하는 것은 프로세스 전체를 다 복사해야 하므로 오래걸린다 - 이것을 thread로 처리하면 작업속도를 많이 올릴 수 있게 된다\n\n예시 - 함수 병행 처리 §\n\n함수를 호출하는거를 RPC(Remote Procedure Call) 이라고 하는데 이렇게 RPC를 하게 되면 그 callee가 처리되고 처리되는동안 caller는 놀게 된다\n근데 이제 쓰레드를 이용하면 하나의 함수를 call해서 처리하는 동안 다른 함수를 다른 쓰레드로 실행시키면 이 둘이 context switch되며 평행하게 실행되게 된다\n\nThread의 상태 §\n\nSpawn : fork에 대응\nBlock : 프로세스에서의 Block과 같다\nUnblock : ready에 대응\nFinish : terminate에 대응\n\nUser-level thread(ULT), Kernel-level thread(KLT) §\n\nUser-level thread(ULT) : 쓰레드의 생성이 user mode에서 일어나는 것 - 리눅스 POSIX표준의 p_thread가 여기에 해당한다\nKernel-level thread(KLT) : 쓰레드의 생성이 kernel mode에서 일어나는 것 - 윈도우계열 쓰레드들이 여기에 해당한다\nULT 는 실행되다가 block을 먹으면 ULT의 경우에는 user mode에서 라이브러리의 도움을 받아 생성된 것 이므로 kernel에서 보기에는 그냥 하나의 프로세스처럼 보인다 - 때문에 그냥 process를 block시켜버린다\n하지만 KLT는 block을 먹어도 kernel-level에서 실행되기 때문에 이놈이 thread인것을 알고 thread 하나만 block을 먹인다\n따라서 ULT는 block을 먹으면 그 process내에 있는 thread전부가 block을 먹게 되고, KLT는 block을 먹어도 그 thread하나만 block을 먹게 된다*\n이렇게 KLT의 경우 process전체가 block을 먹으면 thread가 가지는 concurrent의 이점을 가질 수 없기 때문에 상대적으로 느리다 - multi-thread로 짜나 uni-thread로 짜나 별반 차이가 없으니까 IO request가 많은 등의 블락을 많이 먹을거같으면 process가 dispatch의 단위가 되도록 프로그래밍 하는 것이 나을 때도 있다\n하지만 대신 ULT의 경우 kernel과 무관하게 실행될 수 있으므로 os에 자유롭게 구동된다 - multi-platform하게 구동될 수 있다\nKLT는 kernel mode로 들어가서 구동해야 하므로 실행시간이 느리다는 단점이 있다 - 하지만 ULT와는 다르게 쓰레드 하나만 블락을 먹는다는 multi-thread의 장점때문에 결과적으로는 더 빠르게 구동된다\n"},"originals/os.spring.2021.cse.cnu.ac.kr/04.-Concurrency":{"title":"04. Concurrency","links":[],"tags":[],"content":"\n\n                  \n                  충남대학교 컴퓨터공학과 류재철 교수님의 &quot;운영체제 및 실습&quot; 강의를 필기한 내용입니다. \n                  \n                \n\n\n\n                  \n                  다소 잘못된 내용과 구어적 표현 이 포함되어 있을 수 있습니다. \n                  \n                \n\nSynchronize 문제의 발생 §\n\n프로세스가 concurrence하게 실행될 경우 발생하게 되는 문제이다 - concurrency 문제라고도 부른다\n프로세스 여러개가 공유하는 변수의 경우 이 프로세스들의 실행 순서에 따라 결과가 다르게 나올 수 있는 것을 의미한다\n이러한 문제의 경우 os딴에서는 절대 이 문제를 캐치해 낼 수 없다 → 프로그래머는 이러한 문제가 생길 수 있다는 것을 반드시 고려하고 대처할 수 있어야 한다\n\nmulti-thread로 프로그래밍을 하는 경우\nmultiprogramming, multiprocessing도중 공유변수를 사용하는 경우\nOS자체도 공유변수를 많이 사용하기 때문에 OS를 개발하는 경우\n\n\n이 경우에 프로세스들 간에 동기화가 되어 있지 않으면 문제가 생길 수 있다\n\n동기화 문제를 해결하기 위해서 §\n\n이것을 해결해주는 system call 이 존재한다\n이렇게 공유공간 존재하는 경우를 이 공간를 특별히 관리해야된다는 의미에서 critical section이라고 한다\n이때 mutual exclusion - 상호배제이 중요하다 - 누군가 이 변수를 사용하고 있으면 사용하면 안되고 사용하는 프로세스가 없어야 사용 가능한 것\n어떤 프로세스가 사용하고 있다는 것은 entry code와 exit code 를 통해 알아냄 - mutex나 semaphore등이 여기에 해당한다고 볼 수 있다\n변수가 사용중이면 entry code를 통해 이미 사용중이라는 것이라는 것을 알 수 있고 그럼 이 변수를 사용하는 다른 프로세스는 이 변수를 사용하지 못하고 wait상태에 들어가게 된다 - 이러한 과정을 synchronize한다고 한다\n그리고 기존에 이 변수를 사용하던 프로세스가 변수 사용을 끝내면 exit code가 실행되고 그럼 이 변수는 critical section을 빠져 나오게 된다 → 그러면 다른 프로세스가 접근해서 entry code를 확인했을 때 이 변수는 critical section에 들어있지 않다는 것을 알 수 있고 그럼 다른 프로세스에서 이 변수를 사용할 수 있게 된다\n또한 progress라는 것도 만족해야 한다 → entry / exit code를 잘못 짜면 critical section에 아무도 없는데 있는것으로 착각하고 waiting상태로 들어갈 수도 있다는 것\n\n이 progress에는 deadlock라는 케이스가 있다\n\n\nBounded waiting이라는 것도 만족해야 한다 → 변수가 critical section에 빠져서 다른 프로세스가 waiting에 들어가면 이 기다리는 시간은 무기한 기다림이 아니라 정해진 시간동안만 기다리게 된다는 것\n만약에 이런 bounded waiting 이라는게 없으면 starvation - 기아상태상태에 빠질 수도 있다 → 프로세스가 cpu할당을 오랫동안 받지 못하는것을 굶주리는 데에 비유한 것\n이렇게 mutual exclusion, progress, bounded waiting을 만족시킬 수 있는 entry code와 exit code를 짜야 concurrency의 문제가 발생하지 않는다\n\nRace Condition §\n\n여러개의 프로세스가 공유변수에 접근하고\n이 프로세스 들 간의 순서에 따라 결과가 달라진다면\n이때 프로세스들이 공규공간을 경쟁적으로 사용하려고 한다는 의미에서 Race Condition이라고 한다\n이렇게 race condition이 일어나는 구간을 critical section이라고 하는거고 변수가 이 구간에 포함되게 되면 뭐 mutual exclusion에 의해서 다른 프로세스가 기다리게 되고 뭐 이런거다\n\nOS가 해야 되는 것 §\n\n여러개의 프로세스들을 추적하고 있어야 한다 - 이놈이 critical section에 들어갔는지, 아니면 빠져나왔는지, 그리고 또 누가 critical section에 들어갈 수 있는지를 파악하고 있어야 한다\n프로세스들한테 자원을 할당하고 해제해야함\n공유변수 이외의 것은 다른 프로세스가 침범하지 못하게 보호해야 함\n프로세서의 속도에 따라서도 동기화 문제가 발생할 수도 있고 아닐 수도 있는데 프로세서의 속도(CPU의 처리속도)와 무관하게 동기화 문제가 발생하지 않도록해야 함\n\nMutual Exclusion 의 원칙 §\n\n모든 프로세스가 따라야 한다\n프로세스들간의 순서를 지정해 주는 거지 프로세스들 간에 간섭이 일어나게 해서는 안된다\ndeadlock이나 starvation이 일어나게 해서는 안된다 - progress, bounded waiting하게 실행되어야 한다\n프로세서의 속도나 실행되는 프로세스의 숫자와 무관해야 한다\n\n하드웨어적으로 해결법 §\nInterrupt disabling §\n\n인터럽트가 없다면 실행되는 중간에 다른 프로세스가 끼어드는 일이 없기 때문에 상호배제가 가능하다\n하지만 이렇게 되면 multiprogram이 아닌 uniprogram이 되어서 context change에 대한 이점을 얻지 못하게 된다\n\nAtomic operation §\n\n동기화의 문제가 발생할 수 있는 부분을 atomic operation으로 만들어보자는 것\natomic operation이라는 것은 해당 부분을 하드웨어적으로 구현해놓아 이 함수를 하나의 instruction으로 만들겠다는 것\n당연히 하나의 instruction을 실행할 때는 inturrupt가 걸리지 않으므로 동기화의 문제도 발생하지 않는다\n이렇게 atomic opration을 적극 활용하면 동기화의 문제를 막을 수 있다\n이놈을 잘 살펴볼 것 - compare_and_swap과 exchange라는 atomic operation을 이용해 mutual exclusion하게 코드를 짠 예시이다\n\n\n하지만 위의 코드는 문제가 있다\n\n다른 프로세스가 기다리는 동안 while(keyi != 0)이라는 조건을 계속 체크해야 되므로 기다리는 와중에도 cpu를 차지하게 된다 → busy waiting이라고 한다\n그리고 다음 실행 순서가 랜덤이다 → 이렇게 되면 운없는 어떤 프로세스는 starvation에 빠질 수도 있게 된다\n그리고 deadlock도 막지 못한댄다\n\nSemaphore §\n\n동기화의 문제점을 해결하기 위한 하나의 방법 - 제일 널리 사용된단다\n위의 코드와는 다르게 기다리는 중에는 cpu를 먹지 않아 busy waiting하지 않는다\n그리고 다음 실행 순서가 랜덤하지 않고 대기 큐에 들어가 FIFO하게 빠져나온다 - 그래서 starvation의 문제를 막을 수 있음\n\nMonitor §\n\n동기화의 문제를 해결하기 위해 프로그래밍 언어 차원에서 자동으로 해주는 것들도 있는데 얘네들을 monitor라고 한다\n"},"originals/os.spring.2021.cse.cnu.ac.kr/05.-Semaphore":{"title":"05. Semaphore","links":[],"tags":[],"content":"\n\n                  \n                  충남대학교 컴퓨터공학과 류재철 교수님의 &quot;운영체제 및 실습&quot; 강의를 필기한 내용입니다. \n                  \n                \n\n\n\n                  \n                  다소 잘못된 내용과 구어적 표현 이 포함되어 있을 수 있습니다. \n                  \n                \n\nSemaphore란? §\n\n자료형이다\n0이상의 정수로 초기화되는 것, 1을 빼는 것(sem_wait), 1을 더하는 것(sem_signal, sem_post) 세개의 연산만 가능하다\nsem_wait가 값을 1 뺀다는 것은 프로세스 하나가 critical section에 들어가서 공유변수에 접근할 수 있는 프로세스의 갯수가 하나 줄어들었다는 의미를 가진다\n반대로 sem_signal가 값을 1 추가시킨다는 것은 프로세스 하나가 critical section에서 나와서 공유변수에 접근할 수 있는 프로세스 하나가 더 늘었다는 의미를 가진다\ncritical section을 넓게 잡으면 굳이 concurrency문제가 발생하지 않는데도 다른 프로세스들이 블락을 먹으므로 최대한 좁게 잡아서 context change가 원활하게 이루어지게 하는 것이 중요하다\n세마포 변수가 0일 경우에 다른 프로세스가 sem_wait()함수를 실행시키게 되면 이 프로세스에서의 세마포 변수는 음의 값을 갖고 이 경우에 이 프로세스는 waiting queue에 들어가게 된다\n따라서 세마포 변수가 음의 값을 가질 때 이것의 절대값은 큐에서 대기하는 프로세스의 갯수를 의미하게 된다\n그리고 sem_signal()함수가 호출되면 세마포 변수를 하나 증가시키고 큐에서 한놈을 wait에서 깨운다 - 즉, critical section에 들어있던 프로세스가 하나 사라져 가장 처음에 큐에 들어온(FIFO)프로세스를 깨워 critical section에 넣게 되는 것이다\n공유변수에 접근하는 것을 제한하는 용도로의 세마포는 당연히 0과 1의 값만 가져야 되므로 binary semaphore를 사용한다\n근데 좀 더 사용처를 넓혀서 예를 들면 10명 이하의 유저가 게임에 접속하는 것만을 허용한다 뭐 이런 경우에는 세마포 변수의 초깃값을 10으로 잡아서 활용하는것도 가능하다\n그리고 초깃값을 0으로 잡아주면 실행순서를 조절하는 것도 가능하다 - 초깃값이 0이면 이 세마포를 sem_signal()해주는 프로세스가 반드시 선행되어야 해당 세마포를 sem_wait()해주는 프로세스가 동작할 수 있는것 - 하나의 세마포가 반드시 하나의 프로세스에서 semWait, semSignal돼야되는건 아니다\nsem_signal시에 깨우는 순서를 FIFO로 하는 경우를 strong semaphore이라고 하고 깨우는 순서를 랜덤하게 하는 경우를 weak semaphore라고 한다\n여기서 주의할 점은 critical section을 공유하는 애들 중 여기에 들어가는 프로세스의 갯수가 제한되어 있는 거지 normal execution의 경우에는 critical section과 parallel하게 작동할 수 있다\n\nProducer &amp; Consumer(Bounded Buffer) §\n\n세마포를 이용해 해결할 수 있는 대표적인 예시\n봐봐라\n\n제한된 갯수의 버퍼가 있고\n제한된 갯수의 producer 프로세스, 하나의 consumer 프로세스가 존재한다\n그리고 버퍼공간 통틀어 한번에 하나의 프로세스만 접근할 수 있다\n빈 버퍼에만 producer가 접근할 수 있다\n비지 않은 버퍼에만 consumer가 접근할 수 있다 - consumer는 destructive read작업(읽으면 자동으로 지워지는)을 수행한다\n\n\n다음은 이 문제의 해결법이다\n\n\n\n근데 봐봐라\n만약에 semWait 두개의 순서가 바뀌면 어떤일이 일어나느냐\nproducer의 경우에는 만약 버퍼가 다 차있는 상태라면 semWait(s)를 통해 s를 0으로 만들었는데 마침 semWait(e)를 했더니 e가 -1이 되게 된다\n그러면 얘가 이상태로 자게 되는데 그럼 입이 돌아간다\n왜냐면 얘가 s를 하나 먹고 자므로 e를 올려줄 수 있는 consumer도 접근을 못하게 돼 둘 다 자게 되는 것이다\n이러한 경우를 deadlock 이라고 한다\nconsumer의 경우에도 semWait의 순서를 바꾸면 둘 다 입돌아가게 된다\n이렇듯 semWait의 경우에는 순서가 아주 중요하다 - 약간 보니까 실행순서나 참여 프로세스 갯수 제한이 아닌 상호배제의 용도로의 semaphore는 다른 용도로의 semaphore보다 늦게 - 딱 그 공유공간에 접근하기 바로 직전에만 - lock을 걸어줘야 되는듯\n하지만 semSignal의 경우에는 잠에서 깨워주는 역할을 하므로 순서가 바뀌어도 된다\n\nMassage Passing §\n\n얘는 그냥 프로세스들 간에 메세지를 주고받으며 동기화를 하는 방법이랜다\n"},"originals/os.spring.2021.cse.cnu.ac.kr/06.-Deadlock-&-Starvation":{"title":"06. Deadlock & Starvation","links":[],"tags":[],"content":"\n\n                  \n                  충남대학교 컴퓨터공학과 류재철 교수님의 &quot;운영체제 및 실습&quot; 강의를 필기한 내용입니다. \n                  \n                \n\n\n\n                  \n                  다소 잘못된 내용과 구어적 표현 이 포함되어 있을 수 있습니다. \n                  \n                \n\nDeadlock §\n\n일련의 프로세스가 영원히 블락먹는 상태를 의미한다\n어떤 프로세스의 블락상태가 풀리는것이 다른 프로세스의 실행에 달려있는데 이 다른 프로세스조차 블락을 먹어 둘다 영원히 블락을 먹게 되는 경우 이다\n예를 들면 이런 상황이다 - 프로세스 P가 D → T의 순서로 리소스를 먹고 Q는 T → D의 순서로 리소스를 먹을때 만약에 P가 D를 먹고 Q로 context change가 일어나 얘가 T를 먹으면 P도 자원을 먹지 못해 블락먹고 Q도 자원을 먹지 못해 블락을 먹으므로 둘 다 블락을 먹게 된다 - 이러한 경우에는 무조건 deadlock을 먹는건 아니므로 deadlock possible이라고 표현한다 - 즉, 무조건 deadlock이 발생하는건 아니지만 아다리가 맞으면 deadlock이 발생하게 되는 경우를 말한다\n이러한 경우에 첫번째로는 먹는 순서를 일치시킴으로 해결할 수 있다 - Q도 D → T의 순으로 자원을 먹으면 P가 D를 먹고 context change가 일어나도 Q는 D를 먹지 못하므로 T도 먹을 수 없어 Q는 블락을 먹어도 P는 블락을 안먹어 P가 자원을 뱉은 후 Q가 실행될 수 있게 되는 것이다\n\nConsumable 리소스의 deadlock §\nReusable, Consumable §\n\nreusable : 프로세스 하나가 먹고 뱉으면 다른 프로세스도 사용할 수 있는 자원 - 대표적으로 cpu가 여기에 해당한다\nconsumable : 하나의 프로세스가 먹고 나면 뱉어도 없어지기 때문에 다른 프로세스가 이용할 수 없는 자원 - interrupt처럼 처리하고 나면 없어지는 자원을 얘기한다\n\nDeadlock of Consumable resources §\n\n메세지 송수신에서의 deadlock\n\n\n\n보면 서로 메세지를 받아서 자신의 메세지를 보내는 과정을 거치는데 순서가 동일하다면 둘 다 메세지를 받아야 전송을 하므로 둘 다 블락을 먹게 된다 - 송신을 해야 반대편이 블락을 안먹는데 송신을 하려면 수신을 해야되고 그건 상대방도 동일하므로\n\nDeadlock of reusable resources §\n\n메모리 공간 할당에서의 deadlock\n\n\n\n예를들어서 메모리 총 공간이 200일때 프로세스 P는 80 → 60의 순서로 메모리 할당을 요청하고 프로세스 Q는 70 → 80의 순서로 메모리 할당을 요청할때 만약 P가 80을 먹고 context change가 일어나서 Q가 70을 먹으면 남은 공간은 50이므로 둘 다 원하는 메모리를 전부 먹지 못해 블락을 먹게 된다\n이렇듯 deadlock은 context change가 일어나지 않으면 일어나지 않지만 재수없게 context change가 일어나게 되면 일어나게 되는 경우가 많다\n프로세스 둘 중 하나의 자원을 뺏던가 아예 kill해버리는 방법으로 자원을 뱉게 하면 해결될 수 있다\n\n그림으로 deadlock 이해하기 - Resource Allocation Graph §\n\n\n동그라미가 프로세스, 네모가 자원, 네모 안의 검은 점이 이용할 수 있는 자원이다\n그리고 동그라미로부터 뻗어나오는 화살표가 자원 요청이고, 점으로부터 뻗어나오는 화살표는 자원 할당을 나타낸 것 이다\n왼쪽의 경우를 보면 P1이 Ra의 자원을 요청하나 이미 P2가 먹은 상태이다. 반면에 P2는 Rb의 자원을 요청하나 얘는 이미 P1이 먹은 상태이다. 따라서 계속 waiting하므로 deadlock이 걸리게 되는 것이다 - 이런식으로 리소스를 일부 먹고 기다리는걸 hold &amp; wait라고 한다\n반면에 오른쪽의 경우 P1은 Ra의 자원을 요청하는데 이용가능한 자원이 있으므로 문제없이 먹을 수 있다. 그리고 P2의 경우에도 Rb의 자원을 요청할때 이용가능한 자원이 있으므로 먹을 수 있다. 따라서 이 경우에는 deadlock이 걸리지 않게 된다\n\nDeadlock의 필요조건 §\n\nMutual Exclusion : 자원이 상호 배타적으로 접근해야만 정상적으로 작동할 때어떤 자원이 mutual exclusion하지 않으면 그냥 다 먹을 수 있으므로 deadlock이 걸리지 않는다\nHold &amp; wait : 프로세스가 자원을 하나 먹고 다른 자원을 먹으려고 기다릴 때 - 어떤 프로세스가 먹고 기다리는게 아닌 먹고 다시 뱉으면 다른 프로세스가 와서 사용할 수 있으므로 deadlock이 걸리지 않는다\nCircular wait : 자원의 요청, 할당관계 그래프가 화살표를 따라가봤더니 원형으로 그어질 때 - 원형으로 그어지지 않고 프로세스가 전혀 다른 리소스를 요청하는 그런 경우에는 한 프로세스가 블락을 먹어도 그걸 풀어줄 다른 프로세스가 다른 자원을 이용해 블락을 먹지 않게 되므로 블락먹은 프로세스도 풀리게 된다\nNo pre-emption : 프로세스들이 우선순위가 동일해 우선순위에 의한 작동순서를 정할 수 없고 프로세스의 자원을 뺏어오는것도 불가능할때 - 프로세스 두개가 deadlock을 먹었는데 하나의 우선순위가 높아 나머지 하나를 죽여버리면 deadlock이 풀리기 된다\n이 넷중에 하나만 만족하지 않아도 deadlock이 걸리지 않는다 - 즉, 이중에. 일부만 만족하는 것이 무조건적으로 deadlock을 야기하는건 아니다 - Circular wait의 상태여도 deadlock이 무조건 걸리는건 아니다 이말이야 - 원이 있어도 Mutual exclusion하지 않다던지 하는 연유로 프로세스 종료 시나리오가 완성된다면 deadlock이 아닌 것이다\n반면에 circular wait이면 반드시 deadlock이 되는 상황이 있다 - 연관되어 있는 모든 자원이 mutual exclusion, 즉, 한번에 한놈만 접근할 수 있을 때에는 circular wait이 일어나면 반드시 deadlock이 걸리게 된다\n\nDeadlock의 해결 §\n정보가 있는 경우 §\n\n여기서의 정보라는 것은 프로세스가 미래에 어떤 자원을 요청할지에 대한 정보나 자원이 mutual exclusion하다 등의 정보를 말한다. 나중에 프로세스가 어떤 자원을 요청할지를 미리 안다면 지금 내가 누구한테 자원을 줬을때 이것이 결국에는 deadlock을 야기할지 안할지를 알 수 있기 때문\nAvoidance : 자원의 요청과 할당관계에서 위와 같은 정보가 OS에 전달된다면 OS는 이 상황을 피하도록 대비를 할 수 있다 - 미래를 알고 피하는 것 - 그래서 OS는 deadlock posible 한 상황이면 리소스를 아예 할당해주지 않는다\n\n정보가 없는 경우 §\n\nPrevention : 이러한 정보가 없어도 저 4개의 필요조건중 하나라도 피할 수 있도록 잘 조정하는 것을 의미한다 - 미래는 모르지만 미리미리 방지하는 것\nDetection &amp; Recovery : 프로세스가 deadlock에 걸렸는지 아닌지를 계속 확인하고 걸렸으면 여기에서 빠져나오도록 일부를 kill한다던가 하는 등의 복구작업을 하는 것을 의미한다 - 여기서 deadlock을 탐지하는 방법은 프로세스들을 계속 관찰하면서 이 프로세스가 종료될 수 있는 시나리오가 있느냐를 확인하는 것이다 - 따라서 deadlock인것처럼 보여도 연관된 프로세스가 순차적으로 종료될 수 있는 그런 시나리오가 존재한다면 이것은 deadlock이 아닌 것이다\n\nPrevention strategy §\n\n아까도 말했지만 4가지 조건들을 회피해 deadlock이 걸리지 않게 하는 것\n간접(Indirect) 적인 방법 - Circular wait외의 나머지(Mutual exclusion, Hold&amp;Wait, No pre-emption) 이 세가지중 하나라도 발생하지 않도록 조치하는것\n직접(Direct) 적인 방법 - Circular wait가 일어나지 않게 조치하는 것\n\nMutual exclusion의 경우에는 리소스를 상호배타적으로 할당하지 않는 것이다\n\n하지만 리소스의 특성상 이놈이 상호배타적으로 할당해야만 하는놈인지 아니면 상호배타적으로 안해도 되는지 를OS가 알기가 힘드므로 쉽지 않다\n\n\nHold&amp;wait은 방지가 가능하다 - 프로세스가 시작하면 여기에 필요한 자원들을 중간에 끊지 않고 한번에 다 할당시킨다(serial하게)\n\n하지만 여기에는 몇가지 단점이 있다\n프로세스가 시작하면 거기에 필요한 자원들을 모두 할당하므로 이놈이 사용하지 않을 때 에도 먹고 있게 되어 비효율적이 될 수도 있다\n또한 어떤 리소스가 필요한지 실행시점에 다 알 수 없는 경우도 있다\n따라서 OS는 별로 선호하지 않는 방식이다\n\n\nNo pre-emption : 우선순위가 같은 경우에 OS가 프로세스 하나의 편을 일방적으로 들어서 나머지 프로세스의 리소스를 다 뺏어버리는 방법\n\n하지만 리소스를 뺏어버리면 그 프로세스는 그만큼 딜레이되는 것이므로 형평성의 문제가 있어 OS입장에서는 간편하지만 문제가 생길 수도 있다\n\n\nCircular wait : 리소스 할당에 원칙을 매기는 것으로 해결할 수 있다\n\n예를들면 오름차순으로 먹고 요청하는 것은 가능하지만 내림차순은 안된다고 했을 때 circular wait가 일어나려면 반드시 한번은 내림차순으로 가야되므로 이놈에게 리소스를 할당해주지 않으면 된다\n구체적인 예를 들어보면 프로세스 P가 R1먹고 R2요청하는 것은 오름차순이므로 허용, 다른 프로세스 Q가 R2먹고 R1 요청하는 것은 내림차순이니까 안된다고 했을 때 Circular wait이 성립하지 않으므로 deadlock이 발생하지 않는다\n\n\n\n\nprevention strategy는 아주 보수적인 해결방법이다 - avoidance와 다르게 미래를 잘 알지 못하는 상황에서 deadlock이 걸릴지 안걸릴지를 판단해야되므로 보수적으로 할 수밖에 없다\n\nAvoidance Strategy §\nDeadlock이 걸리지 않는 경우 §\n\n\nClaim matrix : 프로세스가 종료되는데 필요한 리소스들의 갯수\nAllocation matrix : 현제 프로세스들에게 할당된 리소스의 갯수\nC - A : 프로세스가 종료되기 위해 더 필요한 리소스의 갯수\nResource vector : 리소스를 동시에 할당받을 수 있는 프로세스의 통 갯수 - 아까의 allocation graph에서 검은 점의 갯수라고 보면 된다\nAvailable vector : 현재 프로세스들이 할당받은 다음 더 할당받을 수 있는 프로세스의 갯수 - 잔여분\nClaim matrix와 Resource vector를 아까말한 정보라고 하는 것이다 - 프로세스가 얼마나 자원을 필요로 할 지, 자원을 얼마까지 할당해줄 수가 있는지에 대한 정보가 존재하기 때문에 OS가 Avoidance strategy를 사용할 수 있는 것\n여기서 보면 P2가 R3를 하나 필요로 하는데 R3도 한개가 남으므로 줄 수 있다. 따라서 얘가 종료되고 남은 리소스를 전부 반환하면 Available vector는 623이 될 것이다. 이제 얘네들을 가지고 P1, P3, P4를 하나씩 끝내보면 모두 종료되는 시나리오가 존재하므로 이 경우에는 deadlock이 걸리지 않을 수 있다\n\nDeadlock이 걸리는 경우 §\n\n\n윗쪽의 상태를 보면 아직 종료 시나리오가 존재한다 - P2에게 102를 할당해주면 P2가 종료되며 순차적으로 종료될 수 있기 때문 - 이렇게 종료 시나리오가 존재하는 상태를 safe state라고 한다\n하지만 P1에게 101을 할당해주면 아래와 같이 종료 시나리오가 나오지 않게 된다\n왜냐면 아래쪽을 보면 모든 프로세스가 R1을 필요로 하는데 R1의 잔고가 하나도 남아있지 않은 상황이다. 따라서 프로세스 종료 시나리오가 나오지 않기 때문에 이 경우 추후에 deadlock이 발생하게 된다\n하지만 아직은 deadlock이 아니다 : 아직 P1이후로는 아무도 리소스를 요청하지 않았기 때문에 deadlock이라고는 할 수 없는것 - 즉, 아직 할당해줄 수 있는 자원이 남았기 때문에 이 범위 안에서 리소스를 요청하게 되면 그것을 수락할 수 있기 때문이다\n그래도 worst case를 가정했을 때 - 만약 저 프로세스들 중 어느 누구라도 R1을 요청하는 상황 - deadlock이 걸리게 되고 따라서 종료시나리오가 나오지 않는 것이라고 판단하는 것이다 - 이렇게 deadlock은 아니지만 종료 시나리오가 나오지 않는 그러한 상태를 unsafe state라고 한다\n따라서 OS는 P1한테 101을 주면 unsafe state이 걸린다는것을 알 수 있으므로 P1이 101을 요청해왔을때 이것을 거절하는 식으로 deadlock을 avoid할 수 있다\n이렇게 요청이 들어왔을때 unsafe state로 바뀌는지를 계산해 할당여부를 결정하는 식으로 avoid하게 된다\n이렇게 할당할때 조심스럽게 다 계한하고 위험요소가 없을 때 할당하는 것(worst case를 판단해서 할당여부를 결정하는 것)을 banker’s algorithm이라고 한다\n하지만 프로세스가 얼마만큼의 리소스를 필요로 하는지 알기 어렵기 때문에 - 저 claim matrix와 resource vector를 알아내는게 쉬운일이 아니기 때문에 avoid를 하는 것은 쉬운일이 아니다\navoidance는 미래를 알고 대비하는 것 이기 때문에 보수와 방임의 중간정도이다\n\nDetection strategy §\n\n\nDetection의 경우에는 저 Claim matrix를 알 수가 없고 단지 Request matrix만 알고있는 상황이라는 점에서 Avoidance와는 좀 다르다 - 여기서 request matrix는 앞으로 더 요청할 수도 있지만 일단 지금은 요정도 요청한다이런 의미의 표이다\n그래서 Request matrix와 Available vector를 가지고 프로세스 종료 시나리오를 짜봣을때 시나리오가 안나오면 deadlock이라고 판단하게 되는 것 이다 - 시나리오 짜는 방법은 저 request matrix 이후 더 이상 요청을 하지 않고 종료된다는 가정 하에 종료 시나리오를 짜는 방법이다\n\nRecovery strategy §\n\n프로세스들을 다 죽일수도 있지만 그럼 처음부터 다다시 해야되므로 효율적이지 않다\n방법1 : git reset HEAD^마냥 그 주기적으로 detection을 하고 이전 detection했을때의 상태를 저장해놨다가 deadlock이 발생하면 이 지점으로 다시 돌아가는 방법으로 해결할 수도 있다\n방법2 : deadlock이 풀릴때까지 프로세스를 하나씩 뱉게 하거나 죽여버리는 것이다\nDetection &amp; Recovery는 방임형 해결방법이다 - 걍 냅뒀다가 deadlock이 발생하면 해결하는 것 이므로\n\n밥먹는 철학자 문제 §\n\n철학자는 스파게티를 먹는데 2개의 포크가 필요하다\n포크 하나를 동시에 두명이 들 수 없다\n이 경우 deadlock이 걸리는 상황은 모든 사람이 왼쪽(혹은 오른쪽)의 포크만 들고 기다리는 상태이다\n해결법1 - 한번에 4명에게만 포크를 들 수 있는 자격을 준다\n해결법2 - 한번에 짝수번째/홀수번째에게만 포크를 들 수 있는 자격을 준다\n해결법3 - 포크를 드는 순서를 다르게 한다 - 기준을 한명 정해서 그사람을 기준으로 짝수번째 위치의 사람은 왼쪽거를 먼저 들고, 홀수번째의 사람은 오른쪽꺼를 먼저들게 하는 식으로 하면\n"},"originals/os.spring.2021.cse.cnu.ac.kr/07.-메모리-관리":{"title":"07. 메모리 관리","links":[],"tags":[],"content":"\n\n                  \n                  충남대학교 컴퓨터공학과 류재철 교수님의 &quot;운영체제 및 실습&quot; 강의를 필기한 내용입니다. \n                  \n                \n\n\n\n                  \n                  다소 잘못된 내용과 구어적 표현 이 포함되어 있을 수 있습니다. \n                  \n                \n\nOverlay 기법 §\n\n옛날에는 메모리가 부족하기 때문에 프로그램의 일부분만 메모리에 올려놓고 올려놓은 부분을 전부 실행하고 나면 나머지 부분을 올려서 프로그램을 구동햇다\n새로 올라온 부분은 이전 부분을 지워버리게 되는데 이것을 이제 overwrite라고 한다\n근데 이제 프로그램을 잘못 나눠서 나머지 부분을 실행시키는데 앞부분의 자원이 필요해지면 또 아래서 갖고와야 되므로 프로그램의 구동시간이 오래 걸리게 된다 - 따라서 제대로 나눌 수 있도록 잘 프로그래밍 하는 것이 중요했다 이말이야\n이런 프로그램을 나눠 순차적으로 메모리에 올리며 구동하는 것을 Overlay기법이라고 한다\n얘는 이제 swapping이랑은 다르다 - swapping은 바꿔치기하는거고 overlay는 덮어쓰는 개념\n\nMemory, Program Partition §\n\n이제 multiprogramming을 하기 위해 여러개의 프로그램을 메모리에 올리고싶어졌다\n그래서 메모리를 쪼개서(memory partition)여러 프로그램을 올리게 되는데\n메모리를 쪼개다 보면 프로그램이 그 공간 안에 다 안들어갈 수가 있으므로 프로그램도 쪼개게 된다(program partition)\nOS는 이제 메모리를 어떻게 쪼개고 프로그램도 어떻게 쪼개서 여기에 집어넣을건지를 관리해야 한다\n\nAddress Translation §\n\n우리가 코드를 짤때 쓰는 변수같은것들은 다 symbolic address이다 - 우리가 변수에 값을 저장한다는 말은 그 변수가 의미하는 주소에 저장된 값이 그것이라는 소리이므로\n근데 이제 컴파일 과정을 통해 오브젝트파일(c언어에서 .o 파일)로 바뀌게 되면 이 주소는 logical(relative) address가 된다 - 얘는 프로그램의 시작주소를 0이라고 했을때 해당 symbolic address가 저장된 곳의 위치 - 시작점과 현위치의 차이점이라고 생각하면 된다이다.\n이게 실행가능한 파일(executable code, machine code)가 되어 실행되면 실제로 메모리에 저장된 주소인 physical(absolute) address가 된다\n\n얘는 실제 주소를 가리켜야 되므로 레지스터 하나에다가 프로세스가 적재된 메모리의 첫 시작점을 저장하고 거기에 relative address를 더해 physical address를 구하게 된다\n다만 여기서 시작 주소라는 것은 PCB를 제외한 곳의 시작주소이다\n그래서 시작주소는 Base register, 끝주소는 Bounds register에 저장된다\nbounds register는 경계선을 그어줌으로써 허용된 범위 밖을 참조하지 못하게 하는 기능을 한다\n\n\n근데 swapping이 일어나게 돼 얘가 하드로 내려갔다가 다시 올라오면 원래 있던 그 위치로 올라오게 되는 것이 아니다. 따라서 프로세스의 첫주소가 바뀌게 되는데 이렇게 swapping에 의해 프로세스의 첫주소가 바뀌어 physical address가 바뀌는 것을 Relocate라고 한다\nOS는 이놈이 swapping 되어 다시 올라올때 어떻게 첫주소가 바뀌는지를 관리해야 한다 - relocation돼도 문제없이 physical address를 얻어낼 수 있도록\n\nOS가 메모리 관리를 위해 해야되는 것 §\n\nRelocation : 이걸 추적하고있어야됨\nProtection : 남의 영역에 침범하지 않도록 관리\nSharing : 프로세스 간 공유 메모리가 있을 때 protection을 지키는 선 한에서 문제없이 공유될 수 있도록 해야 함\nLogical organization, Physical organization : 실제로는 프로그램이 여러개로 나뉘어서 메모리에 적재되지만 나뉘어지지 않은것처럼 생각하도록 동작해야됨 - 이때 유저 입장에서 붙어있는걸로 생각하는 것이 Logical organization이고 컴퓨터입장에서 나뉘어있는것으로 생각하는 것이 Physical organization이다\n\nFixed partitioning §\n\nFixed partitioning : 메모리를 나눌때 고정크기로 나누는 것\n\nEqual-size partitioning §\n\n그냥 딱 정해진 크기로만 자르는 것\n하지만 얘한테는 다음과 같은 문제점이 있다 :\n\n프로그램이 잘라진 크기보다 더 크면 프로그램을 잘라서 올리는 overlay기법을 사용해야 된다\n반대로 프로그램의 사이즈가 너무 작게 되면 나머지 공간들이 낭비된다 - 이 낭비되는 공간을 internal fragmentation이라고 한다\n\n\n따라서 나누는 크기가 너무 크면 internal fragmentation이 커지고 너무 작으면 overlay기법에 의해 IO request가 너무 많이 발생해 문제가 된다\n\nUnequal-size partitioning §\n\n얘는 이제 프로그램의 크기에 딱 맞게 메모리를 나누는게 아니고 약간 호텔에서 1-2인실, 3-4인실 있는것처럼 여러개의 사이즈로 미리 나눈 다음 프로그램의 크기에 맞게 이 나뉘어진 공간에 넣는구조이다\n이렇게 넣을때는 각 방마다 큐를 만들어서 미리 프로그램들을 분배해서 이 큐에 넣어놓는 방법도 있고 큐를 하나만 써서 메모리에 적재될때마다 그때그때 분배하는 방법도 있다.\n하지만 얘한테도 단점이 있다 :\n\n나눈 파티션의 갯수가 결국에는 메모리에 올라갈 수 있는 user program의 갯수가 된다. 따라서 fixed 보다는 올릴 수 있는 프로그램의 수가 적어지게 된다\n얘도 internal fragment가 생긴다\n\n\n\nDynamic partitioning §\n\nDynamic partitioning : 메모리를 나눌 때 프로그램의 크기에 따라 유동적으로 나누는 것 - 그냥 프로그램의 사이즈와 동일하게 나뉘어진다\n이제 얘는 다음과 같은 문제점이 있다 :\n\n프로그램이 메모리에 적재되어있다가 나가면 그 아래에 있던애가 위로 땡겨져서 빈공간을 채우는게 아니라 그냥 비워진 상태로 있게 된다\n근데 그 이후 이 공간보다 작은 프로그램이 여기 적재되면 남는공간이 생기는데 이 공간의 크기가 작을 경우 어떤 프로그램도 들어오지 못하는 수가 있다 - 이런 공간들을 External Fragmentation이라고 하며 이런 공간들이 많아지면 역시 메모리가 비효율적으로 돌아가게 된다\n즉, 메모리가 남는 현상에 대해 fixed의 경우에는 internal이란 이름을 붙인거고 dynamic의 경우에는 external이라고 이름을 붙인 것\n\n\n위와 같은 현상을 방지하기 위해 저 비워진 공간을 비워두지 않고 땡겨서 공간들을 다 합쳐 이 공간들을 활용하는 방법이 나온다. 이것을 Compaction이라고 하며 윈도우에서 “디스크 조각 모음”이라고 하는 것(물론 얘는 메모리가 아니라 하드의 빈공간을 합치는거다)이 여기에 해당한다\n\n적재 알고리즘 §\n\n일단 프로그램이 얼마의 메모리를 먹을지는 적재시점에 알기는 어렵다 - 그래서 대략적으로 추정해서 적재하게 됨\n아래와 같은 적재 알고리즘들을 Placement Policy - 적재정책이라고 하더라\nFirst fit : 메모리의 처음부터 찾기 시작해 가장 먼저 등장하는 적재 가능한 공간에 넣는 것\nBest fit : 메모리 전체를 다 뒤져서 제일 적게 External fragment가 생기는 곳에 넣는 것\nWorst fit : 메모리 전체를 다 뒤져서 제일 많이 External fragment가 생기는 곳에 넣는 것 - Worst라고 해서 안좋은게 아니다 - 저게 크면 저부분에 또 다른 프로그램이 올라갈 확률도 많아지므로\nNext fit : 제일 최근에 넣었던 부분 바로 옆에다가 적재하는 것\n저것들 중에 Best, worst가 적재하는데 제일 오래 걸린다\nBuddy system : 얘는 프로그램의 크기에 따라 메모리를 자르긴 하되 2의 배수에 맞춰서 메모리를 자르는 방식이다 - 만약에 100k를 요청하게 되면 128k의 메모리 공간에 적재하는 것 - 메모리 공간을 절반으로 자르고 자르고 해서 제일 잘 맞는 곳에다가 적재하게 된다\n\nPaging §\n\n일단 메모리를 고정크기로 잘게 나눈다. 이 나눈 고정크기의 메모리 조각을 frame이라고 한다\n그리고 프로그램도 같은 크기로 잘게 나눈다. 이 나눈 고정크기의 프로그램 조각은 page라고 한다\n이 둘의 크기가 같기 때문에 하나의 페이지는 하나의 프레임에 올라가게 된다\n고정크기를 활용하기 때문에 fixed partitioning의 상위호환이라 볼 수 있다\n\nPage table §\n\n얘는 프로그램을 메모리에 적재할 때 연속된 공간에 적재하지 않을 수도 있다\n대신 해당 프로그램이 어디어디에 적재되어있는지를 알려주는 역할을 하는 page table이 존재하게 된다\n전에 PCB를 모아놓은 Process table이 있다고 했는데 여기에 page table도 같이 들어있다\n이 page table은 배열처럼 인덱스마다 프로그램이 적재된 페이지의 번호를 저장한다 - 인덱스는 page번호(프로그램을 프레임 크기만큼 잘라서 앞에서부터 0, 1, … 이렇게 번호를 매긴 것), 안에 저장돼있는 값은 frame 번호(메모리 전체를 frame크기만큼 잘라서 0, 1, … 이렇게 번호를 매긴 것)\n따라서 page 번호는 프로그램을 앞에서 잘라 매긴것이므로 logical address를 표현할 때 사용되고 frame번호는 메모리를 앞에서부터 잘라 매긴 것 이므로 physical address를 표현할 때 사용되는 것이다\nfree frame table도 존재해서 남은 프레임들의 번호도 저장하게 된다\n\nPaging에서의 physical address 구하기 §\n\n\nRelative address는 수치상으로 시작점부터 얼마나 떨어져 있는지를 나타내는 개념이고\nLogical address는 relative address를 page 번호를 이용해 나타낸 개념이라는 차이점이 있다 - 어쨋든 둘 다 시작점을 기준으로 거리를 나타내는 개념이다\n왼쪽의 프로세스를 page크기인 1k로 자르면 오른쪽 그림처럼 나온다. Relative address 1502는 1024 + 478이므로 page 하나와 478만큼의 거리만큼 떨어진 곳이 해당 주소가되는 거고 이걸 logical address로 표현하면 page1번 시작점으로부터 478만큼 떨어져 있다는 의미로 page# = 1, Offset = 478이 되는 것이다 - Offset은 페이지의 시작점으로부터 얼마나 떨어져있는지를 나타내는 것\n이것을 이진법으로 계산한 것이 위쪽에 나와있는 수치들이다. 1024는 2의 10제곱이므로 16비트로 표현된 relative address에서 6비트 /10비트로 나누면 앞쪽부분이 page#, 뒤쪽부분이 Offset이 되는 것이다\n\n\n\n이것을 이용해 physical address를 나타내는 것은 이 그림에 나와 있다.\n일단 page# 이 1 이므로 이것을 page table의 인덱스로 넣어주면 거기 저장되어있는 값이 frame# 가 되는것이다\n따라서 이 frame# 을 6-bit page# 에다 넣어주면 바로 physical address가 나오게 되는 것 이다 - page table에 가서 frame# 만 가져다가 붙여주면 되기 때문에 address translation이 아주 간편하다\n\nSegmentation §\n\n이제 얘는 고정크기로 나누는게 아니고 메모리를 프로그램의 function(module)크기로 나눠서 적재하는 기술\n메모리와 프로그램을 같은 크기로 나누되 그 크기는 프로그램의 function(module)의 크기를 따라간다고 생각하면 된다\n이렇게 하는 이유는 memory sharing을 할때도 function(module)단위로 하게 되므로 이것의 크기를 기준으로 나누는게 좋겟다고 생각한것\n이렇게 function(module)을 기준으로 나눈 조각조각을 segmentation이라고 한다\n얘는 가변크기이기 때문에 dynamic partitioning의 상위호환이라고 볼 수 있다\n\nSegmentation에서 physical address 구하기 §\n\n\n얘는 paging처럼 크기가 고정되어 있지 않으므로 앞의 몇비트는 segment# 를 나타내는데 쓰이고 나머지는 Offset을 나타내는데 쓰이는 식으로 구성된다 - paging처럼 relative address에서 몇비트를 자른다고 해서 바로 segment# 가 구해지는게 아니다\n그래서 예시를 보면 segment# 에 4비트가 할당되어 있으므로 한 프로그램이 가질 수 있는 총 segment# 의 갯수는 2의 4제곱인 것이고 그 뒤에 offset으로 12비트가 할당되어 있으니 한 segment는 최대 크기가 2의 12제곱이 되는 것이다\n프로세스 전체를 segment0 750, segment1 1950으로 자른 다음(자르는 기준은 당연히 module이겠쥬?) 계산해보면 logical address segment1의 offset 752부분이 relational address의 1502와 같아지게 되는 것\n\n\n\n그래서 이 logical address로 physical address를 구하는 방법이 위 그림이다\nsegment table은 segment가 어디서 시작하는지에 대한 주소인 base와 한 segment의 길이인 length를 담고 있는 배열이다.\nlogical address의 앞 4비트를 이용해 인덱스를 알아내고, 그 인덱스로 가서 뒤의 16비트를 가져오면 그게 segment의 시작점 주소가 된다. - 이번에는 paging과 다르게 풀 주소값이 저장되어 있으므로 이 값을 offset이랑 더해 physical address를 얻어내는 것\n그리고 length는 offset값이 정상인지를 검사하는 용도로 쓰인다. 즉, segment의 길이가 length이므로 offset이 저 값보다 작아야 정상인 것\n\nPaged Segmentation §\n\n얘는 이제 저 둘을 합친 개념이다. 즉, function(module)별로 메모리에 적재를 하되 얘네들을 여러 frame에 걸쳐서 적재를 하는 것을 Paged segmentation이라고 한다\n즉, function(module)하나를 여러 연속된 frame에 걸쳐 적재하는 것\n"},"originals/os.spring.2021.cse.cnu.ac.kr/08.-가상메모리":{"title":"08. 가상메모리","links":[],"tags":[],"content":"\n\n                  \n                  충남대학교 컴퓨터공학과 류재철 교수님의 &quot;운영체제 및 실습&quot; 강의를 필기한 내용입니다. \n                  \n                \n\n\n\n                  \n                  다소 잘못된 내용과 구어적 표현 이 포함되어 있을 수 있습니다. \n                  \n                \n\n가상메모리 §\n\n봐봐라\n실제로는 프로그램의 전부가 메모리에 올라가는 것이 아닌 프로그램의 페이지 일부만 메모리에 올라가게 된다\n그리고 실제로는 페이지들이 하드에나 메모리에나 연속된 공간에 있지 않고 다 흩어져 있다\n하지만 우리가 생각할때는 이 페이지들이 전부 메모리에 연속적으로 적재되어있다고 생각하고 프로그램을 짜게 된다 - 이렇게 사용자입장에서 생각하기 편하게 하려고 착각을 유도하는 기법을 가상 메모리(Virtual Memory) 라고 한다\n\n이렇게 가상 메모리 기법을 적용한 paging을 일반 paging과 구분해 Virtual Memory Paging이라고도 부르더라\n마찬가지로 가상 메모리 기법을 적용한 segmentation을 Virtual Memory Segmentation이라고 한다\n\n\n이렇게 함으로써 우선 메모리 사이즈보다 더 용량이 큰 프로그램도 메모리에 적재시킬 수 있고, 프로그램 전부가 올라가지 않기 때문에 더 많은 프로그램을 적재할 수 있어 Multiprogramming에서도 이점이 있다(Multiprogramming level을 높일 수 있다)\n\n그리고 이것은 프로그램 개발자의 관점에서도 프로그램 크기에 따라 다르게 프로그래밍 할 필요가 없다는 이점이기도 하다\n\n\n이때 원하는 페이지가 메모리에 적재되어있지 않고 하드에 들어있을때 Page fault가 일어나게 된다 - 이렇게 page fault가 일어나면 block을 먹고 IO operation이 일어나며 가져오고난 뒤에는 인터럽트를 걸고 다시 ready상태로 바뀐 다음에 dispatch되면 실행되는 과정을 거치는 것\n가상메모리가 잘 구동되기 위해서는 물리적으로 메모리 공간을 나눠 page가 들어올 frame들을 구성하는 하드웨어적인 역할 과 page replacement같은 기능을 수행할 소프트웨어적(운영체제적)인 역할 이 중요하다\n\nPage 사이즈 정하기 §\n\nPage 사이즈가 작으면 만약에 page fault가 일어났을때 한번에 가져오는 양이 적기 때문에 page fault가 자주 일어나게 된다\n또한 page table의 사이즈가 커져 PCB가 커지기 때문에 많은양의 메모리를 먹게 된다\n하지만 반대로 page 사이즈가 너무 크면 작은 프로그램의 경우에는 page하나에 담기고 남은 부분이 internal fragmentation이 되기 때문에 메모리의 낭비가 생기게 된다\n이렇듯 운영체제를 설계할때는 항상 대조되는 선택지의 장단점이 존재하기 때문에(Trade-off라고 한다) 이것을 잘 조화시켜서 최선의 결과를 내는 Optimal Design이 중요하다\n요즘의 경우에는 메인메모리의 값이 그렇게 비싸지 않기 때문에 fragmentation이 그렇게 큰 문제가 안돼 page의 사이즈를 크게 하는것이 추세란다\n\n\n\n첫번째 그래프에서 왜 사이즈가 작을때 page fault가 작아지는지는 모르겠음 - 어중간할때는 왜 큰지도 모르겠음\n어쨋든 사이즈가 커지면 한번에 많이 갖고오므로 page fault가 잘 안일어난다는게 중헌것이고\n두번째 그래프는 프로세스 하나에 대해 frame이 몇개가 할당되는지에 대한 그래프다. 높을수록 프로세스 하나에 많은 frame을 할당받으므로 메모리에 올라갈 수 있는 프로세스의 갯수는 적어지고 대신 보다시피 page fault rate는 적어진다\n\n\n\n근데 할당되는 프레임의 갯수가 많아지면 rate가 줄어야 정상인데 replacement algorithm 이 잘못되면 저렇게 rate가 치솟는 현상이 생기고 이것을 Belady’s anomaly라고 한다\n\nPage Replacement §\n\n이전에 프로세스가 메모리에 들어와야 되는데 메모리에 자리가 없으면 한놈이 자리를 비켜주고 하드로 내려가는거를 swapping이라고 했는데\nPaging기법에서도 동일하게 메모리에 자리가 없으면 어느 한 놈이 자리를 비켜주는 동작을 하게 되고 이것을 Page Replacement라고 한다\n근데 이때 아무 page나 내려보내게 되면 프로그램이 비효율적으로 동작할 수도 있다\n\n즉, page 교체 알고리즘에 따라서 동작의 효율성도 달라질 수 있다는 소리임\n뭐 예를 들면 우선순위가 비교적 높은 놈의 page를 내려보내면 얘를 조만간 다시 갖고 올라와야되기 때문에 page fault가 자주 일어나 IO request도 자주 일어나게 되는 것\n\n\n그리고 page는 어차피 원본의 page가 하드디스크에 저장되어있기 때문에 메모리에 적재되어있던 page와 하드디스크에 있던 원본의 page가 차이가 없으면 하드로 내려보낼 때 굳이 새로 write하지 않고 하드에서 올라오는 page를 그 자리에 overwite하게 된다\n하지만 메모리에 올라와있던 page에 변경이 생기게 되면 그제서야 하드에 write하는 작업을 하게 된다\n그리고 이제 안그래도 IO가 일어나서 기다렸는데 자리가 없어서 replacement까지 일어나면 OS입장에서는 굉장히 기다리는 시간이 아까우므로 OS는 항상 일정한 수만큼 blank(비어있는) frame을 만들어놓는다 - 그래서 IO가 끝나면 바로바로 올릴 수 있게\n\n위에꺼를 반영한 paging / segmentation §\n\n\n여기서 페이지 테이블의 한 행의 구조를 나타낸 것이 아래 그림인데 보면 frame number만 있는게 아니고 앞에 Control Bit가 붙는다\n얘는 데통에서 헤더마냥 frame / page 의 여러가지 정보를 담는 부분이다\n일단 P는 이 page가 현재 메모리에 적재되어있냐를 나타내는 비트(Present)이다.\n\n즉, 이게 enable되어 있으면 frame number부분에 유효한 number가 들어가 있을 것이고\ndisable되어 있으면 메모리에 적재되어있지 않다는 뜻으로 유효하지 않은 number가 들어있게 된다\n\n\n그리고 M은 이 page가 변경되었냐를 나타내는 비트(Modified)이다\n\n위에서 설명한것처럼 page replacement를 할 때 변경되지 않았으면 굳이 하드에 write를 하지 않아도 되기 때문\n\n\nsegmentation의 경우에도 앞에서 배운거랑 마찬가지되 P, M이 붙게 된다\n\nPaging의 address translation 방법 복습 §\n\n\n가상 주소에서 offset은 그대로 가고 page# 을 이용해 frame# 를 찾는거\n레지스터에 저장된 page table의 시작점, 즉. page table ptr을 이용해 page table로 이동하고, page# 를 인덱스로 하여 frame# 을 얻어내 physical address를 얻어내는 것\n\nThrashing §\n\n\n봐봐라\n메모리에 많은 프로세스가 올라가게 되면, 즉, multiprogramming level이 올라가게 되면 당연히 cpu utilization도 늘어난다\n근데 multiprogramming level이 늘어난다고 무조건적으로 좋은것은 또 아니다 이말이야\n\n왜냐면 multiprogramming level이 늘어나면 하나의 프로세스에게 할당되는 공간이 줄어들고 그러면 page fault가 더 자주 일어나게 되기 때문이다\n그래서 저 위의 그래프에서 보이듯이 일정수준까지는 multiprogramming level이 늘어갈수록 cpu utilization도 늘어나게 된다.\n하지만 그 수준을 넘어서게 되면 위에서 설명한것처럼 page fault가 자주 일어나 cpu utilization이 급격하게 하락하게 된다\n이 지점을 Thrashing이라고 하는 것. 즉, multiprogramming level이 과도하게 많아지면 page fault가 너무 자주 일어나 cpu utilization이 급락하는 것을 의미한다\n따라서 운영체제 입장에서는 Thrashing은 반드시 막아야 되는 현상이다\n\n\n따라서 multiprogramming level이 너무 낮으면 프로세스 하나가 블락을 먹었을때 대체제의 선택폭이 좁아져 cpu utilization이 안좋고 또 너무 높으면 thrashing이 일어나기 때문에 안좋아져서 적절한 level을 잡는 것이 중요 하다\n\nLocality - 지역성 §\n\n만약에 프로그램에 while문이 하나 있다고 하고 이부분이 세개의 page로 나뉘어졌다고 해보자\n근데 만약 메모리에 공간이 없어서 두개의 frame밖에 할당하지 못한다면 루프가 돌때마다 page fault가 일어나므로 아주 효율성이 떨어질 것이다\n따라서 다음과 같은 경우에는 해당 프로세스에게 3개 이상의 frame을 할당하는 것이 효율성을 높이게 된다\n이렇듯 프로세스를 이루는 page들 중에서도 집중적으로 실행되는 page들을 중간에 끊지 않고 전부 메모리에 올려 page fault를 줄이는 것을 지역성(Locality) 이라고 한다\n\nCombined segmentation &amp; paging §\n\n\n이부분은 별로 설명 안함 - 가상메모리에 page# 와 seg# 둘 다 있어서 page table과 segment table을 둘 다 이용한댄다\n\nMulti-Level Hierarchical Page Table §\n\n\npage table을 다계층 구조로 만들어 page table의 사이즈를 줄이는 기법이다\n\n봐봐라\n만약에 page# 에 20비트가 할당되어있고 offset이 12비트인 32비트 체제라면 page table의 길이는 2의 20승이다\n하지만 프로그램의 크기가 작아서 page가 몇개 되지 않는다면 2의 20승 중에 일부만 사용하고 나머지는 버리게 되는 셈이다\n근데 이것을 두개의 계층으로 나누면 첫 10비트는 첫번째 계층 table에서의 index를 나타내고 나머지 10비트는 두번째 계층 table에서의 index를 나타내는데\n만약에 프로그램을 구성하는 page의 갯수가 2의 10제곱보다 작으면 하나의 2^10 사이즈 테이블로 모든 page# 에 대응되는 frame# 을 저장할 수 있자네\n이때 이 2^10 사이즈 테이블이 2계층 테이블인거고 이 2계층 테이블들로 접근할 수 있도록 얘네들의 주소를 담고 있는 테이블이 1계층 테이블인 것이다\n따라서 page의 사이즈가 2^10보다 작으면 1계층 테이블에는 하나의 원소만 존재하고 2계층 table하나만 있어도 모든 page에 대응되는 frame을 저장할 수 있으므로 메모리를 2^11 만 차지하게 되는 것 - 계층구조를 도입하기 전인 2^20에 비해 엄청난 양의 공간을 절약할 수 있다\n\n\n이런식으로 가상주소의 page# 구역을 여러개로 쪼개 page table하나로 모든 page에 대응하는 것이 아닌 page table을 계층적으로 구조화해 동적으로 page table이 생성되며 메모리를 절약하는 방식 이 Multi-Level Hierarchical Page Table인 것이다\n다만 이 방식에 장점만 있는 것은 아니다 - 다계층이 될 수록 address translation은 복잡해지기 때문에 수행시간이 오래 걸리는 것 = 공간과 시간이 반비례하는 현상이 여기서도 나타나게 되는 것이다\n\n\n\n따라서 보면\n\n첫 10비트와 page table ptr를 통해 알아낸 1계층 테이블로 이 가상주소의 frame# 을 담고 있는 2계층 테이블의 주소를 알아낸다\n그리고 2계층 테이블로 가서 두번째 10비트를 이용해 frame# 을 알아내게 되는 것\n\n\n\nInverted Page Table §\n\n\n봐봐라\n일단 Inverted Page Table의 개념은 프로세스들마다 존재하는 page table을 하나로 합쳐 OS에 하나만 존재하는 테이블로 만드는 것이다\n이렇게 바꾸는 과정은 약간 데베식의 설명을 곁들이면 하나의 frame# 을 특정하기 위해서는 page# 와 pid를 기본키로 하면 특정할 수 있다\n\n근데 프로세스마다 존재하는 page table은 이미 pid가 PCB에 저장되어있기 때문에 page# 만으로 하나의 frame# 을 특정할 수 있었던 것 인데\n이것을 이제 하나의 테이블로 합치면 pid는 알 수가 없기 때문에 pid 어트리뷰트를 하나 추가하고 거기에 대응되는 frame# 을 저장하는 것 - 저기 그림에서 Chain이라고 표시된 부분이 frame# 이 저장되는 부분이다\n근데 하나의 메모리 공간을 여러 프로세스가 공유하는 경우도 생긴다 - 뭐 공유 메모리라던가, 하나의 프로그램을 여러번 실행시켜 read-only인 코드는 여러개의 프로세스가 공유하는 등\n이것을 지원해주기 위해 chain값으로 다른 프로세스의 페이지가 담긴 frame# 을 넣어서 참조하게 할 수 있다\n\n\n따라서 page# 을 가져와서 테이블에서 자신과 page# 와 pid가 같은 인스턴스를 찾아 chain 어트리뷰트의 값인 frame# 을 받아 address translation 을 하는 것\n이때에는 찾는 과정을 빠르게 하기 위해 hash function을 이용한다 - 파이썬 딕셔너리할때 그 해시임\n\nLookaside Buffer §\n\n얘는 저장장치의 한 종류인데\n보통 하나의 값을 배열에서 찾거나 할때는 처음부터 serial하게 쭉쭉 찾아나가자네?(O(n))\n근데 이걸 사용하면 배열의 모든 원소를 한번에 비교해 원하는 값을 찾는 것 같은 기능을 제공해준다(O(1))\n저장장치의 한 종류이므로 하드웨어이고 이런 강력한 기능을 제공하는 대신 좀 비싸다\naddress translation을 담당하는 lookaside buffer를 **Traslation Lookaside Buffer(TLB)**라 하고 얘는 레지스터의 한 종류이다\n\n얘를 이용해 address translation을 하는 방법 §\n\n\nPage table의 일부분을 저 TLB로 올린다\n이제 가상주소 하나를 translation할 때 page# 을 저기 TLB에 먼저 넣어본다\n만약에 hit(찾음) 이면 바로 frame# 가 나오게 되고 miss(못찾음) 이면 이제 그제서야 page table로 가서 serial하게 찾게 된다 - page table의 일부분만 TLB에 올라갈 수 있으므로 miss될 수 있다\n찾으면 Locality를 활용하기 위해 TLB에 이 page를 넣어놓는다 - 또 사용되면 빠르게 hit시키기 위해 → 그리고 translation을 해 frame# 을 얻어내는 것\n하지만 page table에서 봤더니 얘가 메모리에 없을 수도 있다 - 그러면 page fault handling routine이 실행되어 이놈을 갖고오고 처음부터 다시 하게 되는 것\n\n\n이 방법은 운이 없어서 miss가 뜨면 TLB에 접근하는 시간만큼 손해이긴 하다\n하지만 위에서 말한 Locality를 이용하면 hit의 비율을 90퍼센트 이상으로 끌어올릴 수 있고 이러면 serial하게 비교하는 경우가 거의 없기 때문에 아주 빠르게 address translation이 가능하다\n\nCache §\n\n캐시도 TLB와 비슷하게 one-time search를 지원해주는 저장장치이다\nphysical address를 구하고 나서 원래는 이 주소에 해당하는 메모리 공간으로 가 instruction을 실행하는데\n메모리에 가기 전에 먼저 cache에 가서 이 주소에 대한 instruction이 이미 존재하는지를 찾는다\n그래서 만약에 hit라면 바로 cpu로 올려 실행하게 되는 것 이고\n아니면 그제서야 메인메모리의 해당 주소로 가게 되는 것\n"},"originals/os.spring.2021.cse.cnu.ac.kr/09.-Segmentation":{"title":"09. Segmentation","links":[],"tags":[],"content":"\n\n                  \n                  충남대학교 컴퓨터공학과 류재철 교수님의 &quot;운영체제 및 실습&quot; 강의를 필기한 내용입니다. \n                  \n                \n\n\n\n                  \n                  다소 잘못된 내용과 구어적 표현 이 포함되어 있을 수 있습니다. \n                  \n                \n\nSegmentation §\nSegmentation 의 장단점 §\n\n우선 장점은 모듈 단위로 끊기 때문에 모듈의 protection과 data shraing이 잘된다는 거고\n단점은 이제 external fragmentation이 발생한다는 것과 이것을 최소화하는 것이 힘들다는 것이다\n\nAddress Translation §\n\n\n이전에도 한번 설명한거같은데\n일단 Seg# 를 인덱스로 하고 Seg Table Ptr을 이용해 테이블에 접근하고\n거기서 Base는 Segment의 시작주소가 담겨있으므로 이거에 offset을 더하면 된다\n그리고 Length는 Segment의 길이로 offset은 이것보다 커서는 안된다\nPaging과 Segmentation의 Address Translation 차이점을 잘 기억해라\n\nSegmentation Paging §\n\n\n그래서 보통은 Segmentation과 Paging을 섞은 Segmentation Paging을 사용한다\n얘는 Module단위로 Segment으로 나뉘긴 하는데 이 각각의 Segment들은 일정한 크기의 Page로 나뉘는 것\n따라서 Logical address도 ( Seg# - Page# - offset ) 순서로 구성된다\n\nAddress Translation §\n\n\n보면 이제 일단 Seg Table Ptr를 이용해 테이블에 접근하고 Seg# 를 인덱스로 해서 해당 원소에 접근한다\n근데 여기서 중요한 것은 Seg# 를 인덱스로 한 곳에는 Page Table의 주소가 들어있다. 즉, Segment table은 Process마다 하나씩 갖지만 Page Table은 Segment마다 하나씩 갖게 된다\n그렇게 Page table로 접근해 Page# 를 인덱스로 해서 frame# 을 알아낸다\n그리고 offset앞에 frame# 을 딱 붙여주기만 하면 변환이 마무리되는 것\n\n\n\n따라서 주소와 테이블 인스턴스는 저렇게 구성된다\n아까 말한것처럼 Segment Base에 Page Table의 시작주소가 들어가게 되는 것\n그리고 Page Table도 기존처럼 변경 유무를 저장해 replacement를 쉽게 하는 등의 기능들을 지원하기 위해 Pbit와 Mbit같은 Control Bits가 존재한다\n\nOS Policies for Virtual Memory §\n\n아래의 용어들을 다 알아야된다\n\n\nFetch Policy §\n\nFetch Policy : 언제 페이지를 하드에서부터 갖고올 것이냐\nDemand Paging : 요구가 있을때 갖고옴. 즉, 참조를 할때 그제서야 갖고오는 정책\n\n당연히 메모리는 적게먹는다. 하지만 Page fault가 많이 일어나게 되는 단점이 있다\n\n\nPrepaging : 하드에서 갖고올때 걔만갖고오는게 아니고 다음에 쓸거같은애들도 같이 갖고 옴\n\n예를들면 page# 1 을 가져올때 page# 2도 나중에 쓰게될 확률이 높으므로 얘도 같이 가져오는 것\n메모리는 좀 더 먹지만 page fault가 적게 일어난다는 장점이 있다\n따라서 오늘날 주로 쓰이는 OS정책임\n\n\n\nPlacement Policy §\n\nPlacement Policy : best fit 같은애들. segment를 빈공간 어디에 적재할 것인가\n당연히 paging기법을 사용하면 이런거를 고민할일이 없기 때문에 요즘은 별로 중요하지 않은 정책이다\n\nReplacement Policy §\n\nReplacement Policy : Page fault가 일어났을 때 어떤애를 선택하여 아래로 내려보낼 것인가 - 교체대상 선정\nFrame Lock : 커널같은 중요한 프로세스들은 하드로 내려가면 안되기 때문에 lock을 걸어서 replacement 대상에서 제외하는 것\n\n\n\nReplacement Algorithm 예시 - 이거 시험문제 나온다 - 어떤 알고리즘을 선택했을때 앞에서 배운 Anomaly(이상현상)이 일어나는지 생각해볼것 - 정 모르겠으면 구글링해서 찾아봐라 - 안알려주노 ㅅㅂ\n위에 나열돼있는 숫자들이 요청된 페이지 번호, 그리고 그 아래가 프로세스에 할당된 프레임의 모습이다 - 3개로 일정하고 자신의 프로세스 내에 있는 페이지를 버리므로 local이라고 할 수 있다 - 예시에서는 초기에 적재되는 page fault는 무시하고 page fault가 일어나 replace가 일어나야되는 것만 카운트했다\n\nOPT(Optimal) : Replacement가 일어났을 때 미래의 페이지 사용을 보고 안쓰이거나 가장 나중에 쓰이는 (혹은 가장 최근에 사용된 - 가장 최근에 사용된 놈은 다시 사용할 가능성이 비교적 낮다고 판단)페이지를 내려보낸다 - 당연히 미래의 일을 알아야되므로 구현이 불가능 하며 다른 알고리즘과의 비교를 위해 존재하는 것이다 - 위의 예시에서는 3번의 Fault가 일어나며 제일 좋은 성능을 보여주지만\nLRU(Least Recently Use) : 제일 오래전에 사용된 놈을 버리는 구조\nFIFO(First In First Out) : 이건 뭔지알제? 제일 먼저 들어온놈이 먼저 나가는 구조 - 얘는 LRU랑 헷갈리면 안된다 - LRU는 제일 오래전에 사용된거고 FIFO는 제일 오래전에 메모리로 올라온거임\nCLOCK(Secondary Chance Algorithm) :\n\n\n\n\n\n이게 뭔뜻이냐면 원 밖에 있는 숫자는 frame# 을 의미 하고 저 한칸한칸에는 해당 프레임에 할당된 page# 와 몇번사용(참조)했는지(use)가 저장되어있다\n그리고 저 시계바늘이 룰렛마냥 방출될 애를 가리키는 역할이다\n일단 이러한 구조때문에 CLOCK이라는 이름이 붙어있는 것\n그리고 이 알고리즘이 구동하는 방식때문에 Second Chance Alg라는 이름이 붙었는데\n저 시계바늘이 가리키고있는 놈의 use가 0이 아니면 얘를 방출시키지 않고 다음칸으로 넘어가며 use를 0으로 초기화하기 때문에 한번 더 기회를 준다는 의미에서 저런 이름이 붙은 것이다\n이제 반대로 시계바늘이 가리키고있는놈의 use가 0일 경우에는 그놈을 방출시키고 새로운 페이지를 들이는 것\n따라서 위의 예시에서 frame# 2, 3의 use가 0으로 바뀌고 4번에 새로운 페이지가 들어오며 들어옴과 동시에 한번 사용하기 때문에 use는 1로 되어있는 것이다\n이렇게 되면 use가 0이라는 것은 시계바늘이 한바퀴 돌때동안 사용되지 않았다는 뜻이므로 가장 오래전에 사용된거랑 비슷하다 - LRU와 유사한 효과, 성능을 낸다\n반대로 use가 0이되고 나서 시계바늘이 한바퀴 돌때동안 사용되었다면 다시 use가 올라가므로 시계바늘이 다시 돌아왔을 때 방출되지 않고 다시 0으로 바뀌게 되는것\nPage Buffering : 얘는 뭐냐면\n\n만약 메모리의 일정부분을 free로 유지하기 위해 페이지 한놈을 하드로 내려보냈다고 해보자\n근데 실행되다가 이놈이 다시 필요해진 순간이 왔을때 page table로 가서 Pbit를 보면 당연히 하드로 내려갔으므로 없다고 뜰것이다 이말이야\n근데 만약에 아직 이자리에 다른 프레임이 overwrite되지 않았으면 이놈은 free이긴 해도 데이터는 그대로 남아있을거란말이지\n그래서 바로 IO를 때려 하드에서 갖고오기보다는 데이터가 아직 overwrite되지 않았을 수도 있으므로 free인 저 공간을 다시 조사해 원래의 페이지가 남아있으면 다시 Pbit를 바꾸고 그대로 사용하는 개념이다\n\n\n\nResident Set Management §\n\nResident Set Size : 한개의 프로세스에 몇개의 프레임을 할당할 것 인가\n\nFixed : 고정된 갯수의 프레임을 할당\nVariable : 가변갯수의 프레임을 할당 - 요즘 추세란다\n\n\n\n\n\nWorking Set Model : 걍 단순하다 - 특정 시점에 Window size(할당되는 프레임 최대 갯수)만큼의 최근 페이지 참조(위의 예시에서 한 시점 기준 window size만큼 위에있는만큼의 페이지를 묶어서)를 보고 그거를 집합으로 묶어 그 시점에의 할당 프레임 갯수를 정하는 것\n\n알고리즘이 간단하고 Locality가 반영된다는 장점 이 있음\n하지만 실제로 써보니까 Locality도 제대로 반영 안되고 에 따라 너무 할당되는 갯수도 달라지고 window size를 정하기도 어려운 등의 문제가 있더라\n\n\n\n\n\nVariable-Interval Sampled Working Set(VSWS) - 얘는 이제 page fault rate의 상한선과 하한선을 정해놓고 할당갯수를 변화시키면서 rate가 너무 높으면 할당갯수를 늘리고 rate가 하한선보다 떨어져서 할당갯수가 너무 많으면 줄이고 하는식으로 유동적으로 할당갯수를 줄이는 방식이다\nReplacement Scope : 하드로 내려보낼 페이지를 정하는 범위\n\nGlobal : 현재 프로세스가 아닌 다른 프로세스의 페이지를 내려보냄 - 속도를 위해 요즘은 얘를 사용한댄다\nLocal : 현재 프로세스의 페이지를 내려보냄\n\n\n\nCleaning Policy §\n\nCleaning Policy : 프로세스가 종료되고 프레임들을 비우는 것에 대한 정책\n메모리에 있는 페이지가 변경되었을 경우에 변경될때마다 하드에 있는 페이지를 바꿔주기(Demand Cleaning)보다는\n메모리에 있는놈이 하드로 내려갈때 변경사항을 한번에 업데이트해주는 방법(Precleaning)을 이용한댄다\n\nLoad Control §\n\nLoad Control : 프로세스를 메모리에 올려주는 Loader와 관련된 정책 - 몇개의 프로세스를 올려 multiprogramming level을 어떻게 가져가 최적의 cpu utilization을 낼 것인가(Thrasing을 내지 않을 것인가) - 위에서의 Resident Set Management와도 연결되는 내용\n여기서 multiprogramming level이 너무 높아 page fault가 너무 많이 일어나 프로세스를 내쫒을때는 다음과 같은 룰들을 적용한다(이게 전부는 아님 - 참고)\n\n우선순위가 낮은놈\nfault를 많이 일으키는 놈\n마지막으로 실행된놈\n가장 적은 프레임을 가지고있거나\n가장 사이즈가 큰 프로세스\n\n\n"},"originals/os.spring.2021.cse.cnu.ac.kr/10.-CPU-Scheduling":{"title":"10. CPU Scheduling","links":[],"tags":[],"content":"\n\n                  \n                  충남대학교 컴퓨터공학과 류재철 교수님의 &quot;운영체제 및 실습&quot; 강의를 필기한 내용입니다. \n                  \n                \n\n\n\n                  \n                  다소 잘못된 내용과 구어적 표현 이 포함되어 있을 수 있습니다. \n                  \n                \n\nShort, mid, long - term Schedule §\n\n\n일단 Ready Queue에 있다가 Dispatch가 되어서 CPU를 할당받는 작업이나 Timeout이 걸려 Ready Queue로 내려가는 것, IO등의 이벤트로 인해 Block되는 작업 은 가장 빈번하게 일어나기 때문에 이것에 관련된 정책을 Short-term Schedule 이라고 한다\n그리고 메모리에 자리가 없어서 Ready상태에 있던 놈이 swap-out되는 Ready, Suspend나 Block된 놈이 Swap-out되는 Blocked, Suspend의 경우에는 적당히 일어나기 때문에 이것에 관련된 정책을 Mid-term Schedule라고 한다\n또한 프로세스가 folk되어 new state에 있다가 자원을 모두 할당받으면 Ready state가 되는데 너무 많은 프로세스가 Ready queue에 있으면 시스템에 부담이 되기 때문에 new state에서 자원을 할당받는거를 기다리게 되는데 이러한 과정은 잘 일어나지 않기 때문에 이것에 관련된 정책을 Long-term Schedule이라고 한다\n\n\n\n따라서 new, exit과 관련된 작업은 Long-term Schedule, suspend와 관련된 작업은 Mid-term Schedule, Running, Ready, Blocked랑 관련된 작업은 Short-term Schedule이라고 할 수 있다\nMid-term Scheduling과 Long-term Scheduling은 메인메모리에 올라가는 프로세스의 갯수와 연관된다는 점에서 Multiprogramming Level을 조절해주는 역할을 하게 된다\n\nShort-term Scheduling §\n\nDispatcher, Short-term Scheduling, CPU-time Scheduling 다 비슷한 말이다\n자주 일어나기 때문에 이 과정이 빠르게 일어날 수 있도록 알고리즘을 짜야되고\n빠른것 뿐만 아니라 모든 프로세스에게 공평하게 자원이 돌아갈 수 있도록 알고리즘을을 짜야 된다\n\nCriteria §\n\nShort-term Scheduling의 알고리즘을 선택하는 기준(Criteria)\nTurnaround Time : 어떤 프로세스가 생성되고(new) 종료(exit)될때까지 걸린 시간\n\n프로세스가 생성된 후에는 여러번의 wait과 running을 거치기 때문에 Trunaround Time은 총 Service Time(Running Time)과 총 Waiting Time의 합이다\n일단 프로세스가 생성된 후에 일을 마치고 종료되는 시간이 짧으면 좋기 때문에 Turnaround Time이 짧으면 좋은데\n프로세서가 같다면 저 프로세스가 실행되는데 걸리는 시간은 동일하기 때문에 Service Time은 동일하다\n따라서 Waiting Time을 줄이는 것이 관건이며 이것들의 평균인 Average Waiting Time 혹은 Service Time까지 합쳐서 Average Turnaround Time이 낮은 Scheduling Algorithm을 선택하는 것이 효율적이다\n\n\nResponse Time : 얘는 프로세스의 실행 후 첫번째로 결과물이 나오는(뭐 printf로 뭔가가 출력되게 한다던지)데까지 걸리는 시간을 의미한다\n\n얘도 당연히 적을수록 좋지만 결과물을 출력하는 지점을 어디에 설정하느냐에 따라 값이 달라지기 떄문에 CPU Scheduling Algorithm을 선택하는 데에는 별로 중요한 척도가 되지 못한다\n하지만 사용자 편의성의 관점에서 보자면 매우 중요 - 일례로 여러 클라이언트가 접속하는 서버의 경우에는 첫번째로 받게되는 결과물이 완성된 html파일이기 때문에 이 response time이 이러한 경우에는 아주 중요한 척도가 된다\n\n\nDeadlines : 얘는 이제 반드시 이 시간 내로는 프로새스가 완전히 실행되어 종료되어야 한다라는 뜻을 가지고 있다 - 특히 아주 중요한 실시간 프로그램의 경우\nThroughput : 얘는 단위시간 내에 몇개의 프로세스가 종료되는지이다 - service time이 얼마나 걸리는지와 scheduling algorithm에 따라 많이 달라지더라 - 얘도 당연히 많이 끝내면 좋은거이기 때문에 클수록 좋은거다\nProcessor Utilization : CPU 이용률을 의미 - CPU를 많이 이용할수록 더 좋다\n\n알고리즘측면에서는 높으면 높을수록 좋기는 하지만 실제로는 100퍼센트까지 올라가면 시스템이 다운될수도 있기 때문에 대략 50-60퍼센트정도로 유지시킨다\n\n\nEnforcing Priority : 프로세스들에게 우선순위를 주어서 우선순위가 높은 프로세스를 먼저 CPU에게 할당하는 알고리즘\n\nPriority Queuing §\n\n\n커널 프로세스같은 중요한 프로세스는 fixed priority를 가질수도 있지만 유저 프로세스 대부분은 우선순위가 바뀌는 dynamic priority를 가지게 된다\nCPU time(timeout과 관련된 시간이 아니고 지금까지 총 할당받은 시간)이 많은 놈은 우선순위를 좀 낮추고 총 waiting time이 많은놈의 경우에는 우선순위를 높여서 빈부격차를 줄인다\n저 RQ가 프로세스 우선순위에 따른 큐 이고 상위계층의 큐가 다 비어야 그 다음의 큐에 들어있던 프로세스가 실행되게 된다\nPre-emptive라는 것은 낮은 우선순위를 가진프로세스가 실행되다가 높은 우선순위의 프로세스가 들어오면 낮은 우선순위의 프로세스를 중단시키고 높은 우선순위의 프로세스로 문맥을 교체시키는 것을 의미하고 Non Pre-emptive라는 것은 데드락에서 배운거처럼 반대로 높은 우선순위의 프로세스가 들어와도 현재 프로세스를 중단시키지 않는 것을 의미한다\n\nSelection Function(Algorithm) §\n\nw는 waiting time을 뜻하는 기호\ne는 execution time을 뜻하는 기호\ns는 service time 을 뜻하는 기호\n\n여기서 e과 s의 차이는 s는 프로세스가 종료되기까지 필요로 하는 CPU time 총 시간을 의미하고 e는 지금까지 얼마만큼의 CPU time을 할당받았냐를 의미\n따라서 e = s가 될때 프로세스가 종료되게 된다\nTurnaround time은 w + s가 되는 것\n\n\n\nAlgorithm §\n\n\n위처럼 프로세스 5개의 도착시간(Arrival Time)과 종료되기까지 필요로 하는 시간(Service Time)이 있다고 할 때\n\nFirst Come First Served(FCFS) §\n\n\n얘는 무적권 먼저 도착한놈한테 먼저 CPU 를 할당해주는 것을 의미\n\n\n\n이때의 Turnaround time은 위와 같다\n이 표를 읽는 방법은 우선\nFinish time은 말 그래도 끝난 시간을 의미하고\nTurnaround time은 Finish time에서 Arrival time을 뺀 시작에서부터 종료되기까지 걸린 시간\n그리고 Tr / Ts 는 Turnaround time / Service time 이다 - 즉, 총 걸린 시간을 실제 작동한 시간으로 나눈 것을 의미\n\nTr / Ts 가 1이라는 것은 waiting time이 하나도 없었다는 것을 의미하고 1보다 크다는 것은 waiting time이 존재했다는 뜻으로도 생각할 수 있음\n그리고 이 값이 클수록 waiting time의 비율이 높은거이기도 하다\n\n\n위의 그래프를 Gantt chart라고 하고 저런 표들이나 이 차트를 주고 w, s, 등등을 구하는 문제 나온댄다\nFCFS의 경우에는 프로세스가 종료되기 전까지 CPU를 뺏지 않으므로 No Pre-emptive라고 할 수 있다\n하지만 만약 제수없게 실행시간이 엄청 긴 프로세스가 먼저 오면 w가 엄청 커지게 되는 단점이 있는데 이것을Convoy effect라고 한다\n\nRound Robin(RR) §\n\n\n얘는 q 단위시간마다 프로세스를 교체시키는 알고리즘이다\ntime quantum(q) 는 얼마의 단위시간마다 프로세스를 교체할건지를 의미한다\n위의 차트는 q = 1인 상황으로 1 단위시간마다 프로세스가 교체되는 것을 알 수 있으며\n처음에 A프로세스의 경우에는 1 단위시간을 실행하고 난 다음에도 아무 프로세스도 들어오지 않았기 때문에 1단위시간을 더 실행하게 되는 것\n그리고 할당된 시간이 끝나고 누구에게 넘겨줄 것인가를 결정하는 것을 Tie Break Rule이라고 하는데 위의 그래프에서는 FCFS방식으로 넘겨줬기 때문에 먼저 들어온놈에게 프로세스가 넘어가는 것\n하지만 Tie Break Rule을 execution time이 적은놈이라고 정하면 또 차트가 달라질 수도 있다\nRound Robin의 경우에는 q를 너무 짧게 잡으면 context switch가 자주 일어나기 때문에 별로 좋지 않다 - 어쨋든 context switch가 일어난다는 것도 추가적인 시간을 잡아먹는 일이기 때문\n이렇듯 q를 너무 짧게 잡으면 context switch가 너무 자주 일어나게 되고 너무 길게 잡으면 FCFS와 다를바가 없기 때문에 보통 q 시간 내에 80퍼센트의 프로세스들이 종료될 수 있도록 q값을 설정해준다\nRound Robin은 같은시간동안 순서대로 프로세스들에게 CPU를 할당해주기 때문에 interactive program에서 자주 쓰인다\nRound Robin의 경우에는 정해진 시간이 지나면 CPU를 뻇으므로 Pre-emptive라고 할 수 있다\nShortest Process Next(SPN)\n\n\n\n얘는 프로세스가 종료되고 난 후에 가장 Service time이 적은 프로세스로 옮겨가는 알고리즘이다\n얘도 프로세스가 종료되기 전까지는 CPU를 뺏지 않으므로 Non Pre-emptive라고 할 수 있다\n이 알고리즘은 waiting time의 평균이 다른 알고리즘들보다 작다 - 프로세스가 필요로 하는 총 Service time을 알기 어렵다는 점에서 현실적으로는 구현하기 힘들고 어떤 알고리즘의 효율을 비교하는데 사용하는 이론적인 알고리즘이다\n즉, 어떤 알고리즘이 있을 때 waiting time이 SPN에 근접하면 좋은 알고리즘인거고 너무 차이가 많이 나면 안좋은 알고리즘인 셈\nShortest Remaining Time(SRT)\n\n\n\n얘는 SPN의 Pre-emptive 버전 이다\n작동방식은 새로운 프로세스가 들어왔을 때 지금 실행하고있는것의 남은시간(Remaining time)과 새로 들어온놈의 Service time을 비교해 짧은놈이 실행되게 하는 것\n위의 예시로 보자면 일단 2시에 B가 들어왔는데 A는 1시간만 있으면 종료되므로 그대로 A를 실행한거고\n그다음 B를 실행하다가 4시에 C가 들어왔는데 B는 종료되려면 5시간이 남았고 C는 4시간이면 종료되기 때문에 C로 프로세스를 교체한 것을 알 수 있다\n얘는 SPN보다도 더 waiting time이 짧으나 SPN과 마찬가지로 service time과 remaining time을 알 수 없기 때문에 이론적으로만 존재하는 알고리즘이다\n따라서 마찬가지로 어떤 알고리즘의 효율성을 비교할때 사용되는 기준점을 제시해주는 역할을 함\nHighest Response Ratio Next(HRRN) : 얘는 다음과 같은 수치를 이용해 다음 실행될 프로세스를 결정한다\n\n\n\n여기서 일단 aging이라는 용어가 나온다 - 오래 기다려서 folk된지 오래된 프로세스를 나이가 드는것에 빗대어 waiting time이 긴 프로세스일수록 age가 많다고 판단 - 이런 프로세스에게 우선권이 넘어가도록 한다\n그래서 위 수식을 보면 일단 waiting time이 길수록 저 ratio가 커지게 되고\n그리고 service time적을수록 ratio가 커지게 되어 - SPN과 SRT를 생각해보면 service time이 적은 프로세스를 먼저 실행시키는 것이 waiting time을 줄이는 방법이므로\n종합적으로 ratio가 크다는 말은 waiting time이 크거나 service time이 작다는 말이므로 ratio가 큰 프로세스를 선택하는 것\n하지만 이 역시도 service time을 알아야 하기 때문에 구현하기에는 어려움이 많은 알고리즘이다\nFeedback Scheduling : 얘는 이제 waiting time을 줄이려면 service time을 알아야 가능하다는 생각에서부터 출발한 알고리즘이다\n\n\n\n일단 이 알고리즘은 우선순위에 따라 여러개의 큐가 존재하는데\n예를 들어서 n이 2까지 있어서 3단계로 우선순위를 나눈다고 해보자\n이때 첫번째 큐(RQ0)의 경우 RR로 작동하고 q를 1로 두고\n두번째 큐(RQ1)도 RR로 작동하는 대신 q를 2로 두고\n세번째 큐(RQ2)는 FCFS로 작동한다고 해보자\n이때 프로세스가 생성되면 전부 RQ0로 집어넣은 다음\n프로세스를 실행시켜 RQ0에서 1 단위시간 내에 끝나면 그냥 끝나는거지만\n만약에 1 단위시간 내에 안끝내면 RQ1으로 내려보내고 RQ0이 비기 전까지는 RQ1을 실행하지 않게 된다\n그리고 RQ0이 비게 되면 그제서야 RQ1를 실행하게 되는데\nRQ1에서 2 단위시간 내로 프로세스가 종료되면 그냥 끝나는거지만 만약에 2 단위시간 내로 끝나지 않으면 이제 RQ2로 내려보내고\n마찬가지로 RQ1이 비기 전까지는 RQ2를 실행시키지 않는다\nRQ1까지 비게 되면 이제 RQ2를 실행시키는데 얘는 FCFS이기 때문에 들어온 순서대로 프로세스가 종료될때까지 실행되게 된다\n대신 새로운 프로세스가 실행되어 RQ0으로 들어오면 지금 하던일을 멈추고 RQ0으로 가서 실행시킴 - 따라서 Pre-emptive 하게 작동한다고 할 수 있다\n이런식으로 우선순위마다 큐를 여러개 두고 각 큐마다 다른 알고리즘을 적용시키되 각 큐들의 Quantum Time을 다르게 두어서 먼저 끝나는 프로세스를 먼저 실행시킬 수 있게 하는 것이다\nservice time을 실행시키는 당시에는 알 수 없기 때문에 시간제한을 두고 일단 실행시켜서 시간제한 내에 종료되면 service time이 짧은 놈을 먼저 실행시킨 꼴이므로 waiting time을 줄이는 효과를 가져오고\n그리고 제한시간 내에서 끝내지 못했으면 일단 service time이 제일 적은놈은 아니라는 것이 증명되므로 우선순위를 낮춰 나중에 실행되게 하는 꼴이고\n마지막 우선순위에 도달할때까지 종료되지 못했으면 service time이 아주 오래걸린다는 소리이므로 제일 나중에 FCFS같은 Non-preemptive한 알고리즘으로 실행시켜 나머지 과정을 마무리 짓는것\n즉, 시간제한을 여러개를 두어서 service time을 직접 실행시키면서 추론하는 방식으로 service time이 짧은 프로세스를 먼저 실행시키는 효과를 내어 waiting time을 줄이고하 하는 알고리즘이 Feedback Scheduling이다 - 상위 우선순위에서 끝마치지 못해 하위 우선순위로 내리는 것을 Feedback이라고 한다\n이 알고리즘이 요즘의 많은 OS에서 채택하고 있는 Scheduling 방식이다\n\nFair Share Scheduling(FSS) §\n\n이게 현재 UNIX시스템에서 채택하고있는 Scheduling 방식이다\n\nLinux 는 아니다 - 얘는 지금 CFS (Completely Fair Scheduler) 를 사용하는듯\n\n\n\n\n\n일단 위의 수식을 이해할 필요가 있다\n일단 CPUj(I) 는 현재의 CPU time을 나타낸다 - 그럼 CPUj(I - 1) 은 바로 이전의 CPU time을 나타내것제\n그리고 Base랑 nice는 일단은 그냥 상수값으로 생각해래이\n그럼 위의 수식에 따라 현재의 CPU time은 이전의 CPU time의 절반이 되고\n그걸 또 Priority(위의 수식에서는 Pj(I))를 계산할때는 현재의 CPU time에서 절반을 나누므로 결과적으로는 이전의 CPU time에서 4를 나눈 값으로 계산하게 된다\n그리고 다음의 예시를 이해해보면\n\n\n\n일단 먼저 프로세스 A, B, C가 동일한 시간에 들어왔다고 해보자\n그리고 여기에서 Base랑 nice의 합은 60이라고 가정해보자\n일단 셋이 같이 들어왔고 CPU time도 0이므로 Priority는 60이 되어 셋 다 동일한 상태이다\n어차피 차이가 없으므로 A를 먼저 선택했을 경우\n보면 1 단위시간동안 CPU time동안 CPU time이 60씩 증가하게 된다 - 따라서 프로세스 A가 실행되는 0 ~ 1의 시간에는 CPU time이 60이 된다\n근데 다음 1 ~ 2의 기간에는 A의 경우 이전의 CPU time이 60이었으므로 4로 나눠 15가 되기 때문에 이것을 Base와 nice에 더해 Priority가 75가 된다 - 그리고 현재의 CPU time의 경우에는 절반을 나누기 때문에 1 ~ 2에서의 CPU time은 30이 되는 것\n그럼 A는 75이고 B와 C는 60이기 때문에 B와 C중 하나를 고르게 된다 - 여기서는 P가 낮을수록 우선순위가 높은거임\n만약 B를 선택했다면 0 ~ 1에서의 A와 마찬가지로 2 ~ 3에서의 B의 Priority는 75가 된다\n근데 A의 경우에는 이전의 CPU time이 30이었기 때문에 이것을 4로 나눠 계산한 Priority는 67.5로 재조정되고 현재의 CPU time은 15가 되는 것\nC는 아직 1 ~ 2에서는 실행되지 않았기 때문에 Priority가 60으로 그대로 유지된다\n그럼 2~3에서의 우선순위는 순서대로 67, 75, 60이 되기 때문에 가장 낮은 C가 선택되게 된다\n이제 그럼 3 ~ 4에서의 A를 보면 이전의 CPU time이 15였기 때문에 현재의 CPU time은 7.5가 되고 따라서 Priority는 63.75가 되는것이고\nB를 보면 2 ~ 3에서의 A처럼 67.5가 되며 C는 방금 실행되었기 때문에 75가 된다 - 따라서 A가 다시 선택되게 되는 것 - 이런식으로 돌아가게 된다\n따라서 종합해보면 프로세스가 1 time quantum만 실행되고 교체되기 때문에 RR의 성격을 가진다고할 수 있고 CPU를 할당받지 못한 동안에는 CPU time이 점차 감소되어 재조정되는 방식을 통해 aging도 반영되게 된다\nSPN도 반영된다는데 이거까지는 아직 잘 모르겠다\n"},"originals/os.spring.2021.cse.cnu.ac.kr/11.-Multicore-Scheduling":{"title":"11. Multicore Scheduling","links":[],"tags":[],"content":"\n\n                  \n                  충남대학교 컴퓨터공학과 류재철 교수님의 &quot;운영체제 및 실습&quot; 강의를 필기한 내용입니다. \n                  \n                \n\n\n\n                  \n                  다소 잘못된 내용과 구어적 표현 이 포함되어 있을 수 있습니다. \n                  \n                \n\nMultiprocessor System의 구조 §\nLoosley Coupled Multiprocessor §\n\n코어가 자신의 메인 메모리를 따로 갖고있는 코어들로 구성된 것\nDistributed혹은 Cluster라고도 불린다\n\nTightly Coupled Multiprocessor §\n\n모든 코어가 하나의 메인 메모리를 공유하는 구조\n대부분의 컴퓨터가 이와 같은 구조를 가진다\n이번 강의에서는 이 시스템을 가지고 Multiprocessor의 작동방식을 설명한다\n\nFunctionally Specialized Processors §\n\nmaster processor가 하나 있고 그것의 지배를 받는 IO전담 프로세서 등 slave processor가 존재하는 구조\n\nReady Queue의 구성 §\n\n\n일단 통합된 하나의 ready queue를 두고 여기에서 프로세스가 하나씩 빠져 프로세서로 들어가는 방식을 Dynamic이라고 한다\n\n왜 Dynamic이라고 하냐면 만약 하나의 프로세스가 실행되다가 timeout이 걸리든 block을 먹든 해서 빠져나왔다가 다시 Ready queue로 들어가면 기존에 실행되던 프로세서에 다시 할당되리라는 보장은 없기 때문에 하나의 프로세스가 여러개의 프로세서를 거쳐 실행된다는 뜻이다\n\n\n하지만 각 코어마다 ready queue를 두고 프로세스가 이 큐들로 분배되는 방식을 Static이라고 한다\n\n얘같은 경우에는 프로세스가 실행되다가 다시 내려와도 어차피 원래 실행되던 프로세서의 큐로 가기 때문에 이놈은 처음 할당받은 프로세서에서만 실행되다가 종료된다\n\n\n\n프로세스 선택 알고리즘 §\n\nUniprocessor일때는 FCFS를 선택했을 때 Convoy effect가 일어나서 average waiting time이 길어질 수가 있었는데\nMultiprocessor일때는 어차피 남는 CPU에 할당해주면 되기 때문에 Convoy effect에 대해 크게 신경쓰지 않는다\n따라서 FCFS가 알고리즘중에는 가장 공평하므로 FCFS도 많이 이용하게 되는 것\n\nThread Scheduling §\n\n쓰레드의 경우에 어떻게 할 것인가 - 쓰레드도 각각의 독립적인 개체로 보고 여러 프로세스에게 할당할 수도 있는데 이때 한 프로세스에서 파생된 쓰레드들 중 일부만 프로세서를 잡고 실행되게 되면 쓰레드들 간의 통신이 원활하지 않기 때문에 하나의 프로세스에서 파생된 쓰레드들을 한정된 프로세서들에게만 할당해주는 것도 가능하다?\nLoad Sharing : 쓰레드들을 Dynamic 시스템을 이용해 처리 - 하나의 Ready queue에 넣어서 처리함으로 정해진 프로세서에게만 처리되는 형식이 아닌 것\nGang Scheduling : 한개의 프로세스에서 파생된 쓰레드들에게 하나씩 프로세서를 할당하는 구조\n\n하지만 얘도 하나의 쓰레드가 하나의 프로세서에서만 돌아가지는 않는다\n말그대로 쓰레드들이 동시에 실행되기 때문에 게임같은 프로세스를 돌릴때 많이 사용되었다\n하지만 쓰레드의 갯수를 세야되고 하는 절차가 존재하기 때문에 옛날에 컴퓨터가 안좋았을 시절에는 많이 사용했지만 요즘은 컴퓨터가 좋아 리소스가 풍부하기 때문에 알고리즘을 단순화시키자는 생각으로 Load sharing을 더 사용한댄다\n\n\nDedicated Processor Assignment : Gang Scheduling과 비슷하지만 이제는 하나의 프로세서가 하나의 쓰레드를 전담하는 구조이다\nDynamic Scheduling : 얘는 프로세스의 쓰레드 갯수가 동적으로 바뀌는 상황에 대응하기 위해 만들어진 알고리즘이다\n\nReal-time Systems §\n\nReal-Time System은 실시간 시스템을 의미한다\nHard Real-Time : 얘는 앞에서 배운 Deadline이 존재하고 반드시 그걸 지켜야 되는 시스템 을 의미하고\nSoft Real-Time : 얘는 Deadline이 존재하지만 권장사항일 뿐 반드시 지켜야되는건 아닌 시스템을 의미한다\n\n얘는 의무사항은 아니어도 Deadline을 되도록이면 지켜야 하기 때문에 deadline이 걸린 프로세스는 메모리에 상주하고 우선순위를 높이게 된다\n\n\n\nReal-Time Scheduling §\n\n\n보면 맨 위에가 프로세스들이 언제 들어오고 얼마만큼의 시간을 필요로 하고 deadline이 언제까지인지를 나타내는 그림이고(편의를 위해 uniprocessor를 기준으로 한다)\n두번째는 A프로세스에게 우선권이 있을때의 그림, 세번째는 B프로세스에게 우선권이 있을때의 그림이다\n우선순위가 존재할때를 살펴보면 deadline을 지키지 못해 miss가 일어나는 것을 볼 수 있다 - deadline이 존재하는 경우에는 특정 프로세스에게 우선권을 주는 식으로 실행을 하면 miss가 자주 일어나므로 잘 사용하지 않는다\n네번째 그림인 Earliest Deadline Scheduling은 deadline이 가장 빠른것(=마감일이 얼마 안남은 것)을 먼저 실행시키는 알고리즘이다 - 이경우에는 miss가 안나는 것을 알 수 있다\n이 알고리즘은 프로세스가 하나밖에 없으면 그냥 그걸 실행시키고, 다른 프로세스가 들어오면 둘중에 deadline이 더 빠른놈을 선택하여 실행한다. 만약 deadline이 동일하다면 기존에 실행시키던 것을 계속 실행시키는 식으로 작동한다\n"},"originals/os.spring.2021.cse.cnu.ac.kr/12.-IO-&-Disk-Scheduling":{"title":"12. IO & Disk Scheduling","links":[],"tags":[],"content":"\n\n                  \n                  충남대학교 컴퓨터공학과 류재철 교수님의 &quot;운영체제 및 실습&quot; 강의를 필기한 내용입니다. \n                  \n                \n\n\n\n                  \n                  다소 잘못된 내용과 구어적 표현 이 포함되어 있을 수 있습니다. \n                  \n                \n\nIO Device §\n\nHuman Reachable : 키보드나 모니터, 마우스같은거\nMachine Reachable : USB, 센서같은거\nCommunication : 통신을 위한 장비\nIO장비는 하드웨어면으로나 소프트웨어 면으로나 장비마다 다양하기 때문에 이쪽을 개발하는 것은 전문성을 요구하는 쉽지 않은 일이다\n\nIO Techniques §\n구분 §\n\n\n보면\nProgrammed IO는 IO 처리를 구현한 프로그램이 있어서 프로세서가 직접 이 프로세스를 실행시키며 디스크에서 파일을 읽어오는 것을 의미한다\nInterrupt-Driven IO는 블락이 먹기 전까지 실행하다 IO가 필요해져서 블락을 먹으면 다른 프로세스를 실행하고 IO가 완료되면 인터럽트를 걸어서 다시 복귀하는 형태를 의미한다\nDirect Memory Access는 Interrupt Driven IO의 진화버전으로써 프로세서가 아닌 IO처리 담당 프로세서가 별도로 존재해서 걔가 IO를 처리하고 끝나면 인터럽트를 거는 일을 의미한다\nProgrammed IO와 나머지 둘의 가장 큰 차이점은 Busy Waiting이다 - Programmed IO는 프로세서가 직접 IO처리 프로세스를 실행시키며 IO처리를 해 기존의 프로세스가 기다리는 와중에도 프로세서를 사용하지만 Interrupt-Driven IO나 Direct Memory Access 는 IO처리를 프로세서가 직접 하지 않아 프로세서는 다른 프로세스를 돌릴 수 있게 한다\n\n발전과정 §\n\n\nProgrammed IO형태에서\nIO 전용의 IO module / Controller가 등장한다\n\nIO module / Controller는 한가지 형태의 IO를 전담하는 것이라고 생각하면 된다\n\n\n하지만 Interrupt 기능은 없어서 CPU가 수시로 IO가 종료되었는지 확인해줘야 되는 Busy Waiting이 여전히 존재했기 때문에 IO Interrupt가 추가된다 - 얘가 추가되고 나서는 Busy Waiting을 하지 않음\nIO module / Controller가 하드와 메모리를 직접적으로 제어하는 DMA가 추가됨\n\nDMA가 IO와 관련된 모든 일을 전담하는 것으로 생각하면 될거같다\nIO Module / Controller들을 DMA가 관리하게 되는 것\nCPU가 DMA에게 IO를 맡기기만 하면 얘가 알아서 다 처리하는 형태\n\n\nIO module / Controller가 별도의 프로세서로 분리됨 - IO만을 위한 특별한 Instruction을 실행시키며 IO를 처리한다\n\n4, 5번에서 하드와 메모리를 직접적으로 제어하는 프로세서를 별도로 분리한 것을 IO Channel이라고도 표현한다\n\n\n이전까지는 DMA도 메인메모리를 공유했지만 이제는 DMA전용의 메모리가 별도로 분리되어서 더 빠르게 작동할 수 있게 됐다\n\n\n\n옛날에는 데이터를 주고받는 Bus가 하나여서 여기에 DMA나 IO Module / Controller들이 전부 연결되어있었지만 - Single Bus, Detached DMA\nbus에는 DMA만 붙고 그 아래 IO Module / Controller들이 있는 형태로 바뀌었다가 - Single Bus, Integrated DMA\n이제는 System bus에는 DMA하나만 붙고 그 아래 IO Bus가 별도로 존재해 IO Module / Controller가 사용하는 Bus가 별도로 분리되게 된다\n\nIO 설계 §\n\nEfficiency : IO들은 프로세서나 메모리보다 처리속도가 더 늦기 때문에 이런 처리속도가 느린 IO 하드웨어들을 어떻게 효율적으로 관리하는가\nGenerality : IO의 인터페이스가 다 제각각이어서 그것을 이용하려는 프로그래머가 IO에 따라 다른 방법을 사용해야한다면 매우 불편 - IO의 사용법(인터페이스)을 통일시켜서 간편하게 사용할 수 있게끔 하는 것\n\n\n\n위 그림은 세 IO를 예시로 든건데\n보면 맨 아래 3개가 하드웨어로 구현된 IO 이다\n그리고 그 위에가 OS 레벨 이며 맨 위의 user process에서는 OS가 제공해주는 API들을 이용해 사용자가 프로그램을 짜게 되는 것\n우선 Logical Peripheral Device를 보면\n\nLogical IO에서 open, read, write, close등의 API등을 사용자에게 제공한다\n그리고 이런 API를 사용해 명령을 내리면 Logical IO에서 그것을 처리해 표준화된 인터페이스를 제공하는 Device IO로 전달하게 된다\nDevice IO가 이런 표준화된 인터페이스를 제공하기 때문에 우리는 HW레벨의 지식 없이 간편하게 HW를 제어할 수 있는 것이다\n\n\nCommunication Port에서도 동일하게 Communication Architecture을 이용해 사용자에게 API를 제공하고, 그것을 처리해 Device IO로 넘겨주게 된다\nFile System에서는\n\n일단 Directory Management는 우리가 문자열 형태로 전달한 파일의 경로를 File Descriptor로 바꾸는 역할을 한다\n\nFile Descriptor 별거 아니다 - 프로세스는 고유한 pid를 갖고있듯이 파일도 File Descriptor 라는 고유한 번호를 갖게 된다\n\n\n그리고 File System에서 파일에 대한 Open, Read, Write, Close 명령어를 제공해준다\n그리고 Physical Organization에서는 Virtual Address를 Physical Address로 변환하는 등의 일을 하게 된다\n\n\n\nBuffering §\nData IO size §\n\n일단 Device는 IO로 갖고오는 데이터의 크기에 따라 두가지로 나눌 수 있다\nBlock Oriented Device - 얘는 블럭(IO에서는 페이지를 블럭이라고 표현한다)단위로 IO를 처리하는 Device를 말한다\n\n보통 Machine Reachable Device가 블럭단위로 IO처리하므로 이놈이 여기에 들어간다\n\n\nStream Oriented Device - 예는 바이트나 워드 단위로 IO를 처리하는 Device를 의미한다\n\n보통 Human Reachable Device가 바이트나 워드 단위로 IO를 처리하므로 이놈이 여기에 들어간다\n\n\n따라서 Block Oriented Device가 블럭단위로 갖고오므로 Stream Oriented Device보다 갖고오는 양이 많다\n\nBuffer §\n\n\n일단 Buffer라는 것은 IO를 통해 가져온 데이터를 메인메모리의 OS파트에 잠깐 저장하기 위한 용도로의 공간을 의미한다.\n버퍼라는게 존재하지 않을 때 어떤일이 벌어지는지 보자\n유져 프로세스가 page fault가 일어나서 OS에게 특정 페이지를 요청했다고 해보자\n그럼 OS는 IO에게 해당 페이지를 가져오라고 시킨 뒤 다른 프로세스를 실행시키게 되는데\nIO가 끝나게 되면 버퍼가 없기 때문에 가져온 페이지가 메인메모리의 유저 프로세스 영역으로 들어가게 된다\n근데 만약에 유저 프로세스가 블락을 먹은 동안 메모리에 공간이 부족해져서 이놈이 Swap-out당하면 유저 프로세스가 메인메모리에 없기 때문에 IO는 가져온 데이터를 둘 곳이 없어지게 된다\n따라서 유저 프로세스는 IO가 완료되지 않았기 때문에 블락이 풀리지 않고 IO입장에서는 데이터를 갖고와도 둘곳이 없기 때문에 IO를 완료하지 못해 계속 블락을 먹은 상태로 있게 된다 - 이것을 Single Process Deadlock이라고 한다\n\n즉, 프로세스가 한개여도 버퍼가 없다면 데드락에 걸릴 수 있게 되는 것이다\n\n\n\n\n\n따라서 메모리의 OS파트에 버퍼라는 공간을 두어서 유저 프로세스가 Swap-out을 당하더라도 IO가 완료될 수 있도록 하는 것이다.\n그리고 이렇게 함으로써 Write에도 좀 더 이점을 가질 수 있다 - 유저 프로세스에서 Write가 일어났을 때 하드디스크를 바로바로 변경시키면 처리량이 많기 때문에 Write가 일어나면 일단 Buffer에 있는 페이지를 변경하고 나중에 하드에 한번에 업데이트 시킬 수 있게 한다\n또한 IO의 성능에 대해서도 이점이 있다 - Page Fault가 일어나면 하드디스크로 가기 전에 버퍼를 먼저 찾아서 여기에 이미 내가 원하는 페이지가 존재하는지 찾아보게 된다 - 만약에 있으면 하드에 갈 필요가 없으므로 훨씬 빠르게 Page Fault가 해결됨\n\n\n\n근데 버퍼를 여러개 갖게 되면 하나의 버퍼에 하드에서 가져온 페이지를 쓰는 것과 동시에 다른 프로세스가 다른 버퍼레 접근하여 데이터를 가져갈 수 있으므로\n요즘은 OS파트 안에 버퍼를 여러개 두고 여러개의 유저 프로세스가 버퍼들을 나눠서 사용하는 구조인 Circular Buffering 으로 운영된다\n\nDisk Performance §\n\n\n일단 디스크는 LP판처럼 생겼고 이와 유사하게 작동한다\n먼저 디스크의 한 표면(Surface)에는 여러개의 Track이 존재한다\n\n하나의 디스크는 앞면, 뒷면 두개의 Surface를 갖게 된다\n\n\n그리고 일정한 각도로 Surface를 잘라 만들어진 Track의 한 부분을 Sector 라고 한다\n또한 Sector는 여러개의 Block들로 구성되어 있고 어느 Sector든 같은 수의 Block으로 구성되어 있다\n\n그 각속도 기억나제? - 디스크 판은 같은 속도로 회전하기 때문에 한 섹터에서 같은 양의 블럭을 가져오기 위해서는 바깥쪽의 블럭은 좀 더 듬성듬성하게 위치하게 된다\n\n\n그리고 Disk Arm이 있어서 이놈이 Surface를 읽으며 데이터를 읽게 되는 것\n따라서 디스크에서 특정 블럭을 찾는 과정은 다음과 같은 세가지의 단계를 거치게 된다\n\n일단 Disk Arm이 특정 Track으로 움직이는 작업을 한다 - 이것을 Seek이라고 한다\n그리고 Track으로 간 뒤에는 디스크가 회전하며 해당 Sector를 찾는다 - 이것을 Rotational Delay라고 한다\n마지막으로 디스크에서 비트들을 읽어 전송하는 Data Transfer과정이 있다\n\n\n여기에 걸리는 시간을 보면\n\nData Transfer는 그냥 읽어서 전송하는 것이기 때문에 시간을 별로 잡아먹지 않는다\n하지만 Seek의 경우에는 Disk Arm이 물리적으로 움직여야 되므로 가장 오래 걸리게 되고\nRotational Delay도 디스크를 회전시켜야 되기 때문에 적지 않은 시간이 걸린다\n즉, Seek &gt; Rotational Delay &gt; Data Transfer 의 순서대로 시간이 소요된다\n\n\n특정 주소를 이용해 디스크의 위치를 알아내는 과정은 다음과 같다\n\n일단 Logical Address를 이용해 Page# 을 알아낸다\n그리고 그 Page# 를 Block# 로 바꾸게 된다\n그리고 Block# 을 이용해 해당 Block이 어느 Track에 있는지 알아낸다\n\n\n이 과정이 정확히 어떻게 이루어지는지는 안알랴줌\n\n\n근데 이제 Seek이 제일 오래 걸리기 때문에 이 시간을 줄여야 되고 따라서 일련의 Track# 들이 주어졌을 때 Disk Arm을 어떻게 움직여서 어떤 순서로 Track을 읽어야 할지가 Disk Scheduling이다\n\nDisk Scheduling §\n\n\n\nFIFO : 말그대로 들어온 순서대로 처리하는 것\n\nTrack# 이 Arm이 효율적으로 움직일 수 있는 동선대로 들어오는게 아니기 때문에 가장 최악의 시간이 걸린다\n\n\nSSTF(Shortest Serve Time First) : 얘는 지금 현재의 위치에서 가장 가까이 있는 놈을 처리한다\n\n보면 가장 효율적으로 움직이기 때문에 Seek가 제일 적게 걸리는 것을 알 수 있다\n하지만 매번 Queue를 전부 확인해서 나랑 가장 가까운 놈을 찾아야 하기 때문에 실제로 사용하기에는 무리가 있다\n\n\nSCAN : 얘는 엘리베이터마냥 한방향으로 가면서 그 방향에 있는애들 다 처리하고, 끝나면 다시 방향을 틀어 그 방향에 있는애들 다 처리하는 방식이다\nC-SCAN : SCAN은 양방향으로 움직이며 해당 방향에 있는 애들을 다 처리하는 반면, 얘는 한방향으로만 움직인다 - 한방향으로 움직이며 애들을 다 처리하고, 처리가 끝나면 다시 0번으로 복귀해 한방향으로 움직이게 되는 것\n\n즉, 0번으로 복귀할때에는 처리를 안한다\n이것은 하드웨어적 관점에서 봤을 때 한뱡향으로만 움직이는게 더 좋을수도 있기 때문에 이런 알고리즘을 채택하는 것\n\n\n\n\n\nN-Step SCAN : 이전의 SCAN에서는 큐를 하나만 두고 이 큐 안에 있는 애들을 처리하는 방식이었는데\n\n근데 SCAN방식은 요청순서와는 전혀 무관하게 작동하므로 약간 형평성의 문제가 있을 수 있다\n따라서 이러한 요청순서를 어느정도 반영하여 SCAN을 돌리는 것이 N-Step SCAN이다\n얘는 일단 크기가 N인 큐를 여러개 갖고 여기에 들어온 순서대로 넣는다 - 큐 하나가 다 차면 그다음 큐로 가서 채우는 방식으로\n그리고 하나의 큐 안에서는 SCAN방식으로 작동하게 함으로 일찍 들어온놈이 재수없게 나중에 처리되는 일을 줄인다\n따라서 N = 1이면 그냥 FIFO와 다를바가 없고 N이 엄청 크다면 SCAN과 다를바가 없는 방식이 된다\n\n\n\n\n\nFSCAN은 큐를 단 두개만 갖는 N-Step이라고 할 수 있다\n즉, 큐를 두개 가지고 하나를 채운 뒤 SCAN으로 처리하고, 그동안 다른 하나를 채워 SCAN처리하고 앞선 큐가 다 처리되어 비워졌으므로 다시 여기에 채우는 식으로 작동한다\n\nRAID §\n\nRAID(Redundant Array of Independent Disk) 라는 것은 별도의 디스크를 두어 디스크의 속도를 빠르게 함과 동시에 디스크가 손상되는 것을 막는(Fault Tolerant) 7가지 기법을 의미한다\n\nLevel 0 §\n\n\n일단 Strip이라는 것은 Session이랑 같은말이다 - 일련의 블럭들\n여러개의 블럭으로 구성된 파일을 하나의 디스크에 넣으면 하나의 IO에 의해 처리되므로 블럭들을 Serial하게 처리할 수 밖에 없다\n따라서 파일의 여러 블락들을 여러 디스크에 나눠 담아 여러개의 IO에 의해 처리되게 함으로 Parallel하게 처리되게 한다\nLevel 0에서는 그냥 이렇게 나눠담는 방법만 사용하여 속도에만 집중한 방법이다\nError에 대한 대비책은 고려하지 않으므로(Non-redundant) 진정한 의미의 RAID와는 좀 거리가 있다\n\nLevel 1 §\n\n\n얘는 이제 Level 0과 동일하게 하되, 동일한 Level 0구성을 두개를 놓아 하나에서 문제가 생겼을 때 다른 하나로 바로 이동해 처리하는 구조이다\n마치 like 백업을 두는 구조 - 이중화(Mirrored)\n요즘은 이 방법을 많이 사용하지만 Disk가 많이 필요하다는 단점이 존재한다\n\nLevel 2 §\n\n\n얘는 똑같은거 두개를 놓는게 아니라 Hamming Code라는 Error Correction Code를 별도의 디스크에 저장해 디스크의 갯수를 좀 줄이는 방법이다\n\nLevel 3 §\n\n\n얘는 Hamming Code 가 아닌 비트 단위(Bit-Interleaved)의 Parity bit을 이용해 Error Correction에서는 한계가 있지만 디스크의 갯수를 더욱더 줄이는 방법\nParity Bit은 Single Bit Error에 대해서는 Correction이 가능하지만 Double Bit Error에 대해서는 Detection만 가능하다는 점에 있어서 한계가 있다\n\nLevel 4 §\n\n\n얘는 비트 단위가 아닌 블럭 단위(Block-Level)로 Parity Bit을 구성해 Parity Bit를 더 줄이고 Error Detection연산도 줄이는 방법이다\n\nLevel 5 §\n\n\nLevel 3이나 4같은 경우에는 Parity Bit이 디스크 하나에 몰려있기 때문에 해당 디스크를 너무 많이 참조하고 Write가 발생할때마다 해당 디스크에 가서 Parity Bit를 다시 계산해줘야 하므로 Bottleneck현상(트래픽이 몰리는 것)이 일어날 수 있다 - 몰린다는 뜻\n따라서 Parity Bit을 분산하여 배치해 이러한 문제를 막는 기법이 Level 5 이다 - Distributed Parity\n\nLevel 6 §\n\n\n얘는 Parity Bit을 두개를 계산하여 저장(Dual Redundancy)하여 더 Error Correction의 정확성을 높이는 방법이다\n"},"originals/os.spring.2021.cse.cnu.ac.kr/13.-File-Management":{"title":"13. File Management","links":[],"tags":[],"content":"\n\n                  \n                  충남대학교 컴퓨터공학과 류재철 교수님의 &quot;운영체제 및 실습&quot; 강의를 필기한 내용입니다. \n                  \n                \n\n\n\n                  \n                  다소 잘못된 내용과 구어적 표현 이 포함되어 있을 수 있습니다. \n                  \n                \n\nFiles §\n\nFile : 사용자가 만든 비트들의 모음\n\n성질 §\n\nLong-term Existence : 오랫동안 보관되어야 함\nShareable between Processes : 프로세스들이 공유할 수 있어야 함\nStructure : 확장자 얘기하는듯 - 여러 구조의 파일들을 잘 관리할 수 있어야 함\n\n구성 요소 §\n\nName : 파일의 이름\n\n유닉스 시스템에서는 inode# 라는 정수형태로 파일의 이름을 저장한다\n\n\nType : 확장자\nLocation : 위치 - Block# 로 디스크에서의 위치가 저장된다\nSize : 파일의 크기\nProtection : 파일의 Log\n\nCreation : 생성\nLast Modification : 마지막 변경\nLast Use : 마지막 사용\n위 세가지에 대해 Time, Date, *UID(User ID)*를 로그로 저장한다\n\n\n\nOperation §\n\nCreate : 파일의 생성\nDelete : 파일의 삭제\nOpen : 파일 열기\nClose : 파일 닫기\nRead : 파일 읽기\nWrite : 파일 쓰기\nC언어에서는 open system call 이 create와 open 을 모두 책임진다\n사용자가 파일 하나를 open하면 파일의 이름을 inode로 변환하고 그것을 이용해 Block# 를 알아낸 다음 메인 메모리로 갖고 올라와 read 혹은 write의 연산을 하고 끝나면 close를 통해 파일이 닫히는 구조이다\n\nStructure - Database와 File System 의 차이점 §\n\nOS의 File System에서는 위에서 명시한 파일을 생성하고 삭제하고 열고쓰는 등의 Rough한 연산들만 지원한다\n반면에 Database에서는 File의 내용, 즉, File의 Field(데이터베이스에서 Column을 말하는듯)와 Record(데이터베이스에서의 Row를 말하는듯)등의 File의 세부적인 내용을 관리하는 역할을 한다\n\nUNIX File System §\n\n\n일단 디스크의 구조가 저렇게 n개의 블락으로 구성되어있다고 할 때\n첫번째 블록을 Boot Block이라고 한다 - 얘는 처음 부팅할때 메인메모리에 들어가서 OS초기화하고 부팅작업을 하는데에 사용된다\n그리고 두번째 블록을 Super Block이라고 한다 - 얘는 부팅 이후 메인메모리로 들어가서 전체적인 File System에 대한 정보를 OS에 제공해준다\n그 이후 위의 예시에서 2~m-1까지를 inode list라고 한다\n\ninode list에는 inode들이 저장되고 블록보다는 사이즈가 작기 때문에 한 블록에 여러개의 inode가 저장되게 된다\n따라서 하나의 시스템 안에 저장될 수 있는 파일의 갯수는 저 m에 달려있는 것이다\n\n\n그 다음 m부터 n-1까지는 data block이라고 한다\n\ndata block 은 파일의 실질적인 내용이 블럭단위로 잘려서 저장되게 된다\n\n\ninode는 파일 하나에 대한 정보를 저장하게 된다 - 프로세스에 PCB가 있었듯이 파일에는 inode가 존재하는 셈이다\n\ninode에는 다양한 정보들이 저장되는데 일단\n위에서 말한 파일의 구성 요소인 name, type, size, location, protection과 파일의 주인인 owner가 들어간다\n그리고 index table이 들어가게 되는데 이놈이 하나의 파일에 대한 내용을 블럭단위로 쪼개서 data block에 저장하게 되므로 그 블럭들이 data block의 어디에 존재하는지를 나타내는 테이블이다\n위의 예시에서는 327, 15, 216이라고 돼있으므로 파일의 첫번째 블럭은 data block의 327에 가면 있다는 거고 두번째 블럭은 15, 마지막 블럭은 216에 가면 있다는 소리이다\n따라서 파일 하나가 가질 수 있는 최대 크기는 index table에 달려있게 된다\n\n\n그리고 한 파일이 열리면 그 파일에 대한 inode가 메인메모리로 올라가고, index table을 이용해 data block들도 하나씩 차례로 올라가게 된다\n\nIndex table §\n\nindex table의 구조를 조금 더 자세히 살펴보면 다음과 같다\n\n\n\n일단 index table의 일정부분은 바로 파일의 내용이 저장된 data block의 블럭으로 연결된다 - 여기를 direct block이라고 함\n위의 예시에서는 10까지는 따라가보면 바로 파일의 내용이 나오게 된다는 소리이다\n그리고 그 다음부터는 계층구조를 가지게 된다\n이게 뭔말이냐면, index table에 적혀있는 block# 으로 가보면 해당 블럭에 들어있는 내용은 파일의 내용이 아니라 또다른 index table이 존재하는 것이다\n즉, data block에 저장되어있는 블럭은 파일의 내용을 저장하는 블럭일 뿐만 아니라 index table일 수도 있다는 소리이다\n따라서 인덱스 테이블에서 다시 또다른 인텍스 테이블로 움직이고, 거기서 파일의 내용이 저장된 블럭으로 이동하는 계층구조를 가진다\n최상위 index table은 이렇게 일정구간은 바로 파일 내용 블럭으로 가지만 나머지는 차수가 점차 늘어나는 계층구조를 갖도록 되어 있다 - 이부분을 indirect block이라고 한다\n즉, 위의 예시에서는 11번째 칸에는 또다른 index table의 위치가 저장되어있고, 그 index table에는 파일 내용 블럭의 위치가 저장된 1중 계층구조였다면,\n12번째 칸에는 2중 계층구조, 13번째 칸에는 3중 계층구조로 되어있는 것이다\n이때 data block에 저장된 index table의 크기가 256이라면, 하나의 파일은 10 + 256 + 256^2 + 256^3 개의 블럭에 나뉘어져 저장되는 셈인거다\n보통 블럭 10개를 direct block으로 갖고 3개를 indirect block 로 1-Level, 2-Level, 3-Level 을 갖는 식으로 inode의 index table이 구성된댄다\n\nDirectory §\n\n일단 유닉스 시스템에서는 directory도 하나의 file로 취급한다\n\n\n\n일단 현재 디렉토리(current directory)가 inode 300번이라고 해보자\n그럼 거기의 index table을 통해 data block으로 간 결과가 그 옆의 column두개짜리 테이블이다\n디렉토리이기 때문에 파일의 내용이 저렇게 2 column table로 나타나게 되고\n이 2 column table에는 위의 예시에서는 오른쪽에는 해당 디렉토리에 들어있는 파일의 이름, 그리고 왼쪽에는 그 파일의 index# 가 저장된다\n그리고 만약 내가 A라는 디렉토리로 가고 싶으면 A 옆의 inode로 들어가게 된다\nA의 inode가 766이라고 했을 때 해당 inode list의 원소로 가면 동일하게 A의 정보와 A의 내용을 볼 수 있다(index table을 이용해서)\nA의 내용을 보면 A 또한 디렉토리이기 때문에 2 column table을 볼 수 있고, A에는 f1이 들어있기 때문에 f1과 f1의 inode# 가 2 column table에 저장되게 된다\n마찬가지로 f1의 inode# 인 111로 가면 거기에서 마찬가지로 index table을 이용해 f1의 내용을 볼 수 있는 것이다\n따라서 핵심은 유닉스에서는 디렉토리도 file로 관리되어 inode가 존재하고, 디렉토리의 inode에 저장된 index table을 이용해 내용 블럭으로 가면 거기에는 해당 디렉토리의 하위 디렉토리 / 파일에 대한 ( 이름, inode# ) 들이 저장되어 있는 것이다 - 따라서 해당 inode# 을 쫒아가면 하위 디렉토리 / 폴더로 접근하게 되는 구조이다\n\nFile Directory Structure §\n\nSingle Level Directory : 한명의 유저와 하나의 current directory만을 지원해 모든 파일들이 다 같은 곳에 unique한 이름들을 가지며 존재하는 것\n\n\n\nTwo Level Directory : 이제는 여러명의 유저와 하나의 current directory만을 지원해 파일들이 하나의 유저한테 속하여 존재하는 구조 - 한 유저 안에서는 unique한 이름을 가져야 되지만 유저가 다르다면 이름이 중복되어도 된다\n\n\n\nTree Structured Directory : 일반적으로 우리가 생각하는 디렉토리의 구조 여러명의 유저가 있고 한 유저 안에서도 여러개의 디렉토리, 디렉토리 안의 디렉토리를 생성해 트리구조로 디렉토리들이 형성되는 것\n\n\n\nAcyclic Graph Directory : 얘도 동일하게 트리구조를 갖지만 트리구조에서는 할 수 없는 공유의 개념이 가능한 구조이다 - 파일 하나를 여러명의 유저가 공유할 수 있는 구조\n\n\nFile Sharing System §\n\n\nHard Link : 공유파일에 대해 하나의 inode와 data block을 두 디렉토리 / 유저가 공유하는 형태이다\n\ninode와 data block을 하나씩 사용하기 때문에 resource를 적게 사용한다는 장점이 있다\n\n\nSymbolic Link : 얘는 두 디렉토리 / 유저가 각각 하나씩 공유파일에 대한 inode와 data block을 갖고있고 둘 중 하나의 data block에 나머지 하나의 inode의 경로가 적혀있는 형태이다\n\n얘는 inode와 data block이 더 필요하므로 resource를 더 많이 먹는다는 단점은 있지만, network를 사용해서 파일을 공유한다거나 하는 등의 더 강력한 파일 공유를 지원할 수 있다 - 그냥 파일의 경로만 data block에 적어주면 되므로\n\n\n\nFile Allocation §\n\ninode에서 쓰는 index table방식 말고 다른 방식의 data block을 찾아가는 방식들\n\nContiguous File Allocation §\n\n\nContiguous File Allocation : 얘는 data block을 연속적으로 디스크에 배치한 뒤, 시작블럭과 갯수를 File Allocation Table에 저장하는 방식이다\n이놈의 단점은 일단\n\n마지막 data block 뒤에 다른 파일의 data block이 들어있으면 그자리를 사용하지 못하므로 파일의 크기가 커졌을 때 대처할 수 없다는 것과\n파일이 삭제되어 data block들을 삭제했을 때에 External Fragmentation이 일어난다는 것이다\n옛날 windows xp가 이런 방식으로 작동해 external fragmentation 들을 모으는 조각 모음(compaction) 이 있었던 것이다\n\n\n\nChained Allocation §\n\n\nChained Allocation은 Linked List마냥 다음 data block의 위치를 data block의 마지막에다 저장해서 찾아가도록 하는 구조이다\n단점은 당연히\n\npointer를 잃어버리면 파일이 날라가는 문제가 발생한다는 것과\n파일의 특정 지점을 읽으려면 그곳까지 datablock을 차례로 들러야 하기 때문에 오래걸린다는 것이다\n이것을 해결하기 위해 FAT(File Allocation Table) 라는 것을 이용한다.\n\n\n\n\n\n얘는 여기저기 흩어져있는 포인터를 하나의 테이블에 모은 것으로, ( Block# , next Block# )을 저장하는 테이블이다\n포인터를 잃어버리지 않는다는 것과 이것이 특정 위치로 갈때 블락들을 찾는게 아닌 이 테이블만 읽으면 되니까 훨씬 더 빠르다는 장점이 있지만\n디스크의 사이즈가 커지면 FAT도 너무 커진다는 단점도 존재한다\n\nIndex Allocation with Variable-Length Portions §\n\n\nIndex Allocation with Variable-Length Portion은 index table개념과 contiguous allocation 개념을 합친거다\n즉, index table을 사용하되 연속된 블럭을 하나의 행에 저장하는 방법 - (start block, lengh)를 저장한다\n\nFree Block Management §\n\n비어있는 블럭을 관리하는 방법\n\nBit table §\n\n\nBit Table은 모든 Block# 에 하나씩 비트를 할당한 테이블로 이 비트를 이용해 해당 블럭이 비었는지 아닌지를 표시하는 방법이다\n\nChained Free Portions §\n\n\nChained Free Portions는 Free block들을 Linked List처럼 이어놓은 형태이다\n\nIndexing §\n\n\nIndexing은 table 하나를 만들어서 거기에 free block의 block# 를 다 저장하는 방법이다\n얘는 크기가 디스크의 블락의 갯수랑 같을 필요는 없다\n\nfree block의 갯수가 table의 갯수보다 클때는 일단 table을 다 채워놓고서 table에 들어있는 free block들이 다 사용되고 나면 다시 하드를 조사해 free block들을 채우면 되기 때문\n즉, 디스크의 모든 free block을 아는것이 중요한게 아니기 때문에 몇개를 채워놓고 다쓰면 다시 채우고 하는 방식으로 작동하게 된다\n\n\n"},"originals/pl.spring.2021.cse.cnu.ac.kr/(충남대)-프로그래밍-언어-개론-강의록":{"title":"(충남대) 프로그래밍 언어 개론 강의록","links":["originals/pl.spring.2021.cse.cnu.ac.kr/01.-OCaml-문법-(1)","originals/pl.spring.2021.cse.cnu.ac.kr/02.-OCaml-문법-(2)","originals/pl.spring.2021.cse.cnu.ac.kr/03.-재귀-호출-최적화-기법","originals/pl.spring.2021.cse.cnu.ac.kr/04.-Syntax와-Semantics","originals/pl.spring.2021.cse.cnu.ac.kr/05.-Lexical-Analyzer-(Lexer,-어휘분석기)","originals/pl.spring.2021.cse.cnu.ac.kr/06.-Syntax-Analyzer-(Parser,-구문분석기)","originals/pl.spring.2021.cse.cnu.ac.kr/07.-언어의-정의","originals/pl.spring.2021.cse.cnu.ac.kr/08.-문법적-설탕과-식별자","originals/pl.spring.2021.cse.cnu.ac.kr/09.-함수와-함수호출","originals/pl.spring.2021.cse.cnu.ac.kr/10.-1등-시민-함수","originals/pl.spring.2021.cse.cnu.ac.kr/11.-조건분기문","originals/pl.spring.2021.cse.cnu.ac.kr/12.-재귀함수","originals/pl.spring.2021.cse.cnu.ac.kr/13.-명령형-언어-(1)","originals/pl.spring.2021.cse.cnu.ac.kr/14.-명령형언어-(2)"],"tags":[],"content":"개요 §\n강의 정보 §\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n강의 구분소속교수시기학부 수업충남대학교 공과대학 컴퓨터공학과이성호 교수님2021년 봄학기\n실습 자료 §\n\ngithub://haeramkeem/Spring2021-CNU-UPL\n\n목차 §\n\n01. OCaml 문법 (1)\n02. OCaml 문법 (2)\n03. 재귀 호출 최적화 기법\n04. Syntax와 Semantics\n05. Lexical Analyzer (Lexer, 어휘분석기)\n06. Syntax Analyzer (Parser, 구문분석기)\n07. 언어의 정의\n08. 문법적 설탕과 식별자\n09. 함수와 함수호출\n10. 1등 시민 함수\n11. 조건분기문\n12. 재귀함수\n13. 명령형 언어 (1)\n14. 명령형언어 (2)\n"},"originals/pl.spring.2021.cse.cnu.ac.kr/01.-OCaml-문법-(1)":{"title":"01. OCaml 문법 (1)","links":[],"tags":[],"content":"\n\n                  \n                  충남대학교 컴퓨터공학과 이성호 교수님의 &quot;프로그래밍 언어 개론&quot; 강의를 필기한 내용입니다. \n                  \n                \n\n\n\n                  \n                  다소 잘못된 내용과 구어적 표현 이 포함되어 있을 수 있습니다. \n                  \n                \n\n들어가기에 앞서 §\n\nOCaml은 점유율 낮은 언어인것은 맞다.\n하지만 지독하게 매니악한 극한의 함수형 언어란 것임에는 이견이 없는거같다\n한번 배워놓으면 다른 언어에서의 함수형 기능을 좀 원활하게 습득할 수 있지 않을까 싶다\n\nOCaml §\n\n함수형 언어\nStrongly typed language : 정적 자료형 선언\n\n하지만 자료형 추론기능을 제공하므로 타입을 써주지 않아도 됨. 단, 동적선언이 아니므로 자료형 미스매치의 경우 오류가 난다\n\n\nPolimorphism : 기억안나제?\nPattern matching : 아직 뭔지 모르겠음\nModule system : 모듈기능 제공\nOOP : 객체기능을 사용할 수 있다\n\n자료형 §\n\n() : unit. void와 같은 기능이다\n모든 자료형은 원시타입이다. 객체타입이 아니다\n실수의 사칙연산은 반드시 기호 옆에 .를 붙여줘야 한다\n\n예를들어 +연산은 +.이다\n\n\n문자열 연산\n\n^ : 문자열 이어붙이기\n“문자열”.[인덱스] : 인덱스 접근\nString.length “문자열” : 길이구하기\nString.sub “문자열” 2 3 : 슬라이싱\n\n\n주의할 논리연산자\n\nx = y, x &lt;&gt; y : 값비교 연산자\nx == y, x != y : 값, 주소비교 연산자\n=가 할당연산자가 아니라는것에 유의해라\n\n\n\n컴파일 §\n\nDune 파일 고치고\n커맨드에 이걸 친다\n\ndune exec --profile release ./file.exe\n화면 입출력 §\n\n화면 출력\n\nFormat.printf 출력할거\n\n화면 입력\n\nlet x = read_line() in\n함수호출 §\n\n호출시 인자를 넣어줄때 괄호를 쓰지 않고 띄어쓰기로 대체한다\n인자들을 구분하는것도 띄어쓰기를 이용한다\n\nfunc(a, b) → func a b\n\n\n오캠엘에서의 함수는 무적권 값을 반환해야 한다 : 아무것도 반환할게 없으면 ()을 반환하면 된다\n\n()는 unit이라는 값으로 void와 의미는 동일하지만 어떤 ‘값’이라는 점에서 차이점을 가진다\n\n\n\n변수 선언, 초기화 §\nlet 변수 = 값 in\n\n일반적인 언어처럼 = 로 할당하는게 아닌 let = in 이라는 구문을 써야 한다\n모든 변수는 선언과 함께 초기화가 이루어져야 한다\nscope는 변수의 사용 범위를 나타내며 in이 그 역할을 한다 - in을 사용하면 로컬, 사용안하면 글로벌\nOCaml에서는 모든 변수가 불변으로 선언됨\n\nx에 1을 넣고 나중에 2를 넣으면 변수 x에 2를 넣는게 아니라 변수x를 새로 할당해서 2를 넣는다 - 주소값이 달라진다\n\n\n\n시퀀스 §\n\nOCaml에서는 세미콜론(;)이 문장종료기호가 아닌 다음 문장 실행 이라는 뜻을 가진다\n따라서 더 이상 실행할 문장이 없는 마지막 문장에는 세미콜론을 붙이지 않는다\nbegin-end 구문을 이용해 명시적으로 실행방향을 정해줄 수도 있고\nin도 무적권 다음 문장이 실행되게 되므로 let-in구문을 통해 다음문장이 실행되게 해줄 수도 있다\n\nWildcard §\n\n언더바(_)로 사용할 수 있는 와일드카드는 아무 값이라는 의미를 가진다\n오캠엘에서 함수나 연산에서 반환되거나 결과로 나온 값을 let-in을 통해 어딘가에 저장하지 않으면 오류가 난다(unit의 경우에는 오류가 안난다)\n만약 함수의 반환값을 받아서 버리기 위해서는 와일드카드 _ 를 사용하면 된다\n\n함수선언 §\nlet 함수이름 = fun 매개변수 -&gt; 리턴연산 in\nlet 함수이름 매개변수 = 리턴연산 in\n\n두번째처럼 표현하는 것을 curried function이라고 한다\n\n함수의 타입 표시 §\n\n반환값 → 매개변수1 → 매개변수2 → ... → 마지막 매개변수\n예를들어 int두개를 받아 float하나를 반환하는 함수의 경우 이 함수의 타입은 float → int → int 이 된다\n\n함수의 매개변수보다 부족하게 인자를 줬을 때 §\n\n인자가 다 매개변수에 채워지고 남은 매개변수는 그대로 남아 결과가 어떤 값이 아닌 함수가 된다\n함수에 일부 인자만 전달하는 것으로 partial application이라고도 한다\n\n튜플은 파이썬과 똑같다 §\n\n다만 타입 기호는 * 로 한다\n예를들어 (1, 2.34)의 경우 int * float 이 타입인 것이다\n\nHigher order function §\n\n함수를 인자로 받는 함수를 의미함\n\nlet f x = f x in\n\n이렇게 어떤 함수를 동적으로 실행하는것을 지원한다\nppt예제 보면서 느낌을 기억할 것\n\nOCaml의 경우 반복문을 지원하지 않는다 §\n\n대신 무조건 함수를 재귀적으로 돌려 반복을 수행하게 만든다\n단, 어떤함수를 재귀적으로 호출하려면 함수이름 앞에 rec이라는 키워드를 붙여줘야 한다\n\n조건문은 if-then-else형태로 실행된다 §\nif 조건 then 참결과 else 거짓결과\n\n여기서 주의할 점은 참결과와 거짓결과의 자료형이 무조건 같아야 한다\n\n함수 몸체 및 main은 하나의 expression으로 구성되어야 한다 §\n\nlet-in문의 경우 사이에 들어가는 놈이나 in 다음줄을 let-in문이 다 감싸서 하나의 expression으로 취급된다\nif-then-else도 인덴트 안의 내용은 하나의 expression으로 취급된다\nbegin-end나 ;을 통한 시퀀스도 하나의 expression으로 취급된다\n이 점은 고려하여 모든놈이 하나의 expression으로 되어 있어야 하고 그렇지 않으면 오류가 난다\n"},"originals/pl.spring.2021.cse.cnu.ac.kr/02.-OCaml-문법-(2)":{"title":"02. OCaml 문법 (2)","links":[],"tags":[],"content":"\n\n                  \n                  충남대학교 컴퓨터공학과 이성호 교수님의 &quot;프로그래밍 언어 개론&quot; 강의를 필기한 내용입니다. \n                  \n                \n\n\n\n                  \n                  다소 잘못된 내용과 구어적 표현 이 포함되어 있을 수 있습니다. \n                  \n                \n\n모듈 §\n\n대문자로 시작함 - 소문자로 해주면 컴파일이 되지 않는다(관례가 아님)\nimport해줄 필요 없음 - dune이 자동으로 모듈화한다\ndune은 굳이 안건들여도 된다 - (include_subdirs unqualified) 해주면 하위디렉토리까지 전부 모듈화시켜줌\n\nNested module §\n\n모듈 내에 모듈을 또 정의해서 사용 가능함\n\nmodule module_name_ = struct ... end\n\nnested module은 이렇게 접근 가능하다\n\nModule.Nested_module_.func_\n모듈 불러오기 §\n\n기본적으로 import는 할 필요 없다\n하지만 경로가 길어지면 불편해지므로 open이라는 기능을 지원한다\n\nModule_name_.func_\n(* 이건 아래와 같다 *)\nopen Module_name_\nfunc_\n\nopen 을 이용하면 모듈 내의 함수/변수 등을 . 로 경로를 들어가서 불러내지 않아도 바로 불러줄 수 있다\n하지만 같은 이름의 변수 / 함수의 경우 충돌이 있으므로 잘 생각해서 사용할 것(충돌이 일어날 경우 그늘효과에 의해 마지막에 불러온 놈으로 앞의 놈까지 다 가려진다)\nlet-open-in 을 통해 scope를 제한할 수 있다 - 해당 모듈 내에서만 open하여 사용하고 싶을 때\n함수 module을 이용해서도 모듈을 불러올 수 있다 - 모듈의 경로가 긴 경우 이것으로 닉네임을 설정해 사용할 수 있음\n\nmodule M_ = Module_\n\nconflict를 막을수도 있고 가독성도 떨어지지 않으므로 추천하는 방향이다\n\nPattern matching §\n\n매우 중요하고 유용하다\n값의 형태에 기반하여 다르게 처리함\n처리안한 형태가 있을 경우 warning을 뿜는다\n\nmatch expression_ with\n    pattern1_ -&gt; expression1_\n    pattern2_ -&gt; expression2_\n    pattern3_ -&gt; expression3_\n    ...\n\npattern에 선언되지 않은 변수를 사용해도 된다 - expression의 결과가 자동으로 그 변수에 할당됨 (매칭시 어떤 값을 담는 그릇)\n따라서 변수는 하나의 패턴에만 사용해야 한다(미리선언한 변수를 갖고와서 사용하는것도 안된다 이거야)\nwildcard를 pattern에 넣으면 나머지 전부의 경우의 수를 처리할 수 있다\n\n변수를 써도 되지만 이 변수를 다시 사용하지 않으면 warning이 나오므로 사용하지 않을거면 wildcard를 쓰는게 현명하다\n예상하지 못한 경우의 수가 있을 수 있으므로 항상 마지막엔 wildcard를 pattern에 넣어주는것이 에러가 안난다\n\n\n그리고 처음에 넣어준 expression의 결과값의 type을 보고 모든 가능한 범위가 커버되었는지 확인하므로 논리적으로는 가능한 범위가 커버되었어도 자료형적으로는 모든 범위가 커버되지 않았을 경우가 있다\n연속된 값을 pattern으로 처리하고 싶을때에는 정규식에서의 [a-b]와 비슷한 연산을 제공한다\n\n[a-b] (* 정규식에서의 이 표현은 *)\n&#039;a&#039; .. &#039;b&#039; (* 이것과 같다 *)\n\nif-then-else와 마찬가지로 모든 pattern에 대한 매칭값은 자료형이 일관되어야 한다\n\nfailwith §\n\n파이썬에서의 raise와 비슷하다\n\nfailwith &quot;error_message&quot;\n\n에러를 발생시키고 넣어준 문구를 반환하는 함수이다\n아주 많은 경우의 수에 대해 각각 복잡한 구현을 해야한다면 하나의 경우의 수 pattern에 넣고 나머지는 failwith로 두고 이런식으로 점진적으로 구현하는 것이 가능하다\n\n리스트 §\n\n원소들의 타입이 반드시 같아야 한다\n리스트의 타입은 int list, string list 등 type list 형태이다\n\n이것이 해당 리스트의 자료형 이름이 되는 것\n\n\n리스트의 원소 구분은 세미콜론(;)이다\n:: 연산자\n\nappend_first기능\n\n\n@ 연산자\n\n+기능\n\n\n다행히도 동적배열을 지원한다\n\nList.iter 함수 §\n\n아무것도 반환하지 않는 함수와 리스트를 받아 각 원소들을 함수에 넣어 실행하고 아무것도 반환하지 않음\nargs:\n\nf(function) : 리스트를 받아 뭔가를 실행하고 unit을 반환\nl(list) : 함수에 넣어줄 값들을 원소로 하는 리스트\n\n\nreturn:\n\nunit : 아무것도 반환하지 않음\n\n\n\nList.map 함수 §\n\n함수와 리스트를 받아 리스트 원소들을 함수에 넣어 실행하고 그 결과를 다시 리스트로 묶어 반환\nargs:\n\nf(function) : 원하는 동작을 담은 함수\nl(list) : 함수에 넣어줄 값들을 원소로 하는 리스트\n\n\nreturn:\n\nlist : 함수 실행 결과들을 묶어서 만든 리스트\n\n\n\nList.fold_left 함수 §\n\nf와 어떤 값x, 리스트l을 받아 f(f(f(x, l[0]), l[1]…)을 실행하는 함수\nargs:\n\nf(function) : 원하는 동작을 담은 함수\nx(whatever) : 어떤 값\nl(list) : 중첩실행할 리스트\n\n\nreturn:\n\nwhatever : 결과값\n\n\n자료형 유의해라 - f, x, l에 어떤 자료형을 넣어야 하는지\n\n리스트 패턴매칭에의 활용 §\n\n:: 연산자는 append_first라는 기능을 하기도 하지만 패턴매칭에서 패턴으로 활용하면 쪼개는 기능으로 활용할 수 있다\npattern을 a :: b 이렇게 적어주면 리스트의 첫번째 원소가 a로 들어가고 첫번째 원소를 제외한 나머리 리스트는 b에 담기게 된다\n\nDisjoint unions §\n\n여러개의 자료형들을 하나의 자료형으로 묶어서 다양한 형태를 갖는 하나의 자료형을 정의하는 것이다\n\ntype type_name_ =\n    | Identifier1_ of int\n    | Identifier2_ of string\n    | Identifier3_ of char\n    ...\n\nIdentifier은 variant라고 불리는데 type_name_ 자료형의 한가지 형태라고 볼 수 있다.\n\n예를들어 number 자료형에 Integer of int라고 명시한다면 Integer 3은 정수로써 기능은 하지만 자료형은 number인 것이다\n\n\ntype_name_ 은 반드시 소문자로 시작하여야 한다\n그리고 Identifier 은 반드시 대문자로 시작하여야 한다\nof 자료형은 반드시 적어줘야 하는 것은 아니다 - of 자료형을 적지 않으면 unit을 대체하는 자료형이 생성되는 것이다\nIdentifier 값 으로 type_name_ 의 자료형을 하나 생성할 수도 있지만 그 반대도 된다\n\ntype_name_ 을 자료형으로 하는 변수를 만든 다음 이 변수에 값을 넣어주면 이 값의 자료형에 따라 Identifier 가 결정되기도 함\n\n\n따라서 pattern matching에서 pattern에 걸리도록 할 수 있다\ntype이 모듈이 들어있을때 type의 variant을 사용할때도 모듈이름을 붙여줘야 한다\n\nDisjoint union을 활용한 내장 자료형 - option §\n\nNone과 Some의 두 형태를 가짐\n어따쓰는건지는 나도 잘 모르겠다\n\n함수에서의 자료형 명시 §\nfunc_name_ (arg1 : type) (arg2 : type) ... :type\n\n이렇게 매개변수는 : 자료형 을 함께 괄호로 묶어주고 리턴타입은 맨 끝에 저렇게 적어주면 된다\n"},"originals/pl.spring.2021.cse.cnu.ac.kr/03.-재귀-호출-최적화-기법":{"title":"03. 재귀 호출 최적화 기법","links":[],"tags":[],"content":"\n\n                  \n                  충남대학교 컴퓨터공학과 이성호 교수님의 &quot;프로그래밍 언어 개론&quot; 강의를 필기한 내용입니다. \n                  \n                \n\n\n\n                  \n                  다소 잘못된 내용과 구어적 표현 이 포함되어 있을 수 있습니다. \n                  \n                \n\n재귀문 최적화 §\n\n함수형 언어에서는 알고리즘적으로 최적화할 수 있는 방법이 많지 않다\n대신 이런 최적화는 컴파일러에서 수행하므로 우리가 할 것은 컴파일러가 최적화를 잘 해줄 수 있는 방향으로 코드를 짜야 된다\nOCaml에서 변수는 불변하게 선언되는데 이것이 최적화에 아주 많은 도움이 된단다\n\nTail call optimization §\n\n함수가 하나 더 실행되어 callee가 하나 생성되면 이전의 caller를 지워버리는 기법\n메모리를 추가적으로 먹지 않으므로 메모리 관리에 유용하다\n\n방법 §\n\n재귀를 호출할때 함수의 맨 끝에서 호출하면 된다\n재귀의 경우 다시 돌아와야 되는 이유는 돌아온 이후에 코드가 더 있어서 작업을 더 해줘야 하기 때문\n하지만 돌아온 이후에 할일이 없어 바로 caller가 종료되는 구조라면 굳이 돌아오지 않아도 된다\n따라서 맘편하게 caller를 메모리에서 지워도 되므로 재귀호출시에 메모리를 더 먹지 않는다\n\n이런식으로 굴러가게 하는 것을 tail call optimization이라고 하는 것\n\n\n\n활용 - 누산기(Accumulator)이용 §\n\n결과값을 다 더해야 하는 함수의 경우 재귀 호출 종료 후 더하는게 아니고 매개 변수 acc를 하나 추가해서 값을 누적하는 작업도 함수 내에서 수행하게 함\n하지만 매개변수를 추가해야 되므로 함수의 구조가 바뀌게 된다\n\n이것을 방지하는 방법은 구조가 바뀐 함수를 기존 구조의 함수로 포장지를 싸듯이 감싸는 것이다.\n즉, 기존 구조의 함수 내에 매개변수가 추가된 함수를 local하게 넣어서 기존 구조 함수는 재귀적으로 실행되지 않고 안에 들어있는 함수가 재귀적으로 호출되어 tail call적으로 연산을 수행함\n이렇게 되면 함수의 구조도 바뀌지 않고 메모리 사용도 현저히 줄어들므로 꿩먹고 알먹고 이다\n이러한 구조를 wrapping한다\n\n\n"},"originals/pl.spring.2021.cse.cnu.ac.kr/04.-Syntax와-Semantics":{"title":"04. Syntax와 Semantics","links":[],"tags":[],"content":"\n\n                  \n                  충남대학교 컴퓨터공학과 이성호 교수님의 &quot;프로그래밍 언어 개론&quot; 강의를 필기한 내용입니다. \n                  \n                \n\n\n\n                  \n                  다소 잘못된 내용과 구어적 표현 이 포함되어 있을 수 있습니다. \n                  \n                \n\nImperative &lt;-&gt; Declarative §\n\nImerative : 보통의 명령들을 나열해 문제를 푸는 방법을 선언하는 방식으로 프로그래밍 하는 것\nDeclaraive : 문제를 푸는 방법을 적는게 아니라 어떤 문제인지를 적어서 프로그래밍하는 방법\n\n문제는 얘가 알아서 풀어준다\n옛날에는 구렸는데 요즘은 엔진이 좋아져 종종 쓰인댄다\nSQL같은게 여기에 해당한다고 할 수 있음\n\n\n\n프로그래밍 언어의 번역 vs 해석 §\nCompile §\n\n번역은 그냥 동일한 의미의 기계어로 바꾸는 것 (Compiled language)\n오류를 컴파일 타임에 잡을 수 있다\n프로그램 전체를 검토해 기계어로 바꾸기 때문에 최적화 가능 (성능의 이점)\n비교적 low level이어서 시스템 프로그래밍에도 사용할 수 있다\n다만 비교적 배우기 어렵고 컴파일 과정이 복잡하다\n그리고. static-typed language이다\n\n컴파일 시점에 변수들의 자료형이 모두 결정된다\n\n\n자바같은 경우에는 JVM이라는 가상 기계어 환경으로 컴파일해 구동하는 과정을 거친다\n\n여러 플랫폼에서 일관되게 지원하기 위함\n\n\n\nInterprete §\n\n해석은 언어를 읽고 이해해 바로 실행하는 것 (Interpreted language)\ninterprete는 프로그램을 통째로 컴파일하는 과정이 아닌 바로바로 해석해서 실행하게 된다\n\n컴파일의 경우에는 통째로 번역하기 때문에 최적화가 용이하지만 인터프리트의 경우 한줄한줄 바로바로 실행하기 때문에 최적화가 어려움\n속도가 비교적 느리다\n\n\n간단한 검증만을 수행하기 때문에 오류를 미연에 방지하기는 컴파일 언어보다 어렵다\n대신 배우기 쉽고 자유로우며 자료형들이 동적으로 선언(Dynamic-typed language)된다\n스크립트 언어들이 여기에 해당된다\n그리고 shell들도 이런식으로 구동된다\n\n프로그래밍 언어의 구성 §\n\n프로그래밍 언어는 syntax와 semantics로 구성되며 얘네들은 해당 언어의 specification(사용 설명서) 에 기술된다\nSyntax : 명령어들이 어떻게 생겼는지\nSemantics : 해당 syntax가 어떻게 작동하는지를 기술\n\nsyntax별로 semantics가 정의되게 된다\n\n\n\nUnspecified Behaviors §\n\n특정 syntax에 대해 일부로 semantics를 정의 않는 것\n동작을 정의하는데에 있어 자유를 부여함\n\n이때 자유라는 것은 나의 자유가 아니라 어떻게 동작할지는 해당 언어의 컴파일러 / 인터프리터 개발자의 자유이다\n얘네들을 개발할때 임의적으로 정의해서 개발을 하게 된다는 것\n컴파일러 / 인터프리터에 따라 다르게 작동할 수 있다\n\n\n보통 어떻게 정의하든 별로 중요하지 않을 때 이런식으로 기술한다\n\n정의가 중요했으면 당연히 semantics를 정의했겠지\n\n\n다만 개발자는 얘가 semantics를 정의하지 않은 놈이라는것을 알고는 있어야 한다\n\nUndefined Behaviors §\n\n특정 syntax에 대해 semantics가 정의 않은 것\n얘네들은 약간 에러같은애들이다\n\n프로그램을 오작동하게 하지만 에러로 처리하기에는 성능면에서 안좋거나 하는 등의 사유가 있는 애들\n\n\n얘를들어서 쓰레기값에 접근하는 경우이다\n\n얘네들은 에러는 안나지만 undefined여서 오작동하게 된다\n\n\n따라서 개발자는 어떤 경우에 undefined인지를 반드시 숙지해야 한다\n"},"originals/pl.spring.2021.cse.cnu.ac.kr/05.-Lexical-Analyzer-(Lexer,-어휘분석기)":{"title":"05. Lexical Analyzer (Lexer, 어휘분석기)","links":[],"tags":[],"content":"\n\n                  \n                  충남대학교 컴퓨터공학과 이성호 교수님의 &quot;프로그래밍 언어 개론&quot; 강의를 필기한 내용입니다. \n                  \n                \n\n\n\n                  \n                  다소 잘못된 내용과 구어적 표현 이 포함되어 있을 수 있습니다. \n                  \n                \n\n프로그래밍 언어란 §\n\n프로그래밍 언어는 &lt;정해진 문법&gt;을 따르는 &lt;알파벳 문자열&gt;이다\n\n구문분석기(syntax analyzer 혹은 parser) §\n\nG = 문법 = 규칙\n함수 L()를 인자로 받은 문법으로 만들 수 있는 모든 문자열들의 집합을 반환하는 함수라고 가정해보자 - 그럼 L(G) 는 해당 문법에 부합하는 모든 문자열의 집합이다\n임의의 문자열 s가 집합 L(G)의 원소인지를 판단하는 것이 syntax analyser 혹은 parser가 하는 일이다\n\nChomsky hierarchy §\n\n\n여기 보면 왼쪽에 있는 놈이 L(G)에 대응하고 오른쪽에 있는 놈이 Parser에 대응한다\n\nautomaton(복수형 - automata)이라는 것은 parser랑 비슷하게 어떤 문자열이 어떤 문법을 따르고 있는지 판단해주는 가상(상상에만 존재하는) 기계(머신)이다\n\n\n즉, 어떤 문자열이 [왼쪽]에 속하는 지를 [오른쪽]놈이 판단한다 이말이다\n그리고 원이 클수록 더 많은 표현을 할 수 있게 된다\n일반적인 프로그래밍 언어는 Context-Free Language로 정의된다\n그리고 일부의 프로그래밍 언어가 Context-Sensitive Language로 정의되고\nRecursively-Enumerable Language는 존재하지 않는다\n\n무한대의 저장공간을 가지고 있는 이상적인 parser가 Turung Machine이기 때문\n\n\n\n기본 정의 §\nAlphabet §\n\n여기에서 alphabet이란 &lt;기호&gt;들의 &lt;유한집합&gt;(finite set)이다\n굳이 영어의 알파벳이 아니더라도, 몇개의 기호들을 모아 집합으로 만들면 그게 알파벳이 된다 이거다\n알파벳은 Σ 시그마로 표현한다\n\nString - 문자열 §\n\n문자열은 알파벳 내 &lt;기호&gt;들의 &lt;유한 순서&gt;이다\n즉, 기호 몇개를 묶어 순서를 가지게 나열하면 그게 문자열이 된다는 것이다\n길이가 유한하다는 거지 문자열 집합의 크기가 유한하다는게 아니다 - 문자열 집합의 크기는 무한\n알파벳으로 만들 수 있는 모든 문자열의 집합을 Σ * - 시그마 별로 나타낸다\n빈 문자열은 ε로 나타낸다\n문자열만을 언어로 정의하면 유효하지 않은 놈들까지 포함되게 된다\n\n이메일 언어를 정의하기 위해 대, 소문자와 @를 알파벳으로 정의하고 이 알파벳으로 만든 문자열 집합을 이메일 언어로 정의해버리면 @@@도 이메일 언어에 포함되게 됨\n언어의 정의는 좀 더 복잡하게 할 필요가 있더라\n\n\n\n문자열 연산 §\n\n접합 : {xy | x → Σ * 1, y → Σ * 2} - 문자열 두개 같다붙인거\n합집합 : {x | x → Σ * 1 OR x → Σ * 2} - 문자열 두개 OR\n클레이니 스타(kleene closure) : {x | x → ε OR x → Σ OR x → ΣΣ … } - 결국에는 (Σ *) * 는 Σ * 와 같게 된다 - 정규식에서의 별표\n\n문자열 연산을 이용하여 “정밀하게” 언어를 정의하기 §\n\n“정밀하게”정의한다는 것은 “올바른” 문자열만을 언어에 포함시키겠다는 의미이다\n문자열 연산을 활용하여 우리가 원하는 언어만 언어에 포함시키도록 해야 한다\n\n정규식 §\n\n정규식 배웠제?\n정규식으로 표현할 수 있는 언어를 정규 언어라고 한다\n\n저기 chomsky 다이어그램에서 regular language라고 돼있는 애들이 이거임\n\n\n표현력이 아주 제한적이다\n\n생각해보면 정규식은 {ab, aabb, aaabbb, aaaabbbb … }같은 애들을 검거하지 못한다\n\n\n따라서 거의 모든 프로그래밍 언어는 정규언어가 아니지만 Parser에서 정규식을 활용해 입력받은 문자열이 프로그래밍 언어의 syntax에 맞는지 확인한다\n정규식을 문자열 집합으로 표현해보면 이래된다\n\n\n\n정규식에서의 연산자 우선순위 → () &gt; 클레이니스타 &gt; 접합 &gt; 합집합\n\ns가 L에 속한다 §\n\n이 말인 즉슨 문자열 s가 언어집합 L의 원소이다 라는 말이다\n하지만 언어집합L은 무한집합이기 때문에 L의 모든 원소를 나열한 다음 문자열 s가 속하는지를 할 수는 없다\n\nFinite State Automata §\n\n오토마타는 추상기계, 그니까 어떠한 작업을 하는 기계를 머릿속에 상상하면 그놈을 automata라고 부른다\n그니까 FSA(Finite State Automata) 혹은 FA(Finite Automata) 는 유한한 동작 단계를 가지는 머릿속에 존재하는 기계하는 뜻이다\n\n상태를 기계가 작동하며 거치게 되는 단계들이라 생각하면 된다\n\n\nFSA는 다음과 같은 요소들로 구성되어 있다\n\nQ : 상태들의 집합이다. 즉, 기계가 작동하며 거치게 되는 모든 단계들을 모아놓은 것이다\nΣ : 알파벳. 가호들을 모아놓은 집합\nq : 시작 상태. 기계가 작동하기 전 초기의 단계라고 생각하면 될 것이다. 이것도 상태이므로 Q의 한 원소이다\nF : 종료 상태의 집합. 종료될때는 뭐 정상적으로 종료되었는지 아니면 뭐 ㅈ됐는지 등등 다양한 상태를 가질 수 있으므로 집합으로 표현된다. 이것도 마찬가지로 상채이므로 Q의 부분집합이 된다\nδ : 전이 함수 집합. 전이 함수라는 것은 어떤 경우에 다음 상태(단계)로 넘어가고 어떤 경우에 현재 상태(단계)에 머물러 있어야 되는지 등의 동작을 말한다\n\n\n이제 이 기계를 작동시켜 보자.\n\n어떤 문자열이 들어오고 이것이 언어에 속하는지를 판단하기 위한 FSA를 하나 만들었다고 해보자.\n일단 q의 상태로 시작할 것이다.\n그 이후 문자열의 첫번째 문자와 q상태를 전이함수에 넣어 상태를 하나 얻어낸다.\n그리고 또 그 다음 문자와 얻어낸 상태를 전이함수에 넣어 또 상태 하나를 얻어낸다.\n이렇게 문자열의 모든 문자를 훑고 나면 내 손에 최종 결과로 나온 상태가 하나 쥐어져 있을 것이다.\n이것이 종료상태F에 포함된다면 나는 이 문자열이 이 언어에 해당한다고 말할 수 있을 것이고, 그렇지 않다면 포함되지 않는다고 말할 수 있을 것이다.\n또한 작동하는 와중에 전이함수에 정의되지 않은 동작을 해야돼서 상태가 도출되지 않아도 이 언어에 포함되지 않는다고 말할 수 있다.\n\n\n\nLexical Analyzer (Lexer), Syntax Analyzer (Parser) §\n\n코드 한줄을 이 lexical analyzer(혹은 lever)를 통해 토큰으로 바꾸게 된다\nlexical analyzer(혹은 lexer) 는 정규식을 이용해 코드를 토큰들로 쪼개는*프로그램이다\n토큰은 뭐 OCaml에서의 let, fun같은 &lt;키워드&gt;나 =, +, (, )같은 &lt;기호&gt;(어휘항목이라고도 한다)들을 나타내는 하나의 자료형이다\n이 Lexer는 보통 Parser와 같이 동작한다\n\nParser가 토큰 하나를 요청하면 Lexer가 제네레이터마냥 토큰을 하나 던져주고 이런식으로 동작한다\n정규식에서의 ‘소비’개념때문에 제네레이터처럼 작동할 수 있는 것\n\n\n검거 실패했을 경우 syntax error가 발생한다\n\nlexer가 검거에 실패하면 parser가 에러를 판단하고 내보내기 때문\n\n\n"},"originals/pl.spring.2021.cse.cnu.ac.kr/06.-Syntax-Analyzer-(Parser,-구문분석기)":{"title":"06. Syntax Analyzer (Parser, 구문분석기)","links":[],"tags":[],"content":"\n\n                  \n                  충남대학교 컴퓨터공학과 이성호 교수님의 &quot;프로그래밍 언어 개론&quot; 강의를 필기한 내용입니다. \n                  \n                \n\n\n\n                  \n                  다소 잘못된 내용과 구어적 표현 이 포함되어 있을 수 있습니다. \n                  \n                \n\nLexer , Parser §\n\nLexer : 문자열 → 토큰\nParser : 토큰 → Abstract Syntax Tree(AST)\n\nContext Free Grammar(CFG)소개 §\n\n대부분은 이걸로 무한한 문자열 집합을 표현하며\n일부의 언어가 더 고급진 CSG(Context Sensitive Grammar)을 사용한다\n\n하지만 얘의 경우에는 많은 용량을 사용해 파서에게 부담을 안겨준다\n\n\nCFG는 정규표현식보다 더 많은 표현력을 가진다\n\n따라서 정규표현식으로 표현 가능한 문자열을 CFG로 표현 가능하지만 그 반대는 아니게 된다\n\n\n하지만 정규언어가 더 간결하기 때문에 lexer의 경우에는 정규식을 쓰고 parser에서는 정규언어로는 부족하기 때문에 CFG를 쓰는 것\n\nCFG 표현 §\n\n&lt;&gt; : 논 터미널 (다른 기호들로 치환되는 기호)\n\n경유지 같은 느낌\n\n\n→ : 치환이라는 의미\n\n좌측을 우측으로 바꿔치기할 수도 있고 우측을 좌측으로 바꿔치기 할 수도 있음\n\n\n| : or\n0, 1, E : 터미널 (다른 기호들로 치환되지 않는 기호)\n\n종착지같은 느낌\n\n\n\nCFG 수학적 표현 §\n\nΣ : 터미널들의 유한집합\nN : 논터미널의 유한집합\nP : 규칙의 집합\n\n‘ → ‘ 좌측의 논터미널을 우측의 터미널, 논터미널의 조합으로 치환 가능하다\n이때의 ‘ → ‘쌍을 규칙이라고 하는 것\n\n\nS : 시작 논터미널 (시작 기호)\n\n당연히 S는 N의 원소이다\n\n\n\nBackus-Naur form - CFG를 컴퓨터 내에서 기술하는 방법 §\n\n→ 를 ::= 로 기술함\n논터미널을 기술할때는 &lt;&gt;표기는 생략함\n=의 좌측은 무조건 논 터미널로 인식\n\nCFG로 문자열 만들기 - Derive §\n\n\n시작 논터미널로부터 시작해\n규칙에 따라 논터미널을 치환한다\n\n이 규칙에 따른 치환을 유도라고 한다\n\n\n그래서 더이상 치환할 논터미널이 없으면 그게 만들어낸 문자열이 된다\n유도는 =&gt;D 로 표현한다\n\n약간 치환되는 과정을 나타내는 것\n\n\n\n문자열을 CFG로 판별하기 §\n\n\n단순하다. 유도의 반대과정을 거치면 된다\n즉, 오른쪽을 왼쪽으로 치환하는 과정을 반복해서 시작 터미널이 나오면 CFG에 속한다고 표현할 수 있는 것\n이 반대과정은 기호로 =&gt;p로 표현한다\n\n유도(Derivation)의 반대는 파스(Parse)\n\n\n하지만 이 파싱의 알고리즘은 CFG에서는 제공하지 않는다 (형태만을 지정하므로)\nLL(k), LR(k)등의 알고리즘이 존재한다\n다행히도 파서 생성기가 존재한다 (CFG를 가지고 파서를 자동으로 만들어주는 놈)\n\nC언어에서 Bison같은놈이 이런 기능을 한다\n\n\n\nParse tree(Derivation tree) §\n\n이 유도/파스의 과정을 Tree 자료구조로 표현한 것이 Parse(Derivation) tree이다\n\n\n\n각 노드는 터미널 혹은 논터미널로 되어 있다\n루트 노드는 시작 논터미널이고 중단 노드는 논터미널, 리프 노드 만이 터미널이 된다\n부모와 인접한 자식들간의 관계는 좌측 논터미널과 우측 기호들 간의 관계와 일치한다 (자식이 많을 경우 하나하나 생각하는게 아니라 왼쪽 → 오른쪽으로 읽은 것이 우측 기호가 되는 것)\n리프 노드를 왼쪽 → 오른쪽으로 읽으면 유도된 문자열 이 나오게 되는 것\n트리를 거꾸로 읽으면 Parse의 과정 을 알게 되는 셈이다\n\n유도의 종류 §\n\n좌측 우선 유도(Leftmost derivation) : 왼쪽부터 차례로 유도해 나가는 것\n우측 우선 유도(Rightmost derivation) : 이번에는 오른쪽에서부터 차례로 유도해나가는 것\n근데 어떻게 유도하냐에 따라 Parse tree가 달라지고 이것은 결과적으로 AST에도 영향을 끼쳐 비효율적인 동작을 하게 될 수도 있다\n대신 유도 방법이 정해지면 항상 동일한 Parse tree가 나와야 한다\n\n만약에 여러개가 나온다면 문법을 잘못 정의한 것(모호하게 정의한 것)\n하나의 유도방법에는 하나의 Parse tree만\n\n\n문법의 모호성이 나오지 않게 신중하게 작성해야 한다\n\ntip : 좌측의 논터미널이 우측에 두번 이상 나오도록 치환규칙을 짜면 문제가 생기던데\n\n\n\nAST(Abstract Syntax Tree) §\n\n\nAST랑 Parse tree와는 다르다\nParse tree는 실제 문자열이 유도되는 모든 과정을 나타내는 개념적인 과정이고 (따라서 CFG가 있으면 Parse Tree를 유도해낼 수 있는거)\nAST는 parse tree에서 언어의 구조적(동작), 내용적(값) 구문 구조만을 포함시켜 우리가 정의한 규칙을 따른다\n\n어딘가에서 유도되는게 아니고 정의하는 것이여라\nParse tree를 가지고 우리가 단순화시켜서 정의하는 것이다\n\n\n따라서 Parser는 Parse tree를 반환하는게 아니고 AST로 반환한다\n이제 이 AST를 가지고 컴파일러나 인터프리터가 실행하게 된다\n"},"originals/pl.spring.2021.cse.cnu.ac.kr/07.-언어의-정의":{"title":"07. 언어의 정의","links":[],"tags":[],"content":"\n\n                  \n                  충남대학교 컴퓨터공학과 이성호 교수님의 &quot;프로그래밍 언어 개론&quot; 강의를 필기한 내용입니다. \n                  \n                \n\n\n\n                  \n                  다소 잘못된 내용과 구어적 표현 이 포함되어 있을 수 있습니다. \n                  \n                \n\nConcrete, Abstract syntax §\n\nConcrete syntax : 구체적 문법(우리가 사용)\n\nRE, CFG를 구체적 문법이라고 생각하면 된다\n\n\nAbstract syntax : 추상(요약) 구문(컴파일러가 사용)\n\nAST나 BNF(Backus-Naur form)으로 명시된 Abstract syntax를 의미한다\n\n\n\nAST §\n\n구문은 또 다른 구문들로 정의된다는 재귀적 특징은 트리에서 트리의 subtree 또한 트리라는 재귀적 특징과 닮아있으므로 프로그래밍 언어의 구문을 트리로 표현하는 것을 효과적이다\nAST를 쓰는 이유: 불필요한 문법적 디테일을 제거\n\n언어마다 다른 구체적 문법적인 것들을 배제하고 어떤 것들을 받아서 순수하게 어떤 동작을 하는지를 명시하는 것이 추상 문법이다\n뭐 함수를 선언할때 def를 쓸건지, function을 쓸건지 하는 것들은 세부적인 디테일이므로 언어와 독립적인 Abstract syntax를 정의하느데에는 필요 없기 때문\n또한 2 + 1, 02 + 001같은 의미는 같지만 형태만 다른 구제적 문법들을 별도로 정의할 이유가 없기 때문에\n\n\nAST의 경우에는 우리가 정의하는 것이기 때문에 구조가 하나로만 도출되는 Parse Tree와는 다르게 다양한 구조를 가질 수 있다\n\n수업에서 Abstract Syntax를 정의한 방식 §\n\nAST : 부모노드에 얘가 어떤 연산인지를 적어주고, 자식노드에 어떤 인자들이 연산되는 지를 적어주는 식으로 트리를 구성했다\nBNF AS : Abstract Syntax를 BNF로 기술한 것이다.\n\n\n\n(e ::= n) 은 AST (Num - n)와 같다\n(e ::= e + e) 은 AST (Add - e e)와 같다\n(e ::= e - e) 은 AST (Sub - e e)와 같다\n저 표현은 이 세개의 트리를 합쳐놓은 것과 같은 표현이 되며 각각의 트리를 Langauge construct라고 한다\n\nAST 정의 수업에서의 예시 - 언어 AE 기술하기 §\n\n언어 AE는 Arithmetic Expression, 즉, 정수의 합과 차를 표현하는 언어이다\n집합 E는 언어 AE의 모든 AST의 집합이다\nn이 정수일때, 이 정수는 Num이라는 parent node를 가진다\n\nNum은 AE의 숫자를 표현 하는 노드\n\n\n또한 Add노드도 두개의 E의 원소를 자식으로 받는 AE의 덧셈을 표현 하는 노드이다\nSub도 마찬가지로 AE의 뺄셈을 나타내는 노드 이다\n트리를 보면 아래서부터 위로 연산이 되므로 연산의 우선순위를 나타내는 괄호는 이런 상하관계를 시용하면 표현할 수 있다\n매번 트리를 그리기는 귀찮으므로 이것을 코드 형식으로 표기할 수도 있다\n\n’n’은 Num 트리를 가리키고 ‘e1 + e2’는 Add트리, ‘e1 - e2’는 Sub트리를 나타낸다.\n여기서 +와 -는 연산자가 아니라 그냥 기호일 뿐 이다\n\n이제 코드 표기법과 BNF표기법을 이용해 트리를 표기할 예정이랜다\n이 코드 표기법에서는 트리의 상하관계 즉, 우선순위를 나타낼 때 괄호를 사용하는 것도 암묵적으로 허용한댄다\n\n\n\n\n이때의 n, e1, e2를 metavariable(고차원 변수) 라고 한다\n\n실제 프로그래밍 언어에서의 변수와는 다르게 정의된 어떤것으로든 치환될 수 있는 것?\n뭔지 감만 오제?\n\n\n\nSemantics §\n\n프로그래밍 언어의 Semantics : 이 프로그래밍 언어는 어떻게 계산, 실행되는지\n해당 프로그래밍 언어로 구현된 모든 프로그램의 실행시 행동을 정의?\n프로그램적 Semantics : 이 프로그램은 어떻게 계산, 실행되는지\n약간 이런 느낌인거 같다 : 프로그래밍 언어의 Semantics는 더 포괄적인 실행을 의미하는 거고 프로그램의 Semantics는 약간 해당 프로그래밍 언어로 표현된 하나의 코드 예시? 가 어떻게 실행되는지\n이 프로그램적 Semantics는 언어적 Semantics에 기반을 두게 된다\n아닌가\n\n프로그래밍 언어의 Semantics §\n\nAST를 기반으로 한다\n\n불필요한 문법적 디테일을 무시할 수 있고, AST의 각 구문별로 의미를 정의할 수 있으므로\nAST하나당 하나의 대응되는 Sementics를 정의한다는 말이다\n\n\n\n수학적 Semantics 정의 §\n\nSemantics가 자연어로 정의되면 읽는 사람마다 다르게 받아들이는 모호성을 야기할 수 있으므로 이것을 수학적으로 표현해야 한다\n\nBinary relation을 이용한 수학적 정의 §\n\nbinary relation은 걍 단순하게 생각해서 (키, 벨류)로 표현되는 키-벨류 쌍이라고 생각하면 된다\n\n집합 A의 원소를 키로 하고 집합 B의 원소를 벨류로 할 때 이것으로 만들 수 있는 모든 키-벨류 쌍의 집합을 AXB라고 한다\nAXB의 부분집합 R에 대해 이 R을 키-벨류간의 관계를 나타내는 기호라고 한다면\naRb라는 것은 “a가 A의 원소이고 b가 B의 원소이고 (a, b)쌍도 R의 원소이다”라는 것으로 정의할 수 있다\n걍 뭔소린지 모르겠으면 aRb라는 것은 a와 b의 관계가 R이다라고 생각해도 된다\n\n\n피피티에서 아랫쪽 화살표는 “좌항이 우항으로 계산된다”라는 의미로 받아들이면 된다\n\nInference Rule도 이용하기 §\n\nInference Rule : 분자에는 전제를 쓰고 분모에는 결론을 쓰는 형태의 기호\n분자의 전제가 전부 참이라는 전제 하에 분모가 참이 된다\n\nBig / Small step, Operational §\n\n프로그램의 계산을 중간단계를 다 생략하고 초기상태와 결과만 나타내는 것을 Bigstep이라고 한다\n반면에 중간단계를 생략하지 않은 계산법을 Smallstep이라고 한다\n이 계산을 머릿속에 존재하는 계산기가 계산해주는걸로 생각하고 표현하는 것을 Operational이라고 한다\nㅅㅂ small step이랑 orerational차이는 모르곘는데 시험에 나오면 그냥 operational이라고 쓰자\n\nProof tree §\n\n어떤 것의 증명 과정을 Inference rule을 이용하여 표현한 하나의 자료구조이다\n결론을 root로 그것의 전제를 차례로 파고들면서 더 이상 증명할 게 없을 때까지 파고드는 것이다\n부모노드와 자식노드는 inference rule로 연결하고 따라서 자식노드가 모두 참이면 부모노드도 참이 되는 구조를 가지게 된다\n일반적인 트리와 비슷하지만 root가 맨 아래에 위치하고 부모-자식 간 관계가 전제와 결론의 관계라는 특징을 가진다\n"},"originals/pl.spring.2021.cse.cnu.ac.kr/08.-문법적-설탕과-식별자":{"title":"08. 문법적 설탕과 식별자","links":[],"tags":[],"content":"\n\n                  \n                  충남대학교 컴퓨터공학과 이성호 교수님의 &quot;프로그래밍 언어 개론&quot; 강의를 필기한 내용입니다. \n                  \n                \n\n\n\n                  \n                  다소 잘못된 내용과 구어적 표현 이 포함되어 있을 수 있습니다. \n                  \n                \n\n언어의 확장 과정 §\n\nConcrete syntax의 확장\nAbstract syntax의 확장\nParser의 확장(CS → AS로 바꿔주는놈이 parser이므로)\nSemantics 확장(Abstract Syntax가 확장되었으므로)\nInterpreter 수정(AS → 기계어)\n\n\n컴파일 언어의 경우 더 많은 확장 단계를 가지게 된다\n\nSyntactic Sugar §\n\nConcrete syntax를 확장하되 확장된 구문을 기존의 Abstract syntax에 대응시키는 기법을 말함\nCS를 확장하므로 CS와 CS를 사용하는 parser는 확장해야 되지만 AS나 semantics 등은 확장하지 않아도 된다\nparser가 이 설탕쳐진 구문(확장된 CS)에서 설탕을 빼는 과정(기존의 CS로 변환하여 기존의 AS로 변환하는 과정)을 Desugaring이라고 한다\n하나의 AS에 대응되는 CS가 여러개가 되는 셈인거다\n\n따라서 CS를 하나 정의하고 그것을 기존의 AS에 대응만 시켜주면 되는 셈\n\n\n\nIdentifiers §\n\nIdentifier(식별자) : 함수, 변수, 프로퍼티, 메소드, 클래스들에 붙이는 이름을 식별자라 한다\n\nOccurrence of Identifier §\n\nOccurrence of Identifiers : 하나의 식별자는 프로그램에 여러번 등장할 수 있다는 개념\n\n등장의 종류 §\n\nBinding Occurrence : 식별자의 정의를 위한 등장\nBound Occurrence : 정의된 식별자를 사용하기 위한 등장\nFree Occurrence : 정의되지 않은 식별자를 사용하기 위한 등장\n\nScope of Identifier §\n\nBinding된 놈이 Bound될 수 있는 범위\n따라서 bind되어도 scope를 넘어가면 free identifier가 된다\nShadowing : 동일한 이름을 가진 식별자들의 scope가 겹치는 경우 bound했을 때 가장 가까운(가장 안쪽의, 가장 지협적인) scope를 따라가게 된다\n\n가장 가까운 놈이 먼 놈을 가린다는 의미에서 shadowing이라고 하는 것\n\n\n\nStore §\n\n요기 나오는 내용은 전부 언어 AE를 위해 수업에서 임의로 정의한 것이다\n\n개념은 통용되지만 용어나 구체적인 내용들은 수업용임\n\n\nStore : 가상 저장공간들의 집합\n\n가상 저장공간이라는 것은 변수를 받아 정수를 돌려주는 하나의 함수라고도 표현할 수 있다 (변수를 이용해 그 정수에 접근하는 것 이므로)\n근데 함수는 딕셔너리와도 유사하다(키를 이용해 벨류를 반환하므로)\n따라서 가상 저장공간은 변수를 받아 정수를 반환하는 딕셔너리라고도 생각할 수 있다\n가상메모리 = 변수이름을 받아 값을 돌려주는 함수 = 변수이름을 키로 받아 매핑된 값을 돌려주는 딕셔너리\n\n\n가상 저장공간 집합 Store는 변수를 받아 정수로 돌려주는 모든 함수(딕셔너리)들의 집합이다\n시그마 는 Store의 원소이다. 즉, 임의의 한 가상 저장공간(함수, 딕셔너리)이라는 말이다\n시그마[x → n] : 변수 x를 선언하고 n으로 초기화 하는 것(binding)\n\n즉, x를 받으면 n을 반환하는 규칙을 새로 함수에 추가하는 것\n즉, 키x와 값n을 딕셔너리에 추가하는 것\n선언, 초기화 후 업데이트된 시그마를 반환\n\n\n시그마(x) : 변수 x의 값(n)을 찾아 반환 하는 것(bounding)\n추상메모리 ~에서 라는 말의 말뜻 : 이게 말이 좀 어려울 수 있는데 그냥 이런뜻이다\n\ne에서 변수가 등장하지 않으면 이 메모리를 사용하지 않아도 되니까 추상메모리에서 라는 말은 별 의미없는 말이다.\n근데 e에서 변수가 등장한다면 이 변수를 정수로 고치는 바꾸는 것은 저 추상메모리에 정의된 규칙을 따른다는 소리이다\n\n\nternary relation : 말뜻은 뭔지 모르게땅\n\n이것의 기호는 ㅏ 이고 계산 문맥을 표현한다\n즉, EC ㅏ p 는 EC라는 규칙 하에 p가 참이라는 소리이다\n전제랑 문맥의 차이점은 이거다\n\n어떤 연산을 하기 위해 반드시 참으로 규명나야 되는 것은 전제로 들어간다.\n하지만 연산을 하기 위해 이용할 수도 있고 아닐수도 잇는 것은 문맥으로 들어간다?\n\n\n\n\n따라서 해당 추상메모리에서 표현식e를 계산했더니 정수n이 나왔다면 이 관계는 (추상메모리) ㅏ \\[(표현식e) 아래화살표 (정수n)\\] 로 말할 수 있는 것이다\n\n수업에서는 대괄호를 안쳐줬지만 생략된 것이므로 해당 추상메모리 하에서 “표현식 e는 정수 n으로 계산됨”은 참이라는 것을 뜻한다\n\n\n"},"originals/pl.spring.2021.cse.cnu.ac.kr/09.-함수와-함수호출":{"title":"09. 함수와 함수호출","links":[],"tags":[],"content":"\n\n                  \n                  충남대학교 컴퓨터공학과 이성호 교수님의 &quot;프로그래밍 언어 개론&quot; 강의를 필기한 내용입니다. \n                  \n                \n\n\n\n                  \n                  다소 잘못된 내용과 구어적 표현 이 포함되어 있을 수 있습니다. \n                  \n                \n\n수학에서의 함수와 차이점 §\n\n공통점 : 값을 전달하면 결과를 반환한다는 것\n차이점 : 수학에서는 함수를 정의하면 그 함수에 동일한 값을 전달하면 항상 동일한 값을 반환하지만 프로그램에서는 부작용이 있을 수 있어 같은 값을 전달해도 다른값을 반환할 수 있다\n\n부작용을 예로 들면 전역변수를 사용할 때 전역변수의 값에 따라 다른값을 반환 가능\n\n\n\nHigh order, First order §\n\n서로 반대의 개념\nFirst-order function : c언어에서처럼 함수를 인자로 받지도 못하고 함수를 반환하지도 못하는 특성\n\n함수를 객체 / 변수와 별도로 취급함\nSecond-class citizen이라고도 한다\n변수와 별도로 취급하기 때문에 변수를 저장하는 추상 메모리와 별도로 추가로 함수를 저장할 추상 메모리가 필요함\n\n\nHigh-order function : 함수형 기능을 지원하는 언어처럼 함수를 하나의 객체로 취급해 인자로 받을 수 있고 함수를 반환하는것도 가능\n\nF1VAE §\n\nfirst-order를 지원하는 함수 정의문 하나와 그 뒤에 표현식 이 나오는 예시언어\nfirst-order이기 때문에 함수를 저장할 별도의 메모리가 필요한데 그 함수 메모리의 집합을 FunDef 라고 정의\n\nFunDef의 원소는 함수이름(Var)를 키로 받고 (매개변수(Var) * 몸체 표현식(E)) 튜플을 벨류로 한다\n\n\nFunDef의 한 원소를 람다 라고 지칭\n람다(x) : 함수 이름(x)를 키로 조회해 매개변수와 몸체 표현식 튜플을 반환\n람다[x1 - &gt; (x2, e)] : 함수 이름(x1)을 키로 하고 매개변수(x2)와 몸체표현식(e) 튜플을 벨류로 하는 키 - 벨류 쌍을 추가하여 업데이트한 새 메모리를 반환\np 아래화살표P n : 프로그램 p는 정수 n으로 계산된다는 뜻 - (P, Z)튜플\nd 아래화살표D 람다 : 함수정의d는 그 함수를 저장한 람다로 계산된다는 뜻 - (D, FunDef) 튜플\n람다, 시그마 ㅏ e 아래화살표E n : 람다와 시그마를 이용해 e를 계산했을때 n이 나옴 - (FunDef, Store, E, Z)튜플\n\n참고) 저 튜플 ㅅㅂ 아직도 잘 이해가 안되는데 이전까지 사용하던 아래화살표가 (Store, E, Z)튜플인 것을 이용해 잘 이해해봐라\n\n\n\n함수의 호출 §\n접근1 - 치환(Substitution) §\n\n\ne[n / x] 라는 것은 e에 나오는 모든 x를 n으로 치환한다는 뜻이다\n다만 여기서 치환하는 대상은 파라미터를 bound 하는 애들 (파라미터에 대해 bound occurrence한 애들) 이다\n\n즉, 함수의 몸체(e)안에 매개변수랑 동일한 이름으로 bind occurrence가 이루어지면 그 이후부터는 전부 shadowing되기 때문에 치환하면 안된다\nshadowing이 된 값이 변수의 값으로 매핑되어야 되는데 인자의 값이 변수의 매핑되게 되어 문제가 생긴다\n\n\n\n\n\n결과는 이렇게 나온다 - 여기서 중요한 점은 치환이기 때문에 e1을 계산할 때는 어떠한 메모리도 참조하지 않는다는 것이 중요하더라\n\n접근2 - 가상 메모리 사용(Using Store) §\n\n\n일반적으로 우리가 프로그램에서 함수가 동작하는 과정 - 매개변수도 변수니까 매개변수와 그의 값을 가상메모리(Store)에 업데이트시켜서 그 가상메모리로 계산을 하자\n\n\n\n그에대한 결과다 - 여기서 또 중요한 점은 기존 e를 계산할때 사용한 가상메모리와 e1을 계산할때 사용한 메모리는 다르다는 점이다\n\n새로운 메모리가 생성되어 매개변수가 드감\n\n\n\nScope §\n\n보통 언어는 이 둘중 하나의 scope개념을 가지고 설계된다\nLexical(Static) scope : 컴파일 시점에 스코프가 정해짐\nDynamic scope : 실행시점에 스코프가 정해짐\n\n컴파일 시점이라는 것은 보통 한눈에 보면 어디까지가 볌위인지 알 수 있지만 실행시점이면 범위가 어디까지인지 한눈에 알기 힘듦\n예시 - 함수 외부에서 binding된 변수가 함수 내부에서도 bound가 가능한 언어의 경우\n\n\n위에서 가상 메모리를 사용한 함수의 호출에서 매개변수의 값을 계산할때와 함수의 몸체를 계산할때 별도의 메모리를 사용하는 것은 이 언어가 Lexical scope이기 때문인거다\n\n일반적인 Lexical scope에서는 함수의 내부로 외부변수가 들어오지 않기 때문\n따라서 Dynamic scope에서는 함수 외부의 변수가 내부로 들어오기 때문에 별도의 메모리를 사용하지 않는다\n\n\n\n\n\nDynamic으로 설계했을 때의 모습이다. 보다시피 e1을 계산할때 메모리가 그냥 [] 이 아니고 시그마가 붙어있는걸 알 수 있다\n졸라 강조하는거 보니 이 둘 개념 시험에 나오겠다 - 그리고 Substitution의 경우에도 Lexical과 Dynamic의 두가지로 모두 설계할 수 있다고 강조하는 거 보니 이거 저거 두개로 치환 구현하는거 시험에 나온다\n\nList of Function §\n\n위에서는 함수가 반드시 하나만 나와야되는 언어를 정의했다 (없어도 안되고 2개이상이도 안됨)\n따라서 이걸 0개 이상의 함수를 지원하는 언어로 바꾸면 다음과 같다\n\n\n\n\n보면 d위에 언더바가 있는데 걍 0개 이상이라는 의미란다\n\n\n\n원래는 (D, FunDef)였는데 (FunDef, D, FunDef)로 바꿈\n\n보면 마지막줄에 기존의 람다에서 새로운 함수선언 d를 추가한 새로운 람다로 계산되는 것을 알 수 있다\n\n\n\n\n\n그리고 이렇게 바꿀 수 있다\n\n\n\n이거 여러번 연습할 것!! - 뒤에 있는 예제도 함께 - ㅈㄴ강조한다 이새끼\n\nList of Parameters §\n\n\n요래 바꾼다\n\n\n\n빨간부분이 바뀐거랜다 - 이제는 매개변수가 Var하나가 아니라 VarList인 것\n\n\n\n저 동그라미부분이 바뀐것으로 저기만 수정해주면 된다\n시험공부할때 예제 다 꼼꼼히 해보면서 막히면 강의 참고해라 - 강의뒷쪽에 많이 나온다\n"},"originals/pl.spring.2021.cse.cnu.ac.kr/10.-1등-시민-함수":{"title":"10. 1등 시민 함수","links":[],"tags":[],"content":"\n\n                  \n                  충남대학교 컴퓨터공학과 이성호 교수님의 &quot;프로그래밍 언어 개론&quot; 강의를 필기한 내용입니다. \n                  \n                \n\n\n\n                  \n                  다소 잘못된 내용과 구어적 표현 이 포함되어 있을 수 있습니다. \n                  \n                \n\nFirst-class Function §\n\n함수를 값으로 취급해 변수에 저장하거나 인자로 저장, 반환값 등으로 사용할 수 있는 것\n\nFVAE §\n\n일단 이름이 없는 함수(람다마냥)만 정의\n그리고 Syntactic sugar를 이용해 이름이 있는 함수도 정의\n\nConcrete Syntax §\n\n\n(fun var → expr) 가 무명함수를 선언하는 부분\nexpr’ expr’ 가 함수를 호출하는 부분\n\nAbstract Syntax §\n\n\n람다x.e 가 무명함수를 선언한다는 소리이고\n\n저걸 lambda abstraction 라고 하고 더하기 빼기처럼 하나의 연산기호이다\n파이썬에서 [lambda 매개변수 : 몸체] 이렇게 무명함수를 정의하는 것이 여기에서 착안한 아이디어이다\n\n\n\n\n\n이런 AST로 나타내짐\n당연히 x는 binding occurence이고 그의 scope는 e이다\ne e 로 함수를 호출하는 것\n\n\n\n이런 AST를 가짐\n\n값의 domain §\n\n이전까지는 정수만 ‘값’이 될 수 있지만\n이제는 함수도 ‘값’이기 때문에 값의 범위를 확장시켜줘야 한다\n그래서 이젠 값(Value) = 정수(Z) +D Closure로 정의됨\n여기서 Closure라는 것은 (매개변수, 몸체, 함수 정의시점의 Store) 튜플 을 의미하는데 함수 정의시점의 Store도 갖고있는 이유는 Lexical scope에서도 전역변수의 scope는 함수 내부까지 들어오기 때문 이다\n\n하지만 Lexical scope이기 때문에 전역변수가 아닌 외부의 지역변수는 내부에 들어오지 못한다\n\n\n그리고 +D연산자는 도메인 간의 합 을 나타내며 ocaml에서 disjoint union과 동일하고 이 수업에서 정의한(통용되지 않는)연산자다 (합집합)\n그리고 Value의 원소는 v, 정수(Z)의 원소는 n, Closure의 원소는 &lt;ㅅx.e, 시그마&gt; 로 표현한댄다\n또한 이제 스토어에 저장되는 값이 정수가 아니라 값이기 때문에 기존의 정수만 저장하는 체제에서 수정해야 한다\n\n\n\n요래 바뀌드라\n근데 저 and라는 놈은 OCaml에서 상호참조 를 지원해주기 위해 존재한다\n\n저거를 나눠서 type 두개로 쪼갤 수 있지만 그렇게 하면 아래에서는 위의 타입을 사용할 수 있지만 위에서는 아래놈이 아직 선언되지 않은놈이기 때문에 참조할 수가 없음\n따라서 이때에는 저 and를 사용해준다\n\n\nvalue는 스토어 t를 사용하고 t는 value를 사용하기 때문에 상호참조인데 그렇기 때문에 저 and를 사용해야 되는 거고 또한 Store.ml에 저장해야 되는 것\n\n만약에 다른 파일에 선언하게 되면 순환참조(Circular Dependency), 즉, 서로가 서로를 참조해 그 loop를 빠져나오지 못하고 서로 계속 참조해 컴파일이 불가능한 경우가 발생한다\n\n\n\nSemantic Relation §\n\n\n아래화살표 P는 프로그램p가 값v로 계산된다 는 의미\nv는 이제 정수뿐만이 아니라 함수도 포함하는걸로 확장된다\n\n\n\n아래화살표E는 표현식e가 값v로 계산된다 는 의미\n마찬가지로 정수뿐만아니라 함수까지 포함하는 v로 확장됨\n저 아래화살표 사용할때 양쪽의 자료형 주의해야된다\n\n그냥 계산된다고 아래화살표가 아니라 그 자료형으로 계산될때를 말하는거임\n기말에서는 다 틀리게 할 거랜다\n\n\n\nBigstep Operational Semantics §\n\n\n이제 프로그램의 결과는 정수 n이 아니라 값v로 확장됨\n\n\n\ne를 계산할 결과가 정수 n이어야 한다 : 함수 &lt;ㅅx.e, 시그마&gt; 라면 함수끼리의 덧셈은 존재하지 않기 때문\n\n결과가 함수라면 Runtime error를 발생시킨다\n\n따라서 Add할때 화살표 옆에다가 v쓰면 안된다!!\n\n\n\n\n뭔가 문제가 생겼을 때 인터프리터 입장에서는 exception인거고 프로그램 입장에서는 runtime error이다\n\n둘이 다른것!!\n\n\n\n\n\nLetIn의 경우에도 정수 n에서 값v을 지원하는 것으로 확장된다\nadd나 sub과는 다르게 계산의 결과가 함수여도 된다는 것 에 주의할 것\n\n\n\n무명함수의 선언은 위와 같다\n\n현재의 시그마에서 저런 함수 정의문이 나오면 (매개변수, 몸체, 시그마)의 튜플로 계산 이 되는 것\n\n\n함수의 적용(apply)는 그 아래와 같다\n\n현재의 시그마에서 e1이 (x, e3, 시그마’)으로 계산이 되고 e2가 v1으로 계산되며 x가 v1으로 계산되는 새로운 시그마(매개변수의 값이 업데이트된 새로운 시그마)에서 e3을 계산한 결과가 v2이면 e1 e2는 v2로 계산이 되는 것\n\n\n여기서 중요한 것은 시그마가 시그마’으로 바뀌는 건데 이는 함수 선언 시점에의 시그마 이기 때문에 그렇다\n\n\n\n여기서 보면 첫번째 foo에서는 빈 메모리가 튜플의 세번째 원소로 들어가는 반면에 두번째 bar에서는 foo가 추가된 메모리가 튜플의 세번째 뭔소로 들어가는 것을 알 수 있다\nproof tree 시험에 반드시 낸댄다 → semantics 옆에 두고 같이 보면서 pdf예시들 다 그려봐야 된다\n\n\n\n이거 화살표 따라 가면서 이해하고 proof tree까지 다 그려보고 모르겟으면 강의 50분경 확인해라\n\n\n\n여기서 &lt;ㅅy.y+2, []&gt; 가 아니라 &lt;ㅅy.y+x, [x → 2]&gt; 인 이유는 저 ㅅy.y+x 가 선언될 당시에는 매개변수x에 2가 매핑되기 때문에 x → 2가 선언될 당시에의 시그마 이므로 저래되는거다\n이 예시 시험에 나올거같다\n\nLexical scope vs Dynamic scope §\n\n\n이 예시 proof tree그려서 꼼꼼하게 분석해라\n그냥 시그마냐 시그마’냐 구별 잘해야 된다\n\nSyntactic sugar를 이용한 Named function의 지원 §\n\nSyntactic sugar이기 때문에 AST는 수정할 필요 없이 Concrete syntax와 parser만 수정하면 된다\n\nSyntactic sugar를 이용한 Multiple parameter의 지원 §\n\n여러개의 인자를 받는 함수를 syntactic sugar로 표현하는 것은 curried form 을 이용하면 된다\n인자 하나를 넣고 함수 반환하고 또 그거에 인자 하나 더 넣고 또 함수 반환하고 이런식으로 연쇄적으로 계산해서 모든 인자에 대해 계산하는 것\n\nSyntactic sugar를 이용한 LetIn의 지원 §\n\n\n이런식으로 할 수도 있다!\nin뒤에 나오는 놈이 제일 나중에 연산된다는 것과 함수의 몸체는 제일 나중에 연산된다는 것에 착안해 in뒤에있는놈을 함수의 몸체로 두고, LetIn의 변수명을 매개변수명으로 하고 이 함수를 e1에 대해 apply되게 해 자연스레 e1의 결과가 매개변수에 들어가고 그것으로 e2를 계산하는 동일한 흐름이 완성된다\n\nFunction Application §\n\n함수형 프로그래밍에서는 function call 대신 function application라고 부른다\n뭔말인고 하니 함수형이 아닌 언어에서는 ‘함수 f가 인자 x로 호출된다’라고 표현되지만 함수형 언어에서는 함수 f가 인자 x에 apply된다이렇게 표현한다\n함수형 언어가 아닌 언어에서는 그냥 함수에 인자를 넣어서 호출하는거지만 함수형 언어에서는 함수 또한 값이기 때문에 호출이라는 말을 안쓰고 인자에 apply된다 라는 말을 쓰는 것\n\n어떤 값에 적용된다? 정도로 생각하면 될듯\n\n\n\n함수형 언어는 정의가 간결하다 §\n\n함수를 값으로 취급하는 것은 매우 강력한 기능이며\n함수와 그의 적용으로 대부분의 동적을 수행할 수 있다\n\n따라서 AST, semantics, interpreter를 모두 간결하게 짤 수 있음\n\n\n하지만 이 모든것들을 그냥 냅둔다면 프로그래머는 이 모든 기능을 함수와 그의 적용으로만 구현해서 사용해야 되기 때문에 Syntactic sugar를 이용해 표현력을 확장시킨다\n즉, 프로그래머가 Syntactic sugar을 이용한 표현을 쓰면 그것을 함수와 그의 적용으로 인터프리터가 바꿔서(Desugaring) 인터프리트 하는 기법을 사용\n"},"originals/pl.spring.2021.cse.cnu.ac.kr/11.-조건분기문":{"title":"11. 조건분기문","links":[],"tags":[],"content":"\n\n                  \n                  충남대학교 컴퓨터공학과 이성호 교수님의 &quot;프로그래밍 언어 개론&quot; 강의를 필기한 내용입니다. \n                  \n                \n\n\n\n                  \n                  다소 잘못된 내용과 구어적 표현 이 포함되어 있을 수 있습니다. \n                  \n                \n\nExpression vs Statement §\n\n얘네 둘의 구분은 언어마다 다르다\n다만 보편적으로는 결과값이 나오는 코드 조각을 Expression이라고 하고 값으로 계산되지 않고 프로그램의 상태가 전이되는 코드 조각을 Statement라고 한다\n\n당연히 Expression의 경우에는 상태가 전이되지 않것제?\n대부분의 함수형 언어는 Expression만 지원하고\nc언어같은 imperative언어는 Statement도 지원한다\n그리고 자바스크립트같은 애들은 함수형도 지원하고 imperative도 지원하기 때문에 둘 다 지원함\n\n\n여기서 상태가 전이된다는 것은 변수에 값을 추가하는 것 처럼 추상메모리가 변화하는 것 을 의미한다\n분기문의 경우 값이 계산되지 않기 때문에 statement이다. 다만, 삼항연산자의 경우에는 값이 계산되기 때문에 분기문의 expression 버전이다\n\nCFVAE §\n\nFVAE에 분기문을 추가한 버젼\n수업에서는 오른쪽화살표S 가 statement를 나타내며 (구 store, expression, 업데이트된 store) 의 튜플 과 같다\n그리고 얘는 함수형 언어이기 때문에 분기문도 expression으로 지원 한다. 즉, 분기문이 참일때의 값과 거짓일때의 값으로 계산된다는 것 이다\n\nConcrete Syntax §\n\n\n분기문 if then else와\n조건식 &lt;\n그리고 boolean값인 “true”, “false”를 추가함\n\nAbstract Syntax §\n\n\nboolean값을 나타내는 b\n분기문을 의미하는 e ? e : e (당연히 AST이기 때문에 삼항연산자를 나타내는건 아니다)\n그리고 조건을 나타내는 &lt; 가 추가된다\n\nValue §\n\n\n조건식을 계산한 결과인 boolean값이 추가되었으므로 Value의 범위를 확장해준다\n\nBigstep Operational Sementics §\n\n\n뭐 별거 없다\n정수간의 연산이랑 별다를거없음\n당연히 &lt;의 경우 e의 계산값이 정수가 아니라면 런타임 에러가 난다\n\n\n\ne1의 계산결과가 참이냐 거짓이냐에 따라서 계산결과가 e2의 결과(참일 경우), e3의 결과(거짓일 경우)로 나뉘기 때문에 두개의 rule로 정의를 한 것\n마찬가지로 e1의 결과가 boolean이 아닌 경우에는 런타임 에러가 나는 것\n\nSyntactic sugar §\n\nboolean을 syntactic sugar를 이용해 0, 1로 표현하거나 0이아닌 정수, 0으로 표현하는 것도 가능 하다\n\n\n\n위의 분기문이 C언어 스타일로 바꾼 것\n\n0이 아닐때는 참으로 계산, 0일때는 거짓으로 계산된다\n\n\n또한 boolean, 분기문을 함수로 표현하는것도 가능하다\n\n참인 경우에는 인자 x, y를 받아 x를 돌려주는 함수로 표현, 거짓인 경우에는 인자로 x, y를 받아 y를 반환하는 함수로 표현\n따라서 e1 ? e2 : e3 의 분기문을 e1 e2 e3의 function application으로 표현할 수도 있다\n\n\n참과 거짓이 함수로 표현되므로 아래처럼 표현할 수 있다\n\n\n\n&lt;의 결과가 함수로 나오므로\ne1 ? e2 : e3 의 경우에는 e1의 결과가 함수가 되어 인자인 e2, e3의 결과값에 e1의 결과인 함수를 application하는 것으로 처리하는 것이 가능하다\n\nBoolean in Syntactic Sugar §\n\nboolean값을 값의 도메인을 확장하지 않고 표현하기\nC언어 스타일 : 0과 1로 표현\n함수형 언어의 스타일 : 참인 경우에는 인자 x, y를 받아 x를 돌려주는 함수로 표현, 거짓인 경우에는 인자로 x, y를 받아 y를 반환하는 함수로 표현\n"},"originals/pl.spring.2021.cse.cnu.ac.kr/12.-재귀함수":{"title":"12. 재귀함수","links":[],"tags":[],"content":"\n\n                  \n                  충남대학교 컴퓨터공학과 이성호 교수님의 &quot;프로그래밍 언어 개론&quot; 강의를 필기한 내용입니다. \n                  \n                \n\n\n\n                  \n                  다소 잘못된 내용과 구어적 표현 이 포함되어 있을 수 있습니다. \n                  \n                \n\n직간접 호출 §\n\n직접호출(Direct Recursion) : 함수 A가 자기자신인 A를 다시 호출하는것\n간접호출(Indirect Recursion) : 함수 A가 일단 다른 함수 B를 먼저 호출하고 그 함수 B가 A를 호출하는것\n\nRCFVAE §\n\nRCFVAE는 함수 재귀호출을 지원하는 언어이다\n원래 CFVAE에서는 &lt;ㅅx.e, 시그마&gt; 에서 함수 몸체를 계산하는데 필요한 추상메모리가 시그마인데 함수선언시에 이 시그마에 자기자신 함수가 들어있지 않기 때문에 자기자신을 재귀호출할 경우 자기자신은 Free Identifier로 분류되어 Runtime error가 나게 된다\n\nConcrete Syntax §\n\n\n일반적인 함수 호출을 지원하는 let fun in구문과 별도로 let rec fun in 구문을 concrete syntax에 추가했다\n\nAbstract Syntax §\n\n\n여기에도 마찬가지로 let rec x = e in e 추상문법과 그것을 나타내는 AST를 추가하였다\n\nBigstep Operational Semantics §\n\n\n위에꺼가 기존의 일반함수 선언법, 아래꺼가 재귀함수 선언법이다\n일단 재귀함수 호출법에서는 e1을 계산한 결과가 Closure이어야만 하고 그렇지 않은 경우에는 Runtime error를 출력해야 한다\n일단 저 시그마 프라임은 전에 함수를 정의할때처럼 스코프가 함수 내부인, 함수의 몸체를 계산할때 쓰이는 추상메모리 이고\n시그마 투프라임은 재귀함수 호출 구조를 그대로 생각하면 된다\n\n재귀함수를 정의할 때에 안에 자기자신이 들어가듯이 시그마 투프라임을 정의할 때도 자기자신을 이용하여 재귀적으로 정의한 것\n\n\n시그마 투프라임 없이 시그마 프라임 하나로만 정의하면 재귀가 한번밖에 돌지 못하는 구조가 된다?\n\n시그마 투프라임이 없는 경우를 생각해보고 왜 안되는지를 생각할것\n\n\n\n\n\n이 예시를 보면\n\n일단 저기 빨간글씨 (-1 &lt; x)는 오타인거같고\n시그마 = [sum = &lt;ㅅx.(x&lt;1) 0 (x+(sum(x-1))), 시그마&gt;]의 말뜻은 함수 정의시 시그마에 ”sum = Closure” 를 추가한 시그마를 함수 몸체를 계산할때도 사용하겠다 의 의미가 되는 것이다\n\n\n\nOCaml Code §\n1. 시그마 투프라임을 그대로 정의해보기 §\n\n\n위처럼 정의하게 되면 우측(RHS - Right Hand Side)의 s’’은 아직 Free Identifier이기 때문에 에러가 난다\n\n2. Rec 키워드 이용해보기 §\n\nOCaml에서 함수를 정의할 때 “let 함수이름 인자 = 몸체 in”은 “let 함수이름 = fun 인자 몸체 in”의 Syntactic sugar 이기 때문에 “let rec 무언가 = 무언가 in”도 지원한다는 것을 알 수 있다\n\n\n\n근데 위처럼 정의하면 에러가 난다\n\nrec 키워드를 사용할때는 조건이 붙기 때문\n\n일단 RHS가 함수의 정의이고 그 함수의 몸체에서 재귀호출을 하거나\nRHS가 Disjoint Union의 Constructor이고 그의 인자로 재귀호출되며\n\n이게 무슨말이냐면 위의 예시처럼 ClosureV라는 Disjoint Union(자료형)을 생성하기 위해 “ClosureV (인자)” 형태의 Disjoint Union Constructor (자료형 생성자)를 호출해서 인자를 넣어 ClosureV 자료형의 객체를 생성한것\n\n\nRHS 가 Function Application 이어서는 안된다\n\n\n\n\n위의 예시에서는 세번째 조항때문에 문제가 생기는 것 이다\n\n3. Function Application을 제거해보기 §\n\n저 insert함수가 그냥 :: 으로 리스트에 추가하는 연산이 전부이기 때문에\n\n\n\n이렇게 표현하면 된다\n하지만 여기서는 이제 에러는 안나지만 Stack Overflow가 일어나게 된다\n왜냐면 Function Application이\n\n\n\n이렇게 정의되었기 때문\n전에 boolean을 생각해보면 boolean을 인자 두개를 받아서 둘 중 하나를 반환하는 함수로 구현을 했는데 이때 반환되지 않는 인자의 값도 계산한다면 낭비일 것이다\n\n\n\n이 예시를 보면 &lt;ㅅy.x, [x → 0]&gt; (sum (-1)) 부분에서 y에 (sum (-1))이 담기긴 하지만 반환값은 x이므로 사용되지 않는다\n\n근데 이제 (sum (-1))을 계산하느라 또 재귀호출이 되고 어차피 -1 &lt; 1이기 때문에 또 0을 반환해야되는데 반환하지도 않을 인자 (sum (-2))를 계산하고\n이런식으로 가다 보니 스택이 터져 오버플로우가 나는 것\n이것을 해결하기 위해 Expression Freezing 이 필요하다\n\n\n\nExpression Freezing (Lazy Evaluation) §\n\nExpression Freezing(Lazy Evaluation) : 어떤 expression을 등장과 동시에 계산하는 것이 아닌 얼려두었다가 값이 필요해지면 그제서야 계산을 하는 방법\n위의 경우처럼 인자의 값 계산을 늦춰 계산할 필요가 없으면 계산하지 않는 것을 지원하기 위해존재한다\n\n즉, 함수를 먼저 호출하고 인자의 값이 필요해지면 그때 인자의 값을 계산하는 방법\n따라서 call-by-need 라고도 부른다\n\n\n반대개념으로는 Eager Evaluation 가 있으며 얘는 반대로 인자를 먼저 계산하고 함수를 호출하는 방식\n대부분의 함수형 언어들은 Eager Evaluation을 주로 사용하지만 이런 Lazy Evaluation또한 지원한다\n\n예시1 §\n\n\n왼쪽이 Eager의 경우고 오른쪽이 Lazy의 경우이다\n보면 “ # 뭐시기 # “가 해당 부분을 얼린다는 의미로\n오른쪽을 보면 # 안의 expression을 계산하기 위해서는 expression 등장 당시의 store도 필요하기 때문에 (나중에 녹여서 계산할랫드니 store가 달라져서 값이 달라지면 안되니까) expression과 store를 같이 얼려놓는 것\n그렇게 인자 두개를 다 얼려놨다가 최종 계산시에 녹여서 계산하게된다\n\n예시2 §\n\n\n아까 무한루프를 돌았던 예시를 다시 보면 0과 sum()을 둘 다 얼려놨다가 마지막에 0을 반환해야되므로 0을 녹여서 반환하는 것을 알 수 있다\n\nLazy Expression in OCaml §\n\n\nlazy (표현식) : 으로 표현식을 얼리고\nLazy.force(변수) : 로 얼려진 변수를 녹일 수 있다\n\nExpression Freezing을 지원하는 RCFVAE §\n\n일단 App의 Semantics를 바꿀 필요가 있고\n얼린 expression도 값이 될 수 있도록 Value domain도 확장시켜줘야 한다\n또한 녹이는 절차도 필요하다 - 값을 꺼내오는 것은 “Id”에서 진행하기 때문에 “Id”의 Semantics도 녹이는 것을 지원하기 위해 변경되어야 한다\n\nValue Domain §\n\n\n얼릴 값과 녹일때 사용하기 위한 얼릴 당시에의 store를 묶은 튜플로 FreezedExpr을 정의하여 추가해준다\n\nFunction Application §\n\n\n값을 바로바로 계산하는 Eager가 아니고 Lazy를 지원해주기 위해 e1을 먼저 Closure로 계산하고 e2를 계산하지 않고 얼려서 x와 매핑하여 시그마에 넣어주는 연산으로 바꿔준다\n\nId §\n\n\nFreezedExpr가 아니라면 그냥 바로 계산해주고(위에꺼)\nFreezedExpr이라면 거기에서 expression과 store를 꺼내서 얘네들을 계산해서 반환한다\n\n좀 더 구조적으로 정의 §\n\n\nValue를 FreezedExpr와 그것이 아닌 NormalValue로 먼저 나누고\nFreezedExpr의 원소인 I는 (e, s)의 형태를 갖고\nNormalValue의 원소인 m은 (정수 or 함수) 인 것으로 정의할 수도 있음\n그것을 가지고 Id를 정의하면 위 그림의 아랫쪽처럼 정의할 수 있다\n저 Id1에서 m대신 v를 쓰면 안된다!! 이렇게 Inference Rule의 Domain을 잘 지켜서 정답써야된다\n\nRecursion as Syntactic Sugar §\n\n일단 Fixpoint Combinator를 일아야 한다\nFixpoint Combinator의 수식은 다음과 같다\n\n\n\n그리고 이놈의 특징은 다음과 같다\n\n\n\n즉, 임의의 함수 f에 대해 fix f는 f의 fixed point이다\n여기서 fixed point라는 것은 x = f(x) 를 만족하는 x를 의미하고\n따라서 Fixpoint Combinator는 임의의 함수 f를 인자로 받아x = f(x) 를 만족하는 함수x를 반환하는 함수이다\n뭔말인지 모르것제? 나도 모르겠다\n일단 저 수식이랑 특징만 기억하고 이 아래 예시를 봐라\n\n\n\n일단 저 fix로 어떻게 재귀함수를 만들어내는지 알려드림\n함수 sum을 아래 F처럼 변형한 뒤 fix에 넣어주면 재귀함수가 된다\n위의 과정을 보면 fix의 특징을 이용해 재귀적으로 함수가 돌아가는 것을 보이는데 이 특징이 저 수식을 통해 유도되는 것이다\n그럼 F는 어떻게 만들어내냐\n\n\n\n이렇게 재귀호출되는 함수를 인자(f)로 받게 해서 함수를 구성하면 된다\n\n\n\n더 간단하게는 ㅅsum. 만 붙이면 된다\n따라서 재귀함수를 Syntactic Sugar를 이용해 표현하고 Desugaring을 하는 과정은 다음과 같다\n\n\n\n걍 저렇게 fix F 만 해주면 재귀적으로 함수가 돌아감\n\n\n\n실제 구현에서는 위와 같은 Fixpoint Combinator를 사용함\n\nx x가 미리 계산되면 아까처럼 stack overflow가 나기 때문에 x x를 나중에 계산하기 위해 freezing 얼려놓는것\n함수란 것이 결국에는 인자가 들어와야 계산되므로 계산시점을 내가 정할 수 있어 expression freezing이랑 유사한 기능을 한다\n\n\n정 이해안되면 여기는 fix의 수식(+구현시 사용되는 수식)과 특징, F를 구성하는법, fix F로 돌리면 재귀함수가 된다는 것 이거 그냥 외워라\n"},"originals/pl.spring.2021.cse.cnu.ac.kr/13.-명령형-언어-(1)":{"title":"13. 명령형 언어 (1)","links":[],"tags":[],"content":"\n\n                  \n                  충남대학교 컴퓨터공학과 이성호 교수님의 &quot;프로그래밍 언어 개론&quot; 강의를 필기한 내용입니다. \n                  \n                \n\n\n\n                  \n                  다소 잘못된 내용과 구어적 표현 이 포함되어 있을 수 있습니다. \n                  \n                \n\n명령형 언어 §\n\n명령형 언어(Imperative Language) 는 메모리의 상태를 바꾸는 명령들을 통해 프로그램을 구성하는 언어\n즉, 명령을 하나씩 실행할때마다 메모리의 상태가 바뀌며 프로그램이 모두 실행되면 최종 상태가 됨\nC / C++, Java등이 해당됨\n일반적으로 Statement를 지원하는 언어는 모두 명령형언어이다\n함수형 언어는 보통 명령형 언어는 아니지만 반대개념은 아니다\n\n\n\n이걸 보면 한문장이 실행될때마다 메모리의 상태가 바뀌는 것을 알 수 있다\nif문도 expression인 조건식으로 특정위치로 분기한 다음 statement가 실행되는 것을 알 수 있다\n\nMiniC §\n\n이번 수업에서 정의하는 C언어의 축소판\nUntyped, Interpreted Language 로 정의해본다\n\n따라서 타입에러에 대한 런타임 에러가 날 수 있음\n\n\n\nConcrete Syntax §\n\n\n뭐 별거 없다\n\nAbstract Syntax §\n\n\n알파벳 위에 바 가 있는 것은 그냥 그게 여러개 있다(list이다)라고 생각하면 된다\ns는 변수할당(x = e)과 분기문 (e ? s : s-opt)으로 구성되고\ns-opt는 false branch를 지원하기 위한 것으로 s가 있을수도 있고 없을수도 있다는 것이다\n\n\n\n이렇게 오른쪽으로 코드로 바꿔보는거 할 줄 알아야 한다 - 시험각\noption은 ocaml에서 지원하는 타입으로 앞에꺼가 있을수도 있고 없을수도 있다는 소리이다\n\nValue Domain §\n\n\n별거 없쥬?\n다만 여기서도 코드로 바꾸는 거 알아놔야 된다 - 여기서는 and를 사용하지 않지만 and를 어떻게 사용하는지도 알아놓자\n\nSemantics §\n\nImperative Language의 경우 statement가 실행되면 메모리의 상태 전이가 일어나므로 statement는 메모리의 상태를 어떻게 전이시키는지를 명시하는 것으로써 Semantics를 작성할 수 있다\n\n\n\nProgram Semantics : program을 전부 실행한 후의 메모리 상태 (“ → P” 로 표현)\n\n\n\nStatement Semantics : statement 실행 시 변화된 추상 메모리 (“ → S “ 로 표현)\n\n\n\nExpression Semantics : 현재의 메모리 상태에서 expression이 계산되는 값 (“ 아래화살표 E “로 표현)\n\nBigstep Operational Semantics §\n\n나머지는 다 배운거고\n\n\n\nAND와 OR는 저렇게 &amp;&amp;B, ||B 의 논리값 연산자를 통해 표현된다는 것\n저기 오타는 적당히 알아듣도록\n\n\n\nequal to의 경우에는 정수간의 equal to 연산과 boolean간의 equal to 두개로 나눠서 표현한다\n따라서 정수와 논리값 간의 equal to 의 경우에는 런타임 에러가 나도록 처리한다\n\n\n\nStatement의 경우에는 ” → S “ 를 이용해 메모리의 변화로 표현한다\n위에 등장하는 If는 e가 True로 계산될때의 Branch 이다\n따라서 보면 True Branch의 statement들이 하나씩 실행될때마다 추상메모리가 변화하고 마지막의 최종 메모리가 이 If문의 결과 메모리가 되는 것\n\n\n\nFalse의 경우에는 False Branch가 존재할 수도 있고 존재하지 않을 수도 있기 때문에 위처럼 두개로 나눠서 표현된다\n첫번째는 False Branch가 없을때의 얘기로 이때에는 메모리 상태가 전이되지 않는다\n그리고 두번째는 False Branch가 존재할때의 얘기로 이때에는 True Branch일때처럼 하나씩 계산해서 마지막까지 계산했을 때의 메모리 상태가 최종상태가 되는 것\n\n\n\n그리고 Program은 Statement의 list이므로 빈 메모리에서 시작해서 최종 메모리로 끝나는 연산으로 표현된다\n\nOptional Value in OCaml §\n\n\n보면 ’a option 이라는 타입은 아무것도 없음을 나타내는 None과 하나가 존재한다는 Some으로 구성되어 있으며\n뭐 pattern matching으로 None와 Some을 매치시켜 사용하면 될듯\n값이 없음을 뜻하는 NULL과 유사하나 예기치 않은 오류가 날 수 있기 때문에 값이 있을수도 있고 아닐수도 있는 경우에는 이렇게 옵션으로 처리하는 것이 좋다\n"},"originals/pl.spring.2021.cse.cnu.ac.kr/14.-명령형언어-(2)":{"title":"14. 명령형언어 (2)","links":[],"tags":[],"content":"\n\n                  \n                  충남대학교 컴퓨터공학과 이성호 교수님의 &quot;프로그래밍 언어 개론&quot; 강의를 필기한 내용입니다. \n                  \n                \n\n\n\n                  \n                  다소 잘못된 내용과 구어적 표현 이 포함되어 있을 수 있습니다. \n                  \n                \n\n반복문의 구조 §\n\n\n별거없다\n\nMiniC에서의 반복문 §\n\n일단 _while문만 지원하면 syntactic sugar를 이용해 do-while이나 for문을 지원할 수 있다\n\n\nConcrete Syntax §\n\n\nC언어와 동일한 concrete syntax를 따른다\n\nAbstract syntax §\n\n\n하나의 expression과 statement list로 구성된다\n\nSemantics §\n\n\nconditional expression이 참일때와 거짓일때 두가지의 경우로 나눠서 정의한다\n참일때 반복에 대한 의미가 안들어가있어서 좀 헷갈릴 수 있는데 마지막 while(e) s 부분이 재귀적으로 자기자신을 다시 호출한다는 의미로 받아들이면 된다\n\n먼저 e가 참인지 보고, slist를 계산하여 스토어를 업데이트한 뒤, 그 스토어에서 다시 while루프를 호출해 다시 e를 확인하고 s를 실행하고 하는식으로 굴러간다 이거임\n\n\n\nPointer §\n\n어떤 언어가 pointer를 지원한다는 뜻은 그 언어가 Reference와 Dereference를 지원한다는 소리이다\nReference : 어떤 변수의 메모리 주소를 열람하는 것 - C언어에서 &amp;var를 의미함\nDereference : 메모리 주소를 이용해 그 주소에 저장된 값을 열람하는 것 - C언어에서 *addr 를 의미함\n\nMiniC에서의 Pointer §\nConcrete Syntax §\n\n\n원래 우리가 정의한 MiniC에서는 변수의 선언이 없었다 - 걍 변수명을 쓰면 새로 선언되거나 호출되거나 했었는데\n이제는 var이라는 키워드를이용해 변수 선언을 하고\nid = expr을 하면 선언된 그 변수에 값이 들어가며\nexpr = expr을 통해 주소에 저장된 값을 바꿔주는 것을 하게 됨\n위의 세개는 전부 스토어가 바뀌므로 statement라고 할 수 있고\n\n\n\n&amp;와 * 를 이용해 reference하거나 dereference하는 expression을 만들어준다 - 얘네는 스토어가 바뀌지 않으므로 expression이 되는 것\n\nAbstract Syntax §\n\n\n위에서 추가해준대로 변수 선언과 주소에 저장된 값을 바꿔주는 statement\n그리고 reference와 dereference를 해주는 expression 들이 추가가 된다\n또한 변수에 값을 할당하는 것은 syntactic sugar로 처리할 수 있다 x = e; -&gt; *&amp;x = e;\n\n\n\nreference와 dereference, vardeclstmt는 변수 하나만을 필요로 하기 때문에 string하나로 구성이 되고\nstorestmt는 expr의 결과를 주소로 하는 위치에 다음 expr의 결과를 할당할 것이므로 expr 두개의 튜플로 구성된다고 할 수 있다\n\nAbstract Memory Model in MiniC §\n\n\n원래의 MiniC에서는 스토어에 [변수이름 → 값] 으로 저장이 되었지만\n이제는 포인터를 지원하기 위해 중간에 주소의 개념을 추가하게 된다\n즉, 스토어를 Env(환경)과 Mem(메모리)로 니누어\nEnv(환경)에는 [변수이름 → 주소] 로 매핑되게 하고\nMem(메모리)에는 [주소 → 값] 으로 매핑되게 하는 것\n즉, Env는 ref의 과정을 지원하기 위해 존재하는 것 이고\nMem은 deref의 과정을 지원하기 위해 존재하는 것 이다\n다시말해 원래의 스토어에서처럼 변수명으로 값을 꺼내는 한종류의 기능이 아닌 변수명으로 주소를 꺼내는 것과, 주소로 값을 꺼내는 두종류의 기능을 지원하는것으로 바꿔준다는 소리\n시그마의 정의가 바뀌었으므로 헷갈리지 않게 조심할것\n그리고 이제는 주소 또한 값이 돼야 하므로 Value domain에 addr도 추가 하게 된다\n\n\n\n이 예제 보면 딱 감이 온다 어케하려는건지\n\nValue, Store Domain §\n\nSemantic Relation §\n\n\n원래는 프로그램은 스토어 하나만 반환하는 거였는데 env와 mem 두개를 반환하는 것으로 변경되고\nstatement도 스토어만 바뀌는 거였는데 env와 mem이 둘 다 바뀌는 것으로 변경된다\n\n\n\n마찬가지로 스토어를 받아 expression을 계산하는게 아니고 env와 mem을 받아 expression을 계산해 value를 반환하게 된다\n\nBigstep Operational Semantics §\n\n얘도 그냥 대부분은 스토어를 env와 mem으로 바꾼게 전부이기 때문에 쉬운건 버리고\n\n\n\n변수에서 값을 꺼내오는 경우는 변수로 주소를 찾고 그 주소로 값을 찾아오기 때문에 위 그림의 첫번째처럼 된다\n\n다만 여기서 시그마에 대해서만 도메인 체크를 하는 것은 그 변수가 선언되었냐\n\n즉, bind되었느냐를 확인하는 것이고 만약 그렇지 않다면 runtime error가 나게 된다\n\n\n또한 M에 없을수도 있는데 이때 또한 runtime error가 나게 된다\n\n\n그리고 ref의 경우에는 주소값을 반환해야하기 때문에 그냥 env에서 찾아주면 된다\n\n이때에도 시그마 도메인에 없다면 선언을 하지 않은 것 이므로 runtime error가 나게 된다\n\n\n\n\n\nderef의 경우에는 * 뒤에 변수만 붙을 수 있다 (string으로 선언되어있으므로)\n따라서 변수가 선언되어있고 이 변수에 저장된 값이 어떤 주소라면 mem을 통해 그 주소의 값을 가져오게 되는 것\n\n\n\nstatement의 semantics는 위와 같다\n변수 선언의 경우에는 도메인에 일단 그 변수가 없어야 되고 해당 변수에 대해 할당하려는 주소값이 시그마 안에 저장되어있으면 안될때 그 변수와 주소를 매핑해주게 된다\n주소가 시그마 안에 있으면 안된다는 것을 Range() 라고 표현했는데 이미 다른 변수에게 할당되어있는 주소값에 해당 변수를 매핑하면 안되기 때문\n값 변경의 경우에는 e1을 계산한 결과가 주소여야 되고 e2가 어떤 value일때 그 주소에 매핑된 값을 새로운 값으로 바꾸는 과정을 수행한다\n\n주소와 값 간의 매핑관계를 바꾸므로 mem을 건드리게 되는 것\n\n\n\nNumeric Compilation §\n\nMiniC의 경우에는 컴파일을 하지 않지만 컴파일 언어가 어떻게 컴파일되는지는 한번 살펴볼 필요가 있다\n어떤 프로그램이 컴파일되고 나면 그 프로그램에서 변수라는것은 다 사라지고 물리주소값만 남게 된다\n\n\n\n위와 같은 프로그램이 어떻게 컴파일되는지를 알아보면\n\n\n\n일단 프로그램에 등장하는 변수들을 전부 “변수의 주소값에 대한 deref”로 바꿔준다\n\n이게 뭔소리냐면 변수 x 는 *&amp;x 와 같기 때문에 모든 변수를 저렇게 기계적으로 변환시켜주는 것\n\n\n\n\n\n그 다음으로는 변수의 주소값을 “&amp;변수”로 표현하지 말고 전부 “주소”로 바꿔준다\n\n즉, 위의 예시에서 x의 주소값인 &amp;x는 addr0이므로 a0라고 표현함\n\n\n\n\n\n마지막으로 어떤 주소를 deref후 ref를 하는것은 그 주소의 값과 같기 때문에 이러한 표현들을 다 걸러준다\n\n즉, *a0 를 하면 a0의 공간이 나오고 그 공간을 다시 &amp;하는 것은 원래의 a0와 같기 때문에 *&amp; 라는 표현을 다 삭제해주는 것이다\n\n\n\n\n\n그다음에 변수 선언부를 다 삭제해주면 주소만으로 구성된 표현이 나오게 된다\n"},"originals/softwareengineering.fall.2021.cse.cnu.ac.kr/(충남대)-소프트웨어-공학-강의록":{"title":"(충남대) 소프트웨어 공학 강의록","links":["originals/softwareengineering.fall.2021.cse.cnu.ac.kr/01.-소프트웨어-프로세스","originals/softwareengineering.fall.2021.cse.cnu.ac.kr/02.-프로젝트-관리","originals/softwareengineering.fall.2021.cse.cnu.ac.kr/03.-요구사항-분석","originals/softwareengineering.fall.2021.cse.cnu.ac.kr/04.-유스케이스-모델링","originals/softwareengineering.fall.2021.cse.cnu.ac.kr/05.-클래스-모델링","originals/softwareengineering.fall.2021.cse.cnu.ac.kr/06.-동적-모델링","originals/softwareengineering.fall.2021.cse.cnu.ac.kr/07.-아키텍쳐-디자인","originals/softwareengineering.fall.2021.cse.cnu.ac.kr/08.-디자인-패턴","originals/softwareengineering.fall.2021.cse.cnu.ac.kr/09.-소프트웨어-테스트-(1)","originals/softwareengineering.fall.2021.cse.cnu.ac.kr/10.-소프트웨어-테스트-(2)","originals/softwareengineering.fall.2021.cse.cnu.ac.kr/부록---시험대비)-요약정리"],"tags":[],"content":"개요 §\n강의 정보 §\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n강의 구분소속교수시기학부 수업충남대학교 공과대학 컴퓨터공학과김현수 교수님2021년 가을학기\n목차 §\n\n01. 소프트웨어 프로세스\n02. 프로젝트 관리\n03. 요구사항 분석\n04. 유스케이스 모델링\n05. 클래스 모델링\n06. 동적 모델링\n07. 아키텍쳐 디자인\n08. 디자인 패턴\n09. 소프트웨어 테스트 (1)\n10. 소프트웨어 테스트 (2)\n부록 - 시험대비) 요약정리\n"},"originals/softwareengineering.fall.2021.cse.cnu.ac.kr/01.-소프트웨어-프로세스":{"title":"01. 소프트웨어 프로세스","links":[],"tags":[],"content":"\n\n                  \n                  충남대학교 컴퓨터공학과 김현수 교수님의 &quot;소프트웨어 공학&quot; 강의를 필기한 내용입니다. \n                  \n                \n\n\n\n                  \n                  다소 잘못된 내용과 구어적 표현 이 포함되어 있을 수 있습니다. \n                  \n                \n\n소프트웨어 개발 프로세스란 §\n\n하나의 소프트웨어를 개발하는 과정\n무엇을 해야 하는가 / 어떤 순서로 작업할 것인가를 결정하는데 도움이 되어야 함\n\n말 그대로 도움이 되어야 함 - 모델들은 엄격하게 규정되기 보다는 지금 그리고 그 다음에 뭘 해야하는지는 생각하는데 도움이 되도록 구성되어 있다\n\n\n각 프로젝트마다 성격이 다르므로 고유의 계획이 있어야 한다\n\n즉흥적인 개발 프로세스의 문제점 §\n\n설계가 제대로 안되어 품질이 떨어짐\n계획이 없어 목표없이 일하게 됨 - 하나를 다 하고 나면 그 다음에 뭘 해야될지 모른다\n테스트, 품질보증 등이 제대로 이루어지지 않음\n위와 같은 이유로 개발과 유지보수 비용이 증가함\n\nWaterfall Model (Phased Model) §\n과정 §\n\n\nRequirements gathering and definition - 요구사항 수집과 정의\nSpecification - 명세\n\n위 두 과정은 약간 블로그나 책마다 다르게 설명되어 있는데 대략 타당성 조사(비용 대비 이익이 얼마나 되는가, 주어진 시간 내에 우리가 가진 기술력으로 해결이 가능한가 등)와 요구사항 수집과 명세(문서화)정도로 이해하면 된다\n\n\nDesign - 디자인\n\n여기서의 디자인은 외적인 디자인 말고도 시스템 전체에 대한 설계 등의 과정도 포함된다\n\n\nImplementation - 구현\nIntegrate &amp; Deploy - production build + deploy 같은 느낌\nMaintenance - 유지보수\n\n특징 §\n\n현재의 단계가 끝나야 다음단계로 넘어가는 순차적인 구조로 진행된다\n각 단계의 구분이 명확해 중복되는 작업이 이루어지지 않는다\n그리고 각 단계가 시작되기 전에 전단계의 결과에 대해 점검하고 문서화 작업이 이루어진다\n만일 문제점이 발견되면 바로 전 단계로 피드백을 주게 된다\n\n장점 §\n\n요구사항의 변경이 한정된 상황에서 유용\n대규모 시스템 공학 프로젝트에서 많이 쓰임(대표적으로 국방관련 프로젝트)\n\n단점 §\n\n요구사항이 변경되었을 경우 대처하기가 힘들다\n초기 단계(요구사항 분석과 설계 등)에서 잘못하면 미래가 어둡기 때문에 초기 단계가 중요한데 초기단계에서 힘을 너무 빼버리면 구현이나 테스트 등의 뒷 단계가 지연된다\n단계가 전환될때 많은 노력이 필요하다\n한번에 모든걸 끝내고하 하는 성격의 모델이기 때문에 프로토타입을 만들어볼 기회가 적다\n앞으로의 단계에서 무슨일이 일어날지 모르기 때문에 갖가지 문서를 만들게 되는데 이 과정에서 쓸데없는 문서를 생산해낼 가능성이 있다\n\nPrototype Model §\n프로토타입의 종류 §\n\n실험적 프로토타입\n\n인간 - 기계 상호작용 프로토타입 : 뭐 ppt같은걸로 ui같은거 그려서 시나리오 짜보고 그런 경험 있제? 그런걸 말하는거다\nWorking prototype : 프로젝트의 가장 핵심적인 부분만 구현하여 프로토타입을 만들어보는 것\nThrow-away prototype : 요구사항을 이해하기 위해 만들어서 버릴 생각으로 간단하게 만들어보는 것\n\n\n점진적 프로토타입\n\n개선을 목표로 요구되는 기능의 일부 또는 전체를 러프하게 만들어보는 것\n\n\n\n과정 §\n\n\nSystem analysis - 시스템 분석\nRequirement definition / design - 요구사항 분석 및 소프트웨어 설계\nPrototype Development / Refinement - 프로토타입 구현과 코드 정리\nPrototype Evaluation : 프로토타입 테스트(평가)\n\n위의 네 단계가 이루어지고 프로토타입 평가 결과에 따라 1, 2, 3번의 과정을 다시 수행하여 평가가 통과할때까지 프로토타입을 만든다\n\n\nFull-scale implementation - 프로토타입이 다 완성되었으면 정식 버전을 구현한다\n\nIncremental Model §\n과정 §\n\n\n우선 이전의 모델들처럼 요구사항 분석, 명세 등의 과정을 다 끝낸다\n그리고 구현할때 한번에 모든 기능을 구현하는 것이 아닌 기능별로 구현해서 여러번 배포할 목표로 계획을 하고 계획에 따라 구현, 배포한다 - 이게 핵심!\n\n즉 바로 요구사항 분석 등의 과정이 끝난 후에 바로 소프트웨어 설계를 하는 것이 아닌 배포 계획을 세우고 각 배포 단계에 선행하여 설계를 하게 되는 것\n\n\n각 배포 단계마다 설계, 구현, 테스트, 배포가 이루어진다\n\n배포 구성 방법 §\n\n점증적 방법 - 전체 시스템을 기능별로 쪼개어 그 기능이 구현될때마다 배포하는 방법\n반복적 방법 - 기능을 다 구현한 다음 배포 하고 배포할때마다 기능들의 완성도를 높이는 방법\n\n장점 §\n\n빠른 시간 안에 시장에 출시해야 할 경우 강점을 가진다\n\n시장에 처음으로 나온 소프트웨어의 경우 인지도 형성과 시장 점유에서 강점을 가지기 때문\n\n\n자주 릴리즈를 하면 서비스 중일때 일어날 수 있는 문제를 빨리 파악하고 해결할 수 있다\n기능별로 쪼개어 릴리즈를 하는 경우 개발팀이 각 배포 단계마다 하나의 기능에만 집중할 수 있기 때문에 기능의 완성도가 높아질 수 있다\n\nSpiral Model §\n\n\n1사분면이 요구사항 분석 등의 과정(Planning - 목표, 기능선택, 제약조건의 결정)\n2사분면이 위험분석, 프로토타입 생성(Risk analysis - 기능선택의 우선순위, 위험요소의 분석) - 여기가 핵심!\n4사분면이 구현 및 테스트(Engineering - 선택된 기능의 개발)\n3사분면이 다음 단계 계획(Evaluation - 개발 결과의 평가)\n이렇게 구성되어 있고 저렇게 빙글빙글 돌면서 반복한다는 컨셉인듯\n이것도 반복적으로 배포하게 됨\n점진적으로 반복해서 배포한다는 것은 다른 모델들과 비슷하나 위험부담을 최소화하기 위해 리스크 분석 단계가 존재하는 것이 나선형 모델의 가장 큰 특징인 듯 하다\n\n장점 §\n\n대규모 시스템 개발에 적합\n리스트 분석을 매번 하기 때문에 리스크를 줄일 수 있다\n반복적인 개발 및 테스트가 이루어진다\n\n단점 §\n\n관리가 중요\n위험 분석이 중요\n\nEvolutionary Model §\n\n\n위의 그림처럼 하나 구현할때마다 설계 구현 시험 설치 운영을 거친다더라\nIncremental Model과의 차이점은 Incremental Model의 경우에는 요구사항 분석등의 과정을 처음에 한번만 하고 그것을 토대로 앞으로의 계획을 짜서 여러번 배포하는 것이라면\nEvolutionary Model은 매번 그것을 반복한다\n아래의 UP 를 예시로 보면 이해하기 쉬움 이게 뭔지\n\nUP (Unified Process) §\n\n\n위의 그림을 어떻게 이해하면 되냐면\n다음의 4단계가 하나의 사이클이라고 보면 된다\n\nInception(도입 단계) : 프로젝트의 범위를 설정하고 목표를 명확하게 함\nElaboration(정련 단계) : 시스템의 중요한 요구를 찾아내어 기본이 되는 설계를 완성\nConstruction(구축 단계) : 원시코드가 완성되고 중요한 요구의 테스트를 하는 것\nTransition(전환 단계) : 사용자에게 릴리즈\n\n\n근데 다른 모델들과의 차이점은 Inception 단계라고 해서 계획만 하는 것은 아니라는 거다\n\n세로축에 있는 Business Modeling, Requirements, Analysis &amp; Design, Implementation, Test, Deployment의 작업을 각 단계마다 수행하게 되는 것\n\n\n하지만 각 단계마다 집중하는 비율은 당연히 달라지고 그 비율을 나타낸 것이 위의 그래프인 것\n\n보면 Inception단계에서는 Business Modeling과 Requirements의 비중이 높은 것을 알 수 있고\nConstruction에서는 Implementation의 비율이 높은 것을 알 수 있다\n\n\n즉, 다른 모델들은 각 단계마다 한가지의 일만을 하는 반면 UP에서는 비중만 달라질 뿐 모든 일을 골고루 처리한다는 차이점이 존재한다\n\nAgile Model §\n\nAgile [형용사] : 빠른, 기민한, 날렵한, 민첩한\n\n특징 §\n\n설계가 변경되어도 쉽게 수용이 가능하도록 계획부터 배포까지의 사이클을 짧게 가져가는 것\n\n점증적 설계 : 설계를 하되 나중에 충분히 개선될 여지가 있다는 것을 염두해 두고 설계에 대한 결정을 최대한 미루는 것\n약 4-5주의 사이클로 계획 ~ 배포가 이루어진다\n\n\n사용자를 팀에 아예 참여시켜 지속적으로 피드백을 받음\n필요한 문서만 최소한으로 작성하고 대부분 소스코드로 대체, 커뮤니케이션도 문서를 통하기보다는 대화를 통해 해결\n대규모의 프로젝트의 경우에는 설계가 자주 변경되는 것이 좋지 않으므로 소규모 프로젝트를 진행할때 적합하다\n\n소규모의 프로젝트 같은 경우에는 설계가 자주 바뀌어도 품질에 크게 영향을 끼치지 않기 때문\n\n\n\n과정 §\n\n\n위처럼 요구사항 수립을 한 후에 지속적으로 개발 &amp; 통합 &amp; 테스트를 이어나가다가\n고객에게 피드백을 받고 배포할지말지를 결정\n빠꾸먹으면 왜 빠꾸먹었는지 등을 정리해놓고 다시 개발 &amp; 통합 &amp; 테스트 &amp; 피드백\n빠꾸 안먹어도 배포 후에 계속 요구사항을 정리해서 개발 &amp; 통합 &amp; 테스트 &amp; 피드백\n\nXP : eXtreme Programming §\n\n최초의 애자일 프로세스랜다\nMetaphor : 프로젝트에 사용할 아키텍처를 설계하는 것이 아닌 기존의 서비스 중 유사한 것의 아키텍처를 차용함\n불필요하게 복잡한부분은 제거해서 설계\nTDD를 중심적으로 개발 프로세스가 돌아감\nRefactoring : 동일한 동작을 하되 더 간결하고 깔끔하게 시스템을 재구성\n주당 40시간의 개발속도로 진행\n코딩 컨벤션을 정해 동일한 규칙을 적용\n\n과정 §\n\n\nExploration : User story - 즉, 사용자의 니즈를 잘게 나누고 해당 니즈와 관련된 정보들을 모음.\n\nCapture stories in parking lot - 사무실에 앉아서 니즈를 알아내려고 하지 말고 엉뚱한데를 뒤져보라는 것.\nArchitectural spikes : 어떤 user story에 대해 이것을 왜 해결해야 하는지 등의 신뢰성 혹은 기술적인 부분에서 문제가 없는지 등을 확인하기 위해 작성하는 간단한 프로그램\n\n\nIteration planning : 각 user story들에 대해 개발 사이클인 iteration이 얼마나 걸릴지를 예상. + 비용도 예상\nIteration : Pair programming : 하나의 컴퓨터를 공유하고 개발과 테스팅을 분리하여 진행 + 지속적으로 개발의 결과를 통합시킴\n\n개발 + 테스팅 이후에는 기존의 코드들과 연동이 잘 되는지 regression test를 진행함\n그리고 iteration의 중간에 mid iteration review, iteration의 끝에 end of iteration review를 진행함\n\n\nAcceptance tests : 릴리즈 전에 고객한테 피드백을 받음\nSmall release : 고객이 ㅇㅋ하면 소규모의 배포를 진행\n\nScrum §\n과정 §\n\n\nProduct backlog : 고객이나 팀 임원진 등등의 사람들에게 요구사항을 물어봐서 정리함\nSprint planning meeting : Product backlog 중에 어떤 것들을 이번 Sprint(iteration마냥 한 사이클)때 해결할 것인지를 결정함. 그리고 그것들에 대해 시간이 얼마나 걸릴지, 비용은 얼마나 필요할지 등을 산출함\nSprint : 1주에서 4주정도의 기간 동안 회의때 결정한 내용들을 개발하고 테스트함. Daily scrum meeting을 통해 매일 15분 정도 얼마나 진도가 나갔는지, 이슈는 없는지 등을 논의함\nSprint review : 스프린트 후 산출된 결과에 대해 리뷰함\nSprint Retrospective : 스프린트 과정에 대해 변경할 부분은 없는지, 문제는 없었는지 등을 회고함\n\n프로세스 모델 선정 §\n\n참고해라\n\n\nModel과 관계없이 해야되는 작업들 §\nSpecification §\n\nFeasibility study : 타당성 조사. 비용 대비 이익이 얼마나 되는가, 주어진 시간 내에 우리가 가진 기술력으로 해결이 가능한가 등 - Feasibility report의 문서가 나오게 됨\nRequirements elicitation and analysis : 요구사항 도출 및 분석\nSpecification : 명세. 문서화\nValidation : 검증 - Requirement validation의 문서가 나오게 됨\n\n\n\n뭐 대충 이렇댄다\n\nDesign &amp; Implementation §\n\nSpecification으로 실행가능한 프로그램을 만드는 과정\nDesign : 설계\n\nArchitectural design : 프로그램이 돌아갈 OS등의 아키텍처를 고려해 설계\nInterface design : UI등의 인터페이스를 설계함\nComponent design : 프로그램을 구성하는 클래스 등의 구성요소 들을 설계함 (Component는 기능이나 객체 혹은 이들의 그룹을 의미함)\nData structure design : DB또는 자료구조들을 설계\nAlgorithm design : 프로그램이 돌아가는 알고리즘을 설계\n\n\n\n\n\n이렇댄다\n\nVerification &amp; Validation (V &amp; V) §\n\n작성한 프로그램이 명세와 요구사항을 충족하는 것을 보여주기 위한 과정\nComponent or unit testing : unit testing을 진행\nSystem testing : 프로그램 전체 테스트 - 명세에서 유도된 테스트 케이스들을 가지고 시스템 전체를 테스트함\nAcceptance testing : 시스템이 고객의 요구를 충족하는지 확인하기 위해 고객의 데이터를 이용해 테스트\n\n\n\n이건 좀 잘 봐야됨\n\n일단 위엣줄이 Specification과 Design을 진행하는 과정임\n그리고 이 Spec과 design을 가지고 개발을 진행함(맨 오른쪽)\n맨 아랫줄이 Specification과 Design을 진행하는 과정에서 산출된 테스트를 가지고 테스트를 진행하는 과정이다\n위 그림만 보면 &gt;이지만 어쨋든 V형태를 띈다고 해서 V-Model이라고 부르더라\n\n\n\nEvolution §\n\n\n유지보수 과정이라 생각하면 될듯\n"},"originals/softwareengineering.fall.2021.cse.cnu.ac.kr/02.-프로젝트-관리":{"title":"02. 프로젝트 관리","links":[],"tags":[],"content":"\n\n                  \n                  충남대학교 컴퓨터공학과 김현수 교수님의 &quot;소프트웨어 공학&quot; 강의를 필기한 내용입니다. \n                  \n                \n\n\n\n                  \n                  다소 잘못된 내용과 구어적 표현 이 포함되어 있을 수 있습니다. \n                  \n                \n\n프로젝트 관리 §\n\n뻔한내용이지만 프로젝트를 관리하는데는 다음과 같은 일들을 한다\n\n제안서 작성\n계획(과정, 비용, 노력 등) / 스케줄링\n인력 선발 및 평가\n모니터링 / 검토\n보고서 작성 및 프레젠테이션\n\n\n\n프로젝트 계획 수립에 대해 §\n\n일단 당연히 시간이 많이 걸리는 작업이다\n초기 단계부터 마무리 단계(배포)에 이르기까지 지속되는 활동임\n새로운 정보가 생길때마다 계획을 정기적으로 수정할 필요가 있다\n\n계획의 유형 §\n\n품질 계획\n검증(테스트) 계획\n인력 관리 계획\n등등이 있음\n\n프로젝트 개발 노력 추정 §\n\n\n프로젝트 요소는 프로젝트 자체에 대한(쉽게 말해 소스코드에 대한) 요소\n자원은 말그대로 인적자원이든 컴퓨터든 돈이든 이런 자원들\n생산성은 개발자의 능력이나 프로젝트 혹은 개발에 대한 방법론을 말함\n프로젝트 개발 노력을 추정하는데는 Function Point Model 와 Object Point Model 이 두개가 사용된다\n\nFunction Point Model §\n\n기능 점수 모델이라고 번역하대\n이건 사용자에게 제공되는 기능들을 가지고 노력이 얼마나 필요할지 추정해보는 모델이다\n데이터 관리를 위주로 하는 프로젝트의 경우 적합한 모델이고\n기능을 잣대로 판단하기 때문에 조직과 프로그래밍 언어와 무관하게 어플리케이션의 복잡도를 추정 가능하댄다\n과정은 다음과 같다\n\n\n\n일단 유형을 알아야 한댄다\n\n개발 프로젝트의 경우에는 누군가에게 의뢰를 받아 개발하는 것을 의미하고\n유지보수는 말그대로 유지보수\n응용 패키지 개발은 널리 사용될 수 있는 어플리케이션을 개발하는 것이라고 이해하면 될듯\n\n\n범위 / 경계 설정은 사용자와 프로그램 간의 경계를 설정한다는데 뭔소린지 모르겠음\nUFT(Unadjusted Function Point) : 보정하기 전 기능점수를 산정\n\n얘를 산정하기 위해서는 다음의 다섯가지 소프트웨어 구성 요소를 알아야 한다\n\nExternal Input : 외부에서 들어오는 리퀘스트를 처리\nExternal Output : 처리결과인 리스폰스를 외부로 보내는 것\nExternal Inquiry : 사용자가 단순히 정보를 조회하는 것을 처리하는 것 을 말하는거같음 - 약간 GET 메소드같은거 말하는게 아닌가 생각해본다\nInternal Logical File : 시스템 안에서 유지되고 사용자가 식별 가능한 논리적으로 연관된 자료 및 제어 그룹이라는데 뭐 DB같은거 말하는건가\nExternal Interface File : 시스템 안에서 유지되지는 않지만 참조할 수는 있는 다른 어플리케이션에 유지되는 사용자가 식별 가능한 논리적으로 연관된 자료 및 제어 그룹이라는데 뭔지 모르겠음\n\n일단 4번이랑 뭔차이가 있는진 알겠는데 뭘 말하는건지 예시가 생각이 안나누\n\n\n\n\n\n\n\n\n\n그리고 위 그림처럼 각 구성요소마다 가중치를 산정하고\n\n\n\n구성요소 하나하나마다 갯수와 가중치를 곱해 UFP를 계산해준댄다\n대충 감은 오쥬?\n\n\nVAF(Value Adjust Factor) : 보정을 위해 곱해줄 인자들을 산정\n\n\n\nVAF는 위의 14개의 기술적 분야 에 대해 복잡도를 고려하여 0~5의 점수를 부여한댄다\n즉 저 14개 각각에 대해 일단 0~5점씩 점수를 주고\n각 점수에 0.01을 곱한 뒤 0.65를 더해주면 VAF의 결과인 TCF(Total Complexity Factor) 가 나오게 된다\n\n\n\n위의 사진이 뭔말인지 알겠으면 이해된거임\n\n\nAFP(Adjusted Function Point) : 보정된 기능점수 산정\n\n위에서 구한 UFP에 TCF를 곱하면 AFP가 나오게 된다\n근데 여기서 주의할 점은 AFP라는 것은 그냥 프로젝트의 크기(규모)에 대한 추정치 이므로 이것을 이용해 얼마의 노력이 필요할지 또 구해줘야 한다\n프로젝트 전체에 대한 AFP에다 사람 1명이 1개월동안 개발할 수 있는 AFP를 나눠주면 사람 1명이 몇개월이 걸릴지 알아낼 수 있을 것이다\n\n\n\n\n\n위 그림을 잘 생각해보면 FP가 소거되어 결국에 단위가 MM이 되고 이것은 사람 한명에 개발할 수 있는 양을 뜻한다(Man Month - MM)\nFP / 1MM값은 뭐 알아서 알아내라 이거지\n\nObject Point Model §\n\n얘는 지금 대부분의 프로젝트가 객체를 기반으로 개발되고 있다는 점에 착안한 모델이다\n러프하게 말하면 개발에 사용될 객체의 갯수와 각 객체의 구현 난이도를 가지고 노력의 양을 추정하는 것\n\n과정 §\n\n일단 UML이나 요구 분석 등을 통해 객체가 몇개나 필요할지 알아낸다 - 이 값을 Cc라고 하자\n그리고 사용자가 입력할 수 있는 방식을 분류하고 각각에 가중치를 부여한다 - 이 값을 Wi라고 하자\n\n아래의 그림은 분류하고 가중치를 매긴 예시이다\n\n\n\n\n\n이후 다음의 공식을 이용해 최종 클래스 갯수(Total Class count)를 알아낸다\n\n\n\n마지막으로 클래스 하나를 개발하는데 드는 노력의 평균적인 추정치를 곱하면 된다 - 이값은 MD 이며 Man Day, 즉, 사람 한명이 하루에 개발할 수 있는 양을 의미한다\n\n\n\n결과적으로 이 프로젝트를 개발하는데 걸리는 일수의 추정치가 나오고, 보통 한달에 일하는 날은 22일 정도로 잡으므로 22로 나누면 몇개월이나 걸릴 지 추정할 수 있게 된다\n\n프로젝트 일정 관리 §\n\n프로젝트 일정 관리 프로세스는 일단 Activity Definition(활동 정의) 을 해야 한다\n\n이건 뭐냐\n프로젝트에 필요한 주요 활동들(Tasks)을 정의하고 그 활동들을 달성하기 위한 작은 활동들(Sub Tasks)을 식별하는 것이랜다\nWBS(Work Breakdown Structure) 을 짜면서 진행하게 됨\n\n\n\n\n\nWBS라는 것은 위 그림처럼 프로젝트가 있고 그 프로젝트를 위한 여러 Tasks들이 존재하고, 각 Task의 Sub Task를 정리해 나가는 도표인 것\n이러한 방법을 통해 정의한 활동들에 대해 순서를 정하고, 자원은 얼마나 필요할지, 기간은 얼마나 걸릴지 등을 추정하는 과정을 뒤이어 하게 된다\n그리고 이후에는 추정한 내용들을 바탕으로 일정 계획을 수립하고, 통제하는 과정( - 계획 대비 차이나는 일정을 모니터링해서 조치를 취하는 것)을 하게 된다\n\n\n\n그래서 결과적으로는 위와 같은 플로우를 가지게 된다\n저기서 Activity 배열이라는 것이 Activity 순서를 얘기하는 것이고, 이 순서를 도표로 나타낸 것이 네트워크 다이어그램이다\n\n여러 용어들 §\n\nActivity : 뭐 니가 아는 활동이라는 뜻이긴 한데 여기서 중요한 것은 프로젝트의 진행상황을 알 수 있게 하기 위해 가시적인 산출물(뭐 제안서라던지, 프로토타입이라던지 등등)이 나오는 작업에 대해 하나의 활동이라고 칭하더라\nMilestone : 버전 1.0배포같은 중요한 이벤트나 활동의 종료 시점을 의미함\nDeliveries : 고객에게 전달되는 프로젝트 결과물\n\nPERT / CPM 차트 §\n\nPERT / CPM 차트는 WBS등을 통해 세분화된 활동을 효율적으로 일정 관리하고 지원하기 위한 하나의 툴이다\n관리에 대한 작업도 포함시킬 수 있고 작업 시간을 정확하게 예측할 필요가 있댄다\n뭐 장점으로는 일정을 계획하는데 도움이 되고 작업들 간의 관계를 표현하기 좋고 병행 작업 계획을 하기에 좋고 일정 시뮬레이션도 가능하며 일정을 점검하거나 관리가 가능하댄다\n\n일정 계획 수립 과정 예시 §\n\n\n위 표는 활동들과 소요시간, 의존성을 나타낸 표이다\n일단 어떤 Activity들이 있는지 정의한 것이 첫번째 열\n각각 Activity들에 소요되는 시간이 얼마나 걸릴지 추정한 것이 두번째 열\n그리고 해당 Activity에 대해 선행되어야 할 Activity에 대해서 세번째 열에 정리가 되어 있는 것\n\n\n\n그리고 위의 그림은 표를 기반으로 그린 PERT / CPM차트이다\n일단 네모 박스는 Task(활동), 둥근 모서리의 박스는 Milestone(이정표)를 나타낸다\n그리고 Task 위에 있는 Days는 Working Day이고 Milestone 위에 있는 Date는 Calendar Day이다 - 즉, Task위에 있는 Day는 업무일 기준 소요 일수를 나타낸 것이므로 이 일수에 휴일까지 포함시켜줘야지 Milestone 위의 Date가 나오게 되는 것\n\n\n\nPERT / CPM 차트에서 Milestone을 빼고 간략하게 표현하면 위와 같이 된다\n시험문제에 이 PERT / CPM 차트 그리는 문제 나온댄다 - 간략한 표현을 사용하여 그리라네\n그리고 여기에서 Critical Path(임계경로) 라는 말이 등장한다 - Critical Path(임계 경로) 라는 것은 PERT / CPM 차트에서 시작부터 끝까지 가는 경로 중 가장 시간이 오래 걸리는 경로를 뜻한다\n그리고 이 임계경로를 따라가는데 걸리는 시간은 프로젝트를 수행하는데 필요한 최소시간을 나타낸다\n\n이건 왜그러냐면 프로젝트를 진행하는데 저기서의 경로 하나만을 따라가는 것이 아니고 저기 있는 모든 Task들을 끝내야 하기 때문에 모든 노드들을 다 방문하게 된다\n근데 가장 긴 경로를 따라가는 와중에 그 경로상에 있는 작업들만 하는게 아니고 다른 경로도 병렬적으로 수행할 수 있기 때문에 가장 오래걸리는 경로를 기준으로 프로젝트에 소요되는 시간의 최소값을 산정하는 것\n예를들어 S-1-3-0-11-12-F의 경로가 위의 차트의 경우 임계경로가 되는데 여기에 소요되는 시간이 55일이다\n이 경로를 따라감과 동시에 S-4-8-F의 경로를 병렬적으로 수행하면 이 경로는 35일만에 끝나기 때문에 임계 경로의 작업들이 다 끝나기 전에 완수할 수 있다\n이런식으로 다른 경로들도 쫒아가기 때문에 프로젝트를 완수하는데 최소한 임계경로 소요시간인 55일은 필요할 것이라고 생각하는것\n즉, 작업들을 병렬적으로 처리하기 때문에 차트의 모든 일수를 더한 것 보다는 일찍 끝나지만 가장 긴 경로를 따라가는데 걸리는 시간보다 짧을 수는 없다 이거임\n뭔얘긴지 감은 오제?\n\n\n\nGantt chart §\n\n운영체제시간에 한번 본 적 있제?\n\n\n\n위 그림처럼 작업의 시작과 끝을 나타낸 차트를 Gantt chart라고 한다\n여기서는 하얀색 막대는 작업 기간, 파란색 기간은 작업을 끝내고 나서의 여유기간을 나타내며 마름모가 Milestone을 나타낸다\n그리고 시간의 흐름을 보기 쉽기 때문에 계획 대비 진척도를 파악하기 쉬우며\n각 작업마다 담당자를 명시한다면 개인별 진척도를 파악하는데 에도 도움이 된다\n여기서 여유시간이라는 말이 나왔는데 얘는 한마디로 지연 가능 범위를 뜻하게 된다\n\n위에서의 PERT / CPM 차트를 보면 경로중에 S-4-8-F라는 경로가 있었는데 이것을 저 간트차트에서 보자\n예시에서의 임계경로 소요시간이 55일이었는데 S-4-8-F경로의 경우에는 소요시간이 35일 이므로 20일 가량이 남는다\n따라서 이 경로에 대해서는 T4와 T8 합쳐서 20일 가량은 지연이 되어도 지장이 없다는 뜻이다\n만약 T4가 7월 18일에 끝났어야 되는데 좀 밀려서 8월 1일에 끝났다고 해보자 - 2주가 지연된거임\n그럼 T8의 경우에는 8월 1일에 시작을 할 수 있는 것이고 따라서 T8이 2주 이하로 지연되면 전체적인 일정에는 지장이 없는 셈인 것이다\n간트 차트에서 저 파란선은 그러한 여유시간을 나타내는 것임\n\n\n\nAgile Process Planning §\n\n애자일 프로세스에서는 스토리카드라는 것을 사용한다\n스토리 카드는 어떤 유저 스토리인지, 이것을 구현하기 위한 노력이 얼마나 들어갈지, 비즈니스적으로 우선순위는 어떻게 되는지, 연관된 유저 스토리는 뭐가 있는지 적혀있는 카드를 의미한다\n그리고 이러한 스토리 카드들이 준비되면 선행 작업이 없거나 우선순위가 높은 작업을 초기 사이클에 배치하고 그렇지 않은 것들을 나중의 사이클에 배치해서 일정을 계획하게 된다\n\n\n\n위 표를 보면 UC3은 우선순위가 높지만 선행 작업이 있기 때문에 밀린 케이스고\nUC8의 경우에는 선행작업은 없지마 우선순위가 낮기 때문에 밀린 케이스이다\n그리고 생산성에 관한 부분은 위 그림에서 오른쪽 위에처럼 주당 최대 생산성을 잡아놓는다\n위의 예시에서 한 사이클은 3주로 구성되어있기 때문에 한 사이클당 최대로 가질 수 있는 점수는 9점이 되고 1 사이클에는 그 점수를 다 사용한 것을 볼 수 있다\n그리고 2 사이클에는 7점으로 2점을 남겼고 3 사이클에서도 9점을 맞췄다\n하지만 최대 생산성을 넘어설 경우에는 해당 사이클에 다 못끝낼 가능성이 있기 때문에 일정을 조정하게 된다\n\n인적 자원 관리 §\n인적자원 관리가 필요한 이유 §\n\n프로젝트에 딱 맞는 이상적인 인력이 투입되지 않을 가능성은 항상 있다\n예를 들면 뭐 돈이 없다던지 그러한 이유때문에\n또한 기존의 인력으로만 프로젝트를 진행하다 보면 그사람들만 경험이 쌓이게 되니까 조직에서는 신입을 뽑아서 프로젝트에 투입시켜 교육시키는 행동을 하기도 함\n관리자는 이러한 제한된 인적자원 속에서도 프로젝트를 잘 관리해야한다\n\n소프트웨어 개발 팀 구성하기 §\n\n구성할 때에는 프로젝트의 규모가 제일 큰 영향을 주게 된다\n왜냐면 프로젝트의 규모가 크다면 요구사항이 불분명하거나 변경될 가능성이 높아지기 때문에 사람도 많아야되고 의사소통의 기회도 더 많이 가져야 하기 때문\n\n소프트웨어 개발 팀의 세가지 형태 §\n1. 계층형 팀 - 수직관계가 분명함 §\n\n\n보통 이런식으로 경험과 실력을 기준으로 위아래를 나누게 된다\n프로젝트 관리자가 시스템 전반에 대한 지휘를 하고\n고급 프로그래머가 서브 시스템에 대한 지휘를 하게 된다\n그리고 고급 프로그래머와 초급 프로그래머 사이에는 기술적인 소통이 많이 오가고\n프로젝트 관리자와 고급 프로그래머 사이에는 진행상황 보고 등의 업무적인 소통이 많이 오가게 된다\n장점으로는 (특히 대규모 프로젝트같은 경우)소프트웨어의 구조가 계층적으로 구성되어있는 경우에는 소프트웨어의 구조와 유사하게 계층형으로 팀을 구성하여 효율적으로 운용할 수 있다는 것이다\n단점으로는 일을 잘하는 고급 프로그래머가 관리업무를 맡게 되어 역량 발휘를 제대로 못할 수도 있고\n보통 바로 윗 계층이랑 소통하기 때문에 의사 전달 경로가 길어져 의사소통이 제대로 되지 않을 수 있다는 것이 있다\n\n2. Egoless Team - 수평적인 분위기 §\n\n수평적이라는 말답게 구성원들이 동등한 책임과 권한을 갖고있으며 자신의 일을 알아서 수행하거나 여럿이서 협동하여 수행하게 됨\n또한 권한이 동등하기 때문에 민주주의 방식의 의사결정이 이루어지게 된다\n장점으로는 작업 만족도가 올라간다 - 더 책임감을 느끼고 적극적으로 임하게 됨\n또한 의사교류가 더 활발하게 일어나며\n복잡하고 이해되지 않는 장기 프로젝트같은 경우에는 다같이 머리를 맞대로 이해하며 진행되는 것이 좋기 때문에 이러한 프로젝트에도 장점이 된다\n단점으로는 책임이 명확하지 않은 일들이 생길 수 있다는 것과 의사결정이 미뤄질 수 있기 때문에 대규모 프로젝트에는 적합하지 않더라\n\n3. Chief Programmer Team(책임 프로그래머 팀) - 수직관계와 수평관계가 섞여있는 형태 §\n\n이것은 책임 프로그래머의 통제 하에 작은 규모의 팀이 움직이는 형태이다\n우선 책임 프로그래머는 제품을 설계하고, 주요부분을 코딩하며, 의사결정을 하거나 작업을 지시하는 제일 권한이 쎈 사람이고\n프로그램 사서라는 역할이 있는데 프로그램 리스트, 문서, 테스트 계획 등을 관리하는 다소 행정적인 업무를 하는 사람이다\n또한 책임 프로그래머 바로 아래에 있는 보조 프로그래머는 기술적인 부분에 대해 책임 프로그래머와 상의하거나, 부분적으로 설계를 할 수 있고, 고객 등의 외부사람과 접촉하는 일을 한다\n말단에 있는 프로그래머는 그냥 모듈단위로 코드 짜고 테스트하고 디버깅함\n장점으로는 의사결정권자가 있기 때문에 이러한 결정을 빠르게 내릴 수 있고\n소규모 프로젝트나 초보 프로그래머를 훈련시키는 계기로 적합하다는 점이다\n단점으로는 책임 프로그래머의 역량에 프로젝트의 성패가 좌우될 수 있다는 점이 있다\n\n효과적인 팀의 규모를 선택하기 §\n\n팀의 규모를 선택할 때에는 Man-Month와 같은 지표가 있으면 선택하는 데에 많은 도움이 되지만\n그렇다고 해서 팀의 규모가 커진다고 무조건 좋아지는 것도 아니다 - 사람이 많으면 배가 산으로 가는거지\n팀의 크기는 필요한 지식의 총량과 정보교환이 감소하도록 정해야 한다 - 이유라도 좀 설명해주면 안되나\n그리고 이미 했던 프로젝트를 반복하는 경우에 팀의 규모가 바뀔 수도 있다더라\n또한 팀의 스케줄을 맞추지 못할거 같아 팀의 인원수를 늘리는 것은 바람직하지 않다 - 작업을 조정하고 새로 교육시키는 등의 추가적인 시간이 필요하기 때문\n\n팀에게 필요한 기술 §\n\nArchitect : SW Architecture 를 설계하는 일\nProject Manager : 프로젝트의 진행을 관리하는 일\nConfiguration management &amp; build specialist : 소프트웨어가 변경되는 것을 관리하던가 버전을 관리하는 일\nUI specialist : UI 설계\nHardware &amp; third-party SW specialist - 하드웨어나 우리가 만들지 않은 외부 소프트웨어에 대한 지식\nUser documentation specialist : 사용자 설명서 잘만드는거\nTester : 소프트웨어를 테스트해보는 것\n\n\n위의 기술들이 필요하며 한 기술을 여러명이 맡거나, 한명이 하나씩 맡을 수도 있고 여러개 맡을 수도 있다더라\n\n프로젝트 위험 관리 §\n\n위험 관리라는 것은 위험을 식별하고 프로젝트에 끼칠 영향을 추정해 최대한 줄일 수 있게 하는 것이다\n\n위험의 종류 §\n\nProject Risk : 일정이나 자원에 영향을 미치는 것\nProduct Risk : 제품의 품질에 영향을 미치는 것\nBusiness Risk : 조직적인 차원에서 영향을 미치는 것\n\n\n예를 들면 팀원이 나가는 Staff turnover 경우에는 일정과 인적 자원에 영향을 미치므로 Project Risk가 되는 것이다\n그리고 제품을 개발하는데 필요한 케이스 도구(뭐 코드 생성기 같은 느낌인듯)의 성능이 생각보다 좋지 않은 CASE tool under-performance의 경우에는 제품의 품질이 안좋아지므로 Product Risk가 되는 것\n또한 경쟁사에서 먼저 상품을 내놓는 Product competition의 경우에는 우리 제품의 판매량이 저조할 우려가 있으므로 Business Risk가 되는 것\n\n위험 관리 프로세스 §\n\n\nRisk Identification : 위의 세 분류 각각에 대해 일어날 수 있는 위험들을 종합함\n\n예시\n\n\n\n\n\nRisk Analysis : 위험이 일어날 수 있는 가능성 및 해당 위험이 일어났을 경우 심각성평가\n\n예시\n\n\n\n\n\nRisk Planning : 해당 위험이 일어났을 경우 대처 프로토콜을 세워 놓는 것\n\n회피하기 위한 Avoidance strategy\n최소화하기 위한 Minimization strategy\n비상시에 대처하기 위한 Contingency plan등을 계획한다\n예시\n\n\n\n\n\nRisk Monitoring : 프로젝트 전반에 걸쳐 위험에 대해 계속 모니터링함\n\n정기적으로 평가하여 위험의 발생 가능성이나 위험의 심각성 등등을 지속적으로 업데이트함\n즉, Risk identification, analysis, planning을 정기적으로 수행해 업데이트하는 것\n\n\n"},"originals/softwareengineering.fall.2021.cse.cnu.ac.kr/03.-요구사항-분석":{"title":"03. 요구사항 분석","links":[],"tags":[],"content":"\n\n                  \n                  충남대학교 컴퓨터공학과 김현수 교수님의 &quot;소프트웨어 공학&quot; 강의를 필기한 내용입니다. \n                  \n                \n\n\n\n                  \n                  다소 잘못된 내용과 구어적 표현 이 포함되어 있을 수 있습니다. \n                  \n                \n\n요구사항 분석 과정 §\n\n”어떻게 구현할지”가 아닌 “무엇을 구현할지”에 관심을 가져야 한다\n\n\n\n그래서 뭐 뻔한얘기지만\n일단 문제가 무엇인지를 파악하기 위해 문제가 발생하게된 배경과 그 문제의 성격, 문제가 미치는 범위에 대해 파악한다\n그리고 사용자가 소프트웨어에 대해 어떤 것을 필요로 하는지 취합 하고\n취합한 요구사항을 분석하고 문서로 작성한 후\n사용자가 요구한 사항과 일치하는지 검토하고 일치하지 않는다면 다시 취합하는 과정부터 반복한다\n조금 더 자세히 알아보면\n\n도메인 분석 §\n\n일단 도메인은 다음의 예로 이해하는 것이 최고다\nATM을 개발한다고 할 때의 도메인은 은행 업무 이고 도메인 전문가는 은행원 이 된다\n즉, 도메인이라는 것은 해당 소프트웨어를 사용할 고객이 일하는 분야(비즈니스, 기술)를 일컫는 것이고\n도메인 전문가는 그 도메인의 업무를 잘 알고 이해하고있는 사람을 일컫는 것이다\n도메인 분석을 통해 얻을 수 있는 이점은 다음과 같다\n\n일단 이해당사자(고객 / 사용자, 개발자, 관리자)들 간 더욱 효과적으로 소통할 수 있고\n따라서 빠르게 요구사항을 취합할 수 있어 개발기간이 단축될 수 있다\n또한 문제를 더 심도있게 이해할 수 있기 때문에 더 좋은 결과물을 낼 수 있고\n따라서 트렌드를 예측할 수 있어 미래를 예측해 볼 수 있기 때문에 확장성이 높은 결과물을 낼 수 있게 된다\n\n\n\n도메인 분석서의 구조 §\n\n개요 - 이 글이 무엇에 대한 것인지, 이 글을 읽을 대상은 누구인지 등등\n용어 - 이 글에서 등장하는 용어들에 대한 설명\n개괄적 지식 - 도메인 전문가가 알고 있는 해당 도메인에 대한 지식(뭐 이 비즈니스가 어떻게 돌아간다던지, 어떤 기술을 이용한다던지, 기술이 어떻게 동작한다던지 등등)\n고객과 사용자 - 이 소프트웨어를 누가 의뢰했는지(고객), 그리고 이 소프트웨어를 누가 사용할 것인지(사용자)\n환경 - 소프트웨어가 구동될 환경\n작업과 수행절차 - 해당 프로젝트에 동원되는 인력들에 대해 그들이 담당하는 작업과 절차, 그리고 (특히 도메인 전문가에 대해) 그들만이 알고있는 노하우(쉬운 방법)\n경쟁 소프트웨어 - 이미 시장에서 판매되어 사용되고 있는지의 여부와 장단점\n다른 도메인과의 유사성 - 우리가 다루고 있는 도메인과 유사한 도메인이 있다면 그것과의 공통점과 차이점\n\n예를들어 도서 대출시스템과 영화 대출 시스템 등\n\n\n\n문제 정의 §\n\n문제라는 것은 고객이나 상요자가 직면한 어려움이고\n이 문제를 해결하는 것은 일반덕으로 소프트웨어의 개발을 필요로 하고\n문제의 해경른 생산성이나 매출을 높일 수 있는 기회가 되기도 한다\n\n범위 설정 §\n\n범위를 설정한다는 것은 우리가 개발하고자 하는 소프트웨어가 해결할 수 있는 모든 문제들을 생각해 보는 것이다\n만약 범위가 너무 크다면, 일부는 배제해야 할 것이고\n범위가 너무 좁다면 해당 소프트웨어가 우리의 궁극적으로 해결하고자 하는 문제 파악하고 이를 해결 할 수 있는지 검토해 봐야 한다\n\n요구사항 추출 §\n\n요구사항 : 짧고 간결하게 표현된, 관련자들이 동의한, 문제를 해결하기 위한, 소프트웨어가 제공해야 할 기능\n\n요구사항에 따른 프로젝트의 분류 §\n\n\n요구사항이 결정되지 않은 A와 C의 경우에는 보통 상업용 SW인 경우가 많고\n고객에 의해 요구사항이 결정된 B와 D의 경우에는 의뢰 SW인 경우가 많다\n\n요구사항의 분석 §\n\n기능적 요구사항은 결과물이 제공해야 할 기능을을 말하는 것이다\n\n입력 기능 : 사용자 혹은 다른 시스템으로부터 어떤 정보를 입력할 수 있는 지\n출력 기능 : 사용자 혹은 다른 시스템에게 어떤 정보를 출력할 수 있는 지\n저장 기능 : 시스템이 어떤 정보를 저장할 수 있는 지\n컴퓨팅 기능 : 시스템이 어떤 연산을 할 수 있는 지\n타이밍과 동기화 : 특히 하드웨어 장치제어나 리얼타임 프로젝트의 경우, 즉각적인 반응이 가능한지\n\n\n비기능적 요구사항은 기능이 아닌 성능이나 효율, 반응시간, 품질등을 말하는 것이다\n\n얘네는 객관적인 지표(수치)로 검증이 가능해야 하며, 구현 이후 검증절차가 반드시 이루어져야 함\n소프트웨어의 품질 특성 측면\n\n반응시간 : 요청에 대한 결과가 얼마나 빠르게 나오는 지\n처리량 : 분당 처리 트랜잭션의 수가 몇개인지\n자원 사용량 : 사용하는 메모리, 전기 등의 자원은 얼마정도인지\n신뢰성 : 시스템이 고장나지 않고 제대로 동작할 가능성은 얼마나 되는지\n가용성 : 시스템이 실행되고 준비되어있는 시간은 얼마나 되는지 - Down-Time(DT) 은 기준 시간(예를들어 1년) 중에 얼마나 되는지\n고장에서의 회복 : 고장으로 인해 발생할 수 있는 피해의 최대치는 어느정도인지\n유지보수, 확장, 재사용성의 허용 : 유지보수나 시스템의 확장, 그것을 재사용하는 것이 어느 정도까지 가능한지\n\n\n환경과 기술적 측면\n\n플랫폼 : 소프트웨어가 돌아가는 환경 - 뭐 예를 들면 최소 램 4Gb짜리 윈도우 컴퓨터에서 돌아갈 수 있도록 해라\n사용 기술 : 소프트웨어를 만드는데 사용할 프로그래밍 언어나 프레임워크, 라이브러리 등의 기술 - 뭐 예를 들어 전자정부 프레임워크를 이용해 자바로 개발해라\n\n\n계획과 방법론적인 측면\n\n방법론 : 사용할 개발 프로세스(방법론) - 뭐 애자일을 이용해라 등\n비용과 납기일 : 얼마를 이용해서 개발해라, 언제까지 개발해라 - 보통 계약서에 많이 명시됨\n\n\n\n\n예시 보고 기능적 / 비기능적 요소 구별하는 문제는 안나온댄다\n\n요구사항 추출 방법 §\n\n관찰 : 사용자의 업무를 관찰하는 것 - 숨겨진 문제를 파악하기에 좋음\n인터뷰 : 관련 당사자를 만나 인터뷰함 - 요구사항의 오해를 줄일 수 있음\n브레인스토밍 : 아이디어를 정제하지 않고 쏟아내는 것 - 요구사항의 고려 범위가 넓어질 수 있음\n프로토타이핑 : 시범적인 시스템 구현 - 요구사항에 대한 빠르고 현실적인 피드백을 받을 수 있음\n유스케이스 분석 : 시스템 외부 기능 파악 - 체계적 요구사항 분석 - 뭔지 모르겠음\n\n관찰 §\n\n사용자의 업무를 관찰하고 기록\n숨겨진 문제를 파악하기에 좋고 자세한 설명도 들을 수 있음\n예를 들어 비디오 촬영을 하며 기록할 수 있다\n하지만 시간이 많이 소요된다는 단점이 있다\n\n인터뷰 §\n\n관련자 뿐만 아니라 경쟁 제품 이용자나 마케팅 담당자와 같은 관련 없는 사람들에게도 인터뷰를 진행함\n그리고 인터뷰 대상자들의 여유시간에 진행 - 시간에 쫒기면 안된다네\n대상자 선정 → 일정 계획 → 질문 작성 → 인터뷰 → 분석 및 정리의 과정으로 이루어진다\n또한 양질의 질문을 마련해놓는 등 미리 철저히 계획하여야 효율적으로 많은 정보를 얻어낼 수 있음\n\n\n\n\n위의 경우는 좀 알아둘 필요가 있음 - 일단 최소한으로 시스템이 갖춰야 할 것이 뭔지 먼저 파악하고, 그리고 다른 부가 기능들에 대해 질문을 하는 것이 좋다 - 이런 우선순위에 대한 고민 없이 그냥 물어보면 너무나도 많은 아이디어가 나올 가능성이 있어 쓸데없는 기능이 시스템에 포함될 가능성이 있다\n\n\n\n이것도 걍 보고 읽어도 될듯\n\n브레인스토밍 §\n\n뭔지는 알제? 걍 생각나는 아이디어 다 쏟아내는거\n하지만 회의가 약간 산으로 갈 수도 있기 때문에 훈련된 요원이 진행을 맡는 것이 좋댄다\nJoint Application Development(JAD) : 브레인 스토밍의 한 방법으로 시스템 개발에 대해 논의할 때 개발자들끼리 하는 것이 아닌 최종 사용자를 포함시켜 같이 브레인스토밍을 해 요구사항을 정의해 나가는 것\n\n보통 카페같은 별도의 장소를 마련해 모여서 집중적으로 브레인스토밍을 하는 방식으로 진행된다\n\n\n브레인스토밍의 과정은 다음과 같다\n\n\n\n저기 보면 5번 문항이 뭔 소린가 할 수 있는데 종이 한장을 마련하고 질문을 던진 후 한사람부터 시작해 그 질문과 관련된 아이디어를 하나 적고 다음사람으로 넘겨줌. 그럼 다음사람은 그걸 받고 전사람이 적은 것을 참고하거나 아니면 새로운 아이디어를 하나 적고 다음사람에게 넘겨주는 방식으로 진행됨\n그니까 5번 문항의 종이 한장에 하나의 아이디어를 적으라는 것은 내차례가 오면 한가지의 아이디어만 적으라는 소리다\n저기 토론을 유도할 질문이라는 게 있는데 그건 아래 사진 참고해라\n\n\n\n토론을 유도할 질문이기 때문에 예 아니오로 답변할 수 있는 단순한 질문이 아닌 아이디어가 나올 수 있는 질문을 마련해야 된다\n\n프로토타이핑 §\n\n프로토타입은 뭐 알겠지만 시스템의 예상 가능한 기능 몇가지를 빠르고 단순하게 만들어 본 것이다\nPaper prototype : UI를 종이에 그리고 화살표 등으로 사용 시나리오를 보여주는 형태\n\n이러한 프로토타입을 보고 있으면 또 새로운 아이디어가 떠오르기도 하고, 다양한 피드백들을 받을 수 있기 때문에 단순하지만 효율적이다\n또한 작성방법이 쉽기 때문에 각자의 관점에 따른 여러가지의 프로토타입을 병행하여 작성해 비교하는 방식으로 진행하는 것도 가능하다\n\n\nMock-up the UI : 프로토타이핑 전용 언어로 프로그램을 작성해 작동 과정을 좀 더 동적으로 보여주는 것\n\n하지만 작동 과정만 시나리오에 따라 보여주기 때문에 컴퓨팅이나 DB, 다른 시스템과의 상호작용 등은 불가능하다\n\n\n또한 시스템의 알고리즘이나 데이터베이스같은 특별한 측면에 대해서 실현가능성 등을 보기 위해 프로토타입을 만들어보기도 한다\n\n요구사항 문서화 §\n\n요구사항을 문서화 할때는\n요구사항의 outline만 대강 잡는 식으로 간단하게 문서화하기도 하고\n수천 페이지의 복잡하고 자세한 명세를 하는것도 가능하다\n또한 대규모 시스템의 경우에는 시스템을 서브시스템으로 나누어서 계층적으로 정리하기도 한다\n\n상세 수준 정하기 §\n\n\n위에서 개발을 위한 계약부분은 외주 계약의 경우에는 우리가 원하는 것을 자세하게 적어줄 필요가 있고, 정부기관 계약의 경우에는 정해진 양식이 있어 그거에 따라 적어야 될 경우도 있다는 것을 말하고 있는 것이다.\n\n문서의 구성 §\n\n\n일단 명세서의 구성을 자세히 살펴보면 위와 같다\nIntroduction 부분에는 문서의 목적, 범주, 용어 등을 적어주면 된다\n그리고 External Interface Requirements부분을 좀 보면\n\nUser Interface는 니가 아는 그 UI를 말하는 거고\nHardware Interface는 잘 이해 안되는데 SW가 탑재되어 작동하게 될 HW에 대한 인터페이스를 말한댄다\nSoftware Interface는 해당 시스템과 다른 시스템이 어떻게 상호작용 하는지를 말하는 거고\nCommunication Interface는 걍 통신 인터페이스다\n\n\n그리고 System Feature에는 기능적 요구사항이 주로 들어간다고 보면 되고\nOther Nonfunctional Requirements에는 비기능적 요구사항\nOther Requirements는 위의 항목에 넣기 애매한 그 외의 제약조건들이 들어간다\n\nIntroduction §\n\n다음의 네가지가 들어간다\n\n\n\nStakeholder 는 프로젝트와 금전적 등의 이익관계가 있는 사람들을 말한다\n\n뭐 고객, 사용자, 개발자, 관리자 등\n\n\n\nExternal Interface Requirements §\n\n위에서 말한거처럼 소프트웨어와 사용자, 하드웨어, 다른 시스템 등등과의 소통에 있어 필요한 인터페이스를 설명하는 부분 이다\n\n\n\nUI 는 걍 한번 읽어봐라\n\n\n\nHardware Interface 는 위에서 말한거처럼 시스템이 작동하게 될 하드웨어에 대해 기술하는 부분이라고 생각하면 될거같다\n\n\n\n솔직히 필기하는것보다는 설명 한번 읽어보고 사례를 통해 감을 잡는게 나을거같다\n\n\n\n위에서 간력한 설명만 보면 Software Interface와 Communication Interface와 무슨 차이점이 있는건지 헷갈릴 수 있는데\n사례와 자세한 설명을 보면 Software Interface는 어떤 외부 시스템과 어떠한 flow를 통해 어떤 것을 소통할 것인지가 중점인 반면, Communication Interface는 시스템에서 사용할 HTTP와 같은 표준 프로토콜이나 API 형식 등에 대해 논하고 있는 것을 알 수 있다.\n\nSystem Feature §\n\n\n그리고 아래의 사례에서도 계속 확인할 수 있는 내용인데 각 요구사항은 일련 번호나 태그 등의 식별자로 유일하게 식별되야 한다더라\n\n\n\n사례도 한번 읽어봐라\n\nOther Nonfunctional Requirements §\n\n비기능적 요구사항인데\n비기능적 요구사항들 중에 해당 비기능에 대해 요구사항이 없으면 생략할 수도 있다\n\n\n\n우선 성능 제약 조건인데 읽으면 된다\n\n\n\n신뢰성 제약 조건에 대한 내용이다.\n\n\n\n보안 제약 조건에 대한 내용이다.\n\n\n\n위처럼 다영한 측면의 품질에 대해서 제약조건(요구사항)을 마련할 수 있다.\n\nOther Requirements §\n\n\n하드웨어 제약조건의 예시로 하드와 램의 크기에대해 요구사항을 명시하거나 통신 대역폭에 관한 내용을 명시할 수도 있다\n\n요구사항 검토 §\n\n\n저기서 80대 20 법칙은 20의 투자로 80의 문제를 해결 할 수 있느냐이다\n\n즉, 80대 20 법칙을 만족하는 것은 우선순위가 높은 것이고 그렇지 않으면 우선순위가 낮아지게 되는 것으로 생각할 수 있다\n\n\n그리고 마지막 설계 제한은 요구사항 명세를 할 때에는 요구사항의 구현보다는 어떤 요구사항이 있을지에 더 포커스를 맞추고 있기 때문에 구현의 관점때문에 요구사항을 너무 적게 잡은 것은 아닌지 등을 검토해 볼 필요가 있는 것\n\n요구사항 변경 관리 §\n\n비즈니스가 변한다던가, 기술이 변경된다던가, 문제를 더 심도있게 이해했다거나의 이슈를 통해 요구사항은 계속해서 바뀔 수 있다\n\n\n\n고려해야될 점은 위와 같다\n저 중에서 마지막 위장된 확장은 요구사항의 명세는 보다 나은 시스템의 구축에 집중해야 하기 때문에 시스템의 규모를 확장하는 것은 되도록이면 피하는게 좋다는 것이다.\n\n즉, 기능을 늘리기보다는 지금 있는 기능을 더 좋게 하는 것이 목적이 되어야 한다는 것이다\n\n\n"},"originals/softwareengineering.fall.2021.cse.cnu.ac.kr/04.-유스케이스-모델링":{"title":"04. 유스케이스 모델링","links":[],"tags":[],"content":"\n\n                  \n                  충남대학교 컴퓨터공학과 김현수 교수님의 &quot;소프트웨어 공학&quot; 강의를 필기한 내용입니다. \n                  \n                \n\n\n\n                  \n                  다소 잘못된 내용과 구어적 표현 이 포함되어 있을 수 있습니다. \n                  \n                \n\n유스케이스 모델링 §\n\n얘는 요구사항을 좀 더 명확하고 많이 수집하기 위해 사용한댄다\n일단 유스케이스라는 것은 사용사례라고도 하는데 사용자가 어떠한 요청을 할 수 있고, 그 요청에 대해 어떠한 처리가 이루어지고, 그로인해 어떠한 결과를 사용자에게 주어 사용자가 어떠한 경험을 하게 되는지를 명세한 것이라고 할 수 있다\n즉, 시스템이 어떤 기능(function, service)을 제공하는지, 그리고 그 기능들은 어떠한 프로세스로 이루어지는지 설명한 것이라고도 말할 수 있는것\n\n걍 시스템이 제공하는 기능들 각각을 유스케이스라고 생각하면 될듯\n\n\n대충 뭔지 감은 오제?\n뭐 피피티에는 프로세스에 대해서 조직이나 개인 사용자에게 가치 있는 것을 생산하기 위해 필요한 사건, 행동, 거래의 연속 이라고 어려운 말을 적어놨는데 그냥 처리 과정이라고 심플하게 이해해도 될거같음\n그리고 이렇게 보면 시나리오와도 비슷한거같다는 느낌을 받을 수 있는데\n실제로는 시나리오는 어떠한 목표를 위해 수행되는 일련의 행동이고 가능한 모든 시나리오를 모은 것을 유스케이스라고 한댄다\n\n즉, 시나리오는 유스케이스의 한 원소인 셈\n뭔소린지 감이 안온다면 예시 보면 감이올거임\n계좌 출금 요청 이라는 유스케이스는 잔고가 충분한 계좌에서의 출금 이랑 잔고가 부족한 계좌에서의 출금 이라는 시나리오들로 구성될 수 있는 것\n\n\n\n유스케이스의 목적 §\n\n기능 요구사항(시스템이 뭘 해야하는지)를 명확하고 일관된 설명으로 제공하고자 하는 것에 그 목적이 있다\n그리고 이러한 가능 요구사항을 개발자들에게 전달해 개발과정에 도움이 되고자 하는 것이며\n유스케이스는 테스트 케이스를 작성하는데에도 참고할 만한 자료가 되고\n뭐 기능 요구사항에서 프로그램적인 클래스나 메소드들을 도출해 내는 과정에도 도움이 되고\n유스케이스 모델을 변경해서 시스템을 변경하거나 확장하는 것을 단순화핫할 수도 있댄다\n유스케이스 모델링을 하고 나면 Usecase Diagram과 Usecase Description두가지의 결과물이 산출된다\n\nUsecase Diagram, Description §\n\n\n일단 가운데 네모가 시스템 이고\n네모 안에 들어가있는 동그라미들이 시스템이 제공하는 기능(유스케이스) 이다\n그리고 양옆에 사람이 있는데 얘네들은 사용자(Actor) 이다\n위의 예시를 보면 일반 사용자는 첫번째 기능을 사용할 수 있고 뭐 보험사 직원같은 경우에는 세가지 기능을 다 사용할 수 있는 것을 한눈에 볼 수 있다\n즉, 시스템이 제공하는 기능과 그 기능을 어떤 사람들이 이용하는지 그림으로 나타낸 것을 Usecase Diagram이라고 하더라\n단, 이때의 기능은 사용자 관점에서의 기능들만 명시하게 된다\n뭐 위의 그림에서도 쉽게 알 수 있듯이 시스템, 기능, 사용자 세개의 구성요소로 이루어진댄다\n그리고 각각의 그림에 대한 자세한 설명을 하는 부분을 Usecase Description이라고 한댄다\n\n유스케이스 모델링 절차 §\n\n1. 시스템 정의 §\n\n어떤 기능들이 시스템에 포함되고, 어떤것들이 들어가지 않는지를 기술하는 것\n\n2. 액터 찾기 §\n\n액터라는 것을 위에서는 그냥 사용자라고 대충 말했지만, 좀 더 정확하게 말하면 시스템을 사용하는 객체의 역할이라고 말할 수 있음\n\n시스템을 사용하는 사람이 아닌 객체라고 표현한 것은 사용하는 주체가 사람일 수도 있지만 하드웨어일 수도 있고, 다른 시스템일 수도 있기 때문이고\n역할이라는 말뜻은 아래의 예시 보면 좀 감이 올거다\n\n은행 시스템의 경우에 대출을 담당하는 사람은 대출 담당 역할 을 맡고 있는 것이고\n해당 은행에 계좌를 가지고 이용하는 사람은 고객의 역할 을 맡고 있는 것\n뭐 역할이라는 말의 의미를 분류, 그룹의 뉘앙스로 이해해도 될거같음\n\n\n액터는 주 액터 - 기능을 사용하고 결과를 받아보는 대상과 부 액터 - 기능이 잘 작동하게하기 위해 지원해주는 대상으로 분류할 수 있댄다\n그리고 유스케이스는 해당 유스케이스를 처음에 작동시키는 Initiating actor와 유스케이스를 사용하는 Participating actor가 있더라\n여기서 Initiating actor가 반드시 필요하다는 사실에 주목할 것 - 해당 유스케이스를 개시/작동시키는 액터가 반드시 있어야 된다\n\n\n\n\n\n액터를 찾는 것은 위의 그림에 나와있는 고민을 해보면 된다\n\n\n\n액터는 위의 그림처럼 졸라맨으로 그리거나, Actor 클래스로 표현한다\n\n\n\n그리고 위처럼 상속관계를 이용해 일반화된 액터를 표현하는 것도 가능하다\n액터들의 공통점을 생각해 하나의 액터로 일반화시키는 것\n\n3. 유스케이스 찾기 §\n\n유스케이스를 찾기에 앞서 유스케이스가 만족해야 하는 특징들 몇가지를 다시 한번 정리해보면\n\n반드시 액터에 의해 개시되어야 함\n액터에게 결과를 제공해야함\n어떤 기능의 일부분만 제공하는 것이 아닌 특정 기능의 전부를 제공하는 완전한 형태여야 함 - 요청과 그에 대한 결과가 명확하게 드러나야된다는 것\n\n\n\n\n\n유스케이스를 찾을때는 위의 질문들을 생각하면서 어떤 유스케이스가 있을지 고민해보면 된다\n\n\n\n유스케이스를 찾고 나서는 위에서 설명한 Usecase Diagram을 통해 그림으로 표현한다\n\n4. 유스케이스 기술(Description) §\n\n유스케이스의 기술에는 다음과 같은 것을 포함시키면 된다\n\n유스케이스가 달성하고자 하는 궁극적인 목표\n유스케이스의 개시와 관련된 것 - 방법, 조건 등등\n전형적인 처리 순서(Typical flow) - 정상적으로 작동할때의 처리순서\n예외적인 처리순서(Alternative flow) - 뭐 어떤 에러가 발생했다던지 그러한 경우에의 처리 - 이건 너무 자세히 적지 말아야 한댄다\n유스케이스가 완료되어 결과물을 액터에게 전달하는 방법, 시점, 조건 등\n유스케이스를 작성할때는 텍스트로 표현하거나, 플로우 차트등을 이용한 시각자료인 Activity diagram등을 활용할 수 있다\n또한 일정한 템플릿(형식) 을 만들어놓고 활용할 수도 있다\n\n\n\n\n\n뭐 이런식으로 템플릿을 정해서 하면 된댄다\n위의 그림을 좀 자세히 보면\n\nBrief description에 뭐 유스케이스의 목표라던지 그런게 들어가고\nSecondary actor는 굳이 안적어도 되고\nPrecondition은 유스케이스의 개시 조건을 말하는거고\nMain flow는 뭐 니가 생각하는 그거 맞고\nPostcondition은 유스케이스의 종료조건을 말하는거고\nAlternative flow도 위에서 설명한 그거다\n\n\n\n\n\n뭐 예시 한번 읽어보면 이해될거임\n\n5. 유스케이스 간의 관계 정의 §\n\n\n일반화(Generalization) : 니가 생각하는 상속 말하는거 맞음\n\n뭐 부모의 플로우나 그런것들을 다 물려받고\n자식 유스케이스에서는 부모의 유스케이스 플로우에 과정을 추가할 수 있고(Override의 개념)\n부모 유스케이스를 사용할 수 있는 곳에는 자식 유스케이스로 대체할 수 있는 등\n\n\n\n\n\n포함 관계(Include Relationship) : 공통적으로 수행하는 플로우를 묶는것\n\n뭐 상속과 비슷하기는 하다고 생각할 수 있는데 상속은 의미적인 부분에서 일반화시키거나 구체화하는 것인 반면\n포함관계는 의미적으로는 관련이 없지만 공통된 절차가 들어있다면 그것을 모으는 것을 의미함\n뭐 위의 예시 보면 뭔소린지 감올거임\n상속은 말그대로 클래스 상속이라고 생각하면 되고 포함관계는 마치 공통된 코드를 함수를 만들어 분리하는 것의 차이 정도로 생각하면 된다\n함수를 만들어 분리하는 것과 유사하기 때문에 유스케이스의 진행 플로우 중간에 다른 유스케이스를 포함하는 것이 가능하다 - 코드 실행 중간에 함수를 호출해 그쪽으로 흐름이 넘어가는 것과 유사\n그리고 포함되는 유스케이스가 완전할 경우에는 일반적인 유스케이스처럼 액터의 개시에 의해 즉시 사용 가능하지만 완전하지 않은 불완전한 유스케이스인경우에는 액터가 직접적으로 개시하는 것은 안된다\nIncluding use case = Base use case\nIncluded use case = Inclusion use case\n그리고 당연히 Base usecase의 경우에는 Inclusion usecase의 플로우를 필요로 하기 때문에 Base usecase없이는 불완전한 유스케이스가 된다\n\n\n\n\n\n확장관계(Extension Relationship) : 이것도 일반화 관계랑 좀 유사하다\n\n플로우를 진행하다가 특정 지점에서 특정 조건을 만족하면 추가적인 플로우를 진행한 후 원래의 플로우로 돌아갈 때 그 추가되는 유스케이스를 Extension Usecase라고 하고, 원래의 유스케이스를 Base Usecase, 그리고 이 둘의 관계를 확장관계라 하더라\n이것도 플로우의 중간에 흐름이 달라진다는 면에서는 포함관계와 어느정도 유사하다고 볼 수 있지만 포함관계의 경우에는 공통된 부분을 묶는 것에 관심이 있었으면, 얘는 특정 조건시에만 호출되어야 하는 분기문 정도로 생각할 수 있음\nBase Usecase에 추가되는 지점을 Entension Point라고 한다\n특정 조건이 맞아야 확장된다는 특징은 Alternative flow를 모델링하는데에도 사용할 수 있다\n그리고 포함관계와 또 다른 차이점은 포함관계는 Base usecase만으로는 불완전하지만 확장관계의 경우에는 Base usecase만으로도 독립적으로 작동하는 완전한 유스케이스라는 것이다\n당연히 Extension usecase는 파편이기 때문에 보통 불완전하다\n\n\n\n6. 유스케이스 검증 §\n\n올바르게, 만들어진 명세에 따라, 고객 또는 최종 사용자의 요구를 충족시키는 방향으로 개발되었는가를 확인(Verification), 검증(Validation) 하는 것\nUsecase work through라는 과정을 통해 검증할 수 있다\n\n이것은 액터 그룹, 시스템 그룹을 나누어 역할극을 하고 역할극에 참여하지 않은 사람들이 보고 결함을 찾으려고 노력하는 하나의 방법론이다\n\n\n\nUsecase Realization §\n\n유스케이스를 프로그램으로 구현하는 것\n\n\n\n실제 세계(RW, Real World)에서의 유스케이스들이 컴퓨터 세계(CW, Computer World)에서 어떻게 구현되는가를 보이는 것\n뭐 당연한 얘기지만 하나의 유스케이스는 다양한 클래스들과 오퍼레이션(함수)들을 조합하여 완성된다\n\n주의할 점 §\n\nActor generalization, Use case generalization, including, extending등의 방법은 최대한 자제해야 한다 - 모델을 단순화하는 것이 명확하게 드러나고 이해관계자들이 그렇게 하는 것의 의미에 대해 이해할 수 있을 때에만 수행해래는 의미\n\nActor Generalization §\n\n\n이걸\n\n\n\n이렇게 바꿈\n보다시피 일반화를 해서 다이어그램이 단순해 지는것이 명확할 때만 사용해야 된다는 것 기억해라\n\nInclude Relationship §\n\n\n\n\n위처럼 사용할 수 있는데 이것도\n다이어그램이 단순화되는 것이 명확할 때만 사용해야 한다\nInclude관계에서 주의해야 할 점이 기능을 최대한 쪼개서 include하는 것을 지양해야된다는 것(Avoid Decomposition)이다\n최대한 쪼개려 하지 말고 액터가 바라보는 기능단위로 유스케이스들을 구성하는게 바람직하다더라\n\n\n\n위의 그림처럼 하나의 루트에서 시작해서 각기 뻗어나가거나 너무 많은 계층 구조를 가지게 되는 것은 바람직 하지 않고\n계층구조가 많아봐야 2단계로 이루어지는 상태가 바람직하다더라\n\n\n\n위의 그림처럼 너무 세부적인 기능을 유스케이스로 만드는 것도 피해야 된다\n\nExtend Relationship §\n\n\n\n위처럼 사용할 수 있는데 이것도\n다이어그램이 단순화되는 것이 명확할 때만 사용해야 한다\n\n유스케이스 순서화를 피해라 §\n\n\n위의 그림처럼 순서가 중요한 경우에는 그것을 유스케이스 다이어그램에 표현하지 말아야 한다\n순서가 필요한 경우에는 Use case description의 precondition을 이용해라\n\n작성시에의 팁 §\n\n\n위의 그림에서도 주목해야 할 것은\n유스케이스 모델링도 요구사항 명세의 하나의 과정이기 때문에 How가 아니라 What에 집중해야 된다는 것과\n위에서 설명한거처럼 더이상 분할이 안될때까지 기능을 분리해서 작성하는 것이 아닌 액터가 바라보는 기능 단위로 유스케이스 작성을 해야된다는 것이다\n"},"originals/softwareengineering.fall.2021.cse.cnu.ac.kr/05.-클래스-모델링":{"title":"05. 클래스 모델링","links":[],"tags":[],"content":"\n\n                  \n                  충남대학교 컴퓨터공학과 김현수 교수님의 &quot;소프트웨어 공학&quot; 강의를 필기한 내용입니다. \n                  \n                \n\n\n\n                  \n                  다소 잘못된 내용과 구어적 표현 이 포함되어 있을 수 있습니다. \n                  \n                \n\nUML §\n\n객체지향 소프트웨어를 모델링하기 위한 표준 그래픽 언어\n\n종류 §\n\n클래스 다이어그램 : 클래스들과 그들의 관계\n상호작용 다이어그램 : 객체(인스턴스)들이 상호작용하는 방식에 대해 그들의 동작을 표현\n상태 / 활동 다이어그램 : 시스템으로 어떻게 행동하는지를 보여줌 - 객체(인스턴스)들이 상호작용할때가 아닌 내부적으로 어떻게 행동하는지를 말하는 거인듯\n컴포넌트 / 배치 다이어그램 : 시스템을 구성하는 컴포넌트와 그들이 (논리적으로 혹은 물리적으로)배치되는 방식\n\n기능 §\n\n각각의 표기법(도형, 선 등등)마다 의미(Semantics)를 가지고 있음\n확장 매커니즘을 가지고 있음 - 뭐 새로운 Semantic을 정의해서 사용한다던지 이런게 가능함\n관련 텍스트 언어가 있음\n방법론이 아니고 개발을 돕는 하나의 툴이다\n\n모델이란 §\n\n일단 UML등의 모델링이 필요한 이유는\n지금까지 한 요구사항 수집, 명세, 유스케이스 명세 등의 과정은 Real World에서의 일들을 기술하기 위한 것이었다면\n이제는 위에서 명세한 저러한 것을을 Computer World에서 분석하고 명세하기 위한 모델링이 시스템 모델링이고 이들중 하나가 UML인 것이다\n이 과정을 거치게 되면 그 다음에는 설계과정을 뒤이어 하게 되고 그 다음에는 구현을 하게 되는 것이다\n\n\n\n위의 그림이나 읽어봐라\n\n클래스 §\n\n뭔지는 알제? 자료 타입으로 Property와 Method로 구성됨\n\n\n\n속성, Property 같은말이고\nMethod, Operation 같은말인거 당연히 알고있어야되고\n맨 위에 클래스 이름, 중간에 프로퍼티, 마지막에 메소드가 들어간다\n가시성(Visibility) 표현 : -는 private, + 는 public, # 는 protected이다\n프로퍼티는 이름: 타입으로 명시한다\n메소드는 이름(인자: 타입): 반환타입으로 명시한다\n참고로 프로퍼티와 메소드를 생략하고 클래스의 이름만 적는 것도 가능 하다\n\n추상 클래스 §\n\n뭐 당연히 알겠지만\n추상 오퍼레이션(메소드) 는 정의만 있고 구현이 없는 것을 의미하고\n추상 클래스는 인스턴스를 만들지 못하는 클래스를 의미함\n또한 인터페이스는 추상 클래스와 비슷하게 구현된 메소드가 없고 인스턴스를 생성하지 못하는 경우를 의미한다.\n\n연관관계 §\n\n클래스와 객체(인스턴스) 사이의 연관 관계\n실선으로 이어 둘 간의 관계가 있음을 표현하게 된다\n\n\n\n일단 위의 그림에는 안나와있지만 관계 이름을 지어줄 수 있다 - 선 위에다가 동사나 동사구로 지어준다\n그리고 다중성은 위에서 보다시피 연관되는 인스턴스의 갯수를 의미한다\n일반화라는 것은 클래스들간의 상속관계를 말함\n역할 이름은 클래스에 의해 수행되는 역할이라는데 걍 위 그림보고 감잡는게 좋다 - 걍 변수(프로퍼티)이름임\n방향성은 뭐 별거 없음 - 위 그림에서 보는거처럼 저런식으로 연관성의 방향을 명시하는게 가능하다 이거야\n\n방향성에서의 화살표 방향이 헷갈린다면 이렇게 생각하면 된다 - PhoneBook에서는 PhoneNumber를 참조할 수 있으니까 화살표 방향이 저래되어있는 것\n연관관계의 방향성은 기본적으로 양방향 관계이다. 그리고 화살표를 통해 방향을 제한해주는 셈\n\n\n\n다중성(Multiplicity) §\n\n뭐 Cardinality Constraint와 비슷하다\n왜 클래스가 아니고 인스턴스라고 표현하는지 궁금하다면 배열에는 클래스가 아닌 객체가 들어가기 때문이다\n다중성은 표현하지 않으면 1로 간주된다\n그리고 임의의 다수를 표현할때는 * 를 이용하고\n일대일(One-to-One) 은 만약 A와 B가 일대일의 관계라면, A는 반드시 하나의 B와 관게를 맺어야되고 반대로 B또한 반드시 하나의 A와 관계를 맺어야 할때이다\n다대다(Many-to-Many) 은 만약 A와 B가 다대다의 관계라면, A는 여러개의 B와 관계를 맺을 수 있고 반대로 B도 여러개의 A와 관계를 맺을 수 있을 때이다\n얘는 예시로 감을 잡는게 좋음\n\n\n\n\n\n범위를 지정할때는 예를들어 1이상이면 1 … * 로 표현하고 3이상 5이하면 3 … 5 이런식으로 표현한다\n불필요한 일대일 관계를 제거하고 그 둘을 그냥 하나의 클래스로 묶는 것이 더 좋다는 점 주의할것\n\n연관 클래스 §\n\n연관 클래스는 언제 사용하면 되냐면 두 클래스가 연동되었을때 의미가 있는 속성들에 대해 해당 속성을 클래스로 감싸면 된다\n예를들면\n\n\n\n학생과 수업 두개의 클래스가 있을 때 학생이 수업을 수강해야 해당 과목에 대한 학점이 나오기 때문에 이때 수강 클래스에 학점이라는 속성을 둘 수 있는 것\n\n재귀 연관관계 §\n\n클래스 자신과 연관관계를 맺되 해당 관계의 선후가 있는 경우\n예를들면\n\n\n\n과목 A는 과목 B의 선행과목일때 A와 B는 모두 과목이므로 과목 클래스를 재귀 연관관계로 표현해줄 수 있는 것\n\n인스턴스 다이어그램 §\n\n\n위 그림처럼 클래스만 명시하는 것이 아닌 클래스로 생성되는 인스턴스들간의 관계도 명시할 수 있다\n그리고 반드시 해줘야할 것이 인스턴스명:클래스명 의 형식을 지켜주는 것이다\n즉, : 로 클래스명과 인스턴스 명을 구분해주고 밑줄을 그어줘야 인스턴스 다이어그램으로 인식한다는 소리임\n\n전체 / 부분 관계 §\n\nAggregation관계는 전체와 부분(Whole-Part)관계를 나타내는 특수한 연관관계이다\n\n\n\n전체에 해당하는 놈을 Aggregate 혹은 Assembly 라고 부른다\n뭐 그리고 당연한 내용이지만 전체를 제어하거나 소유하면 부분도 제어하거나 소유한다\n\n\n\n그리고 다른 관계와는 다르게 이런식으로 계층구조로 표현할 수도 있다\n\n\n\n그리고 Aggregation이 강한 경우에는 Composition 이라고 부른다\n즉, 전체가 소멸되면 부품도 소멸되게 되고\nA가 B에 포함되면 A는 B와 무관한 C에 포함될 수는 없다 - 온전히 전체에 포함되는 경우\n\n일반화 §\n\n클래스들간의 상속관계\n뭐 뭔지 알제? - 공통부분을 묶어 수퍼클래스로 만드는 것은 일반화, 수퍼클래스의 자식으로 서브클래스를 구체화하는 것을 구체화, 상세화, Specialization이라고 한다\n불필요한 상속을 피해야 한다는 점에 주의하라 - 상속을 한다는 것은 수퍼클래스와 다른점이 있다는 것인데 다른점이 없으면 굳이 할 필요가 없다는 것\n또한 어찌보면 당연한얘긴데 인스턴스는 클래스가 변경되어서는 안된다\n\n\n\n위와 같은 예시일때\nFullTime을 뛰다가 PartTime으로 옮겨가면 클래스가 변경되는 것이므로 문제가 됨\n이때는 FullTime이냐 PartTime이냐를 상태로 두고 상태의 변경으로 처리하는게 맞다\n이렇듯 상태와 상속을 혼동하면 안된다\n\nObject Constraint Language(OCL) §\n\n이건 소프트웨어 모듈의 제약사항을 명세하기 위한 용도로 만들어진 언어이다\n시스템에 대한 논리적인 사실(참인 명제들)만을 나타냄\nside-effect가 없음 - 참이나 거짓이 아닌 결과를 낼 수 없으며 데이터(상태)를 수정하지도 않음\n속성값이 무엇인지, 연관관계가 존재해야 하는지 등에 대해 명세할 수 있음\n\n"},"originals/softwareengineering.fall.2021.cse.cnu.ac.kr/06.-동적-모델링":{"title":"06. 동적 모델링","links":[],"tags":[],"content":"\n\n                  \n                  충남대학교 컴퓨터공학과 김현수 교수님의 &quot;소프트웨어 공학&quot; 강의를 필기한 내용입니다. \n                  \n                \n\n\n\n                  \n                  다소 잘못된 내용과 구어적 표현 이 포함되어 있을 수 있습니다. \n                  \n                \n\n동적 모델링 §\n\n시스템의 기능을 수행하기 위해 컴포넌트들이 어떻게 상호작용하는지 표현\n시퀀스 다이어그램, 상태 다이어그램, 액티비티 다이어그램이 있댄다\n\n시퀀스 다이어그램 §\n\n컴포넌트간 메세지(데이터?) 교환 과정을 순서대로 시각화하여 나타낸 것\n유스케이스 단위로 Initial Class Diagram(지난번에 그렸던 그거)로부터 작성한다\n\n\n\n일단 보면 뭔가 많이 익숙한 그림일거임\n왼쪽 위에 Initiating Actor가 위치하고\n박스 안에 객체이름:클래스이름 이렇게 되어있는 게 하나의 객체 표현법인데\n먼저 중요한 개념은 세로축이 시간흐름이고 세로축으로 그려진 길다란 박스가 Activation Box라고 해서 해당 객체가 활성화되어있는 기간이라는 것이다\n이것만 봐도 어떤 느낌인지 알것제? 세로축 시간흐름대로 객체들이 메세지를 주고 받는 것을 화살표로 표시하고 어떤 작업을 하느라 객체가 활성화되어 있는 기간이 세로방향 박스인 것\n\n실선 → 은 Synchronous message 로 메세지 이름과, 괄호에 매개변수가 드간다\n\n보통 메세지 이름은 메소드의 이름이나 Signal이 드간다\n아니면 객체의 생성을 나타내기 위해 &lt;&lt;create&gt;&gt; 라는 메세지를 붙일 수도 있다\n\n\n점선 → 은 이제 값을 리턴하는 것을 의미함\n세로 실선은 Life Line 이라고 하는데 이게 객체가 살아있는 기간인 것 - 활성화랑 다르다! 생성과 동시에 Life Line 이 생기고 소멸되면 이게 끊기는 것\n\n\n\n\n\n객체가 소멸되면 이 그림처럼 X 를 적어주고 Life Line 이 더이상 이어지지 않는다\n\n사례 §\n\n\n수강신청 예시임\n여기서 알아야 할 것은\nreturn message를 생략하고 화살표 위에 반환값 := 라고 적어주기도 한다는 것과\n화살표 위에 [조건] 의 형태로 조건부 메세지를 적어줄 수도 있다 - Guard Message 라고 하더라\n\nCombined fragments §\n\nCombined fragments는 약간 확장판같은거임\n\n\n\n먼저 조건부 메세지의 경우에는 메세지가 날아가는 구역에 opt[조건] 의 형태로 제목을 붙이고 박스로 감싸면 된다\n즉, 위의 그림에서 condition을 만족하면 op1() 메세지가 날아가는 것\n그리고 택 1의 경우에는 그 구역을 alt로 제목을 붙여 박스로 감싼다\n위의 그림에서는 condition1이 맞으면 op2, condition2가 맞으면 op3가 날라가는 식\n옆에 코드로 작성된거 보면 단번에 이해 가능\n\n\n\n예시임\n이걸 수도코드로 적어보면 이렇게된다\n\nif changeQuantity {\n\tsetQuantity()\n}\nif item.quantity == 0 {\n\tdelete item\n} else if deleteItem {\n\tdelete item\n}\n\n\n반복문은 위처럼 표현된다\nloop min, max[condition]으로 최소 반복횟수와 조건을 만족했을 시에 최대 반복 횟수를 정해줄 수 있고\n아니면 loop[condition] 으로 조건을 만족하는 와중에 반복하다가 break[condition] 으로 빠져나올 수도 있다\n\n\n\n이건 이렇게 할 수 있다\n\nfunc FindCourse(name string) Course {\n\tfor course := range courses {\n\t\tcourseName := getName();\n\t\tif name == courseName {\n\t\t\treturn course;\n\t\t}\n\t}\n\treturn null;\n}\n상태 다이어그램 §\n\n얘는 쉽다 - Finite State Automata 생각하면 됨 - 상태 Node와 전이 Arc로 표현된 다이어그램\n\n\n\n검은점이 시작상태 사각형이 중간상태 원 두개가 종료상태\n그리고 위 그림에는 안나와있지만 각 Arc에 전이(트랜지션, Transition) 조건이 붙는다\n\n\n\nTransition의 경우에는 시간개념 없이 바로 일어나는게 원칙이지만 위처럼 ()를 통해 걸리는 시간을 명시할 수 있고 이런걸 결과 시간 표시 트랜지션이라고 한댄다\n\n\n\n그리고 Transition은 그냥 적는 경우가 일반적이지만 위처럼 Boolean operator를 이용하여 적기도 한댄다\n\nActivity §\n\n\nActivity는 해당 상태에 머물면서 하게 되는 일이다\n일정 시간이 소요되고\n끝난 후에 Transition이 일어나거나 끝나기 전에 외부의 Interrupt에 의해 Transition이 될 수도 있다\n위 그림처럼 상태 안에 또 다른 박스를 그리고 do: 키워드를 달아주면 됨\n\nAction §\n\n얘는 시간 지연 거의 없이 바로 일어날 수 있는 동작이다\n\n\n\n일단 첫번째 종류는 Enter / Exit of State Event Listener라고 생각하면 된다 - 해당 노드에 방문했을때 Trigger되거나 해당 노드에서 빠져나왔을 때 Trigger되는 것\n저렇게 상태 안의 박스 안에 Enter / 혹은 Exit / 을 달면 된다\n\n\n\n그리고 이거처럼 event / action 을 통해 Transition이 일어날때 수행되는 Action을 명시할 수 있다\n\nNested State, Guard Condition §\n\n\n상태 안에 또 다른 상태를 두는 Nested state가 가능하다\n\n이때는 외부상태에서 내부 상태로 바로 들어오거나 나갈 수 있고\nWrapping State로 Transition되면 State내에 위치한 Starting State에서부터 시작하게 된다\n\n\n그리고 [조건] 을 통해 조건부 Transition을 표현할 수 있다\n\nExample §\n\n\n일단 Planned에서\n최소수강인원보다 적으면 OpenNotEnoughStudent 상태고\n많아지면 OpenEnoughStudent 로 갔다가\n꽉 차거나 Enough한 상태에서 닫으면 Closed\n취소하거나 NotEnough한 상태에서 닫으면 Cancelled로 가는 다이어그램이고\n이걸 Open을 하나로 묶어 Nested State를 이용해 좀 더 간결하게 표현한 것이다\n\nActivity Diagram §\n\nActivity Diagram은 상태 다이어그램과 유사하나 상태 다이어그램의 경우에는 Event가 발생하면 Transition이 Trigger되었지만 Activity Diagram의 경우에는 외부 Event가 아닌 Activity가 종료되는 것에 Transition이 Trigger되는 차이점이 있다\n그래서 State가 Activity로 바뀐다는 것 외에는 State Diagram의 문법을 그대로 사용한다\n그 외에 Decision Point라는게 있는데 이건 다이아몬드로 표현되어 하나 이상의 진입 트랜지션에 대해 두개 이상의 진출 트랜지션을 갖는 분기적인 Activity이다\n\n\n\n이것처럼 다이아몬드와 [] 로 분기를 표현하게 되는데\n여기서 못보던거는 ^ 표시는 외부 객체를 나타내는 표시이다 - ^Class.method() 이래하면 외부에 있는 Class의 method()를 실행시키라는 메세지가 되는 것\n\n\n\n시퀀스 다이어그램에서는 위처럼 표현이 된다\n액티비티 다이어그램은 시퀀스 다이어그램에서의 세로바 하나의 작동 과정에 대해 그리게 된다\n\n병행처리 §\n\n액티비티 다이어그램은 병행처리를 나타내는데 효과적이다\n\n\n\nFork: 하나의 입력 트랜시션이 여러개의 출력 트랜지션으로 갈라지는 경우\n\n\n\nRendezvous : 여러개의 입력 트랜지션이 다 들어온 후에 여러개의 출력 트랜지션으로 갈라지는 경우\n\n\n\nJoin : 여러개의 입력 트랜지션이 하나의 출력 트랜지션으로 합쳐지는 경우\n\n\n\nFork와 Join이 표현된 예시다\n\n\n\nSwimlane 이라는 것은 말 그대로 수영장에서 레인 말하는건데\n같은 클래스와 관련된 액티비티끼리 하나의 Swimlane으로 묶은 것을 말한다\n\n동적 모델링 프로세스 §\n\n보통 Sequence Diagram은 전체적으로 객체들이 상호작용하는 것을 시간순대로 표현한 것이기 때문에 거의 필수적으로 그리고\nState Diagram은 객체 하나의 상태 변화를 나타내기 위해 그린다 - 근데 모든 객체가 아닌 중요하고 복잡하다고 판단되는 객체에 대해서만 그림\n그리고 Activity Diagram은 Operation하나의 상태 변화를 나타내기 위해 그린다 - 이것도 마찬가지로 중요하고 복잡한 Operation에만 그림\n모델링 과정을 보면\n\n시나리오 준비\n시나리오의 이벤트식별\n시나리오별 시퀀스 다이어그램 작성\n식별한 이벤트와 그에 따른 상태를 상태 다이어그램으로 녹여냄\n검토\n\n\n과정을 겪게 됨\n\n시나리오 준비 §\n\n생각해보면 유스케이스가 시나리오의 집합이기 때문에\n유스케이스 모델링의 결과를 갖다 쓰면 된다\n유스케이스에서 flow들이 각각의 시나리오가 되는 것\n\n이벤트 식별 §\n\n시나리오는 이벤트의 연속이라는 걸 참고해서 식별하면 됨\n이벤트를 식별할때는 객체간 교환되는 정보들을 유심히 보면 알 수 있더라\n이벤트의 속성은 매소드의 매개변수의 형태로 나타나고, 이벤트가 발생했음을 알리기만 하는 매개변수가 없는 신호 이벤트가 있다\n그리고 시나리오의 이벤트를 식별할때는 외부 이벤트부터 시작하는 게 좋다\n\n뭔소린고 하니 사용자나 외부 장치 등과 상호작용하는 외부 이벤트를 먼저 찾고\n해당 이벤드가 내부 객체에 도달하는 지점에서부터 이벤트들을 식별해나가면 된다\n이벤트를 보내고 받는 지점을 잘 생각해서 이벤트를 할당하면 되고 - 할당이라는 말이 좀 이질적인데 그냥 보내고 받는 지점을 식별해내라 정도로 생각하면 될듯\n그리고 매개변수의 값만 다르고 비슷한 동작을 하는 경우에는 별도의 이벤트로 구성하지 말고 하나의 이벤트로 그룹화 해서 사용하면 된다\n\n\n\n시퀀스 다이어그램 작성 §\n\n이렇게 순서화된 시나리오를 기반으로 하나의 시퀀스 다이어그램을 작성하면 된다\n\n상태 다이어그램 작성 §\n\n일단 UC에서 Main flow부터 상태 다이어그램을 적기 시작한다\n그리고 그 Main flow에 대해 시퀀스 다이어그램에서 한 열을 쭉 따라가며 입출력 이벤트를 확인하고 그것으로부터 이벤트 이름(라벨)을 도출한다\n\n시퀀스 다이어그램에서 출력 이벤트는 다 지워주고 입력 이벤트만 남기면 그게 Transition이 됨\n한 열이 의미하는 바가 결국에는 하나의 객체이기 때문에 하나의 객체에 대해 상태 다이어그램을 작성하게 되는 셈\n\n\n그리고 그 이벤트들을 보고 반복되는 게 있다면 loop를 도입하라\n\n단, 무한루프를 방지하기 위해 루프를 구성하는 상태 중 적어도 하나는 루프를 빠져나가는 출력 전이가 있어야 됨\n\n\n이런 식으로 Main flow에 대한 상태 전이도를 그렸으면\nAlternative flow에 대해서도 고려를 해 추가해준다\nAlternative flow에서 분기하는 지점이 어느 상태인지 확인하고\n어느 지점에서 다시 결합할 것인지 고려하랜다\n그리고 타이밍이나 기타 오류 처리 등을 해주고\n검토를 한 후에\n중요한 객체에 대해 위 과정을 반복해 상태 다이어그램을 그려준다\n\n상태 다이어그램 검토 §\n\n누락된 이벤트가 없는 지 확인해야 한다\n\n만약 이런일 이 일어났을 때 어떻게 작동하는가(what-if분석이랜다)\n이벤트들에 대한 송수신자를 다시 확인\n\n\n또한 선행 / 후행상태가 없는 것을 찾고 걔네가 시작 / 종료 상태인지 봐야한다 - 아니라면 문제가 있는 것\n그리고 경쟁조건(Race Condition)에서는 이벤트가 누락될 수 있기 때문에 경쟁조건이 없는지, 혹은 경쟁조건에서 누락된 이벤트가 없는지 명확하게 확인해야한다.\n"},"originals/softwareengineering.fall.2021.cse.cnu.ac.kr/07.-아키텍쳐-디자인":{"title":"07. 아키텍쳐 디자인","links":[],"tags":[],"content":"\n\n                  \n                  충남대학교 컴퓨터공학과 김현수 교수님의 &quot;소프트웨어 공학&quot; 강의를 필기한 내용입니다. \n                  \n                \n\n\n\n                  \n                  다소 잘못된 내용과 구어적 표현 이 포함되어 있을 수 있습니다. \n                  \n                \n\n아키텍쳐 설계 §\n\n기능적 요구사항을 구현하기 위한 방법을 찾고 비기능적 요구사항에 명시된 제약을 준수하기 위한 설계 과정\n\nDesign Space §\n\n\n위처럼 선택 가능한 모든 설계의 대안을 모아놓은 것을 Design Space 라고 하고\n이 중에서 경로를 하나 선택해서 설계를 하고 이것이 설계의 최종 산출물이 된다\n\n설계를 구성하는 요소들 §\n\n\nModule : 프로그래밍 언어 수준에서 정의된 컴포넌트\n위 그림에서 보이는것처럼 컴포넌트는 컴포넌트로 구성될 수 있고 시스템의 구성요소가 될 수도 있다\n\n상향식 설계 / 하향식 설계 §\n\n하향식 설계(Top-Down) : 시스템의 최상위부분을 설계하고 하위 컴포넌트로 점차 내려오면서 구체적으로 설계하는 방식\n\n하향식 설계는 전체 시스템 구조를 잡는데 좋다는 장점이 있다\n\n\n상향식 설계(Bottom-Up) : 컴포넌트들을 일단 다 구성한 후에 그것들을 배치하며 높은 수준의 구조를 설계하는 것\n\n상향식 설계는 재사용 가능한 컴포넌트를 구성하는 것에 강점이 있다는 장점이 있다\n\n\n보통은 이 둘을 혼용하여 각각의 장점을 모두 취한다\n\n설계의 종류 §\n\n아키텍처 설계 : 전체 시스템과 서브 시스템, 컴포넌트들로 분할하여 구조와 관계를 잡는 것\n클래스 설계 : 각각 컴포넌트들에 대해 설계\n사용자 인터페이스 설계 : UI\n알고리즘 설계 : 계산벙식 설계\n프로토콜 설계 : 통신 규정(프로토콜) 설계\n\n설계 원리1 : Divide &amp; Conquer §\n\n말 그대로 분할 정복\n사람들을 업무대로 나누어 각 부분을 작업하게 함\n뭐 병행적으로 진행되어서 더 빠르고\n자신의 분야에서 전문성이 높아지고\n각 컴포넌트들의 품질이 향상 된다\n\n설계 원리2: 응집력 향상 §\n\n관련있는것들을 하나의 모듈에 모아 시스템의 변경이나 이해에 도움이 되게 함\n따라서 응집력은 높을수롣 좋은 것\n\n\n\n각각 응집도에 따른 응집력은 위와 같음\n\n기능적 응집도 §\n\n말 그대로 기능적으로 밀접하게 관련되어 있는 프로시저들을 하나의 모듈에 묶는 것을 의미함\n모듈이 단일 작업을 수행하고 하나의 결과만 낼수록 기능적 응집도가 커진다\n모듈이 단일한 기능만을 제공하기 때문에\n이해하기 쉽고\n재사용이 쉽고 : 해당 기능을 필요로 할 때마다 호출하면 되기 때문\n대체하기 쉬움 : 다른 더 좋은 라이브러리가 있을때 교체하는 것이 용이\n\n계층적 응집도 §\n\n연관된 서비스들을 하나의 계층에 넣고 다른것들은 배제하는 것\n여기서 계층과 모듈과의 차이점 은 상위계층에서 하위 계층의 서비스를 이용할 수는 있지만 그 반대는 안된다는 것이다\n상호작용 인터페이스만 유지하면 다른 층에 영향을 주지 않고 계층을 변경할 수 있다는 장점 이 있다\n\n순차적 응집도 §\n\n프로시저가 순차적으로 실행되며 우선적으로 실행된 프로시저의 결과물이 이후에 실행되는 프로시저에 사용될 경우 순차적 응집도 가 가깝다고 한다\n\n교환적 응집도 §\n\n교환적 응집도는 클래스 생각하면 이해하기 쉬움\n특정 데이터에 조작하는 애들끼리 모아놓고\n해당 모듈이 그 데이터를 조작하는 것 외에는 별다른 일을 하지 않을 경우 교환적 응집도 가 올라간다\n객체지향의 큰 장점 중 하나는 교환적 응집을 보장한다는 것 이다\n\n절차적 응집도 §\n\n차례로 수행되는 프로시저를 모아놓은 경우\n순차적 응집도와의 차이점은 순차적 응집도는 차례로 수행되는 것 외에도 데이터도 같이 이동하며 묶여있어야 되고\n절차적 응집도의 경우에는 순서대로만 수행되면 되는 것\n\n시간적 응집도 §\n\n비슷한 시점에 작동할 프로시저들을 모아놓은 것\n시스템 시작시에 초기화해주는 역할을 하는 애들 한곳에 모아놓는거 생각하면 된다\n\n실용적 응집도 §\n\n그냥 뭐 어디에 넣기 애매한 유틸리티같은거 걍 한곳에 다 때려박은 것을 의미함\n\n설계 원리3: 결합력 낮춤 §\n\n두 모듈 사이에 결합이 있다는 것은 모듈 간 의존관계가 있다는 것이다\n의존관계가 있으면 한쪽의 변경이 다른 한쪽한테 영향을 주기 때문에 결합은 낮으면 낮을수록 좋음\n또한 의존관계가 높으면 컴포넌트들이 어떻게 수행되는지 파악하기도 힘들다\n\n\n\n위의 그림에서 위에 있는 결합일수록 결합력이 높고 더 안좋다. 반면, 아래에 있는 결합일수록 결합력이 낮고 더 좋다.\n\n내용결합 §\n\n이건 한 컴포넌트가 다른 컴포넌트의 내부 데이터를 비밀리에 수정하는 것으로\n클래스의 property를 getter나 setter를 사용하지 않고 수정할 경우에 내용결합이 생긴다고 예시를 들 수 있다\n\n공통결합 §\n\n이건 전역변수와 연관된 결합으로 전역변수를 선언한 모듈은 그걸 사용하는 모든 모듈과 결합됨\n시스템 전체사 사용하는 디폴트 값이나 상수의 경우에는 허용한다\nSingleton Pattern 은 어떤 객체를 전역으로 딱 하나만 생성되게 해서 캡슐화된 전역 변수, 즉, 공통결합의 부작용이 적은 전역변수를 생성할 수 있게씀 한다\n\n제어결합 §\n\n제어 결합은 뭐 함수의 인자로 플래그나 커맨드같은걸 받아서 그거에 따라 어떤 함수가 호출될지 결정하는 패턴으로 설계를 했을 때 나타날 수 있는 결합이다\n그래서 플래그를 줘서 함수를 호출하는 방식보다는 그냥 그 함수를 Call하는 부분에서 if문으로 함수를 직접적으로 호출하거나\n인터페이스를 만들어서 상속받은 다음 동작의 구분을 객체의 종류에 따라 다르게 해주는 다형성을 이용한 방식을 사용하면 더 좋다\n\n스탬프 결합 §\n\n얘는 클래스를 매개변수로 주는 경우에 해당하는데 여기서 중요한 점은\n매개변수로 받은 클래스의 모든 Property중 일부만 사용해야 한다는 것이다\n이것이 문제가 되는 이유는 클래스의 노출시킬필요가 없는 것들까지 노출되기 때문\n따라서 이것을 해결하는 방법은 그냥 그 클래스 내에서 사용하는 Property들만 을 원시 자료형 매개변수로 각각 주거나\n아니면 사용하는 Property만을 따로 모은 인터페이스 등을 정의해서 인자로 주는 것이 좋다\n\n데이터 결합(자료 결합) §\n\n이건 원시 자료형을 매개변수로 주는 경우인데\n일단 스탬프와의 차이점은 얘는 매개변수로 클래스를 받더라도 클래스의 모든 Property를 메소드 내에서 사용한다는 점이다\n근데 이때 원시자료형을 쓰는게 무조건 좋은건 아니고 매개변수의 갯수가 많아질수록 결합력은 높아짐 - 따라서 매개변수가 너무 많을때는 차라리 스탬프 결합을 이용하는 것이 더 결합력을 낮추는 방법이 된다\n\n루틴 호출 결합 §\n\n얘는 어느 메소드에서 다른 메소드를 호출하는 경우이다\n이것 또한 호출되는 메소드의 변경이 호출하는 메소드의 변경을 가져오기 때문에 어느정도 결합력이 있다고 생각할 수 있음\n즉, 루틴 호출 결합은 어느 시스템에나 존재하게 된다\n만일 두개 이상의 메소드를 반복적으로 호출한다면 그것들을 하나의 메소드로 뺀 다음 걔를 호출하는 것이 루틴 호출 결합을 줄이는 방법이 된다\n\n타입 사용 결합 §\n\n얘는 다른 모듈에서 선언된 타입(자료형)을 불러다 쓰는 경우를 말하는데\n얘도 타입의 정의가 바뀌면 그걸 불러서 사용하는 놈에게도 영향이 가기 때문에 결합력이 생기는거다\n그래서 이때 결합력을 줄이는 방법은 최대한 포괄적이고 상위에 있는 자료형(클래스)를 사용해 자료형의 변경에도 의연하게 대처할 수 있도록 하면 된다\n\n포함 결합 §\n\n얘는 그냥 모듈 import하는 경우 생기는 결합력에 관한 것이다\n\n외부 결합 §\n\n얘는 모듈이 특정 운영체제, 하드웨어에 의존하는 경우 생기는 결합력이다\n따라서 특정 운영체제나 하드웨어에 의존하지 않도록 코드를 짜거나 그러한 라이브러리를 사용하는 것으로 낮출 수 있다\n\n설계 원리4: 높은 수준의 추상화 §\n\n이것은 정보 은닉을 통해 구체적이고 상세한 부분은 감춰져야 한다는 것이다\n\n추상화와 클래스 §\n\n클래스는 자료와 프로시저를 추상화할 수 있다는 강점이 있는 자료형\n추상성을 높이기 위해서는\nprivate변수를 늘려야 하고\n메소드의 숫자를 줄이고\n사용하고자할때 되도록이면 슈퍼클래스나 인터페이스를 사용하거나\n메소드의 매개변수의 갯수를 줄이는 것으로\n추상성을 높일 수 있다\n\n설계 원리5: 재사용성 증진 §\n\n다른 상황에서도 재사용할 수 있도록 설계하는 것\n설계를 일반화, 단순화하고\n응집도와 추상화는 높게, 결합도는 낮게\n사용자의 기호에 따라 기능을 추가할 수 있도록 Hook를 추가하랜다\n\n설계 원리6: 설계와 코드의 재사용 §\n\n설계할때 기존의 코드를 최대한 재사용하는 방향으로 설계하는 것이 좋음\n\n설계 원리7: 유연성 고려 §\n\n코드가 나중에 바뀌거나 요구사항이 변경될 가능성을 항상 고려해야 된다\n이걸 높이기 위해서는 재사용성 증진과 비슷하게\n설계를 일반화, 단순화하고\n응집도와 추상화는 높게, 결합도는 낮게\n상수의 경우에는 하드코딩을 하지 말고\n사용자의 기호에 따라 기능을 추가할 수 있도록 Hook를 추가하거나 선택의 여지를 남기는 방향으로 설계하랜다\n\n설계 원리8: 노후화 예측 §\n\n시스템은 항상 노후화되기 때문에 기술이나 환경에 변화에 유연하게 대처할 수 있게 설계하고 변경될 여지가 많은 기술이나 환경을 사용하는 것은 피해야 한다\n즉, 기술의 초기 배포판을 사용하거나 특정한 환경에서만 사용할 수 있는 라이브러리를 사용하는 것, Deprecated될 가능성이 많은 기능이나 장기간의 지원을 제공할 가능성이 낮은 회사가 제공하는 기술을 사용하는 것을 피해야 한다\n\n설계 원리9: 이식성 고려 §\n\n운영체제, 플랫폼, 아키텍쳐에 종속적인 기능의 사용을 피하고 가능하면 많은 플랫폼에서 실행할 수 있는 기능을 사용해야 한다\n\n설계 원리10: 테스트 가능성 고려 §\n\n테스트가 쉽고 자동적으로 이루어질 수 있도록 하고, GUI를 통한 테스트를 되도록이면 피할 수 있게 설계해야된다\n\n설계 원리11: 방어적인 설계 §\n\n컴포넌트를 부적절하게 사용할 경우에 대비하고 input validation등의 방법이나 precondition check 등의 방법을 이용해라\n\n계약에 의한 설계 §\n\n이건 설계를 할 때 메소드 하나에 대해 다음과 같은 계약을 맺는다고 생각하면서 설계를 하는 것이다\nprecondition: 메소드가 호출되기 전에 만족해야 하는 것\npostcondition: 메소득 호출된 이후에 만족해야 되는 것\ninvariant: 메소드 실행 전과 후에 변하지 않아야 하는 것\n"},"originals/softwareengineering.fall.2021.cse.cnu.ac.kr/08.-디자인-패턴":{"title":"08. 디자인 패턴","links":[],"tags":[],"content":"\n\n                  \n                  충남대학교 컴퓨터공학과 김현수 교수님의 &quot;소프트웨어 공학&quot; 강의를 필기한 내용입니다. \n                  \n                \n\n\n\n                  \n                  다소 잘못된 내용과 구어적 표현 이 포함되어 있을 수 있습니다. \n                  \n                \n\nDesign Pattern §\n\n말 그대로 자주 접하게 되는 디자인(설계)상의 문제점을 해결하기 위한 일정한 패턴\n전문가의 노하우가 들어있기 때문에 내가 만드려고 하는 시스템에 적용시키면 좋은 디자인 패턴이 있을 경우 적용하면 Side effect가 적고 여러 문제점을 사전에 방지하는 좋은 설계를 할 수 있게 된다\n\nBasic Pattern §\n\n디자인 패턴과 무관하게 어떤 것을 설계하든 적용시키면 좋은 기본적인 패턴들\n일단 알아두어야 할 점은 여기서 소개하는 대부분의 패턴들이 실제 구현으로 객체지향에서의 extend와 implement개념을 사용하는데 그렇다고 해서 이 패턴들이 다 똑같은데 그냥 이론충들이 나눠놓은게 아니란 거다\n\n이론적으로는 구분된 개념이지만 그것들을 extend와 implement를 이용해 코드로 짤 수 있다는 것\n\n\n\nAbstract-Occurrence(개념 실체) Pattern §\n\nAbstract(개념) : 일반적이고 추상적이고 공통적인 것\nOccurrence(실체) : 구체적이고 특수한 것\n이렇게 말하면 뭔소린지 모르겠는데 사실 너가 지금까지 많이 해오던 패턴이다\n\n클래스 설계할때 공통된 내용들을 하나의 클래스에 몰아넣고 그 클래스를 상속해서 각각의 클래스를 설계하면 그 공통된걸 담고있는 클래스가 Abstract(개념) 이 되는거고 그걸 상속하는 각각의 클래스가 Occurrnce(실체) 가 되는 것이다\n\n\n뭐 당연히 중복된 정보를 저장하지 않기 위해 사용함\n\nPlayer Role Pattern §\n\n말그대로 어떤 객체가 다양한 역할을 맡을 수 있는 경우에의 패턴임\n일단 역할을 가질 수 있는 객체에 대한 클래스를 만들고, 역할들에 대한 클래스를 만든 뒤 역할들을 묶어줄 하나의 슈퍼클래스를 만들어 객체에 대한 클래스가 그 슈퍼클래스를 사용하는 방식으로 구현하게 됨\n글로 보는것보다 그림으로 보는게 더 이해 잘될거임\n\n\n\n이런식인거다 이말이야\n학생은 FullTimeStudent, PartTimeStudent의 역할을 맡을 수 있을 때 이 역할의 구분을 Student클래스에 넣기보다는 역할들에 대한 클래스를 만든 뒤 AttendanceRole로 일반화하고, Student클래스가 AttendanceRole을 필드로 가지게 하는 것\n\nDelegation Pattern §\n\n이건 모든 기능을 전부 제공하는 포괄적인 클래스를 하나 만들고, 그 기능의 일부만 사용하는 클래스의 경우 포괄클래스를 상속하는게 아닌 포괄클래스가 제공하는 기능을 참조하기만 해서 단순히 포괄클래스에게 일을 맡기고 결과를 받아다가 전달해주는 역할\n니가 가장 와닿을 대표적인 예시가 C++에서의 Adapter Container 이다\nC++에서 양방향 pop과 push에 특화된 컨테이너인 Deque를 만든 뒤 Stack과 Queue같은 Adapter Container는 Deque에서 제공하는 기능을 사용하기만 해서 Deque의 기능 중 특정한 작업만 할 수 있도록 유도하는 식으로 구현이 되어있는데 이게 이 Delegate Pattern의 대표적인 예시임\n\n\n\n이런 Delegation Pattern 는 일단 모든걸 제공하는 클래스를 만든뒤 그걸 사용하기만 하는 클래스를 만들면 되니까 얘도 중복된 코드가 작성되는 것을 막을 수 있고 상속이 아닌 사용을 하는 이유는 그 모든 기능을 전부 필요로 하는게 아니기 때문임\n약간 Abstract-Occurrence Pattern과는 반대방향으로 흘러간다고 생각하면 된다 - Abstract-Occurrence Pattern의 경우에는 작은 클래스를 만들고 그걸 확장하는 방식이라면 얘는 커다란 클래스를 만들고 그중 일부만 가져오는 방식인 것\n\nHierarchy Pattern §\n\n뭐 이건 걍 회사의 조직도처럼 계층, 트리의 구조가 필요할때 사용하게 되는 패턴이다\n\n\n\n맨날 나오는 예시임\n\nGenerate Pattern(생성 패턴) §\n\n이건 클래스를 가지고 객체를 어떻게 생성할것이냐에 대한 것임\n\nFactory Pattern §\n\n\n따마라 Time-to-Live에서 본것처럼\nBaseClass가 있고 그걸 상속받는 ExtensionClass가 있을때 어느시점에 어떤 자식객체가 생성되는지 예측할 수 없는 경우(뭐 사용자 입력에 따라 달라진다던지)에 Factory Pattern을 사용한다\n그래서 다양한 상황에 대응하여 그에 맞는 객체를 반환하는 ClassFactory 클래스를 정의하여 사용하게 된다\n따마라 Time-to-Live에서 js/CalendarFactory.js코드 보면 대략 감올듯\n\nAbstract Factory Pattern §\n\n얘는 Factory Pattern과 유사하게 객체를 만드는 클래스를 따로 정의하지만 Factory Patter과는 다르게 한번에 하나의 객체를 생성하는게 아니라 여러개를 생성하게 된다\n그래서 특정한 클래스 하나를 요청하는 것이 아닌 어떤 클래스와 그것과 연관된 클래스의 객체들을 요청하여 클래스 그룹을 받게 되는 것\n\nPrototype Pattern §\n\n자바스크립트 시간에 배웠쥬? 객체를 생성하는게 아니라 기존 객체를 복사해서 주는 방식\n객체들이 대부분 비슷하고 조금씩 다를 경우에는 객체 하나를 처음부터 만드는게 아니라 복사해서 주는게 더 효율적이기 때문에 이러한 접근을 한댄다\n\nSingleton Pattern §\n\n어떤 클래스가 시스템 전반에 걸쳐 단 하나의 객체만이 생성되어야 하는 경우 객체 생성 갯수를 하나로 제한하기 위해 Singleton Pattern 을 쓴다\n그래서 생성자를 private으로 만들어 외부에서는 이놈을 생성하지 못하게 함 - JS같은 경우에는 익명함수를 선언하고 선언이 끝나자마자 호출되는식으로 단 하나의 객체만이 생성되게 한다\n\nStructure Pattern §\n\n이건 객체들을 엮어서 더 큰 구조의 객체 그룹을 만들고자 할 때 어떻게 이 목표를 달성할 수 있을까에 대한 것이다\n이건 런타임에 객체 그 자체나 객체들간의 구조를 바꾸려고 할 때 더 큰 유연성과 확장성을 갖게 하기 위함이다\n\nComposite Pattern §\n\n얘는 트리 혹은 Nested구조를 표현하기에 적합한 패턴이다\n기본 클래스와 이를 포함하는 컨테이너 클래스를 재귀적으로 표현한다고 돼있는데 예시 보고 나면 뭔말인지 쏙이해될거임\n일단 대표적인 예시는 디렉토리인데\n\n디렉토리의 구조를 보면 디렉토리 안에 또 다른 디렉토리들이 있을 수 있고 아니면 파일들이 있을 수 있자네\n그럼 이 예시에서는 기본 클래스는 파일 인거고 이것을 포함하는 컨테이너 클래스는 디렉토리 가 되는 것\n그리고 디렉토리는 다른 디렉토리 안에 재귀적으로 들어갈 수 있으므로 위에서 말한 컨테이너 클래스가 재귀적으로 표현된다는 말도 이것으로 이해할 수 있는 것\n\n\n\n\n\n이 예시에서도 마찬가지로 볼 수 있듯이 Composite Class의 자식으로 또 다른 Composite Class가 있을 수 있고 다른 Leaf Classe들도 존재할 수 있게 되는 구조\n이러한 구조는 집합 내에 속하는 객체와 집합 그 자체가 모두 동일한 메소드와 데이터를 가질 수 있게 해주고\n객체 집합을 삽입하거나 삭제하기가 용이하며\n특정 객체 집단에 명령을 전달하면 해당 객체 집단 내의 모든 객체가 재귀적으로 명령을 수행하게 할 수 있다\n\nDecorator Pattern §\n\nDecorator Pattern은 Wrapper Class라고 생각하면 된다 - 기존 객체를 Wrapping하여 새로운 기능을 가지게 하기 위한 것\n나문희불여일견이라고 예시를 바로 보면 딱이해됨\n\n\n\nDecorating할때는 Target을 Decorator의 인자로 주어 새로운 객체를 생성하게 하는 식으로 구현된다\n그래서 TextView라는걸 먼저 만든 후, 여기에 Scroll을 포함시키기 위해 ScrollDecorator로 Decorate한 후 또 여기다가 테두리를 만들어주기 위해 BorderDecorator로 Decorate하는 식으로 진행될 수 있는 것\n\nAdapter Pattern §\n\n이건 어떤 기능의 인터페이스를 바꿔서 제공하기 위해 사용하는 것이라 생각하면 되는데\n위에서 Delegate Pattern에서 예시로 든 C++의 Adapter Container에서 Adapter가 이뜻인 것을 생각 하면 이해될거임\n이것도 Delegate를 이용하기 때문인건데 외부 라이브러리 등에서 제공하는 기능의 인터페이스를 내가 수정해서 사용하거나 제공하려할때 내 버전의 인터페이스와 클래스를 만든 후 실제 동작은 저놈한테 Delegate하는 방식을 말하는 것\n이때 내가 만든걸 Adapter라고 하고 내가 위임해서 사용하는 저놈을 Adaptee라고 한다\n즉, 기존에 존재하거나 아니면 외부 라이브러리 등을 사용하려고 할때 원하는 인터페이스와 맞지 않을때 적용하게 된다\n\nFacade Pattern §\n\n얘는 객체지향에서 말하는 정보은닉과 관련지을 수 있는데\n클라이언트한테 기능을 제공할때 클래스를 제공하는게 아니라 해당 클래스의 인터페이스를 만들어서 그 인터페이스를 제공하는 식으로 외부 클라이언트에게는 복잡한 내부의 구현을 감추는 방식이다\nFacade의 뜻이 정문, 대문인 것을 떠올리면 생각하기 쉬움\n\nProxy Pattern §\n\n얘는 복잡하고 생성에 시간이 오래걸리는 객체의 경우에는 일단 경량화된 버전의 객체를 제공한 뒤 진짜 객체가 필요해지면 그때 생성하는 식으로 demand가 있을때까지 객체의 생성을 지연시키는 방식이다\nProxy의 말뜻이 대리인인것처럼 일단 대리인을 내세워 특정 객체의 접근을 조절해 필요할때만 비싼 대가의 객체에 접근할 수 있게 하는 것\nProxy는 원래 클래스랑 동일한 Interface를 갖게 된다\n\n\n\n위 예시처럼 Proxy Pattern을 적용하여 이미지 로딩이 오래걸릴 때 일단 간단한 심벌을 보여주고 사용자가 원하면 그때 로딩을 시작하는 방식 으로 구현할 수 있다\n\nBehavior Pattern §\n\n이건 클라이언트의 요청에 대해 객체들이 어떻게 반응해서 응답할것인지에 대한 패턴이다\n즉, 객체들간의 상호작용이나 협력하는 방법에 대한 가이드라인인 것\n\nObserver Pattern §\n\n웹 프레임워크 개발할때 경험 떠올려보면 데이터를 저장할 Store가 있고 그놈을 감시하는 클래스인 Channel을 만들어놓고 각 Component들이 Channel에 subscribe해놓으면 데이터가 변경됐을 때 publish를 통해 영향을 받을 수 있도록 설계한거 기억나나\n그것처럼 데이터를 감시할 Observer클래스를 만들어놓고 정보의 변경을 알림받고싶은 클래스는 Observer클래스에 구독과 좋아요 알림설정까지 해놓으면 변경되었을때 Observer가 구독자들의 특정 메소드를 실행시켜주는 방식을 일컫는 거다\n따라서 모든 구독하고있는 클래스들은 동일한 이름의 메소드를 갖고있어야 함 - 그래야 Observer에서 일괄적으로 메소드를 호출할 수 있기 때문\n그래서 정보를 제공하는 객체의 변화가 이용 객체에게 전달되어야 할 경우 사용하고\n관찰당하는 객체는 자기를 관찰하는 놈이 누구인지 몇놈인지 알 필요가 없어 의존성을 줄일 수 있댄다\n\n\n\n그래서 이를 구현할때는\n\nConcreteObservable : 관찰당하는 바로 그놈\nObservable : 관찰당하는 놈들을 관리하는 상위클래스 - 이 클래스를 통해 구독하고 알림받을 수 있다\nConcreteObserver : 관찰하는놈들\nObserver : 관찰하는놈들을 묶은 상위클래스 - ConcreteObserver는 이놈을 상속하기 때문에 변경이 감지되었을때 실행되는 메소드를 무조건 갖고있게 되고, Observable쪽에서도 메소드 이름이 통일되어있기 때문에 일괄처리가 가능해지는거다\n\n\n\nMediator Pattern §\n\n이건 객체들 간의 소통을 중재하는 객체를 하나 두어서 직접적인 접근을 막고, 설계자가 의도한 대로 소통할 수 있도록 하는 방법이다\n중재자가 있기 때문에 객체간의 변화나 메세지를 조정할 수 있고\n다른 객체를 직접적으로 참조할 수 없기 때문에 의존성을 줄일 수 있고 다른 객체의 존재를 모르거나 없는 상황에도 대처가 가능하다\n그리고 소통을 전담하는 객체가 생겼기 때문에 소통의 변화가 필요할때는 특정 객체를 바꾸는게 아닌 이 객체를 변경하는 식으로 처리할 수 있다\n\n\n\n그래서 일반적으로 위처럼 구현할 수 있음\nMediator는 객체들간의 소통에 필요한 인터페이스만 정의돼있는 놈\nConcreteColleage는 그냥 각각의 객체이고\nColleague는 그 각각의 객체를 일반화한 클래스인데\n\n이놈이 Mediator를 갖고있기 때문에 이것을 상속받은 ConcreteColleague들은 이 Mediator를 통해서 다른놈과 소통할 수 있는 것이다\n\n\nConcreteMediator는 그 각각의 객체간의 통신을 중재할 놈이 되는 것\n\n근데 이놈은 각각의 Colleague들을 참조할 수 있기 때문에 메시지가 들어왔을 때 메시지의 목적지 객체로 전달해줄 수가 있는 것이다\n\n\n수업에서는 2가지 구동 시나리오를 제시했는데\n\n\n\n이건 중재자에 의해 각각의 Colleague들이 초기화되는 시나리오 를 보여준거고\n\n당연히 중재가가 객체에게 메시지를 보내야하기 때문에 Mediate Interface가 아닌 ConcreteMediator가 나선 것\n\n\n\n\n\n그리고 이건 Colleague하나가 중재자를 통해 자기자신과 다른놈에게 뭔가 시킬때의 시나리오 이다\n\n이번에는 객체가 중재자에게 요청을 하기 때문에 ConcreteMediator가 아닌 Mediate Interface에게 보낸거다\n\n\n\nChain of Responsibility Pattern §\n\n이건 어떤 객체한테 요청할지 모를때 객체 그룹의 대장한테 보내고 LinkedList마냥 순서대로 그룹의 객체들을 쭉 돌면서 그걸 처리할 수 있는 객체를 찾는 방식이다\n\n\n\n그래서 위 그림처럼 Handler superclass가 자기자신을 참조하는 방식으로 Handler들을 일렬로 쭉 Chaining되어있게 하고 Client는 head에게만 요청을 보내게 되는 것\n이렇게 함으로 요청을 보내는 쪽은 요청을 처리하는 쪽의 객체를 하나만 알면 되기 때문에 요청객체와 처리객체의 의존성을 줄일 수 있다\n\nCommand Pattern §\n\n이건 어떤 작업을 할지를 메소드 이름이 아닌 클래스의 이름으로 구분하고 각 클래스는 동일한 인터페이스를 갖게 하여 클라이언트가 요청을 보낼때 객체를 지정해서 요청을 보내면 그에 맞는 동작이 이루어지게 하는 방식이다\n\n\n\n위 그림 예시로 좀 이해를 해보자고\naction1과 action2를 제공하고자 할때 클라이언트가 이걸 직접 접근하는게 아니고\n공통된 Command Interface를 상속받는 Command Class들 중 특정한 놈을 골라서 요청을 보내는 방식\n이렇게 함으로써 이전과 마찬가지로 요청과 처리 간의 의존관계를 낮출 수 있고\n요청된 명령들의 히스토리를 저장해 rollback시에 요긴하게 사용할 수 있댄다\n\nState Pattern §\n\n이것도 예전에 웹 프레임워크 개발할때 상태에 따라서만 화면이 다르게 랜더링되게 했던거 생각하면 되는데\n프로그램의 상태에 따라 다르게 동작해야할 경우에 상태들을 객체화해놓고 상태에 따라 특정 메소드를 호출하게 하는 방식을 말한다\n뭐 상태에 종속적인 행위를 명확하게 분리해서 유지보수가 용이히고\n상태변화가 명확하게 드러나기 때문에 추적하기 좋댄다\n"},"originals/softwareengineering.fall.2021.cse.cnu.ac.kr/09.-소프트웨어-테스트-(1)":{"title":"09. 소프트웨어 테스트 (1)","links":[],"tags":[],"content":"\n\n                  \n                  충남대학교 컴퓨터공학과 김현수 교수님의 &quot;소프트웨어 공학&quot; 강의를 필기한 내용입니다. \n                  \n                \n\n\n\n                  \n                  다소 잘못된 내용과 구어적 표현 이 포함되어 있을 수 있습니다. \n                  \n                \n\nFailure, Defect, Error §\n\nFailure(실패) : 시스템이 실행되는 도중 시스템이 받아들일 수 없는 행위가 발생한 경우\n\n명세와 실행동작의 차이라고도 할 수 있고\n이것을 기준으로 Reliability(신뢰도) 를 계산한다\n\n\nDefect(결함) : 장애의 발생에 기여하거나 잠재적으로 기여할 수 있는 시스템에서의 결함\nError(오류) : 시스템의 결함으로 이끄는 소프트웨어 개발자의 잘못이나 결정\n이렇게 말하면 위 세가지가 뭔차이가 있는지 약간 헷갈리는데\nFailure는 결과적인 측면이다 - 시스템이 오작동한 결과를 말하는 것\nDefect은 시스템에서의 원인이다 - 시스템이 오작동하게된 시스템에서의 원인을 말하는 것\nError는 개발자측면에서의 원인이다 - 시스템이 오작동하게된 개발자의 잘못을 말하는 것\n\nTesting §\n\n뭐 알다시피 시스템의 실패로 이끄는 결함이나 오류를 찾거나 명세와 구현이 일치함을 검증하는 과정을 말함\n\n그래서 목적은 크게 결함 / 오류 찾기\n명세 충족 확인\n설계나 구현을 검증하는 것으로 생각할 수 있다\n\n\n\nTest Case §\n\n입력값과 해당 입력값에 대한 예상되는 결과\n얘네가 일치한다면 해당 Test가 통과한 것이고 아니면 통과하지 못한것(실패)\n테케는 보통 이런것들로 이루어진다\n\n이름(ID)\n대상 - 뭐 측정한 method나 클래스, 서브시스템 등\n조건 - 테스트 대상이 실행되기위한 조건(테스트를 가능하게 하는 조건)\n입력\n예상 결과\n\n여기서 Test Oracle은 테스트의 성공 / 실패를 판단하는 매커니즘 - 예를들면 예상결과와 실제 결과가 일치하는지 판단하는 것\n\n\n\n\n\n좋은 테스팅 §\n\nTest Effectively(효과적인 테스트) : 결함을 최대한 많이 발견하면 당연히 좋겠지\nTest Efficiently(효율적인 테스트) : 최대한 적은 노력과 테스트케이스로 최대한 많은 결함을 찾아내는 것\n효과적 / 효율적인 테스트를 하지 못하면 배포 후의 유지보수비용이 늘어 금전적인 손해가 나거나 극단적으로는 사고가 나 인명피해가 발생하기도 하기 때문에 중허다\n\n결함의 종류(사례) §\n\nIncorrect Logical Conditions : 반복이나 분기의 조건이 잘못된 경우\n\n뭐 동등 분할 기법이나 경계값 분석 기법을 사용해서 찾아내거나\n조건식에 사용되는 변수의 입력을 추적해보랜다\n\n\n제어구조의 잘못된 부분에서 계산 수행 : 프로그램이 수행하지 않아야 할 작업을 수행하거나 수행해야될것을 수행하지 않은 경우\n\n반복이나 분기에서 작업이 부적절하게 제외되거나 포함되는 경우가 많댄다\n이런건 반복 횟수를 특정하는(정확히 0번, 1번, 혹은 n번 돌게 하는) 테스트케이스를 설계함으로 결함을 찾는데 도움이 될 수 있댄다\n\n\nNULL을 처리하지 않음 : 제곧내\nOff-by-one : 1과 관련된것 - 값이 부적절하게 1이 더해지거나 빼지는 경우, 혹은 반복이 한번 더 돌더나 덜 도는 것\nOverflow : 자료형의 범위를 고려하지 않고 사용한 경우\n부동소수점의 값이 같다고 판단하는 경우 : 부동소수점의 경우 값이 정확히 같을때보다 다를 확률이 더 많다 - 따라서 부동소수점의 경우에는 일치여부가 아니라 대소비교로 조건문을 줘야 한다\n\n테스팅 기법 §\n\nBlack Box Testing : 얘는 입력값에 따른 예상 결과를 내부 논리구조를 생각하지 않고 선정하는 것을 의미한다\n여기에는 Equivalence partitioning과 Boundary Value Analysis가 있다\n\nEquivalence Partitioning §\n\nEquivalence Partitioning(동등 분할 기법) 은\n\n동치 클래스 결정을 하고\n동치 클래스 각각에 대해 그 안에서 테스트케이스 각각을 선정하는 방법이다\n\n\n뭔 소린지는 예시를 들어서 설명하면\n\n\n\n일단 1부터 48사이의 정수가 정상 입력값이니까 1부터 48 사이의 정수가 정상 클래스가 되는거고\n1부터 48 사이의 정수가 아닌 범위는 1보다 작은 정수, 48보다 큰 정수, 실수, 숫자가 아닌 값 정도로 나눌 수 있고 얘네 각각이 비정상 클래스가 되는 것이다\n이제 이 클래스들에서 하나씩 테케 입력을 고르고 거기에 따른 예상되는 출력이 나오는지 확인하면 되는 것\n위 예제에서 봤듯이 명세에 따라 값의 범위를 나누고 각각의 범위에서 테케를 고르는 방식으로 진행되는데\n명세에 따라 값의 범위를 나누는 것을 동치 클래스를 결정한다고 한다\n\n동치 클래스는 우선 클래스는 그냥 집합으로 이해하면 되고 그 클래스에 들어가는 값들은 전부 동등하다 - 즉, 같은 출력을 내고 같은 방식으로 작동하는 값들의 집합을 의미하게 된다\n만일 동치 클래스의 값들이 다른방식으로 작동한다면 그건 동치 클래스를 잘못 결정한거임\n따라서 동치 클래스에서는 어떤 값을 선택해도 동일하기 때문에 아무 값이나 골라서 테케 입력으로 선정하는거임\n\n\n\nTest Driver, Stub §\n\n\n일단 프로그램의 구성요소중 하나(메소드 등)를 다른것과의 의존성을 고려하지 않고 테스트하는 것을 Unit Test라고 하는데\nUnit test는 main함수를 실행시킬 수 없기 때문에 main함수를 대신해서 해당 부분을 실행시켜주는 놈을 Test Driver라고 하고\n만일 그 부분이 다른 함수를 필요로 한다면 그 함수를 대신해서 mock값을 대신 제공해주는 것을 Test Stub이라고 한다\n\n그니까 위 그림에서는 e를 테스트하려고 할때 f를 필요로 하지만 f는 동작시킬 수 없기 때문에 f의 반환값또한 테스트 이전에 제공해주는 기능을 하는 라이브러리를 말한다\nJUnit의 when()메소드로 특정 함수의 반환값을 지정해줄 수 있었자네 - 이런게 Test Stub 이 되는거임\n\n\n\nBoundary Value Analysis §\n\nBoundary Value Analysis(경계값 분석, BVA) 는 결함이 보통 경계 부근에서 발견되기 때문에 경계 부근을 집중적으로 테스트하는 것을 말한다\n\n\n\n따라서 위 그림처럼 1, 100이 경계니까 그 부근인 0, 101을 비유효 경계 값(경계와 근접한 비정상 입력값)으로 하고 1, 100 이외에도 2, 99정도까지 유효 경계 값(경계와 근접한 정상 입력값)으로 선정하여 테스트하게 된다\n"},"originals/softwareengineering.fall.2021.cse.cnu.ac.kr/10.-소프트웨어-테스트-(2)":{"title":"10. 소프트웨어 테스트 (2)","links":[],"tags":[],"content":"\n\n                  \n                  충남대학교 컴퓨터공학과 김현수 교수님의 &quot;소프트웨어 공학&quot; 강의를 필기한 내용입니다. \n                  \n                \n\n\n\n                  \n                  다소 잘못된 내용과 구어적 표현 이 포함되어 있을 수 있습니다. \n                  \n                \n\nWhitebox Testing §\n\nBlackbox Testing와는 반대로 내부 논리구조를 테스트하는 방법이다\n컴포넌트 레벨에서는 구문, 결정, 분기 등을 테스트 하고 모듈 레벨에서는 모듈간 호출관계 트리(Call Tree), 시스템 레벨에서는 메뉴, 프로세스 구조, GUI측면에서 테스트를 진행하게 된다\n그리고 Whitebox Testing에서는 Converage라는 개념이 등장하는데\n\n테스트 케이스 집합(Test Suite)으로 시스템 구조가 테스트된 정도를 말한다\n뒤에서 계속 보겠지만 Coverage는 구문 테스팅을 할때는 코드의 어디어디가 실행되었나로 판단하게 되고 뭐 결정 Testing 을 할때는 어떤 분기나 경우의 수가 실행되었나로 판단하는 등 각각의 Test방법에 따라 Coverage를 구하는 방법은 달라진다\nCoverage 목표치를 정해놓고 해당 Coverage에 도달할때까지 Test Suite에 테스트케이스를 추가하며 테스트를 진행하게 되고 이렇게 함으로써 여러 경우에 수에 대한 테스트를 좀 더 체계적으로 진행할 수 있게 된다\n\n\n\nStatement Testing &amp; Coverage §\n\n말 그대로 어느 Statement가 실행되었고 어느 Statement가 실행되지 않았는지를 판단해 Coverage를 구하며 Test Suite를 조정하는 방법\n얘는 Basic Block을 Statement 한줄로 하는 Control Flow Graph를 그리고 Test Suite의 테스트케이스를 진행하며 어느정도 Coverage가 나오는지 확인하는 방법이라고 생각하면 된다\n\n\n\n컴파일러 강의를 제대로 들었고 위의 문장이 이해되면 위의 예시또한 어렵지 않게 이해할 수 있음\n제일 왼쪽이 코드고 그 다음이 해당 코드의 Statement로 그린 CFG, 그리고 오른쪽이 해당 TS로 알아낸 Coverage이다\n하는 방법은 TS의 테케를 돌리고 어디어디가 커버됐는지 확인한 뒤 Coverage를 구하면 되는데\n이때 중요한건 total stmt에서 unreachable stmt의 갯수를 빼줘야 된다는 거다 - unreachable stmt를 빼지 않으면 절대로 100퍼가 나오지 않으므로 - 따라서 unreachable stmt를 coverage를 구하기 전에 반드시 구해줘야 한다\n\nDecision Testing &amp; Coverage §\n\n여기서의 Coverage는 하나의 분기문에 대해 참과 거짓으로 모두 분기했을때 Decision Coverage가 1이라고 본다\n뒤에서 나올 Condition Coverage와는 다르게 Decision Coverage는 분기문의 조건식 전체에 대해 결과가 참이냐 거짓이냐로 Coverage를 계산한다는 점을 주의할 것\n\n즉, 말그대로 Decision이기 때문에 양쪽의 분기방향에 대해서만 생각하게 되는거다\n\n\n\n\n\n예시를 보면 당연히 저 if문이 Decision Point가 되고\n예시로 주어진 TS을 실행해보면 F와 T가 골고루 나왔으므로 covered decision이 1인데 Decision의 총 갯수도 1개이기 때문에 100%의 Coverage가 나오게 되는 것\n여기서는 if문이 하나밖에 없어서 Decision 의 갯수가 1개인거지만 if문이 여러개인 놈을 테스트할때는 Total Decision 값이 n인 것에 주의하셈\n\nCondition Testing &amp; Coverage §\n\n여기서는 Decision Testing과는 다르게 Decision Point의 Condition Expression 각각에 대해 참과 거짓이 모두 나와야 해당 condition이 cover된것으로 판단한다\n\n\n\n예시를 보면\nDecision Point에 Condition Expression이 두개 있으므로 쟤네 각각에 대해 TF가 골고루 나와야 각각이 cover된 것으로 판단하게 됨\n예제로 주어진 TS를 해보면 위 표에서 보는것처럼 x &gt;= -2가 TF가 나오므로 이게 cover가 되고 y &lt; 4도 TF가 골고루 나와 cover가 된다\n따라서 total condition의 갯수가 2이고 covered condition도 2이므로 100%의 Condition Coverage가 나오게 된다\n\nMultiple Condition Coverage §\n\n애는 Condition 각각이 TF가 나오는 경우에서 더 나아가 Condition들이 만들어낼 수 있는 모든 TF조합으로 판단하는 거다\n예를들어 if(c1 BOOLOP c2)의 경우에 TT, TF, FT, FF 4개의 조합이 만들어지고 이 조합을 모두 충족해야 해당 Decision이 cover된 것으로 판단한다\n따라서 Boolean Operation으로 연결된 Condition Expression이 n개 존재한다면 가능한 조합은 2^n이 되고 이것은 엄청나게 많은 수의 테케를 필요로 하므로 반드시 결함이 없어야되는 경우가 아니라면 진행하지 않는다\n\nTesting들 간의 포함관계 §\n\n뭔가 Condition Testing이 더 자세하기 때문에 이걸 만족하면 Decision Testing도 통과할거같지만 Condition Testing과 Decision Testing은 포함관계가 아니고 하나가 통과해도 나머지 하나가 실패하는 경우가 있기 때문에 두개를 반드시 수행해줘야 한다\n\n\n\n위 표를 보면 모든 Test Case들에 대해 Condition Testing의 결과와 Decision Testing의 결과가 적혀있는데\nT1을 보면 Condition Testing는 TF가 골고루 나와 통과하지만 Decision Testing 에서는 FF가 나와 통과하지 못하게 되는 것을 볼 수 있음\nT2는 반대로 Decision Testing은 TF가 나와 통과하지만 Condition Testing에서는 두번째 테케가 TT가 나와 실패한다\n따라서 T1와 T2를 합집합한 T3을 돌려야 Decision Testing과 Condition Testing을 모두 통과하게 되는 것\n\n\n\n따라서 위와 같은 포함관계가 나오게 된다\n\n개발 단계를 기준으로 한 테스트 분류 §\n\nUnit Test : 모듈 하나에 대한 테스트\n\n주로 White Box Test를 진행한다\n\n\nIntegration Test : 전역변수 이슈나 인터페이스 결함 등의 모듈간 통합 과정에서 일어날 수 있는 결함을 체크한다\n\n그냥 모듈들을 다 합치고 한꺼번에 테스트하는 것을 Bing-Bang Test라고 하는데\n저건 너무 무식하니까 모듈들을 붙여가며 서브시스템을 테스트하고 서브시스템도 붙여가며 테스트하는 Incremental Testing을 진행한다\n이건 수평적으로 붙이면서 진행할때도 있고 수직적으로 붙이면서 수행할 때도 있음\nTop-down Testing은 UI에서 DB까지의 순서대로 내려가며 합치는 방법을 의미하고 이때 하위 시스템에 대해서는 사용하지 못하기 때문에 Test Stub을 이용해 하위 시스템에 대한 mock을 사용하여 테스트한다\nBottom-up Testing은 DB에서 UI까지 올라가며 합치는 방법이고 이때 상위 시스템에 대한 mock으로 Test Driver를 이용한다\n그리고 이 둘을 섞은 Sandwich Testing이 있음 - 얘는 UI를 테스트하고 DB를 테스트한 뒤 가운데를 테스트하는 방법이다 - 이때에도 하위나 상위 시스템에 대한 mock으로 Test Driver나 Test Stub을 사용한다\n\n\nSystem Test : 요구사항 명세를 기준으로 기능적, 비기능적(비기능 요구사항에 있었던 뭐 성능이나 이런것들) 테스트를 진행함\nAcceptance Testing : 실제 사용자들을 참여시켜 사용자의 요구대로 돌아가는지 확인함\n\nAlpha Test : 개발팀의 감독 하에 고객이 수행하는 테스트\nBeta Test : 임의의 사용자가 개발팀과는 무관한 환경에서 테스트하게 해볼 목적으로 사용자들이 직접 테스팅하고 문제점을 report하는 형태\n\nOpen Beta Release로 일반인에게 임시 배포를 해 테스팅 하는 방법이 해당한다\n\n\n\n\n\n테스터에 따른 분류 §\n\nDeveloper Test : 개발자나 연관된 테스팅 그룹에 의해 수행되는 테스트\nIndependent Test : 무관한 제 3자에 의해 테스트하는 것\n"},"originals/softwareengineering.fall.2021.cse.cnu.ac.kr/부록---시험대비)-요약정리":{"title":"부록 - 시험대비) 요약정리","links":[],"tags":[],"content":"\n\n                  \n                  충남대학교 컴퓨터공학과 김현수 교수님의 &quot;소프트웨어 공학&quot; 강의를 필기한 내용입니다. \n                  \n                \n\n\n\n                  \n                  다소 잘못된 내용과 구어적 표현 이 포함되어 있을 수 있습니다. \n                  \n                \n\n일단 핵심 포인트 §\n\n프로젝트 관리 방법론\n프로젝트 개발노력 추정 - Function point model, Object point model\n프로젝트 일정 관리 - PERT / CPM차트(간략한버전, 임계경로, 최소시간, 여유시간), 간트차트\n(인적자원관리 / 위험관리) - 보너스\n도메인 분석\n기능성 / 비기능성 요구사항 (예시를 적고 그렇게 분류한 이유를 적으라는 식으로 나오는듯)\n요구사항 명세서 작성했던거 한번 쭉 검토하며 복기\n유스케이스 모델링\n클래스 모델링\n\n프로젝트 관리 방법론 §\nWaterfall(Phased) Model §\n\n구분이 명확한 단계가 존재하고 이전 단계가 끝난 이후에 다음 단계로 진행하며 피드백은 바로 전 단계한테 하는 구조\n장점은 요구사항이 한정된 대규모 프로젝트에서 도움이 되고\n단점은 요구사항 변경에 유연하지 못하고 단계가 전환될때 많은 노력이 필요하며 초기단계가 너무 오래걸릴 위험이 있고 쓸데없는 문서를 생산해낼 가능성이 있다는 것이다.\n\nPrototype Model §\n\n인간-기계 상호작용 프로토타입 : 피그마로 UI 시나리오 그려보는거\nWorking prototype : 프로젝트의 핵심적인 부분만 만들어보는 것\nThrow-away prototype : 요구사항을 이해하기 위해 대충 만들어보는거\n과정은\n\n요구사항 분석과 시스템 분석, 설계를 모두 끝내고\n프로토타입을 만들어보고 평가한 뒤\nFull-scale development에 들어가는 것\n\n\n\nIncremental Model §\n\n얘는 기능별로 쪼개서 릴리즈 계획을 잡거나 완성도를 기준으로 쪼개서 릴리즈 계획을 잡아 단계적으로 배포내가나는 것\n분석과 계획은 처음 한번만 하고, 이후 계단을 올라가듯이 단계적으로 설계 / 구현 / 릴리즈하는 것이 특징\n\nSpiral Model §\n\n계획 - 위험분석 - 구현 - 평가의 과정을 계속해서 반복하며 나선형으로 점점 원이 커저가는 느낌으로 개발하는 것\n\nEvolutionary Model §\n\n얘는 Spiral Model이랑 비슷하게 계획 - 설계 - 구현 - 배포의 과정을 반복하지만 Spiral Model이랑의 차이점은\n위험분석의 과정을 하지 않는 다는 것, 계획 / 설계 / 구현 / 배포의 경계가 명확하지 않고 4개를 병렬적으로 진행하되 비중의 차이만 두는 것이다\n\nAgile Model §\n\n기획에서 배포까지의 사이클을 짧게 여러번 반복적으로 하는 것\n점증적 설계를 하기 때문에, 설계가 자주 변경될 수 있는 경우 적합하다\n\n프로젝트 모델 선정 §\n\n일반적인 구축 - Waterfall model\n소규모 - Agile model\n연구, 타당성 검토 - Spiral / Prototype model\n대규모, 임베디드 - Spiral / Evolutionary model\n\nVerification &amp; Validation §\n\nV-Model을 이용\n기획, 설계에서 어떤 테스트를 진행할 것인지도 기획했다가 개발 이후 기획한 테스트를 진행하는 것\n\n프로젝트 관리 §\nFunction Point Model §\n\n먼저 Unadjusted Function Point를 계산함\n\n컴포넌트의 갯수 * 컴포넌트 분류에 대한 가중치 총합을 더함\n컴포넌트 분류에 대한 가중치는 외부 입력, 외부 출력, 외부 질의, 내부 논리파일, 외부 인터페이스 파일이고 각각에 대해 높음, 중간, 낮음의 가중치가 있음\n\n\n그리고 Value Adjust Factor를 계산함\n\n뭐 데이터통신, 유지보수성 등등에 대한 14개 기술적 분야에 대해 0~5의 점수를 매겨 이걸 다 더한 후 0.01을 곱해서 더함\n\n\n그리고 UFP랑 VAF를 곱해주면 Adjusted Function Point가 나옴\nAFP는 프로젝트 규모에 대한 지표이고, 이것을 사람 1명이 1개월동안 할 수 있는 능력치인 nFP / MM를 나눠주면 해당 프로젝트를 사람 1명이 몇개월동안 해야 다 끝내는지 결론내려지게 되는 것\n\nObject Point Model §\n\n클래스가 몇개나 필요할지에 대한 숫자인 Cc를 구한다\n클래스 구현의 복잡도인 Wi에 대한 점수를 부여하고, 여기에 1을 더해 Cc와 곱한다. - 이것이 TCc임\nTCc에다 사람 한명이 클래스 하나를 개발하는데 걸리는 일수인 MD를 곱하면 최종적으로 사람 한명이 모든 클래스를 개발하는데 걸리는 일수 추정치가 나오게 된다\n\nPERT / CPM Chart §\n\nActivity : 가시적인 산출물이 나오는 활동\nDuration : 영업일수 기준 걸리는 일수\nDependencies : 이 활동을 하기 위해서 어떤 활동이 선행되어야 하는지\nMilestone : 배포 등과 같은 중요한 이벤트\nPERT / CPM차트는 Activity와 Milestone을 Node로 하고, Dependency를 Edge로 하는 그래프이다\n그리고 Activity Node들에 대해서는 Duration을 명시하고 영업휴일을 고려한마감일자를 적어주면 PERT / CPM차트 그리는 것은 끝난다\nCritical Path라는 것은 프로젝트를 마무리하기 위한 최소시간으로, 모든 노드를 병렬적으로 다 방문하는데 걸리는 최소 시간을 의미한다\n이것을 구하는 방법은 시작부터 끝까지의 경로 중 제일 오래 걸리는 경로를 구하면 된다\n\nGantt Chart §\n\n뭔지는 알제? 가로축을 시간으로 하고 세로축을 Activity로 하는 차트\n여기서 여유시간 개념만 좀 알아두라 - 해당 Activity의 Dependency를 고려해서 언제까지 지연되어도 문제가 없는지\n\nAgile Process Planning §\n\nActivity와 그에 들어가는 노력들이 종합적으로 측정된 Story Card를 준비하고\n우선순위가 높고 선행조건이 없는 Story Card부터 먼저 시작하는 것으로 하되 한 사이클당 Story Card의 총점이 일정 수준(보통 9점)을 넘지 않도록 배치한다\n\n인적 자원 관리 §\n\n계층구조를 가진 Hierarchy Team\n수평구조를 가진 Egoless Team\n계층구조와 수평구조를 섞은 Chief Programmer Team : 메인 개발자와 서브가 있어 어느정도 수평적인 구조를 가지면서도 메인 개발자가 중요한 결정을 내리게 해 의사결정이 지체되지 않도록 함\n\n프로젝트 위험 분류 §\n\n팀원이 나가는 Staff turnover 경우에는 일정과 인적 자원에 영향을 미치므로 Project Risk\n제품을 개발하는데 필요한 케이스 도구(뭐 코드 생성기 같은 느낌인듯)의 성능이 생각보다 좋지 않은 CASE tool under-performance의 경우에는 제품의 품질이 안좋아지므로 Product Risk가 되는 것\n경쟁사에서 먼저 상품을 내놓는 Product competition의 경우에는 우리 제품의 판매량이 저조할 우려가 있으므로 Business Risk가 되는 것\n\n요구사항 분석 §\n도메인 분석 §\n\nATM을 개발한다고 할 때의 도메인은 은행 업무 이고 도메인 전문가는 은행원 이 된다\n우리의 프로젝트가 해결할 수 있는 모든 문제에 대해 생각해보고 그 중에서 특정 문제만 골라 그것으로 범위를 한정하는 식으로 범위를 설정한다\n\n요구사항 분석 §\n\n기능적 요구사항은 일반적으로 생각했을 때의 기능\n비기능적 요구사항은 아래와 같음\n\n소프트웨어의 품질 특성 측면\n\n반응시간 : 요청에 대한 결과가 얼마나 빠르게 나오는 지\n처리량 : 분당 처리 트랜잭션의 수가 몇개인지\n자원 사용량 : 사용하는 메모리, 전기 등의 자원은 얼마정도인지\n신뢰성 : 시스템이 고장나지 않고 제대로 동작할 가능성은 얼마나 되는지\n가용성 : 시스템이 실행되고 준비되어있는 시간은 얼마나 되는지 - Down-Time(DT) 은 기준 시간(예를들어 1년) 중에 얼마나 되는지\n고장에서의 회복 : 고장으로 인해 발생할 수 있는 피해의 최대치는 어느정도인지\n유지보수, 확장, 재사용성의 허용 : 유지보수나 시스템의 확장, 그것을 재사용하는 것이 어느 정도까지 가능한지\n\n\n환경과 기술적 측면\n\n플랫폼 : 소프트웨어가 돌아가는 환경 - 뭐 예를 들면 최소 램 4Gb짜리 윈도우 컴퓨터에서 돌아갈 수 있도록 해라\n사용 기술 : 소프트웨어를 만드는데 사용할 프로그래밍 언어나 프레임워크, 라이브러리 등의 기술 - 뭐 예를 들어 전자정부 프레임워크를 이용해 자바로 개발해라\n\n\n계획과 방법론적인 측면\n\n방법론 : 사용할 개발 프로세스(방법론) - 뭐 애자일을 이용해라 등\n비용과 납기일 : 얼마를 이용해서 개발해라, 언제까지 개발해라 - 보통 계약서에 많이 명시됨\n\n\n\n\n\n요구사항 추출 §\n\nJoint Application Development : 브레인스토밍을 도와줌\n\n사회자가 한명 있고\n각자 앞에 종이를 한장씩 주고\n토론의 주제인 아이디어가 유도되는 질문을 사회자가 던짐\n참가자들은 종이에 아이디어를 하나 적고 옆으로 넘김\n옆사람이 준 종이를 받으면 거기에 적힌걸 읽어보고 관련된걸 적거나 아니면 또 다른 아이디어를 내도 됨 - 단, 한번에 하나의 아이디어만 적어야됨\n더이상 아이디어가 안나올때까지 돌림\n\n\n\n요구사항 명세 §\n\n얘네들을 적어라\nUser Interface : 사용자와 상호작용하는 인터페이스\nHardware Interface : 하드웨어와 상호작용하는 인터페이스 - 대표적으로 어떤 머신에서 소프트웨어가 돌아가는지\nSoftware Interface : 소프트웨어와 상호작용하는 인터페이스 - 대표적으로 어떤 OS에서 소프트웨어가 돌아가는지, 어떤 다른 소프트웨어와 상호작용하는지\nCommunication Interface : 통신 프로토콜과 관련됨 - 어떤 프로토콜을 써서 다른 sw와 통신하는지\n그리고 기능적, 비기능적 요구사항을 적되 각각의 요구사항에는 유일하게 구별이 가능한 식별자, 요구사항 분류, 세부 내용, 산출 정보, 관련된 요구사항을 적어라\n\n유스케이스 모델링 §\n분석하기 §\n\n유스케이스 : 계좌 출금 요청 이라는 유스케이스는 잔고가 충분한 계좌에서의 출금 이랑 잔고가 부족한 계좌에서의 출금 이라는 시나리오들로 구성될 수 있는 것\n\n반드시 액터에 의해 개시되어야 함\n반드시 액터에게 결과물을 주어야 함\n특정 기능의 일부만 제공하는 것이 아닌 완전한 기능 전부를 제공해줘야됨\n\n\n액터 : 은행 시스템의 경우에 대출을 담당하는 사람은 대출 담당 역할 을 맡고 있는 것이고 해당 은행에 계좌를 가지고 이용하는 사람은 고객의 역할 을 맡고 있는 것\n\n주 액터 : 시스템을 사용하는 대상\n부 액터 : 기능이 잘 작동하도록 도와주는 대상\nInitiating Actor : 유스케이스를 실행시키는 대상\nParticipating Actor : 유스케이스를 사용하는 대상\n\n\n\nUse Case Diagram §\n\n가운데 사각형이 시스템, 그 밖에 액터, 사각형 안에 유스케이스 타원형으로 그림\n각 액터가 사용하는 유스케이스를 선으로 이음\n유스케이스와 액터들은 일반화할 수 있음\n반복해서 사용되는 유스케이스는 include관계를 이용해 별도로 분리할 수 있음\n특정한 경우에만 추가적으로 수행되는 유스케이스는 extend관계를 이용해 별도로 분리할 수 있음 - 이 때에 분리된 놈이 Extension Usecase이고 이놈이 실행되는 특정 지점이 Extension point가 됨\n주의할 점은 일반화, include, extend의 관계는 유스케이스가 단순화되는 것이 명백할 때에만 사용해야 된다는 것과\n기능별로 include를 다 쪼개는 식으로 구성하면 안된다는 것 - 계층구조는 최대 2단계가 적당하다\n또한 순서에 대한 것은 유스케이스 다이어그램에 표현되면 안된다 - 화살표같은거 쓰지 말아라 이거야\n\nUse Case Description §\n\n각각의 유스케이스들에 대해 설명\nPrecondition : 해당 유스케이스가 실행될 수 있는 선행조건\nPostcondition : 해당 유스케이스가 종료되고 나서 만족해야 할 조건\nMain flow : 유스케이스의 핵심적인 진행과정\nAlternative flow : 에러가 나거나 했을 때의 진행과정\n\n클래스 모델링 §\n선의 종류 §\n\n그냥 실선은 서로 연관이 있다는 것\n일반 화살표, Aggregation, Composition은 모두 이 연관관계의 서브셋임\n\n일반 화살표는 화살표가 나오는 놈이 가르키는 놈을 참조할 수 있고 반대는 안된다는 것\nAggregation은 전체와 부분의 관계를 나타냄 : 마름모가 있는 곳이 전체\nComposition은 전체와 부분이긴 한데 해당 전체에 독점적일때 : 다른 곳에서는 사용될 수 없는 부분에 대해서 - 검은색 마름모가 있는 곳이 전체\n\n\n세모꼴 화살표는 일반화 관계 : 세모가 있는 곳이 부모\n\n라벨의 종류 §\n\nCardinality, Multiplicity, 다중성 : 1이면 생략가능, 0이상이면 * , 범위표현은 1..*\n\n다중성 읽는 방법은 주어에 들어갈 놈을 설정하고 그놈과 연관되어 있는 놈 하나를 목적어로 한다음 목적어에 가까이 있는 숫자가 주어와 연관될 수 있는 목적어의 갯수가 되는 것\n\n\n관계의 이름 : 관계의 이름도 적어줄 수 있고 읽는법은 다중성과 동일하며 해당 이름은 클래스의 필드명으로 사용됨\n\n연관 클래스 §\n\n두 클래스가 연관되었을 때 의미가 있는 필드가 있다면 해당 필드는 연관 클래스에 명시함\n연관 클래스는 두 클래스 연관관계 실선 중간에 점선으로 이어서 명시할 수 있음\n또는 A ( 1..* ) B ( *..1 ) C 의 연관관계로도 표현이 가능\n\n재귀 연관관계 §\n\n과목 A는 과목 B의 선행과목일때 A와 B는 모두 과목이므로 과목 클래스를 재귀 연관관계로 표현해줄 수 있는 것\n실선이 자기자신에게로 돌아가는 환형형태로 그리면 됨\n그리고 선후를 관계 이름으로 양쪽에 적어주면 됨\n잘 모르겠으면 일단 두 클래스를 그리고 관계 다중성이랑 이름 적고 클래스 두개를 겹치면 된다\n\n인스턴스 다이어그램 §\n\n다른건 다 동일한데 이것만 지키면 됨\n인스턴스 이름 : 클래스 이름 → 인스턴스와 클래스 이름을 모두 적고 :로 구분해주며 밑줄그어줘야 한다.\n"},"originals/webprogramming.fall.2021.cse.cnu.ac.kr/(충남대)-웹-프로그래밍-강의록":{"title":"(충남대) 웹 프로그래밍 강의록","links":["originals/webprogramming.fall.2021.cse.cnu.ac.kr/01.-HTML-(1)","originals/webprogramming.fall.2021.cse.cnu.ac.kr/02.-CSS-Basic","originals/webprogramming.fall.2021.cse.cnu.ac.kr/03.-JS-Basic","originals/webprogramming.fall.2021.cse.cnu.ac.kr/04.-JS-DOM","originals/webprogramming.fall.2021.cse.cnu.ac.kr/05.-PHP","originals/webprogramming.fall.2021.cse.cnu.ac.kr/06.-PHP-form","originals/webprogramming.fall.2021.cse.cnu.ac.kr/07.-HTML-(2)","originals/webprogramming.fall.2021.cse.cnu.ac.kr/08.-JQuery,-AJAX","originals/webprogramming.fall.2021.cse.cnu.ac.kr/09.-HTML-API","originals/webprogramming.fall.2021.cse.cnu.ac.kr/10.-JS-Basic-2","originals/webprogramming.fall.2021.cse.cnu.ac.kr/11.-JS-Functions","originals/webprogramming.fall.2021.cse.cnu.ac.kr/12.-HTML,-JS,-HTTP"],"tags":[],"content":"개요 §\n강의 정보 §\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n강의 구분소속교수시기학부 수업충남대학교 공과대학 컴퓨터공학과이규철 교수님2021년 가을학기\n실습 자료 §\n\n주간 실습: github://haeramkeem/Fall2021-CNU-WebP\n텀 프로젝트: github://haeramkeem/Fall2021-CNU-WebP-Pods\n\n목차 §\n\n01. HTML (1)\n02. CSS Basic\n03. JS Basic\n04. JS DOM\n05. PHP\n06. PHP form\n07. HTML (2)\n08. JQuery, AJAX\n09. HTML API\n10. JS Basic 2\n11. JS Functions\n12. HTML, JS, HTTP\n"},"originals/webprogramming.fall.2021.cse.cnu.ac.kr/01.-HTML-(1)":{"title":"01. HTML (1)","links":[],"tags":[],"content":"\n\n                  \n                  충남대학교 컴퓨터공학과 이규철 교수님의 &quot;웹 프로그래밍&quot; 강의를 필기한 내용입니다. \n                  \n                \n\n\n\n                  \n                  다소 잘못된 내용과 구어적 표현 이 포함되어 있을 수 있습니다. \n                  \n                \n\nHTML §\n\nHyper Text Markup Language\nHyper Text 라는 것은 하이퍼 링크를 통해 문서간 이동을 지원한다는 것이고\nMarkup Language라는 것은 태그 등을 사용해서 문서의 구조를 지정하는 형식을 의미함\n\nHTML 문서의 구조 §\nDOCTYPE §\n&lt;!DOCTYPE html&gt;\n\n이 문서가 HTML5를 따르는 문서라는 것을 알려줌\n\nhtml, head, body §\n&lt;html lang=&quot;en-US&quot;&gt;\n\t&lt;head&gt;\n\t&lt;/head&gt;\n\t&lt;body&gt;\n\t&lt;/body&gt;\n&lt;/html&gt;\n\n최상위 html태그아래 문서의 정보(메타데이터)를 나타내는 head, 문서의 내용을 나타내는 body 태그로 이루어져 있음\nhtml 태그의 lang 속성은 문서가 작성된 언어를 나타내며 검색엔진에서 특정 언어어로 된 정보가 필요로 할때, 그리고 시각장애인용 음성지원 등에서 사용한다\n\nElements §\n&lt;tag&gt;content&lt;/tag&gt;\n\n시작태그와 끝 태그(닫는 태그), 그리고 그 안의 내용으로 구성됨\n&lt;br&gt; 태그같은 몇몇 태그들은 닫는 태그가 없기도 함\n\nAttributes §\n&lt;tag name=&quot;value&quot;&gt;&lt;/tag&gt;\n\nAttribute는 Element의 속성을 나타내며\n속성명=“속성의 값” 의 형태로 나타나게 된다\n\n새로 배운 속성 §\n\nalt : img등의 태그에서 콘텐츠를 로드하지 못했을 때 표시할 대체문자. 시각장애인용 음성지원 등으로도 사용된다\ntitle : tooltip - 마우스를 올렸을 때 띄울 텍스트\nsrc : 상대주소가 /로 시작하지 않으면 현재 디렉토리를 기준으로 한다는 것을 기억할 것\n\nHTML 태그 몇가지 §\nh1, h2, h3 … §\n\n문서의 제목, 소제목 등을 나타냄\n글자 크기를 나타내는 태그가 아니고 제목의 중요도(제목인지, 소제목인지 등등)을 나타내는 것이므로 의미를 생각해서 적용해야 한다\n\nhr §\n\n화면에 수평선을 그어줌\n이것도 의미를 생각해서 써야된다 - 문서의 주제가 전환될 때 등에서 사용됨\n\nb, strong, i, em §\n\nb와 strong은 글씨를 굵게하는 공통점이 있지만 b의 경우에는 그냥 bold의 시각적인 효과만 가지는 반면, strong은 강조하는 내용이라는 의미 또한 가지게 된다\n마찬가지로 i와 em은 글자를 기울인다는 공통점이 있지만 i의 경우에는 italic의 시각적인 효과만 가지는 반면, em은 인용문구라는 의미 또한 가지게 된다\n\nsmall, mark, del, ins, §\n\nsmall : 작은 텍스크\nmark : highlighted\ndel : 삭제되었다는 의미 이런 효과\nins : 추가되었다는 의미, 밑줄 이런 효과\nsub : 아래 작게 설명을 위한 텍스트를 보여주는 태그\nsup : 위에 작게 텍스트를 보여줌\n\na §\n\n링크의 상태에 따라 스타일 기본값이 다르다\n\nunvisited : 파란색 글자에 밑줄\nvisited : 보라색 글자에 밑줄\nactive : 클릭되어있는 순간에 빨간색 글자로 보임\n\n\ntarget 속성 : 페이지를 어디에 로드할 것인지 - 대표적으로 다음과 같은 값을 가질 수 있다\n\n_self : 현재의 탭에 띄움\n_blank : 새로운 탭에 띄움\n_parent : 상위 프레임에 띄움(iframe과 관련됨)\n_top : 최상위 프레임에 띄움\niframe의 name값을 넣어줄 수도 있음\n\n\nhref 값으로 id를 적으면 해당 id의 element로 화면이 움직인다 - href=“#element-id” 이런식으로 적으면 됨\n\niframe §\n\n화면 내에 다른 html파일이나 페이지를 띄우는 태그\nname=“” 으로 프레임의 이름을 지어줄 수 있다\n\nimg §\n\n( img의 width, height속성 ) -&gt; ( &lt;style&gt; 태그로 지정해준 스타일 ) -&gt; ( &lt;style=“”&gt; 속성으로 지정해준 스타일 ) 의 우선순위로 이미지의 크기가 정해진다\n\ntable, tr, td, th §\n&lt;table&gt;\n\t&lt;tr&gt;\n\t&lt;th&gt;&lt;/th&gt;\n\t&lt;/tr&gt;\n\t&lt;tr&gt;\n\t&lt;td&gt;&lt;/td&gt;\n\t&lt;/tr&gt;\n&lt;/table&gt;\n\n다음과 같은 구조를 가짐\ntable : wrapper\ntr : table row\nth : table header\ntd : table data\nth의 scope 속성은 해당 헤더가 의미하는 바가 열인지 행인지를 나타낸다 - scope=“row” 는 헤더가 행을 설명하는 것이고, scope=“col” 은 열을 설명한다는 것을 나타낸다\ntd나 th에 colspan=“숫자” 를 넣으면 해당 열만큼 자리를 차지하게 된다 - col이라고 해서 세로방향으로 커지는게 아니다! - 열에 걸쳐 커지는 것\n마찬가지로 rowspan=“숫자” 는 해당 행만큼 자리를 차리한다는 의미이다 - 가로방향으로 커지는게 아니다! - 행에 걸쳐 커지는 것\n헤더를 묶은 thead와 데이터를 묶은 tbody가 존재하듯이 맨 마지막에 통계 등을 표시하는 tfoot도 존재한다\n\nmeta §\n\ncharset : 문자 인코딩 방식\nname=“keyword” : 문서의 키워드\nname=“description” : 문서의 설명\nname=“author” : 문서의 저자\nhttp-equiv=“refresh” content=“30” : 30초마다 새로고침함\nname=“viewport” content=“width=device-width, initial-scale=1.0” : 문서가 보여질 창의 크기와 배율의 초기값을 지정\n\nbase §\n\na같은 하이퍼링크들에 대한 base를 지정함\n\n&lt;base href=&quot;www.google.com&quot; target=&quot;_blank&quot;&gt;\n\n위의 예제는 기본 origin 으로 www.google.com 을 취하고 페이지가 로드될 기본 모드는 _blank 이게 된다\n\nform, input, label, select, option §\n\nform : 입력 정보들을 감싸는 wrapper\n\naction : 리퀘스트를 어디로 날릴건지\ntarget : 서버로부터 받은 응답을 받은 후에 어떻게 할 것인지 - img태그의 target 속성과 동일한 값을 가진다\nmethod : GET, POST\nGET방식의 param은 글자수 제한이 있기 때문에 url이 너무 길어지면 GET을 쓰지 못한다는 점기억해라\n\n\ninput : 정보 입력용 element\n\ntype : 입력할 정보의 타입(비밀번호, 숫자 등등)\n\nradio : 하나만 선택할 수 있음\ncheckbox : 여러개 선택할 수 있음\nnumber일때 step=“숫자” 의 속성을 넣어주면 아래 그림처럼 숫자를 클릭으로 바꿀 수 있는 뭐라해야돼 저걸 어쩃든 저게 나온다 - “숫자”는 한번 눌렀을 때 바뀌는 숫자의 크기이다\n\n\n\n\n\n\n\nrange 는 슬라이더를 만든다. 그리고 min, max 를 통해 슬라이더의 최대최소 값을 지정할 수 있고 step 을 통해 얼마나 빠르게 슬라이더를 움직일 수 있는지 지정해 줄 수 있다\nname : json의 키에 해당한다고 생각하면 됨\nvalue : json의 값에 해당한다고 생각하면 됨 - input태그의 속성으로 value를 지정해주면 input값의 초기값이 된다\nsize : 입력창 크기\nminlength, maxlength : 입력값 글자 숫자 제한\nchecked : radio나 checkbox의 경우에 기본적으로 선택될 놈\nrequired : 반드시 입력해야 하는 항목\npattern=“regex” 를 통해 입력값을 정규식으로 검토할 수도 있다\nlabel : input element에 붙는 제목, 혹은 input을 감싸는 wrapper - for속성을 통해 해당 값을 id로 갖는 input과 연결되거나 label태그의 하위 element로 input태그를 넣어줌으로 연결시킬 수 있음\nselect, option : 옵션 드랍다운\n\nmultiple : 여러개 입력 가능\n\n\ntextarea : 여러줄의 텍스트를 입력받을 수 있는 기능\nfieldset, legend : 여러개의 input태그를 의미적으로 묶는 wrapper, legend는 fieldset의 제목을 붙이는 것\ndatalist : input태그의 list 속성값을 datalist태그의 id로 해주면 datalist의 option들 중 하나로 값을 입력하는 것이 가능함(option들의 값이 아닌 것을 입력하는 것도 당연히 가능함)\n\n"},"originals/webprogramming.fall.2021.cse.cnu.ac.kr/02.-CSS-Basic":{"title":"02. CSS Basic","links":[],"tags":[],"content":"\n\n                  \n                  충남대학교 컴퓨터공학과 이규철 교수님의 &quot;웹 프로그래밍&quot; 강의를 필기한 내용입니다. \n                  \n                \n\n\n\n                  \n                  다소 잘못된 내용과 구어적 표현 이 포함되어 있을 수 있습니다. \n                  \n                \n\n몰랐던거만 캐치해보자고 §\nCascading 의 의미 §\n\nCascade : [명사] 작은 폭포\n폭포수가 위에서 아래로 물이 흐르듯이, 상위 컴포넌트에서 하위 컴포넌트로 스타일이 적용된다는 의미를 가짐\n\nCSS를 사용하는 이유 §\n\n스타일에 관한 것을 분리해 스타일만 교체하면 html을 고칠 필요 없이 손쉽게 스타일을 바꿀 수 있기 때문\n\nSelector의 종류 §\n\nSimple selector : 단순 element이름, class, id\n\nid나 class는 숫자로 시작할 수 없음에 주의할 것\n\n\nCombination selector : 띄어쓰기나 &gt; 로 상하위 관계 표현하는거\nPseudo-class selectors : :hover 등 element의 상태에 따라 선택하는 거\nPseudo-element selectors : element의 일부분만 선택한다는데 뭔소린지 모르겠음\nAttribute selectors : 특정 속성의 특정 값을 가지는 element만 선택하는 것\n\n특정 attribute를 가지는 element들을 선택하는 것은 [] 를 사용하면 된다\n그리고 특정 값이 attribute value에 포함되는 element 를 선택하는 것은 *= 를 사용하면 된다\n\n\n\n/* href attribute 를 가지는 놈을 선택 */\n[href] {\n...\n}\n \n/* attribute-value에 thoth가 포함된 놈을 선택 */\n[href*=&#039;thoth&#039;] {\n...\n}\n \n/* a tag 중 attribute-value에 thoth가 포함되는 놈을 선택 */\na[href*=&#039;thoth&#039;] {\n...\n}\n\n!important 라는게 있는데 얘를 붙여주면 id보다도 높은 제일 높은 우선순위가 되어 적용된다 (e.g. color: black !important;)\n\nCSS 적용 순서 §\n\nhead태그를 읽고 나서 body로 가기 때문에 inline style이 가장 나중에 적용돼 우선순위가 높아진다\nhead태그 안에서는 그냥 나중에 적어준게 적용된다 (link태그 아래 style 태그가 있으면 style 태그의 내용이 적용됨)\n\n색상 포맷 §\n\n# 형식\n\n#RRGGBB 순서로 각각 16진수의 값이 들어감\n#000000 은 흰색을 나타내고 #FFFFFF 는 검은색인거 잊지 말것\n세 숫자들이 16보다 작은 경우에는 #RGB 이렇게 쓸 수도 있다\n그리고 #RRGGBBAA 로 8숫자를 이용해 투명도를 표현할수도 있고\n투명도를 #RGBA 이렇게 쓸 수도 있다\n\n\nrgb, rgba\n\n#RRGGBB 에서의 16진수들을 10진수로 나타낸 것\n즉, rgb(0, 0, 0)은 #000000 와 같고 흰색임\n그리고 rgb(255, 255, 255)는 #FFFFFF 와 같고 검은색이 된다\n그리고 rgba는 불투명도인 alpha가 붙게 되며 0~1의 값을 가지고 0이면 완전투명, 1이면 완전불투명하게 된다\n\n\nhsl, hsla\n\nh는 색원반에서의 각도를 나타내며 0~360의 값을 가짐\ns는 채도(약간 물빠진 색이라고 생각하면 됨)를 나타내며 100~0%의 값을 가짐 : 100%이면 원색, 0%이면 회색이 된다\nl은 밝기를 나타내며 이것도 100~0%의 값을 가짐 : 100%이면 원색, 0%이면 흰색이 된다\nhsl(180, 100%, 100%)뭐 이런식으로 표현하는듯\nhsla는 rgba처럼 불투명도를 나타내는 값도 포함시키는 것임\n\n\n\nbackground §\n\nopacity : rgba대신 투명도를 지정해줄 수 있는 속성 - 마찬가지로 0~1의 값을 가진다\nbackground-image: url(); : background-image 속성은 url() 와 함께 써야된다는 것 잊지말거\nbackground-repeat : background-image 의 경우에는 디폴트로 이미지의 크기를 조정하기 않고 가로세로 반복을 하게 됨\n\nrepeat-x : 가로축 방향으로만 반복하고 세로축으로는 화면을 채움\nrepeat-y : 세로축 방향으로만 반복하고 가로축으로는 화면을 채움\nno-repeat : 반복하지 않음\n\n\nbackground-position : 이미지의 위치 지정 가능 - right top이면 오른쪽 위에 이미지가 위치하게 됨\nbackground-attachment : 이미지의 display지정 가능 - 일반 display 속성마냥 fixed를 주면 스크롤을 해도 화면에 고정돼있게 된다\nbackground : flex마냥 축약형 표현이 존재함\n\nbackground : {{ background-color }} {{ background-image }} {{ background-repeat }} {{ background-attachment }} {{ background-position }}\n\n위와 같은 순서로 적어주면 된다\n\nBox model §\n\nwidth와 height 속성은 content의 크기를 조절해주는 거랜다 - padding, border, margin 은 저 속성의 값에 포함되지 않는댄다\n따라서 element의 크기를 정할떄는 width, height뿐 아니라 padding, border도 고려해줘야 된다는 것\n또는 다음과 같은 방법으로도 해결 가능하다 - box-sizing: border-box; 를 해주면 border까지 포함한 너비나 높이를 width, height로 지정 가능하다\n그리고 max-width, max-height, min-width, min-height등의 속성으로 그리드의 minmax처럼 반응형 설계가 가능하다\n\nBorder §\n\n너가 지금까지 써오던 5px solid black 은 border-width, border-style, border-color 의 축약형이라 할 수 있다\nborder-width는 margin이나 padding마냥 값을 여러개 줄 수 있다\n\n값을 하나 주면 모든 면이 동일한 굵기\n값을 두개 주면 top-bottom이 첫번째 굵기, left-right가 두번째 굵기로 지정됨 - 잊지말어라\n값을 세개 주면 top, left-right, bottom순으로 적용됨\n값을 네개 주면 알다시피 시계방향으로 적용된다\nborder-style이나 border-color도 마찬가지로 적용 가능하다\n\n\nborder를 지정할때는 border-style이 반드시 있어야 한다 - style이 없으면 border가 표시되지 않음\nborder-radius의 값은 반지름이다\n특정 꼭짓점만 radius를 지정하기 위해서는 border-top-right-radius등으로 하거나 값을 4개를 주어 오른쪽 위부터 시계방향으로 돌게 할 수 있다\n\nMargin §\n\nmargin: auto를 통해서 이놈을 중앙배열 시키는 것도 가능하다 - 좌우가 동일하게 반응형으로 들어감\ninherit은 알다시피 부모 값 그대로 사용\ncollapse : 이건 속성이 아니라 현상인데 두 element에 대해 위 element에 margin-bottom이 정의되어 있고 아래 element에 margin-top이 정의되어 있을 경우 브라우져는 이 둘중 가장 큰 값으로 둘 사이의 간격을 지정한다 - margin이 겹치게 되는 셈\n\n예를들어 윗쪽 div의 margin-bottom이 20px이고 아랫쪽 div의 margin-top이 50px이라면 이 둘 사이의 간격은 70px이 아니라 50px이 되는 것\n이 현상은 top-bottom의 관계에서만 나타난다 - left-right에서는 이러한 현상이 나타나지 않음\n\n\n\nText §\n\ntext-align: justify; 로 텍스트 배치를 양옆으로 stratch시킬 수 있다\nvertical-align 으로 높이에 대한 배치를 해 줄 수 있으나 inline tag에서만 가능했던거같다\ntext-transform: uppercase; 으로 텍스트의 대소문자를 해결할 수 있다 - capitalize로 단어 첫글자만 대문자로 하는 것이 가능\ntext-indent: 50px; 로 문단의 첫 문장을 들여쓰기 하는 것이 가능하다\nletter-spacing, word-spacing 의 속성을 이용해 글자간, 단어간 간격을 설정하는 것이 가능하다\nline-height 속성으로 문장 간 간격을 설정할 수 있다 - 얘는 단위가 없는 값을 더 선호한다 - 단위없는 값이 사용되었을 경우 반응형으로 움직이기 때문\nwhite-space 속성은 한번써봤제?\n\nnowrap 의 경우에는 개행을 하지 않고 컨테이너를 빠져나감, \\n 도 무시하고 br태그만을 이용해서 개행이 이루어진다. 또한 탭이나 스페이스들은 전부 스페이스 하나로 변환된다.\nnormal 의 경우에는 컨테이너를 빠져나갈경우 개행되며 \\n 에 의해서도 개행되게 된다. 다만 탭이나 스페이스는 스페이스 하나로 변환된다\npre 의 경우에는 pre태그마냥 컨테이너를 빠져나가는 것으로는 개행이 안되고 \\n 에 의해서만 개행이 된다. 그리고 탭이나 스페이스도 그대로 보여주게 된다\n\n\ntext-shadow : 얘는 shadow가 뒤에 깔리고 그 위에 텍스트가 올라가는 형식으로 이해를 한다면 첫 두개의 값은 뒤에 깔리는 shadow의 위치를 나타내는 값이다. 그리고 세번째 값은 번짐의 정도, 네번째는 색상이다\n\n예를들어 text-shadow: 2px 3px 5px gray 의 경우에는 shadow의 위치가 오른쪽으로 2px, 아래로 3px 내려가며 번짐의 정도는 5px, 그림자의 색은 gray가 되어벌임\n\n\n\nFont §\n\n일단 Serif는 타임즈 글씨마냥 삐죽삐죽 튀어나와있는거고 Sans-serif는 그런게 없는거다\n\nSerif가 인쇄물에 적합하고 컴퓨터 화면은 Sans-serif가 더 가독성이 좋댄다\n\n\nfont는 font-family 속성으로 적용되며 첫번째 값으로 준 폰트가 적용되나 이게 적용되지 않을 경우를 대비해 두세번째 값도 대체폰트로 넣어주더라\nfont-style 은 italic과 같은 기울기 등의 효과를 주는데 활용. oblique 라는 값도 있는데 italic이랑 동일하며 랜더링 과정의 차이만 있고 보통 italic을 많이 쓴댄다\nfont-weight 은 알다시피 폰트의 두께이다\nfont-variant: small-caps; 로 아래와 같은 효과를 주는 것이 가능하다\n\n\n\nfont-size 의 em, ex : em 은 대문자 M의 너비를 1로 잡은 값이고 ex 는 소문자 x의 높이를 1로 잡은 값이다. 글자 크기의 디폴트는 16px이기 때문에 1em은 16px와 같다\nfont 라는 것을 통해 축약형 표현이 가능하다\n\nfont: {{ font-size }} {{ font-variant }} {{ font-weight }} {{ font-size/line-hight }} {{ font-family\n\n구글 웹폰트 사용하기 - 폰트 페이지에서 download font 하지 말고 select this font하면 CDN이나 @import로 가져올 수 있는 링크를 보여준다\n\nVisibility §\n\ndisplay: none; 을 통해 화면에서 아예 지워버리는 것과는 다르게\nvisibility: hidden; 을 통해서도 표시되지 않게 할 수 있다. 다만, 이놈은원래 이놈이 차지하던 자리까지 없어지지 않는다 - 텅 빈상태로 남아있게 된다 이말이야\n\nLink §\n\na:link : unvisited link\na:visited : visited link\na:hover : mouse-over event\na:active : onclick event\nhover 앞에는 link와 visited가 정의되어 있어야 하고 active 앞에는 hover가 정의되어 있어야 한다? - 아니 안해도 되던데?\n\nList §\n\nlist-style-type 으로 각 list의 스타일을 바꿔줄 수 있다\n\nnone으로 했을 경우 text의 위치는 그대로 남는다 - margin, padding을 이용해 위치를 조정해줄 수 있다\n\n\nlist-style-image: url(); 을 통해 이미지를 불러오는 것도 가능하다\nlist-style-position 으로 list icon의 위치를 지정해 줄 수 있다\ninside 의 경우\n\n\n\noutside 의 경우\n\n\n\nlist 속성으로 축약형 표현도 가능하다\n\nlist: {{ list-style-type }} {{ list-style-position }} {{ list-style-image }}\nTable §\n\n셀 안에서의 텍스트 위치는 vertical-align 을 통해 가능하다\n:nth-child 를 통해 다양한 스타일링이 가능하다 - 가령, tr:nth-child(even) 으로 짝수번째 열만 스타일링을 해주는 것이 가능하다\n\nBootstrap4 §\n\nCDN을 이용한 설치는 아쉽게도 4개의 라이브러리를 CDN으로 받아와야 된다\nCDN을 이용한 설치를 하면 다른 bootstrap을 사용하는 웹페이지에 있다 왔을 경우에 bootstrap이 캐시에 남아있기 때문에 재요청을 하지 않아 좀 더 빠르게 페이지가 로드된다\nmeta의 viewport는 vscode 기본 설정을 써도 된다. 즉,\n\n&lt;meta name=&quot;viewport&quot; content=&quot;width=device-width, initial-scale=1&quot;&gt;\n로 해주면 되더라 - mobile device 에 따른 대응도 하기 위함\nGrid System §\nContainer §\n\n부트스트랩은 element를 담기 위한 container를 제공함\n\n.container : 고정된 사이즈지만 반응형을 지원함 - 양옆은 동일한 너비로 비워지게 됨\n.container-fluid : width=100% 으로 화면 너비를 다 채우는 컨테이너\n\n\n\nColumn §\n\n부트스트랩은 전체 container를 12분할한 column을 제공한다\n\n\n\n위의 공간을 땅따먹기하면됨\n그리고 column에 대해 기기마다 다른 설정이 되어 있는 클래스들을 제공한다\n아래의 클래스들은 접두어로 이 뒤에 숫자들이 붙어 grid column을 구성하게 된다 - .col-4 이런식으로\n\n.col- : 가장 작은 스마트폰 정도의 디바이스(~576px)\n.col-sm- : 태블릿 정도 사이즈(576px~768px)\n.col-md- : 노트북 정도 사이즈(768px~992px)\n.col-lg- : 데스크탑 정도 사이즈(992px~1200px)\n.col-xl- : 큰 모니터(1200px~)\n\n\n그리고 숫자들을 적지 않으면 걍 남은 부분에 대해 같은 크기로 나눠먹는다\n한 row에 있는 col들은 숫자의 합이 12가 되어야 한다 - 넘으면 줄바꿈이 들어감\n\n\n\n그리고 위처럼 클래스를 여러개 지정해서 화면크기에 따라 대응을 할 수도 있더라\n\nGrid system hierarchy §\n\n하나의 그리드를 담는 요소로 .container가 사용되고, 그 아래 .row, 말단에 .col이 들어가게 됨\n반드시 위와 같은 계층구조를 지켜야된다 - .container 안에 .container 가 들어갈 수는 없는 노릇이다 이거야\n"},"originals/webprogramming.fall.2021.cse.cnu.ac.kr/03.-JS-Basic":{"title":"03. JS Basic","links":[],"tags":[],"content":"\n\n                  \n                  충남대학교 컴퓨터공학과 이규철 교수님의 &quot;웹 프로그래밍&quot; 강의를 필기한 내용입니다. \n                  \n                \n\n\n\n                  \n                  다소 잘못된 내용과 구어적 표현 이 포함되어 있을 수 있습니다. \n                  \n                \n\n이것도 몰랐던거만 캐치해보자고 §\n\nJavaScript는 ECMAScript 라고 부르기도 한다\n&lt;script&gt; 태그는 &lt;/body&gt; 위에 있어야 한다 - script를 처리할때는 html이나 css등을 처리하지 않고 script만 처리하기 때문에 html이 전부다 로드되어있지 않으면 에러가 날 수도 있음 - 따라서 html을 전부 로드하고 script를 처리해주기 위해 body의 닫는 태그 위에 작성해주는 것\ndocument.write() 함수는 페이지가 로드되고 나서 호출되면 새로운 페이지에 띄우기 때문에 기존의 것이 다 사라지게 된다 - event같은걸로 호출하면 페이지에 있던게 다 지워질 수도 있다\ndocument객체는 브라우저 화면에 대한 조작을 담당하는 객체이고, window객체는 브라우져 화면뿐 아니라 브라우저 전체에 대한 조작을 담당한다 - alert() 가 window 의 함수인 것이 이것때문임\nwindow.print() 메소드는 화면출력이 아니고 프린터기로 출력하는 것을 의미한다\nvar와 let의 차이점은 var의 경우에는 변수 중복 선언시에 이전의 변수를 그대로 사용하게 되지만 let은 그렇지 않고 에러가 나게 된다\n\nvar x = 3; var x; 이렇게 해줘도 x는 여전히 3의 값을 가지게 되는 것\n\n\nLiteral은 숫자나 문자열처럼 어떤 ‘값’을 의미한다\n식별자는 다른 언어와 동일하게 숫자로 시작할 수 없다\n문자열과 문자열이 아닌 것을 더하면 앞에서부터 덧셈를 하되 문자열을 만나면 문자열이 아닌 놈들을 전부 문자열로 변환함 - 문자열 형변환으로 사용하더라\n\n예를들면 ”5” + 2 + 3 의 결과는 523 이고\n2 + 3 + &quot;5&quot; 의 결과는 55 이다\n\n\n비트 연산자는 32bit 형태에서 진행된다\nES6 부터 ** 연산자로 제곱연산을 지원한다\n함수 호출은 다음의 세 경우의 수로 이루질 수 있다\n\n이벤트 콜백\nJS코드로 호출했을때\nSelf-invoke : singleton design pattern에서처럼 (function(){})() 로 스스로 호출되었을 때\n\n\nString, Number, Boolean객체를 new로 생성하지 않아도 해당 클래스에서 제공하는 메소드를 사용할 수 있다\nevent는 onload 처럼 브라우저가 발생시키는 것과 onclick 처럼 사용자가 발생시키는 것이 있다\n그리고 button태그의 onclick attribute처럼 html에 이벤트이름=“JS코드” 속성-값 쌍을 만들어서 넣어줄 수도 있다\n\nMDN에서도 확인할 수 있지만 대표적인 몇개 아래에 정리되어 있다\n\n\n\n\n\n숫자와 문자열로 표현된 숫자를 비교하는 것이 가능하다. 하지만 숫자가 아닌 문자열처럼 숫자의 형태가 아닌 것의 경우(NaN)에는 항상 false가 나오게 된다\n\n예를들면 2 &lt; &quot;12&quot; 의 결과는 true이다.\n하지만 2 &lt; &quot;dude&quot; 의 결과는 false가 된다\n\n\n문자열의 비교는 다른 언어처럼 인덱스별로 ascii코드를 비교한다\n\n&quot;mate&quot; &lt; &quot;dude&quot; 의 결과는 m이 d보다 작으므로 true이다\n&quot;2&quot; &lt; &quot;12&quot; 의 결과도 2가 1보다 크기 때문에 false이다\n\n\n나중에 까먹을게 분명하지만 Number(), String(), Boolean()을 통해서 형변환이 가능하다\nswitch문에서는 === 의 strict comparison을 사용한다 - “0” 을 넣으면 case 0: 에는 걸리지 않는다는 소리\nTypeScript에서 되는지는 모르겠는데 object에 대해서 for-in문을 사용할 수 있다\n\nconst obj = {key1: &quot;1&quot;, key2: &quot;2&quot;};\n \nfor(let key in obj) {\n\tconsole.log(obj[key]);\n}\n\n위 코드의 결과는 1(줄바꿈)2 가 나온다\n만약에 된다면 Object.entries() 를 안써도 된다는 사실\n아마 string index를 object type에 지정해줘야 가능하지 않을까\nfor-of문은 iterable의 경우 사용할 수 있으며 어디선가 iterator가 무효화되어도 사용할 수 있다는 것을 본것 같다\ncontinue문 뭔가 찝찝해서 안쓰게 되는데 continue를 만나면 다음으로 넘어간다 - 전통적인 for문의 경우 I++가 수행된다는 사실\nJS에는 C언어에서의 GOTO와 유사한 기능이 있다 - Label기능 - 얘는 label을 지정하고 break 라벨이름 이나 continue 라벨이름 이런식으로 적으면 해당 label의 context를 빠져나가게 된다\n\nlabelName:\nwhile(true) {\n\tfor(let i = 0; i &lt; 100; i++) {\n\t\tif(i === 10) { break labelName; }\n\t}\n}\n\n위 코드의 경우에 i가 10이 되면 for문 하나를 빠져나오는게 아니고 while전체를 빠져나오게 된다\n\nlabelName: {\n\tconsole.log(&quot;my&quot;);\n\tconsole.log(&quot;god&quot;);\n\tbreak labelName;\n\tconsole.log(&quot;holy&quot;);\n\tconsole.log(&quot;moly&quot;);\n}\n\n이놈의 경우에는 my-god 만 출력되고 해당 블럭을 빠져나오게 된다\n"},"originals/webprogramming.fall.2021.cse.cnu.ac.kr/04.-JS-DOM":{"title":"04. JS DOM","links":[],"tags":[],"content":"\n\n                  \n                  충남대학교 컴퓨터공학과 이규철 교수님의 &quot;웹 프로그래밍&quot; 강의를 필기한 내용입니다. \n                  \n                \n\n\n\n                  \n                  다소 잘못된 내용과 구어적 표현 이 포함되어 있을 수 있습니다. \n                  \n                \n\nJS DOM 구조 §\n\n아래 그림처럼 구조가 되어 있다\n\n\n\n리프노드는 무조건 Text node 이다\n그리고 Attribute는 트리에 속한다기보다는 그냥 해당 노드를 설명해준다고 생각하면 됨 - attribute node는 deprecated되었다는 것\nDOM의 종류는 세가지가 있다\n\nCore DOM : 모든 형식에 공통적으로 적용되는 표준\nXML DOM : XML 형식의 문서에 적용되는 표준\nHTML DOM : HTML 형식의 문서에 적용되는 표준\n\n\n\nHTML DOM §\n\nHTML요소들을 객체로 표현하고 각각에 대해 필드와 메소드를 정의하며, 발생시킬 수 있는 Event들이 정의되어 있음\n대표적인 tag들은 아래처럼 document의 property로 정의되어 있어 바로 사용하는 것이 가능하다\n\nHTML tag property §\n\n\n이놈은 아래와 같은 방식으로 사용 가능하다\n\n\n\ndocument.elementNames 을 통해 해당 태그를 모아서 HTML Collection으로 받아올 수 있다 - HTML Collection이기 때문에 예시에서 보이는것처럼 인덱스 말고도 name이나 id로 접근이 가능하며 Chaining도 가능하다\n\n\n\n또한 이런 방식으로 선택한 객체에는 .elements 라는 property가 있어서 그의 자식들에 index로 접근할 수 있고 자식의 갯수는 .length 로 얻어올 수 있다\n\nForm validation §\n\n\n여기서 주의깊게 볼 점은 onsubmit 이다\n위에서처럼 submit을 했을때 콜백함수를 정의해주고 onsubmit 의 값으로 return callback 을 넣어주면 콜백함수가 true 를 반환했을 때 정상적으로 리퀘스트가 날라가고 아니라면 리퀘스트를 날리지 않는 동작을 해줄 수 있다\nValidation은 다음과 같이 분류할 수 있다는거 - 걍 알아두기만 해라\n\n어디서 검증?\n\nClient-side validation\nServer-side validation\n\n\n어떻게 검증?\n\nHTML Input Attributes : 뭐 required같은 속성 넣어서\nCSS Pseudo Selectors : CSS의 기능을 사용\nDOM Properties and methods : JS의 메소드 사용\n\n\n\n\n\nEvents §\n\nonload, onunload : 화면의 구성이 끝났을때, 화면에서 DOM트리 제거가 완료되었을때의 이벤트\nonchange : input등에서 입력값이 바뀌었을때의 이벤트 - 입력할때마다 바뀌는 건 아니고 enter등의 행위를 해줘야됨\nonfocus : input등을 클릭해 커서가 깜빡거리는 상태가 되었을 때의 이벤트\n이벤트를 프로퍼티에 함수를 할당하는 방식은 allocation연산이기 때문에 여러개의 콜백을 정의할 수 없지만 .addEventListener() 는 할당이 아닌 추가이기 때문에 여러개의 콜백을 정의할 수 있다\n이벤트에 대한 콜백을 지우는 것은 .removeEventListener() 를 쓰면 되는데 너가 저번에 해봐서 알다시피 콜백을 지우는 상황이 생기면 그 콜백을 익명함수로 선언하지 말고 이름을 붙여주는게 정신적으로 이롭다\n그리고 .addEventListener() 함수에 들어가는 콜백은 인자를 안받거나 event객체만 받을 수 있으므로 더 많은 인자를 주기 위해서는 더 많은 인자를 받은 함수를 정의하고 그걸 wrapping해서 콜백으로 넣어주면 된다\n알다시피 event객체의 type프로퍼티를 통해 이벤트의 이름을 갖고 올 수 있고 target프로퍼티를 통해 이벤트를 발생시킨놈 객체를 갖고올 수 있다\n\nEvent bubbling, Event Capturing §\n\n일단 .addEventListener() 메소드의 세번째 인자 이름이 useCapture 인 것을 알고있을것이다\n얘는 기본적으로 false의 값을 가지게 되며 이때는 Event Bubbling이 일어나게 된다\n하지만 true를 넣어주면 이때는 Event Capturing 이 일어나게 된다\nEvent Bubbling이라는 것은 이벤트가 발생했을때 이벤트를 발생시킨 놈에서부터 시작해서 그의 상위 컴포넌트로 점차 확장되는 형태를 말하고\nEvent Capturing이라는 것은 이벤트가 발생했을 때 이벤트를 발생시킨 놈에서부터 시작하는게 아니라 최상위 컴포넌트에서부터 시작하여 발생시킨놈까지 하위 컴포넌트로 내려오며 이벤트가 전이되는 형태를 말한다\n따라서 이건 상위컴포넌트와 하위컴포넌트에 동일한 종류의 이벤트에 대한 콜백이 정의되어 있을때 고려해줘야 한다 - 다른 이벤트에 대한 콜백이 정의되어 있으면 어차피 전이되어봤자 실행되어야 할 콜백이 없으므로\n예를들어 상위컴포넌트와 하위컴포넌트 모두 onclick에 대한 콜백이 정의되어 있으면 bubbling시에는 하위 컴포넌트를 누르면 하위 콜백 → 상위 콜백이 실행된다\n하지만 capturing일때는 하위 컴포넌트를 눌렀을 때 상위 콜백 → 하위 콜백 순서로 실행되게 된다\n\nDOM Navigation §\n\nDOM 객체들 간의 관계\n\n\n\n위 그림 보면 걍 딱 이해된다\n교수가 nodeName 이라는 프로퍼티에 대해 좀 설명을 해주던데\n\n얘는 일단 read-only한 대문자 값이다\n또한 element의 경우에는 tag 의 이름\nattribute일 경우에는 attribute 이름\ntext node의 경우에는 무조건 #text 이고 document의 경우에는 무조건 #document 이다\n\n\n그리고 nodeValue 에 대해서도 설명하는데\n\n얘는 textNode 만 갖고 있는 값이다 - 다른것들은 null의 값을 가짐\n그리고 textNode 의 값을 나타내는 것이다\n\n\n뭔 nodeType 같은것도 알려주는데 그건 이 아래 표 보면 깔끔하다\n\n\nDOM 조작 §\n\n.insertBefore() 메소드는 이름처럼 주어진 element이전에 붙이는 거다\n사용방법은 이거처럼 하면 된다\n\n부모.insertBefore(이놈을, 이놈앞에 /* - 얘는 &quot;부모&quot;의 자식이어야함 */);\n\n.remove() 는 자기자신을 지우는 메소드 - 구형 브라우져 지원안함\n.removeChild() 을 이용해 부모.removeChild(자식)이래 쓰는 것을 권장한댄다\n.replaceChild() 를 이용해 요소를 바꿔치기할 수 있댄다\n\n부모.replaceChild(이놈을, 이놈대신 /* - 얘는 &quot;부모&quot;의 자식이어야함 */);\n\nHTML Collection이랑 NodeList는 비슷하지만 아래와 같은 차이점이 있다\n\nNodeList는 .querySelectorAll() 이나 .childNodes 로 받아올 수 있다 - 메소드나 프로퍼티에 따라 다르다는 점\n그리고 HTML Collection은 index말고도 name이나 id로 접근이 가능하지만 NodeList는 인덱스로밖에 접근이 안된다\n\n\n"},"originals/webprogramming.fall.2021.cse.cnu.ac.kr/05.-PHP":{"title":"05. PHP","links":[],"tags":[],"content":"\n\n                  \n                  충남대학교 컴퓨터공학과 이규철 교수님의 &quot;웹 프로그래밍&quot; 강의를 필기한 내용입니다. \n                  \n                \n\n\n\n                  \n                  다소 잘못된 내용과 구어적 표현 이 포함되어 있을 수 있습니다. \n                  \n                \n\n\n\n                  \n                  본 문서는 작성자의 귀찮음 때문에 참고 문서 링크들로 범벅되어 있습니다.\n                  \n                \n\nCase sensitivity §\n\nif, else while 같은 키워드들은 대소문자를 구분하지 않고\n변수 이름같은 식별자만 대소문자를 구분한다\n\nBasic PHP §\n&lt;?php\n// Comments\n# Comments\n/* Comments */\n$variable = 3 // Loosely typed variable\n?&gt;\nVariable, Constant §\nAccessing Global Variables §\n\nglobal 키워드를 써야 local scope 에서 global variable 을 사용할 수 있다고 한다: global keyword\n$GLOBALS collection\n\nStatic §\n\nstatic keyword\n\nConstant §\n\ndefine()\nconstant array\n\nArray §\n\narray()\ncount()\nAssociative array - map\nMulti-dimensional array\n\nSort §\n\nAscending order\nDescending order\nAssociative array sort\nKey sort\n\nObject §\n\nclass, constructor, new keyword\n\nString §\nFormatting §\n\nConcatenate\n\nUtils §\n\nstrlen()\nstr_word_count()\nstrrev()\nstrpos()\nstr_replace()\n\nNumber §\nUtils §\n\nis_int()\nis_float()\nis_numberic()\nint casting\n\nOperator §\n\n&lt;=&gt; - Spaceship operator\n?? - Null Coalescing\n\nLoop §\n\nforeach - as\nIterating array / object\n\nFunction §\n\nDefault Argument\nReference Argument\n\nSuperglobals §\n\n$_SERVER\n$_REQUEST\n$_POST\n$_GET\n"},"originals/webprogramming.fall.2021.cse.cnu.ac.kr/06.-PHP-form":{"title":"06. PHP form","links":[],"tags":[],"content":"\n\n                  \n                  충남대학교 컴퓨터공학과 이규철 교수님의 &quot;웹 프로그래밍&quot; 강의를 필기한 내용입니다. \n                  \n                \n\n\n\n                  \n                  다소 잘못된 내용과 구어적 표현 이 포함되어 있을 수 있습니다. \n                  \n                \n\nForm request handling §\n$_POST[&quot;name&quot;]\n$_GET[&quot;name&quot;]\n$_REQUEST[&quot;name&quot;] // 이건 $_SERVER[&quot;REQUEST_METHOD&quot;]로 요청 메소드를 확인해주는 작업이 선행되어야 함\nhtml 코드를 심어 공격하는 것에 대한 대응 §\n\n서버로 전달되는 값에 html, js코드를 넣어 전달하게 되면 그것을 제대로 처리하지 못했을 경우 해당 코드가 실행되며 공격을 당할 수 있다\n이러한 공격을 Cross-site Scripting attacks(XSS) 라고 부른다\n어떠한 값을 서버로 전달하는 것은 주소를 통해 전달하는 것과 input 태그를 이용해 전달하는 것이 있으므로 이런 것을 이용해 공격을 하게 된다.\n\n\n주소를 이용해 전달하는 경우\n\n일단 $_SERVER[“PHP_SELF”] 를 통해 자신의 경로를 불러오는 기능을 사용할 경우\n브라우져의 주소에 코드를 입력하여 그것을 실행시키는 것이 가능함\n\n\ninput태그를 이용해 전달하는 경우\n\ninput태그 안에 코드를 입력하여 서버로 보내는 경우 그것이 실행될 가능성이 있다\n\n\n\n\n따라서 뭐 익히 알겠지만 html 태그를 구성하는 &lt; 와 &gt; 를 다른 문자로 바꿔주면 이러한 공격을 막을 수 있음\n\n뭐 &lt; 는 &amp;lt, &gt; 는 &amp;gt 로 바꾸면 겉모습은 그대로 보이지만 html태그로는 인식하지 않는다\n\n\n이런 겉모습은 동일하지만 html태그로는 인식하지 않게 하기 위한 특수문자를 html special characters라고 한다.\n\nXSS를 방어하는 방법 §\n\n\n일단 위의 코드는 그냥 거의 외워둬라\n하나씩 보면\ntrim() 을 통해 양옆의 whitespace를 전부 다 지우고\nstripslashes() 를 통해 html로 오인할 수 있는 백슬래시를 전부 제거하고\nhtmlspecialchars() 를 이용해 전부 html special characters로 바꿀 수 있음\n\nValidate function §\n\nempty() 함수를 통해 빈 값인지 확인하거나\npreg_match()함수를 통해 정규식을 매칭할 수도 있다\n\n\n\n일단 위의 코드\nisset() 함수는 해당 변수가 선언이 되어있냐는 뜻이고\n위에서 보는 것처럼 echo … 를 통해 html 중간에 값을 띄워줄 수 있다 → 위의 코드에서는 echo “checked”; 를 통해 해당 input radio가 checked라는 attribute를 가지도록 설정해주는 용도로 사용된 것\n그래서 위의 코드는 submit을 눌렀을때 선택한 input radio의 checked attribute가 true로 바뀌고 따라서 html이 다시 랜더링됐을 때 input radio가 체크된 상태로 유지시키려는 의도이다.\n\nDate &amp; Time §\n\n\n\n일단 어케 쓰는지는 알것제\n뭐 인자로 넘겨주는 포매팅은 인터넷 검색해라\n그리고 이때의 시간은 서버의 시간을 의미한다.\ndate_default_timezone_set(&quot;Asia/Seoul&quot;) 을 통해 타임존을 바꿔줄 수도 있다.\n\n\n\n그리고 위처럼 특정 날짜를 mktime() 을 이용해 unix time(뭐 서기 2021년 이런것마냥 유닉스가 개발된 시점을 기준으로 하는 시간, 1970년 부터 지금까지의 일수를 의미한다) 만들어 date() 함수에 넣어줄 수도 있다.\n\n이것을 date함수에 사용하면 저렇게 날짜형식으로 포매팅 할 수 있게 되는 것.\n\n\n\n\n\nstrtotime() 함수를 이용해 스트링 값을 unix time으로 변환할 수도 있다.\n\ninclude, require §\n\n\n\n위처럼 파일을 include하는 것이 가능함\nphp의 include, require 은 C-style-include 처럼 전처리시에 복붙되는 느낌이다 - echo같은 실행문이 있으면 바로 실행되고, 변수를 선언해도 해당 변수를 사용하는 것이 가능함\n불러오는 방법은 include 와 require 이 있는데 include 는 불러오는데 실패해도 무시하고 할수 있는건 다 하는 반면, require 은 실패하면 그 이후의 php는 실행되지 않는 차이점이 있음\n\nFile IO §\n\nreadfile(“path-to-file”) : 파일의 내용을 전부 읽어 문자열로 반환\nfopen(“path-to-file”, “mode”) 을 통해 파일을 열 수 있다는 것\n\n\n\n이건 mode의 종류다\n각각의 차이점과 포인터가 어디서부터 시작되는지 잘 숙지하여라\n\nw는 파일의 처음부터 쓰고 파일이 없으면 새로 만듦\na는 파일의 끝부터 쓰고 파일이 없으면 새로 만듦\nx는 파일을 새로 만들고 처음부터 쓰며 파일이 있으면 에러\n\n\nor die(“err msg”) 를 통해 exception handling을 할 수 있다는 것\nfread(_file, _number) 을 통해 길이만큼 파일을 읽어올 수 있다는 것\nfilesize(“path-to-file”) 을 통해 파일의 길이를 얻을 수 있다는 것\nfclose(_file) 을 통해 파일을 닫을 수 있다는 것\nfgets(_file) 는 파일의 한 줄을 읽고 포인터를 그 다음줄로 옮기는 것\nfeof() 는 포인터가 EOF에 도달했는지 - boolean을 반환\nfgetc(_file) 은 파일의 한 문자를 읽고 포인터를 그 다음 문자로 옮김\nfwrite(_file, “content”) 은 파일의 포인터에서부터 한글자씩 적으며 포인터를 움직임\n\n개행하려면 \\n 을 써야되는건 자명하다\n\n\n\n서버에 파일 업로드하기 예제 §\n\n\n\n일단 위의 예제에서 basename(“path-to-file”, “suffix-to-delete”) 는 경로에서 파일의 이름만 가져오고 두번째 인자를 옵션으로 넣어주면 접미사를 제거하는 기능도 해주는 함수다.\n그리고 $_FILES 라는 super global 변수는 request로 들어온 파일 객체를 담고 있는 변수이다\n\n따라서 위의 그림에서처럼 $_FILES[“fileToUpload”] 를 이용해 “fileToUpload” 을 name의 attribute로 가지는 input태그로 입력된 파일의 정보를 불러올 수 있다\n그리고 뒤이어 나오는 [“name”] 를 통해 해당 파일의 이름을 알아낼 수 있고\n이거 말고도 [“type”] 을 통해 파일의 타입을 알아내거나\n[“size”] 을 통해 파일의 크기을 알아내거나\n[“tmp_name”] 을 통해 서버에 임시로 저장된 파일의 이름을 알아내거나\n[“error”] 을 통해 파일 전송 과정에서의 에러를 알아낼수 있다.\n\n\npathinfo(“path-to-file”, PATHINFO_EXTENSION) 을 통해 해당 경로에 있는 파일의 확장자를 읽어오는 것이 가능하다\ngetimagesize($_FILES[&quot;request-param-key&quot;][&quot;tmp_name&quot;]) 를 통해 이미지 파일인지 검사함과 동시에 이미지의 크기에 관한 정보들을 얻어올 수 있다.\nfile_exists(_file) 을 통해 해당 파일객체가 가르키는 경로에 동일한 파일이 있는지 체크할 수 있다.\n\n\n\n그리고 뭐 위와 같은 방식으로 파일 validation을 해줄 수 있다.\n또한 move_upload_file($_FILES[&quot;request-param-key&quot;][&quot;tmp_name&quot;], _file) 을 통해 임시 파일을 옮길 수도 있다.\n\nCookie §\n\n\n문법은 위와 같다\n\n\n\n주의할점은 쿠키의 이름을 담은 변수는 php문서의 제일 위에 와야한다는 것이다\npath는 쿠키가 유효한 최상위 경로를 말한다.\n\n\n\n삭제는 js에서마냥 유효기간을 앞당겨서 할 수 있다\n쿠키를 변경하는것도 걍 setcookie를 사용하면 된다\n\n\n\n쿠키는 $_COOKIE 글로벌 변수에 저장되고 count()를 통해 쿠키가 있는지 검사할 수 있다.\n\nSession §\n\n뭐 알다시피\n사용자 인증이 끝나면 세션을 열고 알파벳과 숫자로 된 세션 id를 발급하여 클라이언트에게 준다\n그리고 클라이언트는 그걸 쿠키에 저장해놨다가 인증이 필요한 요청에 해당 id를 쿠키에 실어서 같이 보내게 되고\n서버에서는 세션id로 이놈이 정상적인 놈인지 확인한 후, 해당 세션에 담겨있는 정보들을 활용하게 되는 것\n\n\n\n뭐 서버에서 세션을 시작하고 여기에 정보를 담는 건 위의 그림처럼 하면 된다.\n\n\n\n뭐 세션을 서버에서의 쿠키처럼 설명하고 있는데 맞는건지는 모르겠긴함\n그리고 세션도 위 그림처럼 다른 페이지에서도 사용이 가능하다\n\n\n\n그리고 열었던 세션을 닫을때는 위처럼 하면 된댄다\n\nCallbacks §\n\n\n뭐 php도 위처럼 함수형 기능을 이용할 수 있고\n\n\n\n위의 그림처럼 익명함수도 가능하다\n\n\n\n뭐 보면 함수형 기능을 제공하는데 다른 언어와의 차이점은\n함수의 이름을 큰따옴표로 묶으면 해당 객체는 함수객체로서의 역할을 함 - 소괄호를 붙여 함수를 호출할 수 있다는 것\n\nException handling §\n\n\nthrow new Exception(“msg-for-error”) 로 에러를 던질 수 있다.\n\n\n\n그리고 뭐 try{} catch(Exception e) {} finally {} 로 에러를 잡을 수 있다\n\n\n\nException객체는 위의 예제처럼 활용할 수 있다.\n"},"originals/webprogramming.fall.2021.cse.cnu.ac.kr/07.-HTML-(2)":{"title":"07. HTML (2)","links":[],"tags":[],"content":"\n\n                  \n                  충남대학교 컴퓨터공학과 이규철 교수님의 &quot;웹 프로그래밍&quot; 강의를 필기한 내용입니다. \n                  \n                \n\n\n\n                  \n                  다소 잘못된 내용과 구어적 표현 이 포함되어 있을 수 있습니다. \n                  \n                \n\n&lt;output&gt; 태그 예시 §\n\n\na와 b의 덧셈 결과를 바로 output태그에 보여주는 예시\n\n&lt;input&gt; 태그 속성 정리 §\n\nreset 은 초기화시키되 html상에서 value로 초기값을 지정하였으면 그걸로 바뀐다\ndate 는 달력을 띄우며 min, max attribute로 날짜의 점위를 지정할 수 있다\ndatetime-local 은 날짜와 시간까지 보여주는 창을 띄운다\nhidden 은 웹에서는 안보여도 소스 보기로 볼 수 있기 때문에 value같을 직접적으로 넣어주지 않는다?\npattern 을 이용해 정규식을 넣을 수 있다\nreadonly 와 disabled 둘 다 변경할 수 없는 값이지만, readonly 는 정보가 서버로 넘어가는 반면 disabled 는 넘어가지 않음\nsize 는 입력창의 크기를 글자n개로 지정한 것이고 maxlength 는 입력할 수 있는 글자 갯수를 제한한다\nmultiple 은 파일 여러개를 입력받을 수 있는 attribute이다\nautofocus 는 화면이 로드되었을 때 자동으로 해당 input에 focus를 하는 속성이다\nautocomplete “on”, “off” 로 자동완성기능을 끄고 킬 수 있다\nform attribute로 &lt;form&gt; 태그 밖에서도 해당 form으로 제출되게 할 수 있다\nformaction attribute로 데이터를 전달하는 서버의 라우터를 변경할 수 있다\nformenctype 은 데이터의 인코딩 방식을 변경할 수 있다\nformmethod 로 특정 input태그에만 method를 변경할 수 있다\nformtarget 은 a태그의 target처럼 결과를 같은 창에 띄울지 등을 설정할 수 있다\nformnovalidate 로 validate를 하지 않을 수 있다\n\nform태그에 novalidate라고 적어서 form전체를 validate하지 않을 수 있다\n\n\n\n&lt;datalist&gt;, &lt;option&gt; 태그 예시 §\n\n\n드랍다운 선택창을 만드는 예시\n\nSemantic element §\n\nsection 은 주제별로 묶은거고 article 은 기사에 대한거다?\n&lt;figure&gt; 은 이미지에 대한 래퍼 태그이고, 해당 이미지에 캡션을 다는 &lt;figurecaption&gt; 가 있다\n또한 &lt;audio&gt; 로 음원을 래핑할 수 있고, &lt;video&gt; 로 비디오를 래핑할 수 있다\n\nEntities §\n\n\n참고해라\n다른 특수문자는 검색해보거라\n\nEncoding §\n\n한국어의 경우에는 UTF-8로 표현할 수 있기 때문에 다음과 같은 방식으로 인코딩 방식을 지정한다\n\n&lt;meta charset=&quot;UTF-8&quot;&gt;\n\nURL 인코딩의 경우에는 기본적으로 ASCII로 인코딩하고 ASCII에 없는 문자의 경우에는 %hex 로 hex-encoding하여 사용한다\n\nURL의 구조 §\n{{ scheme }}://{{ prefix }}.{{ domain }}:{{ port ]}/{{ path }}/{{ filename }}\n\n\nScheme은 http, https같은 internet service type이고\nPrefix는 www같은 도메인 접두어\n뭐 나머지는 다 너가 아는 그거임\n\nJSON §\n\nJSON.parse() 는 문자열을 읽어 JS Object로 파싱하는 것이고\nJSON.stringify() 는 JS Object를 JSON 문자열로 변환하는 것이다\n배열도 이 메소드를 써서 변환이 가능하다\n\nJSON 문법규칙 §\n\nJSON에서는 큰따옴표만 사용해라\nfunction, date, undefined는 JSON으로 표현할 수 없다 - 얘네들은 문자열로 저장한다음에 형변환을 해줘야 한다.\n\nfunction의 경우에는 eval(&quot;(&quot; + _func + &quot;)&quot;) 으로 형변환이 가능하고\ndate는 new Date(_date) 로 형변환 가능하다\n문자열로 변환하는 것은 .toString() 을 이용하면 된다\n\n\n\nPHP와 JSON §\n\n아래는 PHP 객체를 JSON String으로 변환하는 예시이다\n\n\n\n아래는 JSON String을 PHP 객체로 변환하는 예시이다\n\n\n\njson_decode() 의 두번째 인자로 true를 주면 associative array로 변환이 된다\n"},"originals/webprogramming.fall.2021.cse.cnu.ac.kr/08.-JQuery,-AJAX":{"title":"08. JQuery, AJAX","links":[],"tags":[],"content":"\n\n                  \n                  충남대학교 컴퓨터공학과 이규철 교수님의 &quot;웹 프로그래밍&quot; 강의를 필기한 내용입니다. \n                  \n                \n\n\n\n                  \n                  다소 잘못된 내용과 구어적 표현 이 포함되어 있을 수 있습니다. \n                  \n                \n\n\n\n                  \n                  본 문서는 작성자의 귀찮음 때문에 참고 문서 링크들로 범벅되어 있습니다.\n                  \n                \n\nCDN Installation §\n&lt;script src=&quot;https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js&quot;&gt;&lt;/script&gt;\nBasic §\nDocument onload §\n$(document).ready(function() {\n// JQueries\n});\n \n$(function() {\n// JQueries\n});\nSelector §\n$(css-selector).JQueryMethod();\nEvent listener §\n\n$(el).click(listner: () =&gt; void)\n$(el).dblclick(listner: () =&gt; void)\n$(el).mouseenter(listner: () =&gt; void)\n$(el).mouseleave(listner: () =&gt; void)\n$(el).mousedown(listner: () =&gt; void)\n$(el).mouseup(listner: () =&gt; void)\n$(el).hover(listner: () =&gt; void)\n$(el).focus(listner: () =&gt; void)\n$(el).blur(listner: () =&gt; void)\n$(el).on({event: () =&gt; void})\n\nEffects §\n\n$(el).hide(speed: string | number, callback: () =&gt; void);\n$(el).show(speed: string | number, callback: () =&gt; void)\n$(el).toggle(speed: string | number, callback: () =&gt; void)\n$(el).fadeIn(speed: string | number, callback: () =&gt; void)\n$(el).fadeOut(speed: string | number, callback: () =&gt; void)\n$(el).fadeToggle(speed: string | number, callback: () =&gt; void)\n$(el).fadeTo(speed: string | number, opacity: number, callback: () =&gt; void)\n$(el).slideDown(speed: string | number, callback: () =&gt; void)\n$(el).slideUp(speed: string | number, callback: () =&gt; void)\n$(el).slideToggle(speed: string | number, callback: () =&gt; void)\n$(el).animate({cssProperty: string}, speed: string | number, callback: () =&gt; void)\n$(el).stop(stopAll?: bool, goToEnd?: bool)\n\nHTML, CSS Suppport §\nInner Values §\n\ntext(), html()\nval()\nattr()\n\nDOM §\n\nappend()\nprepend()\nafter()\nremove()\nempty()\n\nCSS §\n\naddClass()\nremoveClass()\ntoggleClass()\ncss(“property”), css(“property”, “value”)\n\nBox model §\n\nwidth(), height()\ninnerWidth(), innerHeight()\nouterWidth(), outerHeight()\nbrowser width, height\n\nTraverse §\n\nparent()\nchildren()\nfind()\nsiblings()\nnext\nnextAll()\nnextUntil()\nfirst()\nlast()\nfilter()\nnot()\n\nAJAX §\n\nXMLHttpRequest\nJQuery .load() with selector\n$.get()\n$.post()\n"},"originals/webprogramming.fall.2021.cse.cnu.ac.kr/09.-HTML-API":{"title":"09. HTML API","links":[],"tags":[],"content":"\n\n                  \n                  충남대학교 컴퓨터공학과 이규철 교수님의 &quot;웹 프로그래밍&quot; 강의를 필기한 내용입니다. \n                  \n                \n\n\n\n                  \n                  다소 잘못된 내용과 구어적 표현 이 포함되어 있을 수 있습니다. \n                  \n                \n\nDrag &amp; Drop §\nOverview §\nElement to drag §\n\n태그의 draggable 속성이 true 로 되어있어야 함 : &lt;tag draggable=&quot;true&quot;&gt;\nongradstart 속성에 드래그를 시작할때 호출할 함수를 입력하여 드래그하려는 놈의 id를 Event.dataTransfer 에 저장함\n\n&lt;script&gt;\nfunction _func(event) {\n\tevent.dataTransfer.setData(&quot;text&quot;, #id);\n}\n&lt;/script&gt;\n \n&lt;tag ondragstart=&quot;_func(event)&quot;&gt;\nElement for drop §\n\n드래그된놈이 위에 있을때 ondragover event가 계속 발생하고 그때마다 드래그를 허용해줘야됨\n\n이건 Event.preventDefault() 로 가능함\n\n\n\n&lt;script&gt;\nfunction _func(event) {\n\tevent.preventDefault();\n}\n&lt;/script&gt;\n \n&lt;tag ondragover=&quot;_func(event)&quot;&gt;\n\n드롭되었을때 ondrop event가 발생하고 이때 Event.dataTransfer 에 저장한 정보를 갖고옴\n\n&lt;script&gt;\nfunction _func(event) {\n\tevent.preventDefault();\n\tconst _id = event.dataTransfer.getData(&quot;text&quot;);\n\tevent.target.appendChild(document.getElementById(_id));\n}\n&lt;/script&gt;\n \n&lt;tag ondrop=&quot;_func(event)&quot;&gt;\nExample §\nDrag &amp; Drop\nWeb storage §\nOverview §\n\nCookie는 작은 데이터를 저장하고 서버로 Request를 날릴때 같이 날라감\n\n\n\nWebStorage는 많은 데이터를 저장하고 서버로 날라가지 않음\n\nLocalStorage는 도메인 기준으로 데이터가 저장되고 브라우저를 닫아도 없어지지 않아 장기적인 데이터 보관을 위한 것\nSessionStorage는 세션(탭)기준으로 데이터가 저장되고 탭을 닫으면 없어져 단기적인 데이터 보관을 위한 것\n\n\n\nUsage §\n\n일단 브라우저가 Storage를 지원하는지 체크\n\nif(typeof(Storage) !== &quot;undefined&quot;) { /* ... */ }\n\n값 저장\n\nwindow.localStorage.setItem(&quot;key&quot;, &quot;value&quot;);\nwindow.sessionStorage.setItem(&quot;key&quot;, &quot;value&quot;);\n\n값 조회\n\nwindow.localStorage.getItem(&quot;key&quot;);\nwindow.sessionStorage.getItem(&quot;key&quot;);\n\n값 삭제\n\nwindow.localStorage.removeItem(&quot;key&quot;);\nwindow.sessionStorage.removeItem(&quot;key&quot;);\n\n값 전부 삭제\n\nwindow.localStorage.clear();\nwindow.sessionStorage.clear();\nExample §\n\nLocal Storage\nSession Storage\n\nWeb worker §\nOverview §\n\n시간이 오래걸리는 작업을 백그라운드로 돌리는 것\n\n\n\nDOM을 조작해 UI를 변경하는 것을 직접적으로 할 수 없음\n\nUI Thread로 보내 거기서 조작하도록 해야 한다\n\n\n전용 워커(Dedicated worker) 는 워커를 생성한 페이지에서만 돌아가는 것\n공유 워커(Shared worker) 는 페이지와 무관하게 돌아가는 것\n\nUsage §\n\nWorker 인스턴스를 담을 전역변수 선언\n\nvar w;\n\n일단 브라우저가 Worker를 지원하는지 체크\n\nif(typeof(Worker) !== &quot;undefined&quot;) { /* ... */ }\n\n워커 객체 생성\n\nif(typeof(w) !== undefined) {\n\tw = new Worker(&quot;path-to-js-file.js&quot;)\n}\n\n워커에서 값을 보낼때는 postMessage() 를 사용\n\npostMessage(&quot;data-to-send&quot;);\n\nUI Thread에서 받았을때는 onmessage event가 발생함\n\nw.onmessage = (event) =&gt; { console.log(event.data); }\n\nWorker 종료시키기\n\nw.terminate();\nw = undefined;\nExample §\n\nDedicated Worker\nShared Worker\n\nGeolocation §\nOverview §\n\n브라우저가 지원하는지 확인\n\nif(navigator.geolocation) { /* ... */ }\n\n현재위치 한번 받아오기\n\nnavigator.geolocation.getCurrentPosition((position) =&gt; {\n\tconsole.log(position.coords.latitude);\n\tconsole.log(position.coords.longitude);\n});\n\n현재위치 주기적으로 받아오기\n\nnavigator.geolocation.watchPosition((position) =&gt; {\n\tconsole.log(position.coords.latitude);\n\tconsole.log(position.coords.longitude);\n});\n\n주기적으로 받아오는기 취소\n\nnavigator.geolocation.clearWatch();\nExample §\n\nGeolocation\n\nFile §\nOverview §\n\n파일을 수정할 수는 없고 오직 읽기만 가능\n\nDocument §\nFile §\n\nFileReader §\n\nEditable §\nOverview §\n\n특정 요소에 text를 적을 수 있게 해줌\n\nUsage §\n\n&lt;tag contenteditable&gt; 요소 하나를 편집 가능하도록 만들기\n페이지 전체를 편집 가능하도록 만들기\n\nwindow.onload = () =&gt; {\n\tdocument.designMode = &quot;on&quot;;\n}\n\n텍스트 입력 모드 바꾸기\n\n// 앞으로 입력되는 글자를 굵게 표시\ndocument.execCommand(&quot;bold&quot;);\nDocument §\n\nHTML DOM execCommand() Method\n\nWeb socket §\nOverview §\n\n웹 소켓은 http를 이용하는 것이 아닌 ws를 이용하여 서버로 데이터를 주고받는 프로토콜\n실시간 양방향 통신을 위한 것 - 채팅어플만들때 많이 이용한댄다\n\nUsage §\n\n객체 생성\n\nconst soc = new WebSocket(&quot;address-to-server&quot;);\n\n송신\n\nsoc.send(&quot;data-to send&quot;);\n\n수신\n\nws.onmessage = (event) =&gt; {\n\tconsole.log(event.data);\n};\nDocument §\n\nExample §\n\nWeb Socket Example\n\nServer Sent Event §\n\nSetInterval같은거 안쓰고 일정 시간간격을 두고 계속 Request를 보내서 값을 가져오는 방법\nEvent Source라는 객체를 이용\n\n\n\n이렇게 하면 되고\n\n\n\n이런 이벤트들이 있댄다\n\nExample §\n\nEventSource\n"},"originals/webprogramming.fall.2021.cse.cnu.ac.kr/10.-JS-Basic-2":{"title":"10. JS Basic 2","links":[],"tags":[],"content":"\n\n                  \n                  충남대학교 컴퓨터공학과 이규철 교수님의 &quot;웹 프로그래밍&quot; 강의를 필기한 내용입니다. \n                  \n                \n\n\n\n                  \n                  다소 잘못된 내용과 구어적 표현 이 포함되어 있을 수 있습니다. \n                  \n                \n\n\n\n                  \n                  본 문서는 작성자의 귀찮음 때문에 참고 문서 링크들로 범벅되어 있습니다.\n                  \n                \n\nArray 몰랐던점 §\n배열 순회 §\nconst arr = [1, 2, 3];\n \nfor(const el of arr) {\n\tconsole.log(el);\n}\n\n뒤에 가서 또 나오겠지만 배열의 순회에는 for-of를 써야 하고 객체의 순회에는 for-in을 써야 한다 - 순서가 중요한 경우에는 for-in을, 순서가 중요하지 않은 경우에는 for-of를 사용해라\n\n배열의 출력 §\n\n\ninnerHTML에 배열을 넣으면 위처럼 나온다\n\n배열 인덱스로 값 넣기 §\nconst fruits = [&quot;Banana&quot;, &quot;Orange&quot;, &quot;Apple&quot;];\nfruits[6] = &quot;Lemon&quot;;\n\n위 코드를 실행시키면\n\n\n\nOutOfBounds 에러가 나는게 아니고 위처럼 저장된다\n\nArray() 생성자의 인자 §\n\nnew Array(10, 20); 은 배열에 10과 20을 넣어주지만\nnew Array(40); 은 크기가 40짜리인 배열을 만든다\n\n삽입과 삭제 §\n\nArray.shift() 는 .pop_front() 와 같은거고\nArray.unshift(el) 은 .push_front(el) 와 같은거임\ndelete 는 원소를 지우긴 하지만 그자리를 undefined 로 만들어버린댄다\nArray.splice() 는 주어진 인덱스에서 주어진 갯수만큼 원소를 지우고 주어진 원소들로 다시 채운 후 반환하는 메소드임\n\nArray.splice(index, numToRemove, values …): Array\n\n\n\n정렬 예시 §\n\n알파벳순으로 정렬 예시\n숫자 크기대로 오름차순 정렬 예시\n숫자 크기대로 내림차순 정렬 예시\n랜덤한 순서대로 정렬 예시\n배열에서 최대값 찾기 예시\n배열에서 최솟값 찾기 예시\n배열 뒤집기: Array.reverse(): void\n\n순회 예시 §\n\nArray.reduce()\nArray.reduceRight()\n모든 원소 테스트하기: Array.every()\n어떤 원소 테스트하기: Array.some()\n원소 찾기: Array.indexOf()\n마지막 원소 찾기: Array.lastIndexOf()\n원소가 존재하는지 확인: Array.includes()\n조건을 만족하는 첫번째 원소 찾기: Array.find()\n조건을 만족하는 첫번째 원소의 인덱스 찾기: Array.findIndex()\nIterable로부터 배열 만들기: Array.from()\n인덱스만 모아 배열로 만들기: Array.keys()\n\nObject §\nObject Literal §\n\n자바스크립트는 보통의 다른언어와 다르게 객체 리터럴(Object Literal) 이 존재한다.\n\n{\n\tid: 1234,\n\tname: &quot;holymoly&quot;,\n\tage: 24,\n}\n\n위와 같은 구조를 Object Literal 이라고 하는데\n뭐 많이 써봤으니까 익숙하긴 할거임\n근데 여기서 중요한 것은 Object Literal 과 ES6에서부터 지원하는 class 키워드, 그리고 function + prototype 을 이용한 객체의 생성은 별개의 것이 아니라는 것을 아는 것이다\n즉, 문자열을 const str = new String() 를 이용해 만들 수도 있지만 const str = &quot;&quot; 처럼 Literal을 이용해 만들 수 있듯이\n객체도 new 를 이용해 만들 수도 있고 {} 를 이용해 만들 수도 있는 것이다\n\nPrototype의 이해 §\n\n자바스크립트는 Prototype Design Pattern 을 이용하는 대표적인 언어다\nES6부터는 class 키워드를 지원해 객체를 만들 수 있는 또다른 방법이 생겼지만\n결국에는 class 키워드는 이전의 prototype 을 이용한 객체의 생성방식을 문법과 제약조건만 좀 바꾼 Syntactic Sugar 의 일종이지 작동방식은 prototype 을 여전히 사용하게 된다\n일단 다른 언어와 자바스크립트의 객체 생성 방식을 좀 더 살펴보면\n자바같은 언어는 객체를 new 키워드를 이용해 생성하면 생성자가 클래스를 바탕으로 객체를 생성해서 준다\n하지만 이러한 방식은 객체를 생성하는데 꽤나 많은 자원이 필요하기 때문에 자바스크립트는 Prototype 이라는 것을 이용한다\n그래서 이게 뭐냐면\n생성자를 정의하면 생성자 뿐만 아니라 객체의 원형 - 이게 Prototype 이다 - 도 생성하고 new 를 이용해 객체를 생성하면 밑바닥부터 만드는게 아니고 Prototype 객체를 복사해서 주는 방식이다\n뭐 요즘은 컴퓨터가 다 빨라서 체감도 잘 안되고 진짜 그런진 모르겠는데 이게 더 빠르다네\n그럼 이 생성자는 으케만드는가\nfunction 키워드를 이용해 함수를 정의하면 이놈이 생성자의 권한을 갖게 된다\n\n뭐 ES6에 와서는 arrow function을 지원하면서 진짜 함수같은 함수가 생겼지만 그냥 함수랑 생성자 권한을 가진 함수랑 좀 분리를 시켜놓던지 왜 이렇게 했는지는 알 방법이 없음\nfunction 안에서 this 키워드를 쓸 수 있는 이유가 바로 이거때문\n\n\n그럼 정리해보면\n\nfunction 을 이용해 함수를 정의하면 이놈이 생성자의 권한을 부여받고 동시에 prototype 객체가 생성되어 어딘가에 저장되게 된다\n그리고 new 키워드를 이용해 객체를 생성하면 저장해놓은 prototype 을 복사한 다음 property들을 세팅해서 반환하는 구조인 셈이다\n\n\n그럼 이 prototype 에는 어떻게 접근하는가\n모든 function 에는 .prototype 이라는 property가 존재해 이것을 이용해 prototype 을 수정할 수 있다\n따라서 아래의 코드는\n\nfunction Person() {}\nconsole.log(Person.prototype);\n\n결과가 다음과 같이 나온다 (크롬 기준)\n\nObject { constructor: f Person(), [[Prototype]] }\n\n그리고 .prototype 에 보면 constructor() 라는 함수가 있다는 것을 알 수 있는데\n이놈이 아까 선언한 생성자를 가리키게 된다\n\n\n\n따라서 위와 같은 구조가 된다\n함수에는 prototype property 가 있어서 property 를 참조할 수 있고 property 에는 constructor 가 있어서 다시 원래 함수를 가리키게 되는 원형적이라고 할 수 있는 방식이다\n그리고 저기 보면 __proto__ 라는 놈이 있는데 이놈은 생성자를 이용해 생성된 객체에 포함되어 원본 prototype을 참조할 수 있게 해주는 것이다\n\n\n\n즉, 이렇게 된다 이거임\n복사되는 원본객체를 Prototype Object라 하고 생성된 객체에 있는 __proto__ 를 Prototype Link 라 하며 Prototype Object 와 Prototype Link 를 합쳐서 Prototype 라고 용어를 사용하더라\n\n생성자 선언 종합 §\n\n객체가 생성될때 복사되길 원하는 것들을 prototype 에 넣어주고 객체마다 다른 값을 가질 수 있는 property같은것들은 그냥 this 키워드를 이용해 정의한다\n\nfunction Person(name, age) {\n\tthis.name = name;\n\tthis.age = age;\n}\n \nPerson.prototype.getName = function() {\n\treturn this.name;\n}\n \nPerson.prototype.getAge = function() {\n\treturn this.age;\n}\n\n근데 주의할건 Method를 생성자 밖에서 정의할때는 arrow function을 사용하면 this 키워드가 안먹기 때문에 function 키워드를 사용해야 된다\n\nfunction Person(name, age) {\n\tthis.name = name;\n\tthis.age = age;\n \n\t// 가능\n\tPerson.prototype.getAge = () =&gt; {\n\t\treturn this.age;\n\t}\n}\n \n// 불가능\nPerson.prototype.getName = () =&gt; {\n\treturn this.name;\n}\n\n그리고 Property를 prototype에 넣는 경우 해당 프로퍼티는 객체들마다 같은 값을 가지기 때문에 이 값을 변경할 경우 다른 객체에서도 바뀐다는 것을 꼭 기억하고있으라\n\n멤버를 찾는 방법 §\n\n프로토타입 방식에서 객체의 멤버에 접근할때 우선 해당 객체에 해당 멤버가 있는지 확인하고, 없으면 그놈의 프로토타입 객체에서 확인하고, 없으면 또 그놈의 프로토타입으로 거슬러 올라가는 방식으로 해당 멤버에 접근할 수 있는지 확인하게 된다\n\n몰랐던거 정리 §\n순회 §\nconst obj = {\n\taa: 1,\n\tbb: 2,\n\tcc: 3,\n};\n \nfor(let key in obj) {\n\tconsole.log(`${key}: ${obj[key]}`);\n}\n \nObject.entries(obj).forEach(([key, val]) =&gt; {\n\tconsole.log(`${key}: ${val}`);\n});\n\n주의할점은\n\nfor-in구문은 순회 순서가 보장되지 않는다 - 배열에서 인덱스 0번부터 차례대로 순회한다고 보장할 수 없음 - 따라서 객체에서만 해당 구문을 써야된다\nforeach 가 아니고 forEach 라는 것\nObject.entries().forEach 에 사용하는 함수는 배열 인자를 받도록 되어 있다 - 따라서 파라미터를 배열형식으로 구성하면 배열의 원소를 바로 받아올 수 있음\n\n\n이외에도 Key만 순회하는 Object.prototype.keys() 하고 값만 순회하는 Object.prototype.values() 도 있으니 필요하면 그때 찾아보자\n\n제거 §\n\ndelete 키워드를 사용하면 객체에서 프로퍼티를 삭제할 수 있다\ndelete 키워드를 사용해서 프로토타입에서도 지울 수 있으나 객체 전체에 영향을 미치기 때문에 신중해야 한다는 것\n\nGetter, Setter §\nconst obj = {\n\tthis.name = &quot;&quot;;\n \n\tget uname() {\n\t\treturn this.name;\n\t},\n \n\tset uname(arg) {\n\t\tthis.name = arg.toUpperCase();\n\t}\n};\n \nobj.uname = &quot;abcdef&quot;;\nconsole.log(obj.uname);\n\n뭐 이렇게 getter setter 문법으로 간단하게 프로퍼티값 조회 및 변경시 추가적인 행동을 지정해 줄 수 있는 것알고있제?\n\nDate §\n\n이정도만 숙지하고 나머지는 필요할때 찾아보자\n현재시간\n날짜 지정\n\n\nBoolean §\n\n이건 좀 알고있어라 - truthy와 falsy를 boolean으로 바꿔주는 것!!(falsy expression)\n\nSet §\n\n중복 없는 자료구조\nnew Set()\nSet.prototype.add()\n뭐 순회를 위한 forEach(), values(), keys() 를 지원함\nentries() 도 있는데 Set의 경우에는 Key가 없기 때문에 [value, value] 형태로 반환한댄다\n\nMap §\n\nKey Value 쌍 자료구조\nnew Map()\nMap.prototype.set()\nMap.prototype.delete()\nMap.prototype.clear()\nMap.prototype.has()\n뭐 순회를 위한 forEach(), values(), keys(), entries() 를 지원함\n"},"originals/webprogramming.fall.2021.cse.cnu.ac.kr/11.-JS-Functions":{"title":"11. JS Functions","links":[],"tags":[],"content":"\n\n                  \n                  충남대학교 컴퓨터공학과 이규철 교수님의 &quot;웹 프로그래밍&quot; 강의를 필기한 내용입니다. \n                  \n                \n\n\n\n                  \n                  다소 잘못된 내용과 구어적 표현 이 포함되어 있을 수 있습니다. \n                  \n                \n\nSelf-invoking §\n\n이건 되고\n\n(function() {\n\tconsole.log(&quot;using anonymous function definition&quot;);\n})();\n \n(() =&gt; {\n\tconsole.log(&quot;using arrow function definition&quot;);\n})();\n \n(function ft() {\n\tconsole.log(&quot;using named function definition&quot;);\n})();\n\n이렇게는 안된다는 것 - 이름을 가진 함수 정의하는 것은 Statement expression이지만 변수에 넣는 것은 Statement이기 때문인듯\n\n(const ft = function() {\n\tconsole.log(&quot;ft&quot;);\n})();\n \n(const ft = () =&gt; {\n\tconsole.log(&quot;fuckt&quot;);\n})();\nParameters §\n\njs는 입력받은 인자의 갯수를 확인하지 않는다\n\nfunction print(a, b, c) {\n\tconsole.log(`${a} ${b} ${c}`);\n}\n \nprint(&quot;aa&quot;, &quot;bb&quot;, &quot;cc&quot;); // aa bb cc\nprint(&quot;ab&quot;, &quot;cd&quot;); // ab cd undefined\n\n인자의 갯수보다 적으면 에러가 나는게 아니고 위처럼 해당 파라미터에 접근했을때 undefined가 나온다\n\nfunction print() {\n\tconsole.log(arguments);\n}\n \nprint(&quot;aa&quot;, &quot;bb&quot;, &quot;cc&quot;); // Arguments[&quot;aa&quot;, &quot;bb&quot;, &quot;cc&quot;]\nprint(&quot;ab&quot;, &quot;cd&quot;); // Arguments[&quot;ab&quot;, &quot;cd&quot;]\n\n파라미터의 개수보다 많이 인자를 주면 위처럼 arguments 이라는 iterable 프로퍼티를 통해 접근할 수 있다(배열은 아닌듯)\n\nScope of Function §\n\nJS에서 함수는 항상 Default Global Object 로 선언된다\n그말인 즉슨 HTML페이지가 이놈의 Scope가 된다는 사실 - 다른 JS에 정의를 해도 같은 HTML에 링크되어있으면 사용할 수 있다\nHTML에 종속되는 Default Global Object는 항상 window 객체에 담기게 된다 - 그냥 func() 하는 거랑 window.func() 하는거랑 똑같다 이소리야\n따라서 JS의 모든 함수는 항상 어떤 객체의 메소드라고 생각해야 된다\n\nThis §\n\n함수 내에서 사용되는 this 는 해당 함수를 가지고 있는 객체를 말한다\n\nfunction printGlobalThis() {\n\tconsole.log(this);\n}\n \nprintGlobalThis(); // Window { ... }\n\n위의 예시에서 함수는 어느 객체 내에 선언된것이 아니므로 최상위인 Window에 포함된다\n\nfunction Person() {\n\tthis.name = &quot;abc&quot;;\n}\n \nPerson.prototype.printThis = function() {\n\tconsole.log(this);\n}\n \nconst p = new Person();\np.printThis(); // Person { name: &quot;abc&quot;, printThis: function }\n\n위의 예시에서는 함수가 객체 안에 선언되어 있으므로 해당 객체의 정보가 나오게 된다\n\nCall, Apply, Bind §\n\n.call(), .apply(), .bind() 모두 함수 내에서 사용되는 this 를 직접 전달할 수 있게 해주는 메소드이다\n즉, 함수들이 실행되는 상위객체(환경)을 지정해주는 것이라 생각하면 됨\n\nCall §\nfunction testMethod(arg1, arg2) {\n\tconsole.log(this.prop + arg1 + arg2);\n}\n \nconst obj1 = { prop: 1 };\nconst obj2 = { prop: 2 };\n \ntestMethod.call(obj1, 3, 4); // 8\ntestMethod.call(obj2, 3, 4); // 9\n\n저런식으로 함수 내에서 this 로 사용될 객체를 넣어줌으로 해당 객체의 프로퍼티를 연산에 사용할 수 있게 함\n\nApply §\nfunction testMethod(arg1, arg2) {\n\tconsole.log(this.prop + arg1 + arg2);\n}\n \nconst obj1 = { prop: 1 };\nconst obj2 = { prop: 2 };\n \ntestMethod.apply(obj1, [3, 4]);\ntestMethod.apply(obj2, [3, 4]);\n\nApply와 Call의 차이점은 인자를 개별적으로 주느냐 아니면 배열로 묶어서 주느냐의 차이이다\n\nBind §\nfunction testMethod(arg1, arg2) {\n\tconsole.log(this.prop + arg1 + arg2);\n}\n \nconst obj1 = { prop: 1 };\nconst obj2 = { prop: 2 };\n \ntestMethod.bind(obj1, 2)(3); // 6\ntestMethod.bind(obj2, 3, 4)(); // 9\n\nOCaml에서 함수 인자를 덜 전달해주면 그의 결과로 부분적으로 완성된 함수가 반환되었듯이\nJS에서도 그와 비슷한 기능을 할 수 있음\n일단 Bind의 첫번째 인자는 타겟 객체이고\n그 다음부터 인자를 넘겨주면 되는데 넘겨준 인자만큼 앞에서부터 파라미터를 채워서 함수로 반환 한다\ntestMethod.bind(obj1, 2)(3); 의 예시에서는 obj1을 타겟 객체로 주고 arg1로 2로 주었으므로 다음과 같은 기능을 하는 함수가 반환된다고 생각하면 된다\n\nfunction testMethod(arg2) {\n\tconsole.log(1 + 2 + arg2);\n}\n\n따라서 위 함수의 인자로 3을 주면 그 결과로 6이 나오게 되는 것\ntestMethod.bind(obj2, 3, 4)(); 의 예시에서는 obj2을 타겟 객체로 주고 arg1로 3, arg2로 4를 주었으므로 다음과 동일한 기능을 하는 함수가 반환된다고 생각하면 된다\n\nfunction testMethod() {\n\tconsole.log(2 + 3 + 4);\n}\n\n따라서 위 함수에 인자를 하나도 주지 않고 실행시켰을 때 9가 나오게 되는 것\n"},"originals/webprogramming.fall.2021.cse.cnu.ac.kr/12.-HTML,-JS,-HTTP":{"title":"12. HTML, JS, HTTP","links":[],"tags":[],"content":"\n\n                  \n                  충남대학교 컴퓨터공학과 이규철 교수님의 &quot;웹 프로그래밍&quot; 강의를 필기한 내용입니다. \n                  \n                \n\n\n\n                  \n                  다소 잘못된 내용과 구어적 표현 이 포함되어 있을 수 있습니다. \n                  \n                \n\nJS 짜투리 §\nJS Errors §\n\n\nError 객체의 name property에 다음과 같은 값들이 들어갈 수 있댄다\n\nJS Scope §\nFunction Scope §\n\n\nvar을 쓴다고 무조건 Global scope가 되는건 아닌가봄 - 함수 안에 var을 적으면 Function scope가 된다\n\n“Use Strict” §\n\n매번 이거 볼때마다 뭔가 했는데\n원래는 선언 없이 변수에 값을 할당하면 자동으로 Global 변수로 선언되었는데\nUse Strict를 사용하면 선언 없이 변수에 값을 할당하면 자동으로 Global 변수로 선언되는 것을 막는다\n\nGlobal §\n\n뭐 당연한거지만 Global 변수는 window객체에 종속된다\n그리고 Global 변수는 브라우저 윈도우(탭)이 켜져있는동안 라이프타임이 지속된다\n\nHTML 짜투리 §\n&lt;canvas&gt; 태그, svg §\n\n&lt;canvas&gt; 태그를 이용해 공간을 마련하고 JS를 이용해 여기다가 선을 긋는게 가능하댄다\n\n뭐 메소드가 다 준비되있대\n\n\n그리고 svg는 Scalable Vector Graphic으로 벡터그래픽을 XML형식으로 표현한 문서이다\n\n따라서 SVG DOM이 구성되어있고 HTML DOM에 Mount된 이후에는 DOM객체로 조작할수도 있댄다\n\n\ncanvas와 svg의 차이점은\n\ncanvas는 JS로 그리고 변경되어도 바로바로 반응하지 않지만\nsvg는 XML형식으로 그리고 변경되었을때 바로바로 화면에 랜더링된댄다\n\n\n\nVideo, Audio §\n\nHTML에서는\n비디오는 mp4, webm, ogg만 지원하고\n오디오는 mp3, wav, ogg만 지원한댄다\n&lt;video&gt; 와 &lt;audio&gt; 태그는 사용법이 거의 동일함\n\n태그에다가 controls Attribute를 넣으면 뭐 재생 / 중단 등의 컨트롤 패널이 사용자에게 보여짐\n태그 안에다가 &lt;source&gt; 를 넣어서 보여줄 콘텐츠를 지정할 수 있고 위에서부터 실행하여 가져올 수 있는 첫번째 콘텐츠를 보여줌\n태그 사이에 텍스트를 넣으면 어떠한 콘텐츠도 로딩되지 않았을 때 이 텍스트가 대체로 보여진다\nautoplay 속성으로 자동재생을 지정할 수 있고 muted 로 기본값을 음소거로 할 수 있는데\nChrome에서는 자동재생을 음소거시에만 허용한댄다\n\n\n\nObject, Embed §\n\n&lt;object&gt; 나 &lt;embed&gt; 로 임의의 컨텐츠를 화면에 뿌릴 수 있댄다\n뭐 오디오, HTML이런거 말고도 PDF Reader플러그인같은것들도 이걸 이용한댄다\n\nYoutube §\n\n알다시피 URL의 ID로 비디오를 지정하고\nmute=1 로 음소거\nautoplay=1 로 자동재생\ncontrols=0 로 컨트롤 패널 출력하지 않기\nloop=1 로 반복재생이 가능하댄다\n\nHTTP §\n\nHyperText Transfer Protocol\nTCP / IP를 이용해서 HTML과 그와 관련된 것을 송수신함\n\n중요한 속성들 §\n\nConnectionless : 클라이언트가 서버에게 요청하고 받은 뒤에는 TCP / IP연결을 끊음\n\n즉, 요청 할때마다 새로 Three Handshake를 해야 한다\n이것은 서버사이드에 부담을 줄여주긴 하지만 매번 통신을 연결해야 하기 때문에 시간이 지연된다는 단점이 있다\n\n\nMedia Independent : 데이터의 처리 방법만 content-type으로 명시하면 어떠한 것이든 송수신할 수 있음\nStateless : 서버는 클라이언트의 현재 상태를 저장하지 않음 - 요청을 보낼때마다 문맥을 알려줘야 한다\n\nMessage Format §\n\n\n일단 Start line, Header, empty line, Body로 구성됨\n뭐 Start line이 나오고 Header가 나온 뒤에 한칸의 개행을 두고 Body가 등장하는 형태\nHeader에는 여러가지 header들이 들어가게 되는데 뭐가 들어가는지는 필요할때마다 찾아보고\nBody에는 실질적인 내용이 들어가게 되는데\nStart line은 요청과 응답에 형식이 지정되어 있다\n일단 요청에는 METHOD URI HTTPver이런식으로 명시되고\n응답에는 HTTPver StatusCode StatusMSG 이러한 형태로 제시된다\n"},"originals/오리지날-갈든---Original-Garden":{"title":"오리지날 갈든 - Original Garden","links":["originals/datacommunication.spring.2021.cse.cnu.ac.kr/(충남대)-데이터-통신-강의록","originals/softwareengineering.fall.2021.cse.cnu.ac.kr/(충남대)-소프트웨어-공학-강의록","originals/os.spring.2021.cse.cnu.ac.kr/(충남대)-운영체제-강의록","originals/webprogramming.fall.2021.cse.cnu.ac.kr/(충남대)-웹-프로그래밍-강의록","originals/compiler.fall.2021.cse.cnu.ac.kr/(충남대)-컴파일러-개론-강의록","originals/comnet.fall.2021.cse.cnu.ac.kr/(충남대)-컴퓨터-네트워크-강의록","originals/pl.spring.2021.cse.cnu.ac.kr/(충남대)-프로그래밍-언어-개론-강의록","originals/os.bahn.ewha.kocw.net/(이화여대)-운영체제-강의록","originals/jumptopython.books.wikidocs.net/(책)-점프-투-파이썬-정리록","originals/kubernetes.jan.2023.si-analytics.ai/쿠버네티스-교육자료-(SI-Analytics,-Jan.-2023)","originals/jan.daejeon.k-devcon.com"],"tags":[],"content":"\n\n                  \n                  &quot;오리지날 갈든&quot; 은 Networked-thought 에 포함되지 않는, 강의 필기록과 같은 Sequential 한 작물들을 모아놓는 곳입니다. \n                  \n                \n\n\n\n                  \n                  현재 기존의 Notion 및 Bear 에 기록된 문서들의 Migration 작업이 진행중입니다. \n                  \n                \n\n충남대 컴퓨터공학과 학부 강의 §\n\n데이터 통신\n소프트웨어 공학\n운영체제\n웹 프로그래밍\n컴파일러 개론\n컴퓨터 네트워크\n프로그래밍 언어 개론\n\n온라인 강의 §\n\n이화여대 운영체제 온라인 강의\n\n도서 §\n\n점프 투 파이썬\n\n기타.. §\n\n쿠버네티스 교육자료 (SI Analytics, Jan. 2023)\n2024-01-27) K-DevCon 대전 강연 기록\n"}}