<!DOCTYPE html>
<html><head><title>(논문) Tiered Memory Management: Access Latency is the Key!, SOSP'24 (5. Evaluation)</title><meta charSet="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><meta property="og:title" content="(논문) Tiered Memory Management: Access Latency is the Key!, SOSP'24 (5. Evaluation)"/><meta property="og:description" content="본 글은 논문 Tiered Memory Management: Access Latency is the Key! (SOSP 2024) 를 읽고 정리한 글입니다. 별도의 명시가 없는 한, 본 글의 모든 그림은 위 논문에서 가져왔습니다. 목차 1. Introduction 2."/><meta property="og:image" content="https://mdg.haeramk.im/static/og-image.png"/><meta property="og:width" content="1200"/><meta property="og:height" content="675"/><link rel="icon" href="../../../../../../static/icon.png"/><meta name="description" content="본 글은 논문 Tiered Memory Management: Access Latency is the Key! (SOSP 2024) 를 읽고 정리한 글입니다. 별도의 명시가 없는 한, 본 글의 모든 그림은 위 논문에서 가져왔습니다. 목차 1. Introduction 2."/><meta name="generator" content="Quartz"/><link rel="preconnect" href="https://fonts.googleapis.com"/><link rel="preconnect" href="https://fonts.gstatic.com"/><link href="../../../../../../index.css" rel="stylesheet" type="text/css" spa-preserve/><link href="https://cdn.jsdelivr.net/npm/katex@0.16.0/dist/katex.min.css" rel="stylesheet" type="text/css" spa-preserve/><link href="https://fonts.googleapis.com/css2?family=IBM Plex Mono&amp;family=Gowun Batang:wght@400;700&amp;family=Gowun Dodum:ital,wght@0,400;0,600;1,400;1,600&amp;display=swap" rel="stylesheet" type="text/css" spa-preserve/><script src="../../../../../../prescript.js" type="application/javascript" spa-preserve></script><script type="application/javascript" spa-preserve>const fetchData = fetch(`../../../../../../static/contentIndex.json`).then(data => data.json())</script></head><body data-slug="gardens/os/memory/papers/colloid.2024.sosp.sigops.org/full/5.-Evaluation-(Colloid,-SOSP'24)"><div id="quartz-root" class="page"><div id="quartz-body"><div class="left sidebar"><h1 class="page-title "><a href="../../../../../..">Madison Digital Garden</a></h1><div class="spacer mobile-only"></div><div class="search "><div id="search-icon"><p>Search</p><div></div><svg tabIndex="0" aria-labelledby="title desc" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 19.9 19.7"><title id="title">Search</title><desc id="desc">Search</desc><g class="search-path" fill="none"><path stroke-linecap="square" d="M18.5 18.3l-5.4-5.4"></path><circle cx="8" cy="8" r="7"></circle></g></svg></div><div id="search-container"><div id="search-space"><input autocomplete="off" id="search-bar" name="search" type="text" aria-label="Search for something" placeholder="Search for something"/><div id="results-container"></div></div></div></div><div class="darkmode "><input class="toggle" id="darkmode-toggle" type="checkbox" tabIndex="-1"/><label id="toggle-label-light" for="darkmode-toggle" tabIndex="-1"><svg xmlns="http://www.w3.org/2000/svg" xmlnsXlink="http://www.w3.org/1999/xlink" version="1.1" id="dayIcon" x="0px" y="0px" viewBox="0 0 35 35" style="enable-background:new 0 0 35 35;" xmlSpace="preserve"><title>Light mode</title><path d="M6,17.5C6,16.672,5.328,16,4.5,16h-3C0.672,16,0,16.672,0,17.5    S0.672,19,1.5,19h3C5.328,19,6,18.328,6,17.5z M7.5,26c-0.414,0-0.789,0.168-1.061,0.439l-2,2C4.168,28.711,4,29.086,4,29.5    C4,30.328,4.671,31,5.5,31c0.414,0,0.789-0.168,1.06-0.44l2-2C8.832,28.289,9,27.914,9,27.5C9,26.672,8.329,26,7.5,26z M17.5,6    C18.329,6,19,5.328,19,4.5v-3C19,0.672,18.329,0,17.5,0S16,0.672,16,1.5v3C16,5.328,16.671,6,17.5,6z M27.5,9    c0.414,0,0.789-0.168,1.06-0.439l2-2C30.832,6.289,31,5.914,31,5.5C31,4.672,30.329,4,29.5,4c-0.414,0-0.789,0.168-1.061,0.44    l-2,2C26.168,6.711,26,7.086,26,7.5C26,8.328,26.671,9,27.5,9z M6.439,8.561C6.711,8.832,7.086,9,7.5,9C8.328,9,9,8.328,9,7.5    c0-0.414-0.168-0.789-0.439-1.061l-2-2C6.289,4.168,5.914,4,5.5,4C4.672,4,4,4.672,4,5.5c0,0.414,0.168,0.789,0.439,1.06    L6.439,8.561z M33.5,16h-3c-0.828,0-1.5,0.672-1.5,1.5s0.672,1.5,1.5,1.5h3c0.828,0,1.5-0.672,1.5-1.5S34.328,16,33.5,16z     M28.561,26.439C28.289,26.168,27.914,26,27.5,26c-0.828,0-1.5,0.672-1.5,1.5c0,0.414,0.168,0.789,0.439,1.06l2,2    C28.711,30.832,29.086,31,29.5,31c0.828,0,1.5-0.672,1.5-1.5c0-0.414-0.168-0.789-0.439-1.061L28.561,26.439z M17.5,29    c-0.829,0-1.5,0.672-1.5,1.5v3c0,0.828,0.671,1.5,1.5,1.5s1.5-0.672,1.5-1.5v-3C19,29.672,18.329,29,17.5,29z M17.5,7    C11.71,7,7,11.71,7,17.5S11.71,28,17.5,28S28,23.29,28,17.5S23.29,7,17.5,7z M17.5,25c-4.136,0-7.5-3.364-7.5-7.5    c0-4.136,3.364-7.5,7.5-7.5c4.136,0,7.5,3.364,7.5,7.5C25,21.636,21.636,25,17.5,25z"></path></svg></label><label id="toggle-label-dark" for="darkmode-toggle" tabIndex="-1"><svg xmlns="http://www.w3.org/2000/svg" xmlnsXlink="http://www.w3.org/1999/xlink" version="1.1" id="nightIcon" x="0px" y="0px" viewBox="0 0 100 100" style="enable-background='new 0 0 100 100'" xmlSpace="preserve"><title>Dark mode</title><path d="M96.76,66.458c-0.853-0.852-2.15-1.064-3.23-0.534c-6.063,2.991-12.858,4.571-19.655,4.571  C62.022,70.495,50.88,65.88,42.5,57.5C29.043,44.043,25.658,23.536,34.076,6.47c0.532-1.08,0.318-2.379-0.534-3.23  c-0.851-0.852-2.15-1.064-3.23-0.534c-4.918,2.427-9.375,5.619-13.246,9.491c-9.447,9.447-14.65,22.008-14.65,35.369  c0,13.36,5.203,25.921,14.65,35.368s22.008,14.65,35.368,14.65c13.361,0,25.921-5.203,35.369-14.65  c3.872-3.871,7.064-8.328,9.491-13.246C97.826,68.608,97.611,67.309,96.76,66.458z"></path></svg></label></div></div><div class="center"><div class="page-header"><div class="popover-hint"><h1 class="article-title ">(논문) Tiered Memory Management: Access Latency is the Key!, SOSP'24 (5. Evaluation)</h1><p class="content-meta ">Jan 27, 2025, 26 min read</p><ul class="tags "><li><a href="../../../../../../tags/os" class="internal tag-link">#os</a></li><li><a href="../../../../../../tags/os-memory" class="internal tag-link">#os-memory</a></li><li><a href="../../../../../../tags/paper-review" class="internal tag-link">#paper-review</a></li></ul></div></div><article class="popover-hint"><blockquote class="callout" data-callout="info">
<div class="callout-title">
                  <div class="callout-icon"><svg xmlns="http://www.w3.org/2000/svg" width="100%" height="100%" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="10"></circle><line x1="12" y1="16" x2="12" y2="12"></line><line x1="12" y1="8" x2="12.01" y2="8"></line></svg></div>
                  <div class="callout-title-inner"><p>본 글은 논문 <a href="https://dl.acm.org/doi/10.1145/3694715.3695968" class="external">Tiered Memory Management: Access Latency is the Key! (SOSP 2024)</a> 를 읽고 정리한 글입니다.</p></div>
                  
                </div>
</blockquote>
<blockquote class="callout" data-callout="info">
<div class="callout-title">
                  <div class="callout-icon"><svg xmlns="http://www.w3.org/2000/svg" width="100%" height="100%" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="10"></circle><line x1="12" y1="16" x2="12" y2="12"></line><line x1="12" y1="8" x2="12.01" y2="8"></line></svg></div>
                  <div class="callout-title-inner"><p>별도의 명시가 없는 한, 본 글의 모든 그림은 위 논문에서 가져왔습니다. </p></div>
                  
                </div>
</blockquote>
<blockquote class="callout is-collapsible is-collapsed" data-callout="info" data-callout-fold>
<div class="callout-title">
                  <div class="callout-icon"><svg xmlns="http://www.w3.org/2000/svg" width="100%" height="100%" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="10"></circle><line x1="12" y1="16" x2="12" y2="12"></line><line x1="12" y1="8" x2="12.01" y2="8"></line></svg></div>
                  <div class="callout-title-inner"><p>목차 </p></div>
                  <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="fold">
                  <polyline points="6 9 12 15 18 9"></polyline>
                </svg>
                </div>
<ul>
<li><a href="../../../../../../gardens/os/memory/papers/colloid.2024.sosp.sigops.org/full/1.-Introduction-(Colloid,-SOSP'24)" class="internal" data-slug="gardens/os/memory/papers/colloid.2024.sosp.sigops.org/full/1.-Introduction-(Colloid,-SOSP'24)">1. Introduction</a></li>
<li><a href="../../../../../../gardens/os/memory/papers/colloid.2024.sosp.sigops.org/full/2.-Motivation-(Colloid,-SOSP'24)" class="internal" data-slug="gardens/os/memory/papers/colloid.2024.sosp.sigops.org/full/2.-Motivation-(Colloid,-SOSP'24)">2. Motivation</a></li>
<li><a href="../../../../../../gardens/os/memory/papers/colloid.2024.sosp.sigops.org/full/3.-Colloid-(Colloid,-SOSP'24)" class="internal" data-slug="gardens/os/memory/papers/colloid.2024.sosp.sigops.org/full/3.-Colloid-(Colloid,-SOSP'24)">3. Colloid</a></li>
<li><a href="../../../../../../gardens/os/memory/papers/colloid.2024.sosp.sigops.org/full/4.-Colloid-with-Existing-Memory-Tiering-Systems-(Colloid,-SOSP'24)" class="internal" data-slug="gardens/os/memory/papers/colloid.2024.sosp.sigops.org/full/4.-Colloid-with-Existing-Memory-Tiering-Systems-(Colloid,-SOSP'24)">4. Colloid with Existing Memory Tiering Systems</a></li>
<li><a href="../../../../../../gardens/os/memory/papers/colloid.2024.sosp.sigops.org/full/5.-Evaluation-(Colloid,-SOSP'24)" class="internal" data-slug="gardens/os/memory/papers/colloid.2024.sosp.sigops.org/full/5.-Evaluation-(Colloid,-SOSP'24)">5. Evaluation (현재 글)</a></li>
<li><a href="../../../../../../gardens/os/memory/papers/colloid.2024.sosp.sigops.org/full/6-7.-Related-Work-and-Conclusion-(Colloid,-SOSP'24)" class="internal" data-slug="gardens/os/memory/papers/colloid.2024.sosp.sigops.org/full/6-7.-Related-Work-and-Conclusion-(Colloid,-SOSP'24)">6-7. Related Work and Conclusion</a></li>
</ul>
</blockquote>
<h2 id="50-setup">5.0. Setup<a aria-hidden="true" tabindex="-1" href="#50-setup" class="internal"> §</a></h2>
<blockquote class="callout" data-callout="tip">
<div class="callout-title">
                  <div class="callout-icon"><svg xmlns="http://www.w3.org/2000/svg" width="100%" height="100%" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M8.5 14.5A2.5 2.5 0 0 0 11 12c0-1.38-.5-2-1-3-1.072-2.143-.224-4.054 2-6 .5 2.5 2 4.9 4 6.5 2 1.6 3 3.5 3 5.5a7 7 0 1 1-14 0c0-1.153.433-2.294 1-3a2.5 2.5 0 0 0 2.5 2.5z"></path></svg></div>
                  <div class="callout-title-inner"><p>NXSECTION </p></div>
                  
                </div>
<ul>
<li><code>5.0</code> 은 evaluation setup 으로, 논문에는 이런 section 은 없다.</li>
</ul>
</blockquote>
<ul>
<li>본 section 에서는 <a href="../../../../../../gardens/os/memory/papers/hemem.2021.sosp.sigops.org/HeMem---Scalable-Tiered-Memory-Management-for-Big-Data-Applications-and-Real-NVM-(SOSP'21)" class="internal" data-slug="gardens/os/memory/papers/hemem.2021.sosp.sigops.org/HeMem---Scalable-Tiered-Memory-Management-for-Big-Data-Applications-and-Real-NVM-(SOSP'21)">HeMem</a>, <a href="../../../../../../gardens/os/memory/papers/drafts/(논문)-MEMTIS---Efficient-Memory-Tiering-with-Dynamic-Page-Classification-and-Page-Size-Determination" class="internal" data-slug="gardens/os/memory/papers/drafts/(논문)-MEMTIS---Efficient-Memory-Tiering-with-Dynamic-Page-Classification-and-Page-Size-Determination">MEMTIS</a>, <a href="../../../../../../gardens/os/memory/papers/drafts/(논문)-TPP---Transparent-Page-Placement-for-CXL-Enabled-Tiered-Memory" class="internal" data-slug="gardens/os/memory/papers/drafts/(논문)-TPP---Transparent-Page-Placement-for-CXL-Enabled-Tiered-Memory">TPP</a> 에 <em>Colloid</em> 를 적용했을 때와 안했을 때에 대한 evaluation 결과를 설명한다.</li>
<li>실험 setting 은:
<ul>
<li>일단 <a href="../../../../../../gardens/os/memory/papers/colloid.2024.sosp.sigops.org/full/2.-Motivation-(Colloid,-SOSP'24)#21-experimental-setup" class="internal" data-slug="gardens/os/memory/papers/colloid.2024.sosp.sigops.org/full/2.-Motivation-(Colloid,-SOSP'24)">Section 2.1.</a> 에서와 동일한 환경이고</li>
<li>설정값들은 별도 명시가 없는 한 전부 기본값으로 되어 있으며</li>
<li>TPP + Colloid 의 경우에는 <a href="../../../../../../gardens/os/memory/papers/(논문)-Practical,-Transparent-Operating-System-Support-for-Superpages" class="internal" data-slug="gardens/os/memory/papers/(논문)-Practical,-Transparent-Operating-System-Support-for-Superpages">Transparent Hugepages</a> 를 활성화한 결과이고, 비활성화한 것은 <a href="https://github.com/host-architecture/colloid/tree/master" class="external">여기</a> 에 있다고 한다 <sup><a href="#user-content-fn-evaluation-thp-disable" id="user-content-fnref-evaluation-thp-disable" data-footnote-ref aria-describedby="footnote-label" class="internal">1</a></sup>.</li>
<li>그리고, <span class="math math-inline"><span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">ϵ</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">0.01</span></span></span></span></span> 으로, <span class="math math-inline"><span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal" style="margin-right:0.03785em;">δ</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">0.05</span></span></span></span></span> 로 세팅하였다. 이때, 이 값을 변화시키며 실험한 것도 <a href="https://github.com/host-architecture/colloid/tree/master" class="external">여기</a> 에 있다고 한다 <sup><a href="#user-content-fn-evaluation-config-change" id="user-content-fnref-evaluation-config-change" data-footnote-ref aria-describedby="footnote-label" class="internal">2</a></sup>.</li>
</ul>
</li>
<li>실험에서 집중한 metric 은:
<ul>
<li>Steady-state 일때의 application throughput</li>
<li>Workload 혹은 memory interconnect contention 의 변화에 대한 convergence time</li>
<li>그리고 real-world application 에 대해서는, 해당 application 에 specific 한 metric 이다.</li>
</ul>
</li>
</ul>
<h2 id="51-steady-state-throughput">5.1. Steady-state Throughput<a aria-hidden="true" tabindex="-1" href="#51-steady-state-throughput" class="internal"> §</a></h2>
<h3 id="510-result">5.1.0. Result<a aria-hidden="true" tabindex="-1" href="#510-result" class="internal"> §</a></h3>
<blockquote class="callout" data-callout="tip">
<div class="callout-title">
                  <div class="callout-icon"><svg xmlns="http://www.w3.org/2000/svg" width="100%" height="100%" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M8.5 14.5A2.5 2.5 0 0 0 11 12c0-1.38-.5-2-1-3-1.072-2.143-.224-4.054 2-6 .5 2.5 2 4.9 4 6.5 2 1.6 3 3.5 3 5.5a7 7 0 1 1-14 0c0-1.153.433-2.294 1-3a2.5 2.5 0 0 0 2.5 2.5z"></path></svg></div>
                  <div class="callout-title-inner"><p>NXSECTION </p></div>
                  
                </div>
<ul>
<li><code>5.1.0</code> 은 실험 결과로, 논문에는 이런 section 은 없다.</li>
</ul>
</blockquote>
<ul>
<li><a href="../../../../../../gardens/os/memory/papers/colloid.2024.sosp.sigops.org/full/2.-Motivation-(Colloid,-SOSP'24)#220-result" class="internal" data-slug="gardens/os/memory/papers/colloid.2024.sosp.sigops.org/full/2.-Motivation-(Colloid,-SOSP'24)">Section 2.2.0.</a> 와 동일한 그래프를 그려보면 다음과 같다.</li>
<li>일단 아래의 그림이 <a href="../../../../../../gardens/os/memory/papers/colloid.2024.sosp.sigops.org/full/2.-Motivation-(Colloid,-SOSP'24)#220-result" class="internal" data-slug="gardens/os/memory/papers/colloid.2024.sosp.sigops.org/full/2.-Motivation-(Colloid,-SOSP'24)">Section 2.2.0.</a> 의 그래프이고,</li>
</ul>
<p><img src="../../../../../../images/Pasted-image-20250119190642.png" width="auto" height="auto"/></p>
<ul>
<li>그리고 이 그림이 <em>Colloid</em> 를 추가했을 때의 그래프이다.</li>
</ul>
<p><img src="../../../../../../images/Pasted-image-20250127221256.png" width="auto" height="auto"/></p>
<ul>
<li>보면 일단 전체적으로 <em>Colloid</em> 를 활성화시켰을 때 성능이 대폭 향상하는 것을 알 수 있다.</li>
<li><span class="math math-inline"><span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">0</span><span class="mord">×</span></span></span></span></span> 일 때는 모든 system 이 <em>Colloid</em> 가 있을 때와 없을 때에 동일한 성능을 보이고, best case 와도 유사한 성능을 보여주는 것을 알 수 있다.</li>
<li>근데 memory interconnect contention 이 증가함에 따라, benefit 이 <em>Colloid</em> 가 없을 때에 비해 훨씬 두드러지는 것을 볼 수 있다. 각각:
<ul>
<li>HeMem 은 <span class="math math-inline"><span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">1.2</span><span class="mord">×</span></span></span></span></span> ~ <span class="math math-inline"><span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">2.3</span><span class="mord">×</span></span></span></span></span>,</li>
<li>TPP 는 <span class="math math-inline"><span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">1.35</span><span class="mord">×</span></span></span></span></span> ~ <span class="math math-inline"><span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">2.35</span><span class="mord">×</span></span></span></span></span>,</li>
<li>MEMTIS 은 <span class="math math-inline"><span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">1.29</span><span class="mord">×</span></span></span></span></span> ~ <span class="math math-inline"><span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">2.3</span><span class="mord">×</span></span></span></span></span> 배의 throughput 이득이 있다.</li>
</ul>
</li>
<li>또한 memory interconnect contention 과는 무관하게, <em>Colloid</em> 를 사용했을 경우 best case 와 유사한 성능을 보여준다. 각각 best case 와:
<ul>
<li>HeMem + Colloid 는 3%,</li>
<li>TPP + Colloid 는 8%,</li>
<li>MEMTIS + Colloid 는 13% 이내의 차이를 보여준다.</li>
</ul>
</li>
</ul>
<h3 id="511-understanding-colloid-benefits">5.1.1. Understanding Colloid benefits.<a aria-hidden="true" tabindex="-1" href="#511-understanding-colloid-benefits" class="internal"> §</a></h3>
<ul>
<li>그럼 <a href="../../../../../../gardens/os/memory/papers/colloid.2024.sosp.sigops.org/full/2.-Motivation-(Colloid,-SOSP'24)#221-under-memory-interconnect-contention-default-tier-access-latency-can-exceed-that-of-alternate-tier" class="internal" data-slug="gardens/os/memory/papers/colloid.2024.sosp.sigops.org/full/2.-Motivation-(Colloid,-SOSP'24)">Section 2.2.1.</a> 의 그래프도 비교를 해보자. 아래놈이 <a href="../../../../../../gardens/os/memory/papers/colloid.2024.sosp.sigops.org/full/2.-Motivation-(Colloid,-SOSP'24)#221-under-memory-interconnect-contention-default-tier-access-latency-can-exceed-that-of-alternate-tier" class="internal" data-slug="gardens/os/memory/papers/colloid.2024.sosp.sigops.org/full/2.-Motivation-(Colloid,-SOSP'24)">Section 2.2.1.</a> 의 그래프이고,</li>
</ul>
<p><img src="../../../../../../images/Pasted-image-20250119192113.png" width="auto" height="auto"/></p>
<ul>
<li>이놈은 <em>Colloid</em> 를 추가했을 때에 대한 그래프이다.</li>
</ul>
<p><img src="../../../../../../images/Pasted-image-20250127223217.png" width="auto" height="auto"/></p>
<ul>
<li><a href="../../../../../../gardens/os/memory/papers/colloid.2024.sosp.sigops.org/full/2.-Motivation-(Colloid,-SOSP'24)#221-under-memory-interconnect-contention-default-tier-access-latency-can-exceed-that-of-alternate-tier" class="internal" data-slug="gardens/os/memory/papers/colloid.2024.sosp.sigops.org/full/2.-Motivation-(Colloid,-SOSP'24)">Section 2.2.1.</a> 에서와는 달리, 이제는 HeMem, TPP, MEMTIS 에서도 memory interconnect contention 이 증가함에 따라 alternate tier 에 더 많은 hot page 들을 위치시키는 것을 알 수 있다.</li>
<li>그리고 <a href="../../../../../../gardens/os/memory/papers/colloid.2024.sosp.sigops.org/full/2.-Motivation-(Colloid,-SOSP'24)#222-existing-systems-continue-to-greedily-place-hottest-pages-in-default-tier-under-memory-interconnect-contention" class="internal" data-slug="gardens/os/memory/papers/colloid.2024.sosp.sigops.org/full/2.-Motivation-(Colloid,-SOSP'24)">Section 2.2.2.</a> 의 그래프도 비교를 해보자. 아래의 그래프가 <a href="../../../../../../gardens/os/memory/papers/colloid.2024.sosp.sigops.org/full/2.-Motivation-(Colloid,-SOSP'24)#222-existing-systems-continue-to-greedily-place-hottest-pages-in-default-tier-under-memory-interconnect-contention" class="internal" data-slug="gardens/os/memory/papers/colloid.2024.sosp.sigops.org/full/2.-Motivation-(Colloid,-SOSP'24)">Section 2.2.2.</a> 의 것이고,</li>
</ul>
<p><img src="../../../../../../images/Pasted-image-20250119192002.png" width="auto" height="auto"/></p>
<ul>
<li>이놈은 <em>Colloid</em> 를 추가했을 때에 대한 그래프이다.</li>
</ul>
<p><img src="../../../../../../images/Pasted-image-20250127223234.png" width="auto" height="auto"/></p>
<ul>
<li>보면 일단 default tier 와 alternate tier 간의 latency 차이가 확연하게 줄어든 것을 볼 수 있다.</li>
<li><span class="math math-inline"><span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">0</span><span class="mord">×</span></span></span></span></span> 일 때는 hot page 의 전부가 default tier 로 가있게 되는데, 이때에도 둘 간의 latency 차이를 줄이지 못해 여전히 default tier 의 latency 가 좀 더 낮은 것을 볼 수 있고,</li>
<li><span class="math math-inline"><span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">1</span><span class="mord">×</span></span></span></span></span> 일 때는 default 와 alternate tier 간의 balance 가 맞은 것이며</li>
<li><span class="math math-inline"><span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">2</span><span class="mord">×</span></span></span></span></span> 와 <span class="math math-inline"><span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">3</span><span class="mord">×</span></span></span></span></span> 일 때는 alternate tier 에 모든 hot page 를 배치해도 여전히 latency 차이가 줄어들지 못해 alternate tier 의 latency 가 좀 더 낮은 것을 볼 수 있다.</li>
</ul>
<h3 id="512-impact-of-alternate-tier-unloaded-latency">5.1.2. Impact of alternate tier unloaded latency.<a aria-hidden="true" tabindex="-1" href="#512-impact-of-alternate-tier-unloaded-latency" class="internal"> §</a></h3>
<ul>
<li>추가적으로 다양한 상황들에 대한 evaluation 을 진행해 다양한 상황에서 <em>Colloid</em> 가 주는 이점에 대해 실험했는데,
<ul>
<li><a href="#512-impact-of-alternate-tier-unloaded-latency" class="internal">Section 5.1.2.</a> 은 alternate tier 의 unloaded latency 에 변화를 주었을 때 <em>Colloid</em> 가 어떻게 반응하는지에 대한 실험이고,</li>
<li><a href="#513-impact-of-object-size" class="internal">Section 5.1.3.</a> 은 object size 를 (원래는 64byte 였는데) 바꿨을 때 <em>Colloid</em> 가 어떻게 반응하는지에 대한 실험이다.</li>
<li>그리고 <a href="https://github.com/host-architecture/colloid/tree/master" class="external">여기</a> 에 application 이 사용하는 core 개수를 변화시켰을 때 <sup><a href="#user-content-fn-evaluation-application-core" id="user-content-fnref-evaluation-application-core" data-footnote-ref aria-describedby="footnote-label" class="internal">3</a></sup> 와 read-write ratio 를 변화시켰을 때 <sup><a href="#user-content-fn-evaluation-rw-ratio" id="user-content-fnref-evaluation-rw-ratio" data-footnote-ref aria-describedby="footnote-label" class="internal">4</a></sup> 의 실험 결과가 있다고 한다.</li>
</ul>
</li>
<li>일단 <a href="../../../../../../gardens/arch/memory/drafts/Compute-Express-Link,-CXL-(Arch)" class="internal" data-slug="gardens/arch/memory/drafts/Compute-Express-Link,-CXL-(Arch)">CXL</a> 을 사용하게 되면, DRAM memory 보다 대략 latency 가 2배정도 차이난다고 한다. 그래서 지금까지의 실험에서는 default tier 와 alternate tier 간의 latency 가 1.9 배 차이나도록 하고 있었다고 한다.</li>
<li>근데 이 unloaded latency 를 바꾸기 위해, 이 실험에 대해서만 <a href="../../../../../../gardens/arch/cpu/terms/Uncore-(Intel-CPU-Arch)" class="internal" data-slug="gardens/arch/cpu/terms/Uncore-(Intel-CPU-Arch)">uncore frequency</a> 를 조정해 alternate tier 의 latency 를 1.9 배에서 2.7 배 까지 변화시킬 수 있었다고 한다.
<ul>
<li>근데 이렇게 uncore frequency 를 건드는 것은 alternate tier 의 bandwidth 를 줄이는 side-effect 도 있다고 한다.</li>
<li>따라서, 제시되는 값들은 “보수적인 수치” 라고 할 수 있다: 실제로는 해당 latency 를 가지는 alternate tier 의 bandwidth 는 이것보다 클 것이기 때문에, memory bandwidth saturation 에 의한 latency 의 증가가 이것보다는 더 적을 것이기 때문이다.</li>
</ul>
</li>
<li>그래서 실험 결과는 다음과 같다:</li>
</ul>
<p><img src="../../../../../../images/Pasted-image-20250127232705.png" width="auto" height="auto"/></p>
<ul>
<li>일단 HeMem, TPP, MEMTIS 에 대한 실험 결과이고, 가로축은 unloaded latency 의 변화, 그리고 세로축은 memory interconnect contention intensity 의 변화이며 heatmap 의 각 cell 은 각 상황에 대한 throughput 증가 비율이다.</li>
<li>한눈에 볼 수 있는 것은 전반적으로 <em>Colloid</em> 를 사용했을 때가 더 좋다는 것이다.</li>
<li>구체적으로 두개의 관점에서 변화를 살펴보자.
<ul>
<li>일단 동일한 unloaded latency 상에서는 (즉, 가로축은 고정하고 세로축의 변화만 보면) intensity 가 심해짐에 따라 <em>Colloid</em> 의 benefit 이 더 증가하는 것을 볼 수 있다 (위로 갈수록 색이 진해지니까).
<ul>
<li>이것은 <a href="#510-result" class="internal">Section 5.1.0.</a> 에서 본 것처럼 memory interconnect contention 이 심해질수록 hot page 를 alternate tier 에 두는 것이 더 좋기 때문이다.</li>
</ul>
</li>
<li>그리고 동일한 intensity 상에서는 (즉, 세로축은 고정하고 가로축의 변화만 보면) unloaded latency 가 증가함에 따라 <em>Colloid</em> 의 benefit 이 감소한다 (옆으로 갈수록 색이 옅어지니까).
<ul>
<li>이것은 alternate tier 의 latency 가 워낙에 크기 때문에 default tier 의 latency 가 점점 증가해도 hot page 를 alternate tier 로 옮기기가 힘들기 때문이다.</li>
<li>즉, alternate tier 의 latency 가 크기 때문에 평균 latency 가 더 높은 수준에서 형성되기 때문인 것.</li>
<li>결과적으로  <em>Colloid</em> 의 “hot page 를 alternate tier 에 배치하는 것에서 오는 이점” 을 살리기 힘들어 이런 낮은 성능 향상을 보여주게 되는 것이다.</li>
<li>그럼에도 불구하고, unloaded latency 가 가장 클 때에도, HeMem 은 <span class="math math-inline"><span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">1.01</span><span class="mord">×</span></span></span></span></span> ~ <span class="math math-inline"><span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">1.76</span><span class="mord">×</span></span></span></span></span> 의 성능 향상을, TPP 는 <span class="math math-inline"><span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">1.03</span><span class="mord">×</span></span></span></span></span> ~ <span class="math math-inline"><span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">1.76</span><span class="mord">×</span></span></span></span></span> 의 성능 향상을, MEMTIS <span class="math math-inline"><span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">1.01</span><span class="mord">×</span></span></span></span></span> ~ <span class="math math-inline"><span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">1.63</span><span class="mord">×</span></span></span></span></span> 의 성능 향상을 보여준다.</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="513-impact-of-object-size">5.1.3. Impact of object size.<a aria-hidden="true" tabindex="-1" href="#513-impact-of-object-size" class="internal"> §</a></h3>
<p><img src="../../../../../../images/Pasted-image-20250127234610.png" width="auto" height="auto"/></p>
<ul>
<li>위 그림은 접근하는 object size 만을 64byte 에서 4096byte 로 단계적으로 바꿨을 때의 그래프이다.
<ul>
<li>그래프의 각 축과 heatmap 이 의미하는 바는 가로축만 object size 를 64, 256, 1024, 4096 byte 로 바꾼 것이고 나머지는 <a href="#512-impact-of-alternate-tier-unloaded-latency" class="internal">Section 5.1.2.</a> 와 동일하다.</li>
</ul>
</li>
<li>일단 object size 가 256byte 보다 클 때, <span class="math math-inline"><span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">0</span><span class="mord">×</span></span></span></span></span> intensity 에서도 <em>Colloid</em> 를 사용하는 것이 더 성능이 좋은 것을 확인할 수 있다:
<ul>
<li>HeMem 는 <span class="math math-inline"><span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">1.17</span><span class="mord">×</span></span></span></span></span> ~ <span class="math math-inline"><span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">1.31</span><span class="mord">×</span></span></span></span></span>,</li>
<li>TPP 는 <span class="math math-inline"><span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">1.18</span><span class="mord">×</span></span></span></span></span> ~ <span class="math math-inline"><span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">1.35</span><span class="mord">×</span></span></span></span></span>,</li>
<li>MEMTIS 는 <span class="math math-inline"><span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">1.21</span><span class="mord">×</span></span></span></span></span> ~ <span class="math math-inline"><span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">1.35</span><span class="mord">×</span></span></span></span></span> 배의 성능 향상이 있었다.</li>
</ul>
</li>
<li>이것은 object size 가 커짐에 따라 workload 가 점점 더 memory intensive 해지기 때문이다.
<ul>
<li>즉, 점점 더 memory intensive 해지기 때문에 <span class="math math-inline"><span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">0</span><span class="mord">×</span></span></span></span></span> 에서도 memory interconnect contention 이 발생하여 <em>Colloid</em> 가 benefit 을 주게 된다는 것 <sup><a href="#user-content-fn-object-size-sequential" id="user-content-fnref-object-size-sequential" data-footnote-ref aria-describedby="footnote-label" class="internal">5</a></sup> <sup><a href="#user-content-fn-object-size-l3miss" id="user-content-fnref-object-size-l3miss" data-footnote-ref aria-describedby="footnote-label" class="internal">6</a></sup>.</li>
<li>가령 4096byte 의 object size 를 사용하여 HeMem 실험을 하였더니 memory interconnect contention intensity 가 <span class="math math-inline"><span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">0</span><span class="mord">×</span></span></span></span></span> 일 때에도 default tier 의 latency 가 alternate tier 의 latency 에 비해 1.77 배 더 컸다고 한다.</li>
</ul>
</li>
<li>다만 intensity 가 클 때 object size 도 증가시키면 <em>Colloid</em> 의 benefit 이 점차 줄어드는 것으로 결과가 나왔다.
<ul>
<li>이것은 alternate tier 의 BW 도 saturate 되기 때문이다.</li>
<li>즉, default tier 뿐 아니라 alternate tier 의 latency 도 커져서 default tier 에 체류하는 hot page 의 수가 좀 더 많아지고 따라서 <em>Colloid</em> 에서의 “hot page 를 alternate tier 에 배치함으로써 오는 benefit” 이 적어지기 때문이다.</li>
<li>가령 object size 가 64byte 일 때는 alternate tier 의 BW utilization 이 53% 정도였지만, 4096byte 일 때는 BW utilization 이 96% 까지 올라가게 된다고 한다.</li>
</ul>
</li>
</ul>
<h3 id="514-colloid-cpu-overheads">5.1.4. Colloid CPU overheads.<a aria-hidden="true" tabindex="-1" href="#514-colloid-cpu-overheads" class="internal"> §</a></h3>
<ul>
<li><em>Colloid</em> 에서는 latency measurement 와 page placement algorithm 때문에 추가적인 CPU cycle 을 필요로 한다.</li>
<li><a href="#510-result" class="internal">Section 5.1.0</a> 에서는 이 CPU overhead 를 확인할 수 있는데, HeMem 와 MEMTIS 는 모두 2% 미만의 overhead 를 보여줬다고 한다.
<ul>
<li>다만 TPP 에서는 4% ~ 6.5% 의 overhead 를 보여주었고, 이것은 <a href="../../../../../../gardens/os/memory/papers/colloid.2024.sosp.sigops.org/full/4.-Colloid-with-Existing-Memory-Tiering-Systems-(Colloid,-SOSP'24)#43-tpp-with-colloid" class="internal" data-slug="gardens/os/memory/papers/colloid.2024.sosp.sigops.org/full/4.-Colloid-with-Existing-Memory-Tiering-Systems-(Colloid,-SOSP'24)">Section 4.3.</a> 에서 말한 것 처럼 latency measurement 을 위해 추가적인 core 를 사용하기 때문이라고 한다.</li>
<li>이것은 그래프에서는 <span class="math math-inline"><span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">0</span><span class="mord">×</span></span></span></span></span> intensity 에서의 TPP 의 throughput 에서 보여진다고 생각된다; 이때 throughput 은 TPP 보다 TPP + Colloid 에서 조금 더 떨어지는데, 이게 위와 같은 이유에서인 것으로 보인다.</li>
</ul>
</li>
</ul>
<h2 id="52-convergence-time">5.2. Convergence Time<a aria-hidden="true" tabindex="-1" href="#52-convergence-time" class="internal"> §</a></h2>
<h3 id="520-overview">5.2.0. Overview<a aria-hidden="true" tabindex="-1" href="#520-overview" class="internal"> §</a></h3>
<blockquote class="callout" data-callout="tip">
<div class="callout-title">
                  <div class="callout-icon"><svg xmlns="http://www.w3.org/2000/svg" width="100%" height="100%" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M8.5 14.5A2.5 2.5 0 0 0 11 12c0-1.38-.5-2-1-3-1.072-2.143-.224-4.054 2-6 .5 2.5 2 4.9 4 6.5 2 1.6 3 3.5 3 5.5a7 7 0 1 1-14 0c0-1.153.433-2.294 1-3a2.5 2.5 0 0 0 2.5 2.5z"></path></svg></div>
                  <div class="callout-title-inner"><p>NXSECTION </p></div>
                  
                </div>
<ul>
<li><code>5.2.0</code> 은 overview 로, 논문에는 이런 section 은 없다.</li>
</ul>
</blockquote>
<ul>
<li>Workload 가 바뀌는 것은 tiered memory system 에서 항상 challenge 였다고 한다: 만약에 tiered memory system 이 workload 의 변화에 따라가지 못하면 최적의 성능을 내지 못하기 때문.</li>
<li>그래서 <a href="#52-convergence-time" class="internal">Section 5.2.</a> 에서는 이런 workload 변화에 따라 <em>Colloid</em> 가 어떻게 대응하는지 실험한다. 구체적으로는, workload 를 다음의 두 변화로 나누어서 분석한다:
<ul>
<li><a href="#521-dynamism-due-to-change-in-access-pattern" class="internal">Section 5.2.1.</a> 에서는 <a href="../../../../../../gardens/os/memory/papers/colloid.2024.sosp.sigops.org/full/3.-Colloid-(Colloid,-SOSP'24)#3223-dynamic-workload---changing-access-pattern" class="internal" data-slug="gardens/os/memory/papers/colloid.2024.sosp.sigops.org/full/3.-Colloid-(Colloid,-SOSP'24)">Section 3.2.2.3.</a> 처럼 workload 의 access pattern 이 바뀌었을 때에 대한 evaluation 이고,</li>
<li><a href="#522-dynamism-due-to-change-in-memory-interconnect-contention" class="internal">Section 5.2.2.</a> 에서는 <a href="../../../../../../gardens/os/memory/papers/colloid.2024.sosp.sigops.org/full/3.-Colloid-(Colloid,-SOSP'24)#3224-dynamic-workload---changing-equilibrium-point" class="internal" data-slug="gardens/os/memory/papers/colloid.2024.sosp.sigops.org/full/3.-Colloid-(Colloid,-SOSP'24)">Section 3.2.2.4.</a> 처럼 memory interconnect contention 이 바뀌었을 때에 대한 evaluation 에 대해 설명한다.</li>
</ul>
</li>
</ul>
<h3 id="521-dynamism-due-to-change-in-access-pattern">5.2.1. Dynamism due to change in access pattern.<a aria-hidden="true" tabindex="-1" href="#521-dynamism-due-to-change-in-access-pattern" class="internal"> §</a></h3>
<blockquote class="callout" data-callout="tip">
<div class="callout-title">
                  <div class="callout-icon"><svg xmlns="http://www.w3.org/2000/svg" width="100%" height="100%" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M8.5 14.5A2.5 2.5 0 0 0 11 12c0-1.38-.5-2-1-3-1.072-2.143-.224-4.054 2-6 .5 2.5 2 4.9 4 6.5 2 1.6 3 3.5 3 5.5a7 7 0 1 1-14 0c0-1.153.433-2.294 1-3a2.5 2.5 0 0 0 2.5 2.5z"></path></svg></div>
                  <div class="callout-title-inner"><p>NXSECTION </p></div>
                  
                </div>
<ul>
<li><code>5.2.1.x</code> 은 편의를 위해 주인장이 임의로 구분지은 section 이다.</li>
</ul>
</blockquote>
<h4 id="5211-0x-intensity-scenario">5.2.1.1. 0x intensity scenario<a aria-hidden="true" tabindex="-1" href="#5211-0x-intensity-scenario" class="internal"> §</a></h4>
<p><img src="../../../../../../images/Pasted-image-20250128102349.png" width="auto" height="auto"/></p>
<ul>
<li>일단 위에가 <span class="math math-inline"><span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">0</span><span class="mord">×</span></span></span></span></span> 의 memory interconnect contention 에서 access pattern 을 바꿨을 때의 결과이다.
<ul>
<li>이전처럼 15개의 core 에 GUPS workload 를 돌리고 steady state 가 될 때까지 기다린 다음,</li>
<li><span class="math math-inline"><span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6151em;"></span><span class="mord mathnormal">t</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">100</span></span></span></span></span> 에서 기존에 hot page 였던 애들을 전부 cold page 로 만들고, 기존에 cold page 였던 애들 중 랜덤하게 골라 hot page 로 만들며 access pattern 을 바꾸었다.</li>
</ul>
</li>
<li>그래서 그 결과는 모든 system (HeMem, TPP, MEMTIS) 에서 workload 가 바뀌었을 때 잠깐 throughput 이 떨어졌다가 원래대로 돌아오는 모습을 보인다.
<ul>
<li>이것은 생각해 보면 당연한 것이다: hot page 가 바뀌어서 hot page 들이 alternate tier 에 있게 되었는데 <span class="math math-inline"><span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">0</span><span class="mord">×</span></span></span></span></span> 에서는 alternate tier 의 latency 가 더 크므로 throughput 이 줄어드는 것.</li>
<li>그리고 이후에 이 hot page 들이 default tier 로 움직이며 원래의 throughput 으로 돌아오는 것이다.</li>
</ul>
</li>
<li>또한 <em>Colloid</em> 를 사용했을 때에도 기존의 system 과 동일한 양상을 보여준다.
<ul>
<li>당연히 <span class="math math-inline"><span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">0</span><span class="mord">×</span></span></span></span></span> 일 때는 <em>Colloid</em> 를 사용하든 말든 모든 hot page 가 default tier 에 들어가기 때문.</li>
</ul>
</li>
<li>다만 TPP 의 경우에는 100초 정도로 convergence time 이 더 오래 걸리는 것을 알 수 있다.
<ul>
<li>이것은 TPP 가 page table scan 을 하며 protection bit 를 키고, 이것에 의한 hint fault 를 이용하기 때문에 page table scan overhead 로 변화를 감지하는데 오래걸리기 때문이다.</li>
<li>TPP + Colloid 에서는 이러한 방식을 동일하게 사용하기 때문에 TPP 에서와 마찬가지로 오래걸리게 되는 것.</li>
</ul>
</li>
</ul>
<p><img src="../../../../../../images/Pasted-image-20250128103858.png" width="auto" height="auto"/></p>
<ul>
<li>위의 그래프는 HeMem 와 HeMem + Colloid 에서 page migration rate 를 보여준 것이다.</li>
<li>일단 당연히 <span class="math math-inline"><span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6151em;"></span><span class="mord mathnormal">t</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">100</span></span></span></span></span> 에서 access pattern 이 바뀌었으므로 이때 page migration 이 진행되며 migration rate 도 커지는 것을 볼 수 있다.</li>
<li>이때 HeMem 와 HeMem + Colloid 의 차이점은 크게 두 가지로 볼 수 있다:</li>
</ul>
<ol>
<li>우선 HeMem 보다 HeMem + Colloid 일 때 최대 migration rate 은 더 작고 convergence time 은 조금 더 오래 걸리는 것을 볼 수 있다.
<ul>
<li>이것은 <em>Colloid</em> 의 <a href="../../../../../../gardens/os/memory/papers/colloid.2024.sosp.sigops.org/full/3.-Colloid-(Colloid,-SOSP'24)#323-dynamic-migration-limit" class="internal" data-slug="gardens/os/memory/papers/colloid.2024.sosp.sigops.org/full/3.-Colloid-(Colloid,-SOSP'24)">Dynamic migration limit</a> 때문이다.</li>
<li><em>Colloid</em> 에서는 migration overhead 를 줄이기 위해 <span class="math math-inline"><span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">min</span><span class="mopen">(</span><span class="mord">Δ</span><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:-0.0077em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">D</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:-0.0077em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">A</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">M</span><span class="mclose">)</span></span></span></span></span> 으로 migration limit 을 정하기 때문에, 최대 migration rate 은 <span class="math math-inline"><span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">M</span></span></span></span></span> 을 넘지 못해 HeMem 에 비해 최대 migration rate 이 좀 더 작게 나오게 된다.</li>
<li>또한, convergence 에 가까워지게 되면 <span class="math math-inline"><span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">Δ</span><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:-0.0077em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">D</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:-0.0077em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">A</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span> 으로 migration limit 이 정해져 조금 더 천천히 converge 하게 된다.
<ul>
<li>따라서 이렇게 천천히 converge 하는 것은 hot page 의 크기와는 무관하게 된다: 만약에 hot page 의 크기가 커서 migration 할 것이 많다고 하더라도, <span class="math math-inline"><span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">Δ</span><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:-0.0077em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">D</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:-0.0077em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">A</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span> 에 의한 gradual convergence 는 convergence point 에 가까워져야만 활성화 되기 때문.</li>
</ul>
</li>
</ul>
</li>
<li>그리고 HeMem 보다 HeMem + Colloid 일 때 steady state 일 때의 migration rate 이 살짝 더 높은 것을 알 수 있다.
<ul>
<li>이것은 <em>Colloid</em> 에서 steady state 일 때에도 balance 를 맞추기 위해 조금씩 page migration 을 하기 때문인 것으로 보인다.</li>
<li>하지만 이것이 application performance 에 미치는 영향은 아주 작다: 이 steady state 일 때의 page migration rate 이 application throughput 에 미치는 영향은 0.7% 미만으로 아주 작다고 한다.</li>
</ul>
</li>
</ol>
<h4 id="5212-3x-intensity-scenario">5.2.1.2. 3x intensity scenario<a aria-hidden="true" tabindex="-1" href="#5212-3x-intensity-scenario" class="internal"> §</a></h4>
<p><img src="../../../../../../images/Pasted-image-20250128110436.png" width="auto" height="auto"/></p>
<ul>
<li>위 그래프는 <a href="#5211-0x-intensity-scenario" class="internal">Section 5.2.1.1.</a> 와 동일한 실험이지만, <span class="math math-inline"><span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">3</span><span class="mord">×</span></span></span></span></span> 의 memory interconnect 일 때의 실험 결과이다.</li>
<li>보면 일단 전반적으로 <em>Colloid</em> 를 사용했을 때가 더 throughput 이 좋게 나온다; 앞서 계속 말한 대로 이 때는 hot page 를 alternate tier 에 배치하는 것이 더 좋기 때문.</li>
<li><span class="math math-inline"><span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6151em;"></span><span class="mord mathnormal">t</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">100</span></span></span></span></span> 에 access pattern 이 바뀌었을 때, <em>Colloid</em> 를 사용했을 때와 사용하지 않았을 때 각기 다른 양상을 보인다:
<ul>
<li>일단 <em>Colloid</em> 를 사용했을 때는 일시적으로 throughput 이 감소하게 되는데, 이것은 access pattern 이 바뀌어 hot page 의 일부가 default tier 에 있기 때문이다.
<ul>
<li>따라서 이놈들을 다시 alternate tier 로 옮기며 throughput 이 원상복귀된다.</li>
</ul>
</li>
<li>반면 <em>Colloid</em> 를 사용하지 않았을 때는 일시적으로 throughput 이 증가하게 되는데, 이것은 access pattern 이 바뀌어 hot page 의 일부가 alternate tier 에 있기 때문이다.
<ul>
<li>즉, 일시적으로 <em>Colloid</em> 를 사용했을 때와 유사해지며 throughput 이 증가하게 된다.</li>
<li>근데 다시 이놈들을 default tier 로 옮기며 throughput 이 감소하게 된다.</li>
</ul>
</li>
</ul>
</li>
<li>위와 같은 양상은 HeMem (+ Colloid) 와 TPP (+ Colloid) 에서 모두 보여주고, TPP 에서만 조금 더 convergence 에 오래걸리는 것을 확인할 수 있다.
<ul>
<li>TPP 에서 좀 더 오래걸리는 것은 <a href="#5211-0x-intensity-scenario" class="internal">Section 5.2.1.1.</a> 에서 말한 대로 TPP 에서의 page table scan overhead 때문이다.</li>
</ul>
</li>
<li>다만, MEMTIS + Colloid 에서는 throughput 이 감소하지 않는 것을 알 수 있다.
<ul>
<li>이것은 MEMTIS 에서는 default tier 에 공간이 많이 있어도 cold page 들을 alternate tier 로 적극적으로 옮기기 때문에, access pattern 이 바뀌었을 때 이미 바뀐 hot page 들이 alternate tier 로 옮겨져 있었기 때문이다.</li>
</ul>
</li>
</ul>
<h3 id="522-dynamism-due-to-change-in-memory-interconnect-contention">5.2.2. Dynamism due to change in memory interconnect contention.<a aria-hidden="true" tabindex="-1" href="#522-dynamism-due-to-change-in-memory-interconnect-contention" class="internal"> §</a></h3>
<p><img src="../../../../../../images/Pasted-image-20250128101002.png" width="auto" height="auto"/></p>
<ul>
<li>위 그래프는 이번에는 access pattern 은 그대로 두고, memory interconnect contention 을 <span class="math math-inline"><span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">0</span><span class="mord">×</span></span></span></span></span> 에서 <span class="math math-inline"><span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">3</span><span class="mord">×</span></span></span></span></span> 로 바꿨을 때의 실험 결과이다.</li>
<li>HeMem, TPP, MEMTIS 모두 바꾸기 전에는 <em>Colloid</em> 를 사용하던 말던 비슷한 throughput 을 보여준다.</li>
<li><em>Colloid</em> 를 사용하지 않았을 때는 intensity 가 변한 이후 throughput 이 크게 떨어지고 그대로 유지되는 것을 볼 수 있다.
<ul>
<li>이것은 HeMem, TPP, MEMTIS 모두 이러한 변화에 대응하는 logic 이 없기 때문이다.</li>
</ul>
</li>
<li>하지만 <em>Colloid</em> 를 사용했을 때는 intensity 가 변한 이후 throughput 이 떨어졌다가, 바뀐 intensity 에 대한 optimal throughput 으로 찾아가는 것을 볼 수 있다.
<ul>
<li>Intensity 가 바뀐 이후에의 throughput 은 <a href="#510-result" class="internal">Section 5.1.0.</a> 에서의 best case 의 <span class="math math-inline"><span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">3</span><span class="mord">×</span></span></span></span></span> throughput 과 일치한다고 한다.</li>
</ul>
</li>
<li>그리고 이 때의 convergence time 은 <a href="#5211-0x-intensity-scenario" class="internal">Section 5.2.1.1.</a> 에서와 유사하다: HeMem + Colloid 이 10초, MEMTIS + Colloid 이 25 초 정도로 빠른 convergence time 을 보여줬고, 비효율적인 detection 을 보여주는 TPP + Colloid 는 100 정도로 느린 convergence time 을 보여줬다.</li>
</ul>
<p><img src="../../../../../../images/Pasted-image-20250128113153.png" width="auto" height="auto"/></p>
<ul>
<li>그리고 이것은 migration rate 에서도 나타난다: HeMem 의 경우에는 migration 을 하지 않기 때문에 migration rate 에 변화가 없고, HeMem + Colloid 의 경우에는 optimal 을 찾아가며 migration rate 가 일시적으로 높아지는 것을 볼 수 있다.</li>
</ul>
<h2 id="53-real-applications">5.3. Real Applications<a aria-hidden="true" tabindex="-1" href="#53-real-applications" class="internal"> §</a></h2>
<h3 id="530-overview">5.3.0. Overview<a aria-hidden="true" tabindex="-1" href="#530-overview" class="internal"> §</a></h3>
<blockquote class="callout" data-callout="tip">
<div class="callout-title">
                  <div class="callout-icon"><svg xmlns="http://www.w3.org/2000/svg" width="100%" height="100%" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M8.5 14.5A2.5 2.5 0 0 0 11 12c0-1.38-.5-2-1-3-1.072-2.143-.224-4.054 2-6 .5 2.5 2 4.9 4 6.5 2 1.6 3 3.5 3 5.5a7 7 0 1 1-14 0c0-1.153.433-2.294 1-3a2.5 2.5 0 0 0 2.5 2.5z"></path></svg></div>
                  <div class="callout-title-inner"><p>NXSECTION </p></div>
                  
                </div>
<ul>
<li><code>5.3.0</code> 은 overview 로, 논문에는 이런 section 은 없다.</li>
</ul>
</blockquote>
<ul>
<li>여기서는 다양한 access pattern 을 보여주는 real world application 세개에 대한 evaluation 을 보여준다.</li>
<li>그리고 이놈들에 대해 15개의 core 에 실행시키고, 나머지 core 에서 memory interconnect contention 을 변화시켜서 발생시켜가며 실험했다고 한다.</li>
</ul>
<h3 id="531-graph-processing-gapbs">5.3.1. Graph processing (GAPBS).<a aria-hidden="true" tabindex="-1" href="#531-graph-processing-gapbs" class="internal"> §</a></h3>
<ul>
<li>이놈은 여러 in-memory graph 에 대한 processing algorithm 을 구현한 application 이다.</li>
<li>실험 환경은:
<ul>
<li>사용한 algorithm 은 google 의 <a href="../../../../../../gardens/algorithm/draft/Page-Rank-(Algorithm)" class="internal" data-slug="gardens/algorithm/draft/Page-Rank-(Algorithm)">PageRank</a> 이고, 사용한 graph 는 Twitter graph 라고 한다.</li>
<li>여기에서 graph node 의 skewness 에 의해 hot page 가 결정된다고 한다 <sup><a href="#user-content-fn-gapbs-pagerank" id="user-content-fnref-gapbs-pagerank" data-footnote-ref aria-describedby="footnote-label" class="internal">7</a></sup>.</li>
<li>Default tier 의 크기는 전체 working set 의 <span class="math math-inline"><span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">1/3</span></span></span></span></span> 크기인 12.5GB 정도라고 한다.</li>
<li>그리고 16번을 실행해서 실행시간 평균을 내었다고 한다.</li>
</ul>
</li>
<li>그리고 이때의 결과는 다음과 같다.</li>
</ul>
<p><img src="../../../../../../images/Pasted-image-20250128120225.png" width="auto" height="auto"/></p>
<ul>
<li>가로축은 memory interconnect contention intensity 를 나타내고, 세로축은 이때의 정규화된 성능 향상 정도이다.</li>
<li>예상하다시피, intensity 가 높아질 수록 성능 향상 정도가 좋았다:
<ul>
<li>HeMem + Colloid 는 <span class="math math-inline"><span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">1.05</span><span class="mord">×</span></span></span></span></span> ~ <span class="math math-inline"><span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">1.92</span><span class="mord">×</span></span></span></span></span>,</li>
<li>TPP + Colloid 는 <span class="math math-inline"><span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">1.05</span><span class="mord">×</span></span></span></span></span> ~ <span class="math math-inline"><span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">1.48</span><span class="mord">×</span></span></span></span></span>,</li>
<li>MEMTIS + Colloid 는 <span class="math math-inline"><span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">1.12</span><span class="mord">×</span></span></span></span></span> ~ <span class="math math-inline"><span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">2.12</span><span class="mord">×</span></span></span></span></span> 의 성능 향상이 있었다.</li>
</ul>
</li>
<li>이때 TPP 의 성능 향상 정도가 낮은 이유는 앞에서 계속 말한 것처럼 page table scan overhead 때문이다.</li>
</ul>
<h3 id="532-in-memory-transaction-processing-silo">5.3.2. In-memory transaction processing (Silo).<a aria-hidden="true" tabindex="-1" href="#532-in-memory-transaction-processing-silo" class="internal"> §</a></h3>
<ul>
<li>여기에서는 in-memory transaction processing KV store 인 <a href="../../../../../../gardens/database/transaction/papers/drafts/(논문)-Speedy-transactions-in-multicore-in-memory-databases" class="internal" data-slug="gardens/database/transaction/papers/drafts/(논문)-Speedy-transactions-in-multicore-in-memory-databases">Silo</a> 를 YCSB-C 로 돌린 결과이다. 실험 환경은:
<ul>
<li>64byte key 와 100byte value pair</li>
<li>4억 (400 million) 개의 KV: 총 크기는 대략 60GB</li>
<li>Default tier 의 크기는 전체 크기의 <span class="math math-inline"><span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">1/3</span></span></span></span></span> (대략 20GB)</li>
<li>1500만 (15 million) 번의 zipfian distribution lookup</li>
</ul>
</li>
<li>이때의 실험 결과는 다음과 같다:</li>
</ul>
<p><img src="../../../../../../images/Pasted-image-20250128121452.png" width="auto" height="auto"/></p>
<ul>
<li>그래프는 마찬가지로 가로축은 intensity, 세로축은 정규화된 성능향상 정도이다.</li>
<li>결과는 성능 향상이 있긴 했지만, 그닥 많이 좋아지지는 않았다:
<ul>
<li>HeMem + Colloid 는 <span class="math math-inline"><span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">1.13</span><span class="mord">×</span></span></span></span></span> ~ <span class="math math-inline"><span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">1.25</span><span class="mord">×</span></span></span></span></span>,</li>
<li>TPP + Colloid 는 <span class="math math-inline"><span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">1.09</span><span class="mord">×</span></span></span></span></span> ~ <span class="math math-inline"><span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">1.17</span><span class="mord">×</span></span></span></span></span>,</li>
<li>MEMTIS + Colloid 는 <span class="math math-inline"><span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">1.08</span><span class="mord">×</span></span></span></span></span> ~ <span class="math math-inline"><span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">1.17</span><span class="mord">×</span></span></span></span></span> 의 성능 향상이 있었다.</li>
</ul>
</li>
</ul>
<h3 id="533-in-memory-key-value-cache-cachelib">5.3.3. In-memory key-value cache (Cachelib).<a aria-hidden="true" tabindex="-1" href="#533-in-memory-key-value-cache-cachelib" class="internal"> §</a></h3>
<ul>
<li>마지막으로는 facebook 의 in-memory KV cache 인 Cachlib 에 대한 evaluation 이다.</li>
<li>실험 환경은:
<ul>
<li>Benchmark tool: CacheBench, workload: HeMemKV</li>
<li>Key: 64byte, value: 4byte</li>
<li>20% 의 KV pair 가 hot, 나머지는 cold</li>
<li>Hot KV 는 90% 의 확률로 접근, cold KV 는 10% 의 확률로 접근</li>
<li><code>GET</code>-<code>UPDATE</code> 비율은 9:1</li>
<li>1500만 (15 million) KV 쌍을 준비: 대략 75GB</li>
<li>Default tier 는 working set (75GB) 의 <span class="math math-inline"><span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">1/3</span></span></span></span></span>: 대략 25GB</li>
<li>100만 (1 million) operation 실행</li>
<li>Metric 은 throughput (측정 시간동안 수행한 operation 수)</li>
</ul>
</li>
<li>일때 실험 결과는 다음과 같다:</li>
</ul>
<p><img src="../../../../../../images/Pasted-image-20250128121508.png" width="auto" height="auto"/></p>
<ul>
<li>그래프는 마찬가지로 가로축은 intensity, 세로축은 정규화된 성능향상 정도이다.</li>
<li>실험 결과는 intensity 가 높아짐에 따라 성능이 잘 나왔다:
<ul>
<li>HeMem + Colloid 는 <span class="math math-inline"><span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">1.37</span><span class="mord">×</span></span></span></span></span> ~ <span class="math math-inline"><span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">1.74</span><span class="mord">×</span></span></span></span></span>,</li>
<li>TPP + Colloid 는 <span class="math math-inline"><span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">1.42</span><span class="mord">×</span></span></span></span></span> ~ <span class="math math-inline"><span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">1.79</span><span class="mord">×</span></span></span></span></span>,</li>
<li>MEMTIS + Colloid 는 <span class="math math-inline"><span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">1.48</span><span class="mord">×</span></span></span></span></span> ~ <span class="math math-inline"><span class="katex"><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">1.93</span><span class="mord">×</span></span></span></span></span> 의 성능 향상이 있었다.</li>
</ul>
</li>
</ul>
<section data-footnotes class="footnotes"><h2 class="sr-only" id="footnote-label">Footnotes<a aria-hidden="true" tabindex="-1" href="#footnote-label" class="internal"> §</a></h2>
<ol>
<li id="user-content-fn-evaluation-thp-disable">
<p>확인해 보자. <a href="#user-content-fnref-evaluation-thp-disable" data-footnote-backref class="data-footnote-backref internal" aria-label="Back to content">↩</a></p>
</li>
<li id="user-content-fn-evaluation-config-change">
<p>이것도 확인해 보자. <a href="#user-content-fnref-evaluation-config-change" data-footnote-backref class="data-footnote-backref internal" aria-label="Back to content">↩</a></p>
</li>
<li id="user-content-fn-evaluation-application-core">
<p>이것도 <a href="#user-content-fnref-evaluation-application-core" data-footnote-backref class="data-footnote-backref internal" aria-label="Back to content">↩</a></p>
</li>
<li id="user-content-fn-evaluation-rw-ratio">
<p>그리고 이것도 <a href="#user-content-fnref-evaluation-rw-ratio" data-footnote-backref class="data-footnote-backref internal" aria-label="Back to content">↩</a></p>
</li>
<li id="user-content-fn-object-size-sequential">
<p>이부분에 대해 본문에서는 access pattern 이 점점 더 sequential 으로 바뀌고, 따라서 HW prefetcher 가 더 효율적으로 작동하기 떄문이라고 한다. 그러나 이러한 변화는 Colloid 뿐 아니라 HeMem 이나 TPP 에 대해서도 동일하게 적용되는 것이라 성능 향상의 이유를 설명하기에는 어려워 보인다. <a href="#user-content-fnref-object-size-sequential" data-footnote-backref class="data-footnote-backref internal" aria-label="Back to content">↩</a></p>
</li>
<li id="user-content-fn-object-size-l3miss">
<p>추가적으로 이런 설명도 덧붙인다: CHA 와 L3 의 cache miss 의 비율이 per-core parallelism 의 척도가 되고, 이것은 object size 가 커짐에 따라 증가하기 때문에 object size 가 커짐에 따라 효율적이라는 것이다. 근데 cache miss 가 증가하는 것이 왜 효율적임을 방증하는 것인지 이해는 안된다. <a href="#user-content-fnref-object-size-l3miss" data-footnote-backref class="data-footnote-backref internal" aria-label="Back to content">↩</a></p>
</li>
<li id="user-content-fn-gapbs-pagerank">
<p>이게 뭔소린지는 PR 을 잘 몰라서 모른다. <a href="#user-content-fnref-gapbs-pagerank" data-footnote-backref class="data-footnote-backref internal" aria-label="Back to content">↩</a></p>
</li>
</ol>
</section></article></div><div class="right sidebar"><div class="graph "><h3>Graph View</h3><div class="graph-outer"><div id="graph-container" data-cfg="{&quot;drag&quot;:true,&quot;zoom&quot;:true,&quot;depth&quot;:1,&quot;scale&quot;:1.1,&quot;repelForce&quot;:0.5,&quot;centerForce&quot;:0.3,&quot;linkDistance&quot;:30,&quot;fontSize&quot;:0.6,&quot;opacityScale&quot;:1,&quot;showTags&quot;:true,&quot;removeTags&quot;:[]}"></div><svg version="1.1" id="global-graph-icon" xmlns="http://www.w3.org/2000/svg" xmlnsXlink="http://www.w3.org/1999/xlink" x="0px" y="0px" viewBox="0 0 55 55" fill="currentColor" xmlSpace="preserve"><path d="M49,0c-3.309,0-6,2.691-6,6c0,1.035,0.263,2.009,0.726,2.86l-9.829,9.829C32.542,17.634,30.846,17,29,17
	s-3.542,0.634-4.898,1.688l-7.669-7.669C16.785,10.424,17,9.74,17,9c0-2.206-1.794-4-4-4S9,6.794,9,9s1.794,4,4,4
	c0.74,0,1.424-0.215,2.019-0.567l7.669,7.669C21.634,21.458,21,23.154,21,25s0.634,3.542,1.688,4.897L10.024,42.562
	C8.958,41.595,7.549,41,6,41c-3.309,0-6,2.691-6,6s2.691,6,6,6s6-2.691,6-6c0-1.035-0.263-2.009-0.726-2.86l12.829-12.829
	c1.106,0.86,2.44,1.436,3.898,1.619v10.16c-2.833,0.478-5,2.942-5,5.91c0,3.309,2.691,6,6,6s6-2.691,6-6c0-2.967-2.167-5.431-5-5.91
	v-10.16c1.458-0.183,2.792-0.759,3.898-1.619l7.669,7.669C41.215,39.576,41,40.26,41,41c0,2.206,1.794,4,4,4s4-1.794,4-4
	s-1.794-4-4-4c-0.74,0-1.424,0.215-2.019,0.567l-7.669-7.669C36.366,28.542,37,26.846,37,25s-0.634-3.542-1.688-4.897l9.665-9.665
	C46.042,11.405,47.451,12,49,12c3.309,0,6-2.691,6-6S52.309,0,49,0z M11,9c0-1.103,0.897-2,2-2s2,0.897,2,2s-0.897,2-2,2
	S11,10.103,11,9z M6,51c-2.206,0-4-1.794-4-4s1.794-4,4-4s4,1.794,4,4S8.206,51,6,51z M33,49c0,2.206-1.794,4-4,4s-4-1.794-4-4
	s1.794-4,4-4S33,46.794,33,49z M29,31c-3.309,0-6-2.691-6-6s2.691-6,6-6s6,2.691,6,6S32.309,31,29,31z M47,41c0,1.103-0.897,2-2,2
	s-2-0.897-2-2s0.897-2,2-2S47,39.897,47,41z M49,10c-2.206,0-4-1.794-4-4s1.794-4,4-4s4,1.794,4,4S51.206,10,49,10z"></path></svg></div><div id="global-graph-outer"><div id="global-graph-container" data-cfg="{&quot;drag&quot;:true,&quot;zoom&quot;:true,&quot;depth&quot;:-1,&quot;scale&quot;:0.9,&quot;repelForce&quot;:0.5,&quot;centerForce&quot;:0.3,&quot;linkDistance&quot;:30,&quot;fontSize&quot;:0.6,&quot;opacityScale&quot;:1,&quot;showTags&quot;:true,&quot;removeTags&quot;:[]}"></div></div></div><div class="toc desktop-only"><button type="button" id="toc"><h3>Table of Contents</h3><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="fold"><polyline points="6 9 12 15 18 9"></polyline></svg></button><div id="toc-content"><ul class="overflow"><li class="depth-0"><a href="#50-setup" data-for="50-setup">5.0. Setup</a></li><li class="depth-0"><a href="#51-steady-state-throughput" data-for="51-steady-state-throughput">5.1. Steady-state Throughput</a></li><li class="depth-1"><a href="#510-result" data-for="510-result">5.1.0. Result</a></li><li class="depth-1"><a href="#511-understanding-colloid-benefits" data-for="511-understanding-colloid-benefits">5.1.1. Understanding Colloid benefits.</a></li><li class="depth-1"><a href="#512-impact-of-alternate-tier-unloaded-latency" data-for="512-impact-of-alternate-tier-unloaded-latency">5.1.2. Impact of alternate tier unloaded latency.</a></li><li class="depth-1"><a href="#513-impact-of-object-size" data-for="513-impact-of-object-size">5.1.3. Impact of object size.</a></li><li class="depth-1"><a href="#514-colloid-cpu-overheads" data-for="514-colloid-cpu-overheads">5.1.4. Colloid CPU overheads.</a></li><li class="depth-0"><a href="#52-convergence-time" data-for="52-convergence-time">5.2. Convergence Time</a></li><li class="depth-1"><a href="#520-overview" data-for="520-overview">5.2.0. Overview</a></li><li class="depth-1"><a href="#521-dynamism-due-to-change-in-access-pattern" data-for="521-dynamism-due-to-change-in-access-pattern">5.2.1. Dynamism due to change in access pattern.</a></li><li class="depth-1"><a href="#522-dynamism-due-to-change-in-memory-interconnect-contention" data-for="522-dynamism-due-to-change-in-memory-interconnect-contention">5.2.2. Dynamism due to change in memory interconnect contention.</a></li><li class="depth-0"><a href="#53-real-applications" data-for="53-real-applications">5.3. Real Applications</a></li><li class="depth-1"><a href="#530-overview" data-for="530-overview">5.3.0. Overview</a></li><li class="depth-1"><a href="#531-graph-processing-gapbs" data-for="531-graph-processing-gapbs">5.3.1. Graph processing (GAPBS).</a></li><li class="depth-1"><a href="#532-in-memory-transaction-processing-silo" data-for="532-in-memory-transaction-processing-silo">5.3.2. In-memory transaction processing (Silo).</a></li><li class="depth-1"><a href="#533-in-memory-key-value-cache-cachelib" data-for="533-in-memory-key-value-cache-cachelib">5.3.3. In-memory key-value cache (Cachelib).</a></li></ul></div></div><div class="backlinks "><h3>Backlinks</h3><ul class="overflow"><li><a href="../../../../../../gardens/os/memory/papers/colloid.2024.sosp.sigops.org/Tiered-Memory-Management---Access-Latency-is-the-Key!-(SOSP'24)" class="internal">(논문) Tiered Memory Management: Access Latency is the Key! (SOSP'24)</a></li><li><a href="../../../../../../gardens/os/memory/papers/colloid.2024.sosp.sigops.org/full/1.-Introduction-(Colloid,-SOSP'24)" class="internal">(논문) Tiered Memory Management: Access Latency is the Key!, SOSP'24 (1. Introduction)</a></li><li><a href="../../../../../../gardens/os/memory/papers/colloid.2024.sosp.sigops.org/full/2.-Motivation-(Colloid,-SOSP'24)" class="internal">(논문) Tiered Memory Management: Access Latency is the Key!, SOSP'24 (2. Motivation)</a></li><li><a href="../../../../../../gardens/os/memory/papers/colloid.2024.sosp.sigops.org/full/3.-Colloid-(Colloid,-SOSP'24)" class="internal">(논문) Tiered Memory Management: Access Latency is the Key!, SOSP'24 (3. Colloid)</a></li><li><a href="../../../../../../gardens/os/memory/papers/colloid.2024.sosp.sigops.org/full/4.-Colloid-with-Existing-Memory-Tiering-Systems-(Colloid,-SOSP'24)" class="internal">(논문) Tiered Memory Management: Access Latency is the Key!, SOSP'24 (4. Colloid with existing memory tiering systems)</a></li><li><a href="../../../../../../gardens/os/memory/papers/colloid.2024.sosp.sigops.org/full/5.-Evaluation-(Colloid,-SOSP'24)" class="internal">(논문) Tiered Memory Management: Access Latency is the Key!, SOSP'24 (5. Evaluation)</a></li><li><a href="../../../../../../gardens/os/memory/papers/colloid.2024.sosp.sigops.org/full/6-7.-Related-Work-and-Conclusion-(Colloid,-SOSP'24)" class="internal">(논문) Tiered Memory Management: Access Latency is the Key!, SOSP'24 (6-7. Related Work and Conclusion)</a></li></ul></div></div></div><footer class><hr/><p>Created with <a href="https://quartz.jzhao.xyz/">Quartz v4.1.0</a>, © 2025</p><ul><li><a href="https://github.com/haeramkeem">GitHub</a></li><li><a href="https://www.linkedin.com/in/haeram-kim-277404220">LinkedIn</a></li><li><a href="mailto:haeram.kim1@gmail.com">Email</a></li></ul></footer></div></body><script type="application/javascript">// quartz/components/scripts/quartz/components/scripts/callout.inline.ts
function toggleCallout() {
  const outerBlock = this.parentElement;
  outerBlock.classList.toggle(`is-collapsed`);
  const collapsed = outerBlock.classList.contains(`is-collapsed`);
  const height = collapsed ? this.scrollHeight : outerBlock.scrollHeight;
  outerBlock.style.maxHeight = height + `px`;
  let current = outerBlock;
  let parent = outerBlock.parentElement;
  while (parent) {
    if (!parent.classList.contains(`callout`)) {
      return;
    }
    const collapsed2 = parent.classList.contains(`is-collapsed`);
    const height2 = collapsed2 ? parent.scrollHeight : parent.scrollHeight + current.scrollHeight;
    parent.style.maxHeight = height2 + `px`;
    current = parent;
    parent = parent.parentElement;
  }
}
function setupCallout() {
  const collapsible = document.getElementsByClassName(
    `callout is-collapsible`
  );
  for (const div of collapsible) {
    const title = div.firstElementChild;
    if (title) {
      title.removeEventListener(`click`, toggleCallout);
      title.addEventListener(`click`, toggleCallout);
      const collapsed = div.classList.contains(`is-collapsed`);
      const height = collapsed ? title.scrollHeight : div.scrollHeight;
      div.style.maxHeight = height + `px`;
    }
  }
}
document.addEventListener(`nav`, setupCallout);
window.addEventListener(`resize`, setupCallout);
</script><script type="module">
          import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.esm.min.mjs';
          const darkMode = document.documentElement.getAttribute('saved-theme') === 'dark'
          mermaid.initialize({
            startOnLoad: false,
            securityLevel: 'loose',
            theme: darkMode ? 'dark' : 'default'
          });
          document.addEventListener('nav', async () => {
            await mermaid.run({
              querySelector: '.mermaid'
            })
          });
          </script><script src="https://cdn.jsdelivr.net/npm/katex@0.16.7/dist/contrib/copy-tex.min.js" type="application/javascript"></script><script src="https://www.googletagmanager.com/gtag/js?id=G-N68CCP1QHG" type="application/javascript"></script><script src="../../../../../../postscript.js" type="module"></script></html>