<!DOCTYPE html>
<html><head><title>05. Data Level Parallelism (Advanced Computer Architectures, SNU CSE)</title><meta charSet="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><meta property="og:title" content="05. Data Level Parallelism (Advanced Computer Architectures, SNU CSE)"/><meta property="og:description" content="서울대학교 컴퓨터공학부 유승주 교수님의 &amp;quot;고급 컴퓨터 구조&amp;quot; 강의를 필기한 내용입니다. 목차 SIMD § SIMD 에서는 레지스터의 크기가 애초에 커서 여기에 여러개의 word 를 담고, 이것을 여러개의 ALU 에 한번에 던져서 parallel 하게 처리한다."/><meta property="og:image" content="https://mdg.haeramk.im/static/og-image.png"/><meta property="og:width" content="1200"/><meta property="og:height" content="675"/><link rel="icon" href="../../../../../static/icon.png"/><meta name="description" content="서울대학교 컴퓨터공학부 유승주 교수님의 &amp;quot;고급 컴퓨터 구조&amp;quot; 강의를 필기한 내용입니다. 목차 SIMD § SIMD 에서는 레지스터의 크기가 애초에 커서 여기에 여러개의 word 를 담고, 이것을 여러개의 ALU 에 한번에 던져서 parallel 하게 처리한다."/><meta name="generator" content="Quartz"/><link rel="preconnect" href="https://fonts.googleapis.com"/><link rel="preconnect" href="https://fonts.gstatic.com"/><link href="../../../../../index.css" rel="stylesheet" type="text/css" spa-preserve/><link href="https://cdn.jsdelivr.net/npm/katex@0.16.0/dist/katex.min.css" rel="stylesheet" type="text/css" spa-preserve/><link href="https://fonts.googleapis.com/css2?family=IBM Plex Mono&amp;family=Gowun Batang:wght@400;700&amp;family=Gowun Dodum:ital,wght@0,400;0,600;1,400;1,600&amp;display=swap" rel="stylesheet" type="text/css" spa-preserve/><script src="../../../../../prescript.js" type="application/javascript" spa-preserve></script><script type="application/javascript" spa-preserve>const fetchData = fetch(`../../../../../static/contentIndex.json`).then(data => data.json())</script></head><body data-slug="gardens/arch/originals/aca.spring.2025.cse.snu.ac.kr/lectures/05.-Data-Level-Parallelism"><div id="quartz-root" class="page"><div id="quartz-body"><div class="left sidebar"><h1 class="page-title "><a href="../../../../..">Madison Digital Garden</a></h1><div class="spacer mobile-only"></div><div class="search "><div id="search-icon"><p>Search</p><div></div><svg tabIndex="0" aria-labelledby="title desc" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 19.9 19.7"><title id="title">Search</title><desc id="desc">Search</desc><g class="search-path" fill="none"><path stroke-linecap="square" d="M18.5 18.3l-5.4-5.4"></path><circle cx="8" cy="8" r="7"></circle></g></svg></div><div id="search-container"><div id="search-space"><input autocomplete="off" id="search-bar" name="search" type="text" aria-label="Search for something" placeholder="Search for something"/><div id="results-container"></div></div></div></div><div class="darkmode "><input class="toggle" id="darkmode-toggle" type="checkbox" tabIndex="-1"/><label id="toggle-label-light" for="darkmode-toggle" tabIndex="-1"><svg xmlns="http://www.w3.org/2000/svg" xmlnsXlink="http://www.w3.org/1999/xlink" version="1.1" id="dayIcon" x="0px" y="0px" viewBox="0 0 35 35" style="enable-background:new 0 0 35 35;" xmlSpace="preserve"><title>Light mode</title><path d="M6,17.5C6,16.672,5.328,16,4.5,16h-3C0.672,16,0,16.672,0,17.5    S0.672,19,1.5,19h3C5.328,19,6,18.328,6,17.5z M7.5,26c-0.414,0-0.789,0.168-1.061,0.439l-2,2C4.168,28.711,4,29.086,4,29.5    C4,30.328,4.671,31,5.5,31c0.414,0,0.789-0.168,1.06-0.44l2-2C8.832,28.289,9,27.914,9,27.5C9,26.672,8.329,26,7.5,26z M17.5,6    C18.329,6,19,5.328,19,4.5v-3C19,0.672,18.329,0,17.5,0S16,0.672,16,1.5v3C16,5.328,16.671,6,17.5,6z M27.5,9    c0.414,0,0.789-0.168,1.06-0.439l2-2C30.832,6.289,31,5.914,31,5.5C31,4.672,30.329,4,29.5,4c-0.414,0-0.789,0.168-1.061,0.44    l-2,2C26.168,6.711,26,7.086,26,7.5C26,8.328,26.671,9,27.5,9z M6.439,8.561C6.711,8.832,7.086,9,7.5,9C8.328,9,9,8.328,9,7.5    c0-0.414-0.168-0.789-0.439-1.061l-2-2C6.289,4.168,5.914,4,5.5,4C4.672,4,4,4.672,4,5.5c0,0.414,0.168,0.789,0.439,1.06    L6.439,8.561z M33.5,16h-3c-0.828,0-1.5,0.672-1.5,1.5s0.672,1.5,1.5,1.5h3c0.828,0,1.5-0.672,1.5-1.5S34.328,16,33.5,16z     M28.561,26.439C28.289,26.168,27.914,26,27.5,26c-0.828,0-1.5,0.672-1.5,1.5c0,0.414,0.168,0.789,0.439,1.06l2,2    C28.711,30.832,29.086,31,29.5,31c0.828,0,1.5-0.672,1.5-1.5c0-0.414-0.168-0.789-0.439-1.061L28.561,26.439z M17.5,29    c-0.829,0-1.5,0.672-1.5,1.5v3c0,0.828,0.671,1.5,1.5,1.5s1.5-0.672,1.5-1.5v-3C19,29.672,18.329,29,17.5,29z M17.5,7    C11.71,7,7,11.71,7,17.5S11.71,28,17.5,28S28,23.29,28,17.5S23.29,7,17.5,7z M17.5,25c-4.136,0-7.5-3.364-7.5-7.5    c0-4.136,3.364-7.5,7.5-7.5c4.136,0,7.5,3.364,7.5,7.5C25,21.636,21.636,25,17.5,25z"></path></svg></label><label id="toggle-label-dark" for="darkmode-toggle" tabIndex="-1"><svg xmlns="http://www.w3.org/2000/svg" xmlnsXlink="http://www.w3.org/1999/xlink" version="1.1" id="nightIcon" x="0px" y="0px" viewBox="0 0 100 100" style="enable-background='new 0 0 100 100'" xmlSpace="preserve"><title>Dark mode</title><path d="M96.76,66.458c-0.853-0.852-2.15-1.064-3.23-0.534c-6.063,2.991-12.858,4.571-19.655,4.571  C62.022,70.495,50.88,65.88,42.5,57.5C29.043,44.043,25.658,23.536,34.076,6.47c0.532-1.08,0.318-2.379-0.534-3.23  c-0.851-0.852-2.15-1.064-3.23-0.534c-4.918,2.427-9.375,5.619-13.246,9.491c-9.447,9.447-14.65,22.008-14.65,35.369  c0,13.36,5.203,25.921,14.65,35.368s22.008,14.65,35.368,14.65c13.361,0,25.921-5.203,35.369-14.65  c3.872-3.871,7.064-8.328,9.491-13.246C97.826,68.608,97.611,67.309,96.76,66.458z"></path></svg></label></div></div><div class="center"><div class="page-header"><div class="popover-hint"><h1 class="article-title ">05. Data Level Parallelism (Advanced Computer Architectures, SNU CSE)</h1><p class="content-meta ">Mar 18, 2025, 12 min read</p><ul class="tags "><li><a href="../../../../../tags/arch" class="internal tag-link">#arch</a></li><li><a href="../../../../../tags/originals" class="internal tag-link">#originals</a></li><li><a href="../../../../../tags/snu-aca25s" class="internal tag-link">#snu-aca25s</a></li></ul></div></div><article class="popover-hint"><blockquote class="callout" data-callout="info">
<div class="callout-title">
                  <div class="callout-icon"><svg xmlns="http://www.w3.org/2000/svg" width="100%" height="100%" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="10"></circle><line x1="12" y1="16" x2="12" y2="12"></line><line x1="12" y1="8" x2="12.01" y2="8"></line></svg></div>
                  <div class="callout-title-inner"><p>서울대학교 컴퓨터공학부 유승주 교수님의 &quot;고급 컴퓨터 구조&quot; 강의를 필기한 내용입니다. </p></div>
                  
                </div>
<ul>
<li><a href="../../../../../gardens/arch/originals/aca.spring.2025.cse.snu.ac.kr/(SNU-CSE)-Advanced-Computer-Architectures" class="internal" data-slug="gardens/arch/originals/aca.spring.2025.cse.snu.ac.kr/(SNU-CSE)-Advanced-Computer-Architectures">목차</a></li>
</ul>
</blockquote>
<h2 id="simd">SIMD<a aria-hidden="true" tabindex="-1" href="#simd" class="internal"> §</a></h2>
<ul>
<li><a href="../../../../../gardens/arch/ilp/terms/Single-Instruction-Multiple-Data,-SIMD-(Arch)" class="internal" data-slug="gardens/arch/ilp/terms/Single-Instruction-Multiple-Data,-SIMD-(Arch)">SIMD</a> 에서는 레지스터의 크기가 애초에 커서 여기에 여러개의 word 를 담고, 이것을 여러개의 <a href="../../../../../gardens/arch/originals/shpc.fall.2024.cse.snu.ac.kr/drafts/05/Arithmetic-Logic-Unit,-ALU-(Arch)" class="internal" data-slug="gardens/arch/originals/shpc.fall.2024.cse.snu.ac.kr/drafts/05/Arithmetic-Logic-Unit,-ALU-(Arch)">ALU</a> 에 한번에 던져서 parallel 하게 처리한다.</li>
</ul>
<p><img src="../../../../../images/Pasted-image-20250428172518.png" width="auto" height="auto"/></p>
<ul>
<li>위 그림이 SIMD 를 제공하는 아주 고전적인 architecture 인 Cray-1 인데,
<ul>
<li>다 볼 필요는 없고 저기서 위쪽의 vector register 만 보면 된다.</li>
<li>보면 64-element vector registers 라고 되어 있는데, 이 말이 하나의 register 에는 64개의 element word 가 vector 로써 들어가고</li>
<li>따라서 register 에 있는 데이터가 오른쪽의 ALU 에 들어가게 되는 거다.
<ul>
<li>다만 ALU 에서 한번에 처리하는 개수는 이것보다는 더 작을 수도 있다.</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="vector-simd">Vector, SIMD<a aria-hidden="true" tabindex="-1" href="#vector-simd" class="internal"> §</a></h3>
<p><img src="../../../../../images/Pasted-image-20250428173148.png" width="auto" height="auto"/></p>
<ul>
<li>Vector 랑 SIMD 는 조금의 차이점이 있지만 거의 비슷한 용어이다.
<ul>
<li>Vector processor 에서는 위 그림에서 보여지는 것 처럼 연속되지 않은 DRAM 공간의 데이터도 load 할 수 있다는 차이점이 있는데
<ul>
<li>이건 것을 <em>stride access pattern</em> 이라고 한다.</li>
</ul>
</li>
<li>근데 SIMD 도 요즘 이런게 가능해서 거의 차이가 없는 용어라고 한다.</li>
</ul>
</li>
</ul>
<h3 id="vector-pipelining">Vector Pipelining<a aria-hidden="true" tabindex="-1" href="#vector-pipelining" class="internal"> §</a></h3>
<p><img src="../../../../../images/Pasted-image-20250428182739.png" width="auto" height="auto"/></p>
<ul>
<li>Vector 에서도 <a href="../../../../../gardens/arch/originals/shpc.fall.2024.cse.snu.ac.kr/drafts/04/Instruction-Pipeline-(Arch-Instruction)" class="internal" data-slug="gardens/arch/originals/shpc.fall.2024.cse.snu.ac.kr/drafts/04/Instruction-Pipeline-(Arch-Instruction)">Pipeline</a> 이 가능하다.
<ul>
<li>위 그림은 48개의 element 가 들어가는 register 에 대해 8-lane (즉, 한번에 연산하는 element 의 수) 으로 pipeline 을 하는 것인데,</li>
<li>보면 8개를 먼저 load 하고, 그 다음 8개를 load 하는 동안 8개를 multiply 하는 방식으로 pipeline 되는 것.</li>
</ul>
</li>
</ul>
<h3 id="matrix-multiplication-example-w-simd">Matrix Multiplication Example w/ SIMD<a aria-hidden="true" tabindex="-1" href="#matrix-multiplication-example-w-simd" class="internal"> §</a></h3>
<ul>
<li>SIMD 를 이용해 행렬곱을 하는 예시를 한번 보자.</li>
</ul>
<p><img src="../../../../../images/Pasted-image-20250428183557.png" width="auto" height="auto"/></p>
<ul>
<li>우선 위 그림에서 보다시피 output matrix 인 C 에서 <code>j = 0</code> 을 얻기 위해서는, A matrix 에서 <code>k = 0 ~ K</code> 에 해당하는 각각의 column 에 대해 B matrix 에서 <code>j = 0</code> 에 해당하고 <code>k = 0 ~ K</code> 에 해당하는 값을 모두 곱해서 더해줘야 한다.</li>
<li>이것을 SIMD 연산할 때는, C 의 column vector 에다가 A 의 <code>k = 0</code> 에 대한 column vector, 그리고 B 의 <code>j = 0</code>, <code>k = 0</code> 에 해당하는 값을 채운 vector 두개를 곱한 것을 더해주는 연산을 우선 하게 된다.
<ul>
<li>여기서 하나의 값을 vector 에 모두 채우는 것은 <em>Broadcast</em> 라고 하고</li>
<li>곱한것을 더하는 것은 <a href="../../../../../gardens/arch/originals/shpc.fall.2024.cse.snu.ac.kr/drafts/03/Fused-Multiply-Add,-FMA-(Arch)" class="internal" data-slug="gardens/arch/originals/shpc.fall.2024.cse.snu.ac.kr/drafts/03/Fused-Multiply-Add,-FMA-(Arch)">FMA</a> 연산이다.</li>
</ul>
</li>
</ul>
<p><img src="../../../../../images/Pasted-image-20250428184109.png" width="auto" height="auto"/></p>
<ul>
<li>다음에는 C 의 column vector 에다가 A 의 <code>k = 1</code> 에 대한 column vector, 그리고 B 의 <code>j = 0</code>, <code>k = 1</code> 에 해당하는 값을 채운 vector 두개를 곱한 것을 누적하여 더해주게 된다.</li>
<li>그리고 이것을 모든 <code>k</code> 에 대해 반복하면 C 에 대한 column vector 가 계산되는 것.</li>
</ul>
<h2 id="gpu">GPU<a aria-hidden="true" tabindex="-1" href="#gpu" class="internal"> §</a></h2>
<p><img src="../../../../../images/Pasted-image-20250428184458.png" width="auto" height="auto"/></p>
<ul>
<li>SIMD (<a href="../../../../../gardens/arch/drafts/Instruction-Set-Architecture,-ISA-(Arch)" class="internal" data-slug="gardens/arch/drafts/Instruction-Set-Architecture,-ISA-(Arch)">ISA</a> 그냥 이런 processing pattern) 의 경우에는 instruction 이 모두 동일하기 때문에 이 instruction 을 여러군데에서 fetch-decode 하는 것은 매우 비효율적일 것이다.
<ul>
<li>따라서 fetch-decode 는 공유하고 경장히 많은 ALU 들과 여기에서 사용할 ctx reg 들이 묶여있는 것이 GPU 의 기본 형태이다.</li>
</ul>
</li>
</ul>
<h3 id="cuda-execution-model">CUDA Execution Model<a aria-hidden="true" tabindex="-1" href="#cuda-execution-model" class="internal"> §</a></h3>
<ul>
<li>CUDA 에서 사용하는 execution 과 관련된 용어들을 좀 알아보자.</li>
</ul>
<p><img src="../../../../../images/Pasted-image-20250428190356.png" width="auto" height="auto"/></p>
<ul>
<li>NVIDIA GPU 에서는 하나의 fetch / decode 로 묶인 ALU 및 context register 들을 <a href="../../../../../gardens/arch/originals/shpc.fall.2024.cse.snu.ac.kr/drafts/09/Streaming-Multiprocessor,-SM-(Arch)" class="internal" data-slug="gardens/arch/originals/shpc.fall.2024.cse.snu.ac.kr/drafts/09/Streaming-Multiprocessor,-SM-(Arch)">Streaming Multiprocessor (SM)</a> 이라고 부른다.</li>
<li>그리고 SM 안에서의 각 ALU 는 NVIDIA GPU 에서는 <a href="../../../../../gardens/arch/originals/shpc.fall.2024.cse.snu.ac.kr/drafts/09/Streaming-Multiprocessor,-SM-(Arch)" class="internal" data-slug="gardens/arch/originals/shpc.fall.2024.cse.snu.ac.kr/drafts/09/Streaming-Multiprocessor,-SM-(Arch)">Scalar Processor (SP)</a> 라고 부른다.
<ul>
<li>즉, 하나의 SIMD lane 인 셈</li>
</ul>
</li>
<li>그리고 이놈들이 실행될때의 실행흐름을 NVIDIA GPU 에서는 <a href="../../../../../gardens/arch/cuda/terms/CUDA-Execution-Model-(NVIDIA-CUDA)" class="internal" data-slug="gardens/arch/cuda/terms/CUDA-Execution-Model-(NVIDIA-CUDA)">Thread</a> 라고 부른다.</li>
<li>하나의 SM 에 “할당” 되는 thread 의 묶음을 NVIDIA GPU 에서는 <a href="../../../../../gardens/arch/cuda/terms/CUDA-Execution-Model-(NVIDIA-CUDA)" class="internal" data-slug="gardens/arch/cuda/terms/CUDA-Execution-Model-(NVIDIA-CUDA)">Thread block</a> 이라고 부른다.</li>
<li>그리고 하나의 GPU device 에 할당되는 thread block 들을 <a href="../../../../../gardens/arch/cuda/terms/CUDA-Execution-Model-(NVIDIA-CUDA)" class="internal" data-slug="gardens/arch/cuda/terms/CUDA-Execution-Model-(NVIDIA-CUDA)">Grid</a> 라고 한다.</li>
</ul>
<p><img src="../../../../../images/Pasted-image-20250428190410.png" width="auto" height="auto"/></p>
<ul>
<li>SM 에 scheduling 되는 단위가 thread block 이고 SM 에서 실제로 한번에 “실행” 되는 단위는 <a href="../../../../../gardens/arch/cuda/terms/CUDA-Execution-Model-(NVIDIA-CUDA)" class="internal" data-slug="gardens/arch/cuda/terms/CUDA-Execution-Model-(NVIDIA-CUDA)">Warp</a> 이다.
<ul>
<li>보통 하나의 warp 는 32개의 thread 로 이루어진다.</li>
</ul>
</li>
</ul>
<h3 id="cuda-memory-model">CUDA Memory Model<a aria-hidden="true" tabindex="-1" href="#cuda-memory-model" class="internal"> §</a></h3>
<p><img src="../../../../../images/Pasted-image-20250428190617.png" width="auto" height="auto"/></p>
<ul>
<li>Mem hierarchy 의 관점으로는
<ul>
<li>SP 별로 <em>Context register</em> (<em>Per-thread private memory</em>) 가 있고</li>
<li>SM 별로는 <em>Local memory</em> (<em>Per-block shared memory</em>) 가 있다.
<ul>
<li>이 local memory 의 사이즈는 GPU 가 다루는 데이터의 사이즈에 비해서는 아주 작고 따라서 GPU 에서는 보통 cache hit ratio 가 아주 낮다고 한다.</li>
</ul>
</li>
<li>그리고 GPU 에는 <em>Device global memory</em> 가 있다.
<ul>
<li>여기에 GDDR 혹은 <a href="../../../../../gardens/arch/memory/drafts/High-Bandwidth-Memory,-HBM-(Arch)" class="internal" data-slug="gardens/arch/memory/drafts/High-Bandwidth-Memory,-HBM-(Arch)">HBM</a> 이 들어간다.</li>
</ul>
</li>
</ul>
</li>
<li>그리고 위 그림에서 볼 수 있다시피 얘네들의 접근 범위가 다르다.
<ul>
<li>Private memory 는 당연히 하나의 thread 에서밖에 접근 못하고</li>
<li>Thread block 안에 있는 thread 들은 Local memory 를 공유하고</li>
<li>Thread block 간의 thread 들에 대해서는 Global memory 를 공유한다.</li>
</ul>
</li>
</ul>
<h3 id="control-divergence-branch">Control Divergence (Branch)<a aria-hidden="true" tabindex="-1" href="#control-divergence-branch" class="internal"> §</a></h3>
<p><img src="../../../../../images/Pasted-image-20250428191517.png" width="auto" height="auto"/></p>
<ul>
<li>GPU 에서의 branch 는 SP 의 일부는 true path 를 따라가고, 나머지 일부는 false path 를 따라간 다음 실제 true 인지 false 인지에 따라 해당 path 의 SP exec result 만 남긴다.
<ul>
<li>이것이 GPU 에서 기본적으로 <em>Control divergence</em> (즉, branch) 를 처리하는 방법이다.</li>
<li>뭐 이때의 idle cycle 을 최소한으로 하기 위한 여러 논문들이 있지만 그래도 idle cycle 을 아예 회피해버릴 수는 없다고 한다.</li>
</ul>
</li>
</ul>
<h3 id="latency-hiding">Latency Hiding<a aria-hidden="true" tabindex="-1" href="#latency-hiding" class="internal"> §</a></h3>
<p><img src="../../../../../images/Pasted-image-20250428191943.png" width="auto" height="auto"/></p>
<ul>
<li>SM 안에서는 한 warp 가 mem access 에 의해 stall 이 되면 위 그림처럼 다른 warp 가 돌며 <a href="../../../../../gardens/arch/originals/shpc.fall.2024.cse.snu.ac.kr/drafts/01/Communication-Computation-Overlapping,-Latency-Hiding-(Arch)" class="internal" data-slug="gardens/arch/originals/shpc.fall.2024.cse.snu.ac.kr/drafts/01/Communication-Computation-Overlapping,-Latency-Hiding-(Arch)">Latency hiding</a> 을 하게 된다.
<ul>
<li>즉, communication-computation overlapping 하는 것</li>
<li>근데 이러한 방식으로 처리하기 위한 하나의 조건이 있다: 바로 thread 의 수가 충분히 많아야 된다.
<ul>
<li>즉, thread 의 수가 충분히 많아야 한 warp 가 stall 이 되었을 때 thread block 에서 다른 warp 를 꺼내다가 실행할 수 있게 되는 것이다.</li>
<li>따라서 GPU programming 을 할 때 가장 기본이 되는 것이 thread 가 최대한 많이 돌아갈 수 있게 하는 것이다.</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="matrix-addition-example-w-cuda">Matrix Addition Example w/ CUDA<a aria-hidden="true" tabindex="-1" href="#matrix-addition-example-w-cuda" class="internal"> §</a></h3>
<p><img src="../../../../../images/Pasted-image-20250428192656.png" width="auto" height="auto"/></p>
<ul>
<li>뭐 Matrix addition 자체는 그냥 같은 index 에 위치한 데이터를 그냥 더하면 되는 것이라 별로 어려울 게 없고</li>
<li>Kernel code 를 실행하는 각 thread 에 대해, 본인의 위치를 알아내는 방법에 대해 간단하게 알아보자.
<ul>
<li><code>threadIdx.{x|y|z}</code> 는 thread block 안에서의 본인 thread 에 대한 index 번호 (x, y, z 축 방향으로) 를 알려주는 변수이다.</li>
<li><code>blockIdx.{x|y|z}</code> 는 grid 안에서의 본인 thread 가 속한 thread block 대한 index 번호 (x, y, z 축 방향으로) 를 알려주는 변수이다.</li>
<li><code>blockDim.{x|y|z}</code> thread block 에 대한 (x, y, z 축 방향으로) 크기를 알려주는 변수이다.</li>
</ul>
</li>
<li>그래서 다음과 같이 해주면 grid 안에서의 본인 thread 에 대한 index 번호 (x, y, z 축 방향으로) 를 알 수 있다.</li>
</ul>
<div data-rehype-pretty-code-fragment><pre style="background-color:var(--shiki-color-background);" tabindex="0" data-language="CUDA" data-theme="default"><code data-language="CUDA" data-theme="default"><span data-line><span style="color:var(--shiki-color-text);">blockDim.{x|y|z} * blockIdx.{x|y|z} + threadIdx.{x|y|z}</span></span></code></pre></div>
<h3 id="mapped-memory">Mapped Memory<a aria-hidden="true" tabindex="-1" href="#mapped-memory" class="internal"> §</a></h3>
<ul>
<li>일반적으로는 GPU memory 에 데이터를 전달해 주기 위해 <code>cudaMalloc</code> 하고 <code>cudaMemcpy</code> 를 쓰는 것이 일반적이다.</li>
</ul>
<p><img src="../../../../../images/Screenshot-2025-04-28-at-8.26.03-PM.png" width="auto" height="auto"/></p>
<ul>
<li>근데 요즘은 <a href="../../../../../gardens/os/memory/terms/Virtual-Address-Space,-VAS-(Memory)" class="internal" data-slug="gardens/os/memory/terms/Virtual-Address-Space,-VAS-(Memory)">Virtual Address Space</a> 에 GPU memory 를 붙여서 code 상에는 그냥 일반적인 변수로 접근을 해도 실행할 때는 자동으로 address translation 을 해서 접근하게 하는 방법 (이런것을 <em>Mapped memory</em> 라고 한다) 이나</li>
<li>CUDA Stream 으로 communicate - compute overlapping 을 하는 방식이 많이 사용된다고 한다.</li>
</ul>
<h3 id="matrix-multiplication-example">Matrix Multiplication Example<a aria-hidden="true" tabindex="-1" href="#matrix-multiplication-example" class="internal"> §</a></h3>
<ul>
<li>은 <a href="../../../../../gardens/arch/cuda/story/choiBLAMS---cuBLAS-from-Scratch" class="internal" data-slug="gardens/arch/cuda/story/choiBLAMS---cuBLAS-from-Scratch">choiBLAMS - cuBLAS from Scratch</a> 를 참고하자. 강의에서는 여기에서 Naive approach 정도까지만 설명하고 넘어간다.</li>
</ul>
<h3 id="thread-block-scheduling">Thread Block Scheduling<a aria-hidden="true" tabindex="-1" href="#thread-block-scheduling" class="internal"> §</a></h3>
<p><img src="../../../../../images/Screenshot-2025-04-28-at-8.42.01-PM.png" width="auto" height="auto"/></p>
<ul>
<li>Code 를 짤 때는, 내가 갖고 있는 GPU 에 몇개의 SM 이 있는지 등을 알 수 없다.
<ul>
<li>물론 검색해보면 알 수는 있다. 근데 이런것을 신경쓰지 않게 하는 것이 abstract 자나?</li>
</ul>
</li>
<li>그래서 code 에다가는 <a href="../../../../../gardens/arch/cuda/terms/CUDA-Execution-Model-(NVIDIA-CUDA)" class="internal" data-slug="gardens/arch/cuda/terms/CUDA-Execution-Model-(NVIDIA-CUDA)">Grid</a> 의 크기와 <a href="../../../../../gardens/arch/cuda/terms/CUDA-Execution-Model-(NVIDIA-CUDA)" class="internal" data-slug="gardens/arch/cuda/terms/CUDA-Execution-Model-(NVIDIA-CUDA)">Thread block</a> 의 크기만 알려주면, 그것을 이용해 grid 를 여러개의 thread block 으로 자르고, 각각의 SM 에 할당하는 것은 GPU 내의 <em>Thread block scheduler</em> 가 담당한다.</li>
</ul>
<h3 id="1d-convolution-example">1D Convolution Example<a aria-hidden="true" tabindex="-1" href="#1d-convolution-example" class="internal"> §</a></h3>
<p><img src="../../../../../images/Screenshot-2025-04-28-at-8.57.54-PM.png" width="auto" height="auto"/></p>
<ul>
<li>1D convolution 은 <code>input[i]</code> 부터 W (Window size) 개의 input 들을 aggregate 하여 <code>output[i]</code> 을 계산하는 방법이다.
<ul>
<li>위의 예시는 window size 3 으로 하여 average 를 하는 1D convolution 이다.</li>
</ul>
</li>
<li>이것을 위한 naive version kernel 은 다음과 같다:</li>
</ul>
<p><img src="../../../../../images/Screenshot-2025-04-28-at-9.01.56-PM.png" width="auto" height="auto"/></p>
<ul>
<li>보면 일단 간단하기는 한데, 이 코드는 당연히 느리다.
<ul>
<li>왜냐면 각 thread 가 global memory 인 <code>input[]</code> 에 세번 접근하기 때문.</li>
</ul>
</li>
<li>근데 <code>i</code> 번째 thread 가 <code>output[i]</code> 를 계산하기 위해 <code>input[i]</code>, <code>input[i+1]</code>, <code>input[i+2]</code> 에 접근하고
<ul>
<li><code>i+1</code> 번째 thread 는 <code>output[i+1]</code> 를 계산하기 위해 <code>input[i+1]</code>, <code>input[i+2]</code>, <code>input[i+3]</code> 에 접근한다는 것을 생각해 보면</li>
<li>Thread 들이 동일한 데이터에 접근하는데 매번 global memory 에 접근하고 있다는 것을 알 수 있다.</li>
</ul>
</li>
<li>따라서 이것을 방지하기 위해 thread block 이 사용할 데이터를 shared memory 에 일단 다 올려놓고, 여기에 반복적으로 접근하면 훨씬 더 빠르겠다는 생각을 한다.</li>
</ul>
<p><img src="../../../../../images/Screenshot-2025-04-28-at-9.02.24-PM.png" width="auto" height="auto"/></p>
<ul>
<li>그래서 위의 코드에서는 <code>__shared__</code> 로 정의된 변수에
<ul>
<li>우선 input array element 를 하나씩 load 하고</li>
<li><code>__syncthreads()</code> 로 모든 thread 들이 다 load 할 때까지 기다린 다음에</li>
<li>마지막에 naive code 에서처럼 연산해 주게 된다.</li>
</ul>
</li>
<li>이렇게 되면 <code>3 * NUM_THREADS</code> 만큼 global memory 에 접근해야 했던 것이, <code>NUM_THREADS</code> 만큼 접근하게 되면서 훨씬 빨라지게 된다.</li>
</ul></article></div><div class="right sidebar"><div class="graph "><h3>Graph View</h3><div class="graph-outer"><div id="graph-container" data-cfg="{&quot;drag&quot;:true,&quot;zoom&quot;:true,&quot;depth&quot;:1,&quot;scale&quot;:1.1,&quot;repelForce&quot;:0.5,&quot;centerForce&quot;:0.3,&quot;linkDistance&quot;:30,&quot;fontSize&quot;:0.6,&quot;opacityScale&quot;:1,&quot;showTags&quot;:true,&quot;removeTags&quot;:[]}"></div><svg version="1.1" id="global-graph-icon" xmlns="http://www.w3.org/2000/svg" xmlnsXlink="http://www.w3.org/1999/xlink" x="0px" y="0px" viewBox="0 0 55 55" fill="currentColor" xmlSpace="preserve"><path d="M49,0c-3.309,0-6,2.691-6,6c0,1.035,0.263,2.009,0.726,2.86l-9.829,9.829C32.542,17.634,30.846,17,29,17
	s-3.542,0.634-4.898,1.688l-7.669-7.669C16.785,10.424,17,9.74,17,9c0-2.206-1.794-4-4-4S9,6.794,9,9s1.794,4,4,4
	c0.74,0,1.424-0.215,2.019-0.567l7.669,7.669C21.634,21.458,21,23.154,21,25s0.634,3.542,1.688,4.897L10.024,42.562
	C8.958,41.595,7.549,41,6,41c-3.309,0-6,2.691-6,6s2.691,6,6,6s6-2.691,6-6c0-1.035-0.263-2.009-0.726-2.86l12.829-12.829
	c1.106,0.86,2.44,1.436,3.898,1.619v10.16c-2.833,0.478-5,2.942-5,5.91c0,3.309,2.691,6,6,6s6-2.691,6-6c0-2.967-2.167-5.431-5-5.91
	v-10.16c1.458-0.183,2.792-0.759,3.898-1.619l7.669,7.669C41.215,39.576,41,40.26,41,41c0,2.206,1.794,4,4,4s4-1.794,4-4
	s-1.794-4-4-4c-0.74,0-1.424,0.215-2.019,0.567l-7.669-7.669C36.366,28.542,37,26.846,37,25s-0.634-3.542-1.688-4.897l9.665-9.665
	C46.042,11.405,47.451,12,49,12c3.309,0,6-2.691,6-6S52.309,0,49,0z M11,9c0-1.103,0.897-2,2-2s2,0.897,2,2s-0.897,2-2,2
	S11,10.103,11,9z M6,51c-2.206,0-4-1.794-4-4s1.794-4,4-4s4,1.794,4,4S8.206,51,6,51z M33,49c0,2.206-1.794,4-4,4s-4-1.794-4-4
	s1.794-4,4-4S33,46.794,33,49z M29,31c-3.309,0-6-2.691-6-6s2.691-6,6-6s6,2.691,6,6S32.309,31,29,31z M47,41c0,1.103-0.897,2-2,2
	s-2-0.897-2-2s0.897-2,2-2S47,39.897,47,41z M49,10c-2.206,0-4-1.794-4-4s1.794-4,4-4s4,1.794,4,4S51.206,10,49,10z"></path></svg></div><div id="global-graph-outer"><div id="global-graph-container" data-cfg="{&quot;drag&quot;:true,&quot;zoom&quot;:true,&quot;depth&quot;:-1,&quot;scale&quot;:0.9,&quot;repelForce&quot;:0.5,&quot;centerForce&quot;:0.3,&quot;linkDistance&quot;:30,&quot;fontSize&quot;:0.6,&quot;opacityScale&quot;:1,&quot;showTags&quot;:true,&quot;removeTags&quot;:[]}"></div></div></div><div class="toc desktop-only"><button type="button" id="toc"><h3>Table of Contents</h3><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="fold"><polyline points="6 9 12 15 18 9"></polyline></svg></button><div id="toc-content"><ul class="overflow"><li class="depth-0"><a href="#simd" data-for="simd">SIMD</a></li><li class="depth-1"><a href="#vector-simd" data-for="vector-simd">Vector, SIMD</a></li><li class="depth-1"><a href="#vector-pipelining" data-for="vector-pipelining">Vector Pipelining</a></li><li class="depth-1"><a href="#matrix-multiplication-example-w-simd" data-for="matrix-multiplication-example-w-simd">Matrix Multiplication Example w/ SIMD</a></li><li class="depth-0"><a href="#gpu" data-for="gpu">GPU</a></li><li class="depth-1"><a href="#cuda-execution-model" data-for="cuda-execution-model">CUDA Execution Model</a></li><li class="depth-1"><a href="#cuda-memory-model" data-for="cuda-memory-model">CUDA Memory Model</a></li><li class="depth-1"><a href="#control-divergence-branch" data-for="control-divergence-branch">Control Divergence (Branch)</a></li><li class="depth-1"><a href="#latency-hiding" data-for="latency-hiding">Latency Hiding</a></li><li class="depth-1"><a href="#matrix-addition-example-w-cuda" data-for="matrix-addition-example-w-cuda">Matrix Addition Example w/ CUDA</a></li><li class="depth-1"><a href="#mapped-memory" data-for="mapped-memory">Mapped Memory</a></li><li class="depth-1"><a href="#matrix-multiplication-example" data-for="matrix-multiplication-example">Matrix Multiplication Example</a></li><li class="depth-1"><a href="#thread-block-scheduling" data-for="thread-block-scheduling">Thread Block Scheduling</a></li><li class="depth-1"><a href="#1d-convolution-example" data-for="1d-convolution-example">1D Convolution Example</a></li></ul></div></div><div class="backlinks "><h3>Backlinks</h3><ul class="overflow"><li><a href="../../../../../gardens/arch/originals/aca.spring.2025.cse.snu.ac.kr/(SNU-CSE)-Advanced-Computer-Architectures" class="internal">(SNU CSE) Advanced Computer Architectures</a></li><li><a href="../../../../../gardens/arch/originals/aca.spring.2025.cse.snu.ac.kr/lectures/06.-GPU-Architecture" class="internal">06. GPU Architecture (Advanced Computer Architectures, SNU CSE)</a></li></ul></div></div></div><footer class><hr/><p>Created with <a href="https://quartz.jzhao.xyz/">Quartz v4.1.0</a>, © 2025</p><ul><li><a href="https://github.com/haeramkeem">GitHub</a></li><li><a href="https://www.linkedin.com/in/haeram-kim-277404220">LinkedIn</a></li><li><a href="mailto:haeram.kim1@gmail.com">Email</a></li></ul></footer></div></body><script type="application/javascript">// quartz/components/scripts/quartz/components/scripts/callout.inline.ts
function toggleCallout() {
  const outerBlock = this.parentElement;
  outerBlock.classList.toggle(`is-collapsed`);
  const collapsed = outerBlock.classList.contains(`is-collapsed`);
  const height = collapsed ? this.scrollHeight : outerBlock.scrollHeight;
  outerBlock.style.maxHeight = height + `px`;
  let current = outerBlock;
  let parent = outerBlock.parentElement;
  while (parent) {
    if (!parent.classList.contains(`callout`)) {
      return;
    }
    const collapsed2 = parent.classList.contains(`is-collapsed`);
    const height2 = collapsed2 ? parent.scrollHeight : parent.scrollHeight + current.scrollHeight;
    parent.style.maxHeight = height2 + `px`;
    current = parent;
    parent = parent.parentElement;
  }
}
function setupCallout() {
  const collapsible = document.getElementsByClassName(
    `callout is-collapsible`
  );
  for (const div of collapsible) {
    const title = div.firstElementChild;
    if (title) {
      title.removeEventListener(`click`, toggleCallout);
      title.addEventListener(`click`, toggleCallout);
      const collapsed = div.classList.contains(`is-collapsed`);
      const height = collapsed ? title.scrollHeight : div.scrollHeight;
      div.style.maxHeight = height + `px`;
    }
  }
}
document.addEventListener(`nav`, setupCallout);
window.addEventListener(`resize`, setupCallout);
</script><script type="module">
          import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.esm.min.mjs';
          const darkMode = document.documentElement.getAttribute('saved-theme') === 'dark'
          mermaid.initialize({
            startOnLoad: false,
            securityLevel: 'loose',
            theme: darkMode ? 'dark' : 'default'
          });
          document.addEventListener('nav', async () => {
            await mermaid.run({
              querySelector: '.mermaid'
            })
          });
          </script><script src="https://cdn.jsdelivr.net/npm/katex@0.16.7/dist/contrib/copy-tex.min.js" type="application/javascript"></script><script src="https://www.googletagmanager.com/gtag/js?id=G-N68CCP1QHG" type="application/javascript"></script><script src="../../../../../postscript.js" type="module"></script></html>